<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 266]
- [cs.CL](#cs.CL) [Total: 184]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 101]
- [cs.IR](#cs.IR) [Total: 20]
- [cs.LG](#cs.LG) [Total: 185]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 本文研究了领域特定的自监督预训练对农业病害分类的影响，发现仅用3000张未标注农业图像进行SimCLR预训练即可显著提升模型准确率，且该增益与模型架构无关，强调数据收集比架构选择更重要；提出的HierarchicalViT在多个数据集上优于Swin-Base，并具备良好校准性能。


<details>
  <summary>Details</summary>
Motivation: 农业病害分类任务中，标注数据稀缺，而通用视觉模型在领域适配上表现有限，因此探索更高效、低成本的领域适配方法（如领域自监督预训练）具有重要实践意义。

Method: 采用SimCLR自监督学习方法，在仅3000张未标注农业图像上对多种视觉Transformer（包括Swin-Base、ViT-Base和自研HierarchicalViT）进行预训练，并在多个农业病害数据集上进行微调与评估；同时开展校准分析（ECE）以评估部署可靠性。

Result: SimCLR预训练带来最高+4.57%准确率提升，超过架构改进带来的+3.70%；HierarchicalViT-Base（78M参数）在匹配参数量下优于Swin-Base（88M参数），达+1.68%；模型经温度缩放后ECE低至1.52%。

Conclusion: 领域自监督预训练是提升农业病害分类性能更有效且架构无关的策略，应优先于复杂架构设计；HierarchicalViT兼具精度与校准优势，适合实际部署。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [2] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D TransUNet的图像合成框架，能从常规T1w MRI预测扩散MRI（dMRI）指标FA和MD图，在不增加扫描时间的前提下，提升阿尔茨海默病（AD）和轻度认知障碍（MCI）的分类准确率。


<details>
  <summary>Details</summary>
Motivation: AD早期微结构异常难以通过常规T1w MRI检测，而dMRI虽敏感但耗时且易受运动伪影影响，临床应用受限；亟需一种从T1w MRI可靠推断dMRI信息的方法。

Method: 提出3D TransUNet图像合成模型，以T1w MRI为输入，端到端生成FA和MD图；随后将合成图融入多模态诊断模型进行AD/MCI分类。

Result: 合成FA/MD图与真实dMRI高度一致（SSIM > 0.93，Pearson相关性 > 0.94）；用于AD分类准确率提升5%（78.75%→83.75%），MCI检测提升12.5%。

Conclusion: T1w MRI可有效编码dMRI微结构信息，所提合成方法能在无实际dMRI数据条件下实现高精度AD早期诊断，提升临床可行性与诊断效能。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [3] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++ 是一种新型RGB-D SLAM系统，采用分层约束的神经高斯表示、渐进式位姿优化和动态神经表示图，在深度噪声下实现高精度实时3D重建与逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM方法在深度噪声下难以保持结构一致性和鲁棒位姿估计，限制了其在机器人和AR中的应用。

Method: 提出PointSLAM++：1）分层约束的神经高斯表示以维持结构关系；2）渐进式位姿优化抑制深度噪声；3）基于局部几何复杂度自适应调整高斯节点分布的动态神经表示图。

Result: 在重建精度和渲染质量上优于现有3DGS-based SLAM方法，支持大规模AR和机器人应用。

Conclusion: PointSLAM++通过多机制协同，在实时性、精度与鲁棒性之间取得更好平衡，推动神经SLAM向实用化迈进。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [4] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 本文提出了一种基于单类自编码器的计算框架，用于历史素描真伪验证，利用少量手绘特征（如傅里叶能量、熵、对比度等）在小样本文化遗存数据上实现可解释、可复现的认证支持。


<details>
  <summary>Details</summary>
Motivation: 文化遗存中纸质作品的真伪鉴定与作者归属长期面临参考样本少、风格线索弱（主要依赖线条和有限灰度）的挑战。

Method: 构建十位艺术家专属的单类自编码器验证器，输入为五维可解释手工特征（傅里叶域能量、香农熵、全局对比度、GLCM同质性、盒计数分形复杂度），训练数据来自六大博物馆开放馆藏的已认证素描；采用生物识别式协议评估（90次真实样本+810次冒充样本）。

Result: 整体系统在选定操作点下达到83.3%真实接受率（TAR）与9.5%错误接受率（FAR）；不同艺术家性能差异显著，部分接近零FAR，部分混淆率高；错误接受分析揭示了风格相近性与共用绘图惯例导致的结构化误判路径。

Conclusion: 该方法旨在辅助而非替代专家鉴定，为历史素描这类数据稀缺场景提供可复现、定量化的证据支持，并强调需进一步控制数字化伪影与优化阈值校准。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [5] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

TL;DR: 本文提出了一种从普通非直视（NLOS）照片中进行3D场景重建的新方法，通过重构光传输模型，将隐藏场景分解为遮光与非遮光部分，形成可分离的非线性最小二乘反问题，并提出了基于梯度优化和物理启发的神经网络（Soft Shadow diffusion, SSD）两种求解方案。


<details>
  <summary>Details</summary>
Motivation: 传统成像依赖视线，但在许多场景下不可行；非直视（NLOS）成像可解决该问题，但现有被动NLOS方法仅限于1D、低分辨率2D或已知形状的目标定位，亟需拓展至通用3D重建。

Method: 提出一种新的光传输模型重表述，将隐藏场景分解为‘遮光’与‘非遮光’成分，构建可分离非线性最小二乘（SNLLS）反问题；设计两种求解方法：梯度优化法与物理启发的神经网络Soft Shadow diffusion（SSD）。

Result: 在真实实验中成功实现多种3D隐藏场景的重建；SSD虽在仿真中训练，却能泛化至仿真中未见类别及真实NLOS场景，并对噪声和环境光照表现出强鲁棒性。

Conclusion: 该工作显著拓展了被动NLOS成像能力，首次实现了从单张普通照片出发的通用3D重建，为无视线成像开辟了新路径。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [6] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 本文提出SLT（Single-Layer Transformer），通过知识蒸馏将28层FreeFlow模型压缩为单层共享DiT模块，在大幅减少参数（675M→4.3M）的同时，利用其高速采样能力筛选更优初始噪声点，从而提升FreeFlow单步生成的图像质量与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有单步流匹配方法（如FreeFlow）虽高效但参数量大、对初始噪声敏感，导致生成质量不稳定；需在保持单步生成优势前提下提升鲁棒性与效率。

Method: 将FreeFlow的28层Transformer视为沿深度轴的ODE欧拉离散化，据此设计单层共享DiT块（SLT）；训练时在多个深度patch上匹配教师模型的中间特征并融合，同时对齐最终速度预测，实现知识蒸馏。

Result: SLT将FreeFlow（DiT-XL/2）参数从675M压缩至4.3M；在同等时间预算下完成超100次噪声筛选，显著提升FreeFlow生成图像质量与稳定性，避免因初始噪声差导致的质量波动。

Conclusion: SLT验证了极简架构在流匹配单步生成中的有效性，通过蒸馏+噪声筛选协同策略，兼顾模型轻量化与生成高性能，为高效稳定的一致性生成提供了新思路。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [7] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角RGB图像和视觉语言模型（VLM）引导的高保真动物毛发三维重建方法，采用基于毛丝（strand）的表示，结合几何与光度损失，并利用VLM辅助解决方向歧义性问题。


<details>
  <summary>Details</summary>
Motivation: 动物毛发重建面临细粒度细节、自遮挡和视角依赖外观等挑战，且缺乏可用于学习不同动物毛发先验的数据集。

Method: 首先用传统多视图立体技术重建粗略表面几何；再利用视觉语言模型（VLM）检索各身体部位毛发长度结构信息，构建无毛几何并在其上生长毛丝；通过多视角图像计算几何与光度损失进行监督；同时用VLM指导毛丝生长方向，并引入重力向量作为方向约束损失。

Result: 该方法在多种具有不同毛发类型的动物上展现出良好泛化能力，实现了高保真3D毛发建模。

Conclusion: 将视觉语言模型引入多视角三维重建流程，可有效引导毛发几何与方向建模，为无专用数据集下的动物毛发重建提供了新范式。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [8] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: 本文提出CCPO框架，通过坐标感知空间压缩（CASC）和基于距离的优势函数，在多轮GUI代理中实现高效视觉压缩与策略优化，显著减少token使用并加速训练。


<details>
  <summary>Details</summary>
Motivation: 多轮GUI代理因交互历史累积导致上下文膨胀严重，现有方法在保留长程上下文或维持空间结构方面存在权衡缺陷。

Method: 提出Coordinate Compression Policy Optimization（CCPO），包含Coordinate-Aware Spatial Compression（CASC）用于聚合多轮坐标、动态构建注意力边界，以及Distance-Based Advantage提供细粒度学习信号。

Result: 在四个基准上达到SOTA性能，最高实现55% token压缩和3.8×训练加速。

Conclusion: CCPO有效缓解了多轮GUI代理中的上下文膨胀问题，在保持任务性能的同时大幅提升效率和视觉定位精度。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [9] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 本文提出了一种融合数据驱动语义先验与传统基于手柄网格变形方法精度和速度优势的新技术，通过深度特征邻近性生成平滑、语义一致的变形权重，支持实时计算、语义部件协同变形、对称性保持，并借助改进的重心特征蒸馏实现高效高分辨率处理。


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的变形方法虽精确快速，但手柄布置需先验知识、映射关系不直观且缺乏语义；而现代数据驱动方法虽具语义性，却速度慢、精度低。本文旨在弥合二者鸿沟。

Method: 利用深度特征邻近性直接生成变形权重，无需额外正则化；引入重心特征蒸馏（barycentric feature distillation）提升特征蒸馏效率；通过特征空间约束与局部性加权保留经典方法特性；采用场表示自动检测并保持语义对称性。

Result: 实现了任意表面点的实时权重计算；支持百万面网格在消费级设备上的实时变形；显著加速高分辨率网格处理（<1分钟 vs 数小时）；实现语义部件协同变形与对称性保持。

Conclusion: 该方法成功融合了经典方法的可控性、速度与数据驱动方法的语义性，为交互式语义网格编辑提供了高效、鲁棒且可扩展的新范式。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [10] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: 本文提出KG-ViP框架，通过融合场景图与常识图来增强多模态大语言模型在视觉问答任务中的知识可靠性和细粒度感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在视觉问答中存在知识幻觉和细粒度视觉感知不足两大问题；而场景图和常识图恰好分别能弥补这两方面缺陷，但以往工作未有效结合二者。

Method: 提出KG-ViP统一框架，核心是基于查询语义桥接的检索-融合流程，渐进式整合场景图与常识图，生成统一结构化上下文以支持多模态推理。

Result: 在FVQA 2.0+和MVQA基准上，KG-ViP显著优于现有VQA方法。

Conclusion: 融合场景图与常识图可有效缓解MLLMs在VQA中的知识幻觉与感知不足问题，验证了二者协同增效的可行性与优越性。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [11] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 本文提出了一种面向车辆底盘检测的端到端3D建模 pipeline，利用三相机阵列采集视频，结合改进的结构光重建（rig-aware SfM）与高斯泼溅（Gaussian splatting），生成可交互、实时渲染的高保真底盘3D模型，显著提升检测效率、安全性和买家信任度。


<details>
  <summary>Details</summary>
Motivation: 车辆底盘检查劳动强度大、安全性低，且线上买家缺乏底盘图像；传统SfM方法在宽角镜头畸变和低视差场景下效果差。

Method: 提出rig-aware SfM流程：集成精确相机标定、视频同步、刚性相机阵列几何先验；采用DISK特征提取器与LightGlue匹配器，结合约束匹配策略生成高质量稀疏点云；以此初始化高斯泼溅，生成实时可渲染的3D模型。

Result: 实现了高保真、交互式、实时渲染的车辆底盘3D模型，在锈蚀、泄漏、撞击损伤检测中达到秒级响应；消融实验验证各模块对SOTA性能的关键作用。

Conclusion: 该方法有效克服了宽角畸变与低视差挑战，为工业级移动平台下的快速三维视觉检测提供了新范式，兼具实用性与技术先进性。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [12] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: 本文提出ViEBench，一个可验证推理过程的视觉语言模型基准，通过细粒度视觉证据标注和双轴评估矩阵，揭示VLMs在多步视觉推理中存在答案正确但依据错误、或依据正确但推理失败等问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注结果准确性，无法评估模型是否真正利用细粒度视觉线索进行多步推理，缺乏对推理过程真实性的检验能力。

Method: 构建包含200张高分辨率图像和专家标注视觉证据的ViEBench基准，按感知与推理难度分类任务，并设计双轴诊断矩阵（四个象限）提供细粒度评估指标。

Result: 实验发现：(1) VLMs可能给出正确答案却基于无关图像区域；(2) 可能准确定位证据但仍推理失败；ViEBench能更透明、可解释地评估VLMs的视觉推理忠实性。

Conclusion: ViEBench为评估VLMs的忠实视觉推理能力提供了更可解释、更实用的基准，推动对模型推理过程而非仅结果的关注。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [13] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型（LLM）代理的自动问题发现方法，用于快速识别短视频平台上的新兴内容问题，并自动生成更新的标注策略，显著提升了问题发现效率与内容治理效果。


<details>
  <summary>Details</summary>
Motivation: 短视频平台内容趋势变化快，新问题频发，而传统人工驱动的问题发现方式速度慢，导致标注策略更新滞后，影响内容治理效果。

Method: 提出基于多模态LLM代理的自动问题发现方法：先召回含潜在新问题的短视频，再通过两阶段聚类将视频分组（每组对应一个新问题），最后由代理生成更新的标注策略。

Result: 该方法在离线和在线实验中F1分数提升超20%，问题视频播放量降低约15%，大幅缩短人工耗时，加速标注策略迭代。

Conclusion: 多模态LLM代理可高效、自动地发现新兴内容问题并更新治理策略，是提升短视频平台内容治理时效性与有效性的可行路径。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [14] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 本文提出了一种名为Anon-NET的统一框架，用于面部视频匿名化，在保护隐私的同时保留年龄、性别、种族、姿态和表情等关键属性。该方法结合扩散模型进行面部修复，并通过视频驱动的动画技术实现去标识化面部的自然动态重建。


<details>
  <summary>Details</summary>
Motivation: 解决面部视频匿名化中隐私保护与下游视觉任务（如表情识别、人物跟踪、动作识别）所需语义信息保留之间的矛盾。

Method: 采用基于扩散的生成模型进行面部修复，以高层属性识别和运动感知的表情迁移为引导；再通过视频驱动的动画技术，将原始视频的动态信息迁移到去标识化面部上。

Result: 在VoxCeleb2、CelebV-HQ和HDTF数据集上的实验表明，Anon-NET能有效隐藏身份信息，同时保持视觉真实感和时间一致性。

Conclusion: Anon-NET提供了一个兼顾隐私保护与任务可用性的新范式，代码将开源。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [15] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

TL;DR: 本文提出了一种诊断性微观基准，用于评估视觉-语言代理（VLAs）在迭代自我纠正中的能力，并揭示了其在语义漂移等关键推理瓶颈上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准虽开始评估VLAs的迭代自我纠正能力，但其定量极限和主要推理瓶颈尚不明确。

Method: 构建诊断性微观基准，解耦任务成功率（TSR）与纠正成功率（CSR），量化纠正的边际收益，并建立失败分类体系。

Result: 发现TSR为62%，CSR仅25%-33%；纠正效果在三次重试后趋于饱和；约28%的失败源于语义漂移。

Conclusion: 初始任务能力不能预测修复能力；语义漂移是关键瓶颈；该基准为构建有状态、可信赖的多模态代理提供了可复现框架。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [16] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动的农业杂草检测优化框架Model-Driven Data Correction（MDDC），通过自动错误分析和迭代式数据修正，在不增加模型复杂度的前提下显著提升轻量级检测器（YOLOv8n）在边缘设备上的性能。


<details>
  <summary>Details</summary>
Motivation: 农业杂草检测在边缘设备上受限于模型容量、计算资源和实时推理延迟，难以通过模型扩展或集成来提升性能，亟需一种不依赖模型增大的性能优化方法。

Method: 提出Model-Driven Data Correction（MDDC）框架，包含自动化错误分析（将检测失败分为四类：假阴性、假阳性、类别混淆、定位误差）和结构化训-修-再训流程，并采用版本控制的数据管理机制。

Result: 在多个杂草检测数据集上，使用固定轻量级检测器YOLOv8n，mAP@0.5提升5–25%。

Conclusion: 在模型容量受限条件下，系统性地优化数据质量可有效缓解性能瓶颈，验证了数据中心范式在边缘智能视觉任务中的有效性。

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [17] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: 本文提出MOD-DiT，一种无需采样的动态稀疏注意力机制，用于提升DiT在视频生成中的效率与质量。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在静态模式过于简化或动态采样计算开销大、预测不准的问题，限制了DiT在长序列视频生成中的实际部署。

Method: 提出两阶段动态注意力框架MOD-DiT：第一阶段利用早期去噪先验，通过分布式混合建模线性近似以预测特定去噪区间的掩码模式；第二阶段采用在线块掩码策略，复用历史稀疏信息，避免重复采样。

Result: 在多个基准和模型架构上验证了MOD-DiT能持续提升推理速度与生成质量。

Conclusion: MOD-DiT有效克服了传统稀疏注意力的计算瓶颈，在保持高生成质量的同时显著提升视频生成效率。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [18] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 本文提出了一种基于物理的合成X光扫描模拟框架（PSSF），用于生成可控、隐私安全的膝关节X光图像，以支持骨关节炎（OA）的AI与放射组学评估，并在不同协议下验证了ML模型的鲁棒性与特征稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决膝骨关节炎（OA）评估中依赖主观Kellgren-Lawrence（KL）分级、缺乏大规模高质量标注X光数据的问题，尤其受限于隐私、治理和资源约束。

Method: 构建基于物理的2D X光投影模拟器（PSSF），从股骨远端与胫骨近端参数化解剖模型生成前-后位膝关节X光图像；生成含180名受试者（260膝）、三种成像协议（参考/低剂量/几何偏移）的虚拟队列；对内侧关节区自动定位、预处理并按IBSI标准提取放射组学特征；训练逻辑回归、随机森林、梯度提升三种ML模型进行二分类（KL 0 vs. 2）与三分类（0–2）预测；评估模型在IBSI协议内、跨协议及多协议下的鲁棒性，并用组内相关系数（ICC）评估特征稳定性。

Result: 成功构建PSSF并生成高质量虚拟X光数据集；ML模型在协议内表现良好，在跨协议和多协议场景下仍保持一定鲁棒性；关键放射组学特征表现出较高ICC值，说明其对采集参数变化具有稳定性。

Conclusion: PSSF为OA定量评估提供了无需真实患者数据、符合伦理与隐私要求的可行替代方案，所生成数据支持稳健、可重复的放射组学建模，有望推动AI在骨关节炎影像分析中的临床转化。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [19] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉的置信度估计框架，通过独立的几何验证（利用目标检测）来评估视觉-语言模型（VLM）在空间关系判断上的预测可信度，显著提升了对VLM空间推理结果的信任决策能力。


<details>
  <summary>Details</summary>
Motivation: VLM在空间推理任务上存在系统性失败（准确率仅49%-54%），而其在机器人和自动驾驶等安全关键场景中的部署亟需判断何时信任其输出。

Method: 提出一种融合四类视觉信号（几何对齐度、空间模糊性、检测质量、VLM内部不确定性）的梯度提升置信度估计框架，不依赖文本自评，而是通过目标检测结果进行外部几何验证。

Result: 在BLIP-2上AUROC达0.674（相对提升34.0%），CLIP上达0.583（相对提升16.1%）；选择性预测在60%目标精度下覆盖率达61.9%（基线仅27.6%）；置信度驱动的场景图构建使精度从52.1%提升至78.3%，保留68.2%边。

Conclusion: 基于视觉的外部几何验证比VLM自身置信度更可靠（贡献87.4%特征重要性），该框架可有效提升VLM空间推理结果的可信判别与下游应用鲁棒性。

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [20] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 本文提出了一种名为IMSAHLO的新型深度学习框架，用于荧光显微镜下神经元细胞的鲁棒分割，通过多尺度密集块、分层注意力机制及混合损失函数（Tversky+Focal+clDice+轮廓加权边界损失）提升在密度不均、形态重叠和类别不平衡场景下的分割精度与拓扑连续性。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜下神经元细胞分割面临细胞密度差异大、形态重叠复杂、类别严重不平衡等挑战，传统深度学习模型难以保持精细拓扑结构和准确边界划分。

Method: 提出IMSAHLO框架：1）多尺度密集块（MSDBs）捕获不同感受野特征以适应密度变化；2）分层注意力（HA）机制聚焦关键形态特征并保留ROI边界细节；3）混合损失函数融合Tversky损失、Focal损失、拓扑感知的Centerline Dice（clDice）损失及轮廓加权边界损失，兼顾类别平衡与拓扑连续性。

Result: 在公开FNC数据集上，对困难的密集与稀疏样本分别达到81.4%精确率、82.7%宏F1、83.3%微F1和99.5%平衡准确率；消融实验验证了多尺度注意力与混合损失的协同增益。

Conclusion: IMSAHLO显著提升了神经元细胞分割的鲁棒性与泛化能力，为多种生物医学影像模态提供可迁移的分割基础，推动AI辅助高通量神经生物学分析。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [21] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 本文揭示了文本到图像生成AI中存在的‘算法外貌主义’现象，即系统性地基于面部吸引力给予偏好性对待，并进一步导致下游性别分类任务中的偏见与不公。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI（特别是文本到图像模型）是否继承并放大社会对外貌的刻板印象，并影响下游视觉识别任务（如性别分类）的公平性。

Method: 通过使用Stable Diffusion 2.1和3.5 Medium生成26,400张合成人脸，结合三类性别分类算法，系统分析面部吸引力、性别、年龄、地域等属性与模型输出之间的关联性及偏差模式。

Result: 发现T2I模型系统性地将吸引力与正面属性绑定；女性面孔（尤其被标注为负面属性者）在性别分类中误判率显著高于男性；新版本模型加剧了审美约束，表现为年龄同质化、性别化曝光差异与地域简化。

Conclusion: 算法外貌主义已成为AI视觉系统的结构性问题，同时在表征（生成）与识别（分类）层面加剧社会不平等。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [22] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 本文提出了一种基于图的交互式图像分割新方法，核心是像素-区域相似性指数（PSSI），结合MeanShift预分割与最大生成树（MaxST）划分，提升了鲁棒性、效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算开销大、对用户输入敏感、在前景/背景颜色相近时性能下降等问题，关键瓶颈在于图边权重的相似性度量设计。

Method: 提出像素段相似性指数（PSSI），利用强度与空间平滑特征的通道间相似性的调和平均；先用MeanShift进行低层分割得到像素段；构建以PSSI为边权的像素-段图；采用最大生成树（MaxST）进行图划分。

Result: 在GrabCut和Images250数据集上，该方法在IoU、F1分数、执行时间和平均误差等指标上均优于AMOE、OneCut和SSNCut等主流方法。

Conclusion: PSSI-MaxST框架能联合建模颜色相似性、空间平滑性、纹理、形状及强局部连通性，显著提升交互式分割的鲁棒性、精度与效率。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [23] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

TL;DR: 本文提出Masked Binary U-Net（MBU-Net），通过引入零掩码策略与面向GPU Tensor Core的减法比特编码执行框架，在保持接近全精度分割精度的同时，显著提升速度与能效，适用于边缘设备实时图像分割。


<details>
  <summary>Details</summary>
Motivation: 为满足AR/VR、机器人等边缘场景对高精度、低延迟、低功耗图像分割的需求，需克服传统二值网络精度严重下降及缺乏通用GPU端到端高效实现的问题。

Method: 基于两项实证观察（显式零状态必要性、各层量化敏感度均匀），设计代价感知的掩码策略构建MBU-Net；并开发适配GPU Tensor Core的减法比特编码执行框架，支持掩码二值权重与二值激活的高效计算。

Result: 在3个分割基准上，MBU-Net相较16位浮点U-Net平均精度仅下降3%，但获得2.04倍加速和3.54倍能耗降低。

Conclusion: MBU-Net在精度、速度与能效间取得更好平衡，验证了结合结构化稀疏与硬件协同设计的二值化方法在边缘实时分割中的可行性与实用性。

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [24] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

TL;DR: 本文提出了一种专为热成像设计的轻量级目标检测模型LTV-YOLO，用于在低光和恶劣天气下高效、实时地检测儿童等弱势道路使用者（VRUs），适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在低光和恶劣天气下难以可靠检测儿童等弱势道路使用者（VRUs），亟需更鲁棒的检测方案。

Method: 基于YOLO11架构，结合深度可分离卷积与特征金字塔网络（FPN），构建专用于长波红外（LWIR）热成像的轻量级模型LTV-YOLO，并针对小尺度、部分遮挡及热特征显著的VRUs进行优化。

Result: LTV-YOLO在热成像条件下实现了对小尺度、部分遮挡VRUs的高精度、实时检测，具备边缘部署能力，显著提升学校区域、自动驾驶与智慧城市中的行人安全。

Conclusion: LTV-YOLO是一种任务专用、热成像唯一输入、边缘可部署的创新方案，其针对儿童及远距离/遮挡成人VRUs的热检测优化，在同类工作中具有新颖性与实用性。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [25] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: This paper reviews UAV-based methodologies for infrastructure inspection in the AEC+FM domain, highlighting innovations like path optimization, thermal integration, and ML models (e.g., YOLO, Faster R-CNN); proposes a multimodal (RGB, LiDAR, thermal) workflow with transformer-based architectures to improve defect detection; and identifies future directions including lightweight AI, adaptive flight planning, synthetic data, and richer modality fusion.


<details>
  <summary>Details</summary>
Motivation: To address growing needs for efficient, accurate, and scalable infrastructure inspections in AEC+FM, and to overcome current limitations in real-time processing, multimodal data fusion, and model generalizability.

Method: Systematic synthesis of 150+ studies; design and validation of a novel UAV workflow integrating RGB, LiDAR, and thermal sensing with transformer-based models; case study–informed path planning and multimodal fusion.

Result: A comprehensive, step-by-step framework enabling precise detection of structural defects, thermal anomalies, and geometric inconsistencies through dynamic path adaptation and multimodal fusion.

Conclusion: UAVs significantly enhance infrastructure inspection across SHM, disaster response, urban management, energy evaluation, and heritage preservation; yet real-time, generalizable, and fused-sensing solutions remain open challenges—future work should focus on lightweight AI, adaptive autonomy, synthetic data, and richer modality integration.

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [26] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX是一个用于提升医学视觉-语言模型可解释性的新框架，通过多尺度注意力机制和文本引导的空间先验，生成更精确、稳定且临床意义明确的归因图。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学视觉-语言模型解释方法存在的空间不精确、缺乏解剖学依据和注意力粒度有限等关键问题。

Method: 结合多层注意力展开、文本引导的空间先验和层一致性分析，生成梯度归因图。

Result: 在MS-CXR数据集上，MATEX在空间精度和与专家标注结果的一致性方面均优于当前最优方法M2IB。

Conclusion: MATEX有望提升放射科AI应用中的可信度与透明度。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [27] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: 本文提出了MetamerGen，一种基于潜变量扩散模型的工具，用于生成与人类场景理解相匹配的图像异构体（metamers），通过结合周边视觉（gist）和注视点（fixation）信息，利用双流DINOv2 token表征实现foveated图像合成，并通过行为实验验证其感知对齐性。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过周边低分辨率“整体印象”与注视点高分辨率信息协同构建场景理解，但现有生成模型缺乏对这种生物视觉机制的建模，亟需能反映人类潜意识场景表征的图像生成工具。

Method: 提出MetamerGen——一种潜变量扩散模型，构建双流表征：一为来自注视区域的DINOv2细节特征，二为周边降质的上下文特征；融合二者生成foveated输入驱动的图像；并通过same-different行为实验评估生成图像是否构成人类场景表征的metamers。

Result: MetamerGen成功生成了在行为实验中被判定为与原图‘相同’的图像metamers；分析表明，当以被试真实注视区域为条件时，高层语义对齐度最强地预测metamerism；即使使用随机注视点也能生成metamers，但语义一致性显著提升效果。

Conclusion: MetamerGen为探究人类场景理解提供了新范式，证实融合生物视觉机制（foveated输入+双流表征）可有效逼近人类潜意识场景表征，且高层语义对齐是关键因素。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [28] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 本文探讨了共形点与校准圆锥的概念及其相互关系，这些概念有助于图像几何的可视化，并提供了直观计算图像中角度和方向的方法。


<details>
  <summary>Details</summary>
Motivation: 为了可视化图像几何并提供直观计算图像中角度和方向的方法。

Method: 分析共形点与校准圆锥的概念及其相互关系。

Result: 建立了共形点与校准圆锥之间的关系，为图像几何的可视化和计算提供了新方法。

Conclusion: 共形点与校准圆锥是理解图像几何的重要工具，能够直观地支持角度和方向等几何量的计算。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [29] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: 本文提出了HAVEN框架，通过整合音视频实体一致性与分层视频索引及智能体搜索，实现长视频的连贯、全面理解，在LVBench上达到84.1%整体准确率，推理任务达80.1%。


<details>
  <summary>Details</summary>
Motivation: 现有基于简单分块与检索增强生成的方法在长视频理解中存在信息碎片化和全局连贯性缺失问题。

Method: 提出HAVEN统一框架：1）跨视听模态的实体级语义一致性建模；2）构建涵盖全局摘要、场景、片段和实体的分层视频索引结构；3）引入智能体搜索机制实现跨层级动态检索与推理。

Result: 在LVBench上整体准确率达84.1%，其中推理类别达80.1%，显著提升时间连贯性、实体一致性和检索效率。

Conclusion: 结构化的多模态推理能有效支持长视频的上下文一致、全面理解，HAVEN为长视频理解提供了新范式。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [30] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

TL;DR: 本文提出了一种基于手写轨迹的浅层循环神经网络分类器，用于区分真实人类书写与多种合成器（如GAN、Transformer、扩散模型等）生成的手写行为，在多个数据集和合成方法上实现了98.3% AUC和1.4% EER的优异性能，并在少样本和跨域场景下保持鲁棒性，为设备身份验证提供新型行为生物特征安全机制。


<details>
  <summary>Details</summary>
Motivation: 利用手写运动作为行为生物特征，实现人机鉴别（即反图灵测试），以增强设备或应用中的人类存在验证与安全性。

Method: 使用十个公开手写符号数据集（字符、数字、手势、指向轨迹、签名）及七种合成器（包括Sigma h模型、GAN、Transformer、扩散模型等）生成的伪造样本；训练一个以原始轨迹数据为输入的浅层循环神经网络进行真伪二分类。

Result: 平均AUC达98.3%，等错误率（EER）为1.4%；仅用10%数据训练即获优异性能；在跨域设置下仍表现稳健。

Conclusion: 该方法可有效识别AI生成的手写行为，为需要验证真实用户操作的计算机系统提供了一种轻量、高效且泛化能力强的行为生物特征安全方案。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [31] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 本文提出了一种新的半监督域泛化（SSDG）方法，通过将模型中间特征与视觉语言模型（VLM）的语义丰富、泛化性强的特征空间对齐，提升域不变性，并结合图像级增强和输出级正则化策略，提高数据利用率并缓解过拟合，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确率，忽视了训练过程中的最大数据利用，限制了性能提升；同时需兼顾防止模型过拟合。

Method: 提出基于Vision Language Model（VLM）特征空间对齐的中间层特征学习方法，增强域不变性；辅以图像级数据增强和输出级正则化策略，提升数据利用效率并抑制过拟合。

Result: 在四个基准数据集上的实验表明，该方法在定性和定量评估中均优于现有SSDG基线方法，达到当前最优（SOTA）性能。

Conclusion: 最大化数据利用与域不变特征对齐同等重要；借助VLM先验知识并结合多级正则化策略，可显著提升SSDG模型的泛化能力与鲁棒性。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [32] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 本文提出了一种新的基准测试SpaRRTa，用于评估视觉基础模型（VFMs）的空间关系识别能力，揭示其在空间推理上的显著差异，并分析影响空间感知的机制。


<details>
  <summary>Details</summary>
Motivation: 现有VFMs（如DINO、CLIP）擅长语义理解但空间推理能力有限，尤其在面向具身智能的应用中；尽管已有工作将3D任务引入训练，但模型是否真正具备通用空间意识尚不明确。

Method: 构建了Spatial Relation Recognition Task (SpaRRTa) 基准，生成具有可控物体布局的逼真图像及对应空间关系标注，用于系统评估VFMs对物体相对位置的识别能力。

Result: 在多个SOTA VFMs上评测发现其空间推理能力存在显著差异；分析揭示了支撑或阻碍空间感知的关键机制。

Conclusion: SpaRRTa为衡量和提升VFMs的空间意识提供了新工具，有助于推动更鲁棒、空间感知更强的视觉模型发展。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [33] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 本文提出了一种去类目耦合的视觉搜索架构，结合分类无关的区域建议与统一嵌入进行相似性检索，并引入LLM-as-a-Judge框架实现零样本、无需人工标注的评估，已在全球家居电商平台大规模部署并提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 现有工业视觉搜索系统依赖带噪声的目录数据和类目耦合的检测-分类流程，导致鲁棒性和可扩展性受限，且评估困难。

Method: 提出 taxonomy-decoupled 架构：使用分类无关的区域建议（classification-free region proposals）和统一嵌入（unified embeddings）进行相似性检索；设计 LLM-as-a-Judge 框架，零样本评估查询-结果对的视觉相似性与类别相关性。

Result: 在真实全球家居电商平台上大规模部署，提升了检索质量与用户参与度；离线评估指标与实际业务指标强相关。

Conclusion: 该方法摆脱了对人工标注和噪声目录数据的依赖，提高了视觉搜索的灵活性、泛化性与可评估性，具备工业落地价值。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [34] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

TL;DR: 本文提出studentSplat，一种用于单视图场景重建的3D高斯溅射方法，通过师生架构和外推网络解决单视图下的尺度模糊与场景补全问题，达到当前最优的单视图新视角合成效果，并具备自监督深度估计能力。


<details>
  <summary>Details</summary>
Motivation: 单视图3D场景重建因固有的歧义性（如尺度模糊、缺乏几何约束）而未被充分探索，现有前馈式3D高斯溅射方法主要面向多视图或单对象重建。

Method: 提出studentSplat：1）教师-学生架构，利用多视图教师模型为单视图学生模型提供几何监督以缓解尺度模糊并提升几何合理性；2）引入外推网络补全缺失场景上下文，增强场景完整性与泛化能力。

Result: 在单视图新视角合成任务上达到SOTA性能，场景级重建质量可媲美多视图方法；同时作为自监督单视图深度估计器表现具有竞争力。

Conclusion: studentSplat有效解决了单视图场景重建的核心挑战，拓展了3D高斯溅射在通用单视图3D理解任务中的适用性。

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [35] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 本文提出了一种基于无监督图像翻译生成目标域人工数据集的方法，用于提升无监督域自适应目标检测性能，方法更简洁、可解释性更好，并在自动驾驶真实场景中显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于中间特征对齐的无监督域自适应目标检测方法实现复杂、可解释性差，且与使用目标域标注数据训练的上界性能仍有差距。

Method: 利用CycleGAN和AdaIN两种无监督图像翻译模型，仅使用源域标注数据和目标域未标注数据，生成目标域风格的人工图像数据集，用于训练目标检测器。

Result: 在自动驾驶真实场景中显著优于当前最优方法，在多数情况下进一步缩小了与上界性能的差距。

Conclusion: 所提方法在保持较低实现复杂度的同时提升了性能和可解释性，为无监督域自适应目标检测提供了新思路。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [36] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 本文提出了一种基于F.A.S.T.评估数据的快速、无创多模态深度学习框架，用于院前卒中自动二分类筛查，融合面部表情、语音信号和上肢运动信息，准确率达95.83%，F1-score达96.00%。


<details>
  <summary>Details</summary>
Motivation: 早期识别卒中症状对及时干预和改善患者预后至关重要，尤其在院前场景下亟需快速、无创、可靠的自动筛查工具。

Method: 构建融合面部（基于关键点+Transformer）、语音（梅尔频谱图+Audio Spectrogram Transformer）和上肢动作（姿态序列+MLP-Mixer）三模态的深度学习模型，并采用注意力机制进行跨模态特征融合。

Result: 在自建222段视频（37名受试者）数据集上，模型达到95.83%准确率和96.00% F1-score，敏感性与特异性均衡，成功检出全部卒中病例。

Conclusion: 多模态学习与迁移学习在早期卒中筛查中展现出巨大潜力，但需更大规模、更具临床代表性的数据集支撑真实场景部署。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [37] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: 本文提出RemoteVAR，一种基于视觉自回归模型（VAR）的遥感变化检测新框架，通过跨注意力机制融合双时相多分辨率特征，并设计专门针对变化图预测的自回归训练策略，克服了VAR在像素级判别任务中的可控性差、密集预测性能不佳和暴露偏差等问题，在多个基准上显著优于扩散模型和Transformer基线。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归模型（VARs）虽在图像生成上表现出色，但在像素级判别任务（如遥感变化检测）中受限于弱可控性、密集预测性能差和暴露偏差，亟需改进以适配此类任务。

Method: 提出RemoteVAR框架：1）利用跨注意力机制将自回归预测条件化于多分辨率融合的双时相特征；2）设计专用于变化图预测的自回归训练策略。

Result: 在标准遥感变化检测基准上，RemoteVAR一致且显著优于强扩散模型和Transformer基线，成为具有竞争力的自回归方案。

Conclusion: RemoteVAR成功拓展了视觉自回归模型在遥感变化检测等像素级判别任务中的应用，验证了其作为替代性建模范式的潜力。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [38] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 本文提出了一种基于EfficientNetB4的双任务模型，用于空中目标分类与威胁等级预测，并构建了AODTA数据集，在分类和威胁预测上分别达到96%和90%准确率。


<details>
  <summary>Details</summary>
Motivation: 当前空中平台激增，而现有威胁评估系统依赖人工监控，存在可扩展性差和效率低的问题。

Method: 提出基于EfficientNetB4的双任务模型，同步完成空中物体分类与威胁等级预测；构建并使用AODTA数据集进行训练与验证，并与ResNet-50基线对比。

Result: 在AVD和AODTA数据集上，模型分别实现96%的物体分类准确率和90%的威胁等级预测准确率，显著优于ResNet-50基线。

Conclusion: 该高效双任务模型具备实际部署潜力，适用于监视、国防及空域管理等场景。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [39] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 本研究探讨了光强度编码函数对中心/周围Retinex模型颜色恒常性（CC）性能的影响，发现Naka-Rushton函数结合双拮抗颜色平面表征在不同光照下目标颜色判别方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 颜色是视觉功能（如物体识别）的重要信息源，但易受照明颜色影响；为实现颜色恒常性（即不受照明色影响地感知物体真实颜色），需改进现有计算模型的光强编码机制。

Method: 比较原始C/S Retinex模型使用的对数函数与模拟视网膜感光细胞响应的Naka-Rushton（N-R）函数在颜色恒常性建模中的效果；采用色可变LED提供多种照明色，利用HSV空间及经典拮抗色理论构建的颜色平面表征颜色信息，并评估不同光照下目标颜色的可区分度。

Result: Naka-Rushton函数与双拮抗颜色平面组合显著提升了不同照明条件下视觉目标颜色的判别性能。

Conclusion: 光强度编码函数的选择对Retinex模型的颜色恒常性性能有显著影响，N-R函数比传统对数函数更符合生物视觉机制，能更好支持鲁棒的颜色判别。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [40] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的开放词汇目标检测方法GW-VLM，通过多尺度视觉语言搜索（MS-VLS）和上下文概念提示（CCP），结合预训练视觉语言模型（VLM）与大语言模型（LLM）协同完成‘猜物体’任务，实现零训练开销下的高性能OVOD。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测（OVOD）方法虽借助大规模预训练基础模型提升零样本能力，但忽视了如何基于已有预训练模型构建对任意物体的通用理解范式。

Method: 提出训练自由的Guess What Vision Language Model（GW-VLM），核心包括：1）多尺度视觉语言搜索（MS-VLS），利用类无关检测结果与VLM进行多尺度软对齐生成视觉片段；2）上下文概念提示（CCP），引导LLM理解MS-VLS生成的片段并形成概念流，从而支持OVOD。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10等自然与遥感数据集上实验表明，GW-VLM在无需任何训练的前提下，性能优于当前最优方法。

Conclusion: GW-VLM验证了无需训练即可构建通用物体理解范式的可行性，为开放词汇目标检测提供了新思路，尤其适用于资源受限或需快速适配新类别的场景。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [41] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

TL;DR: 本文提出并评估了一个紧凑型卷积神经网络（CNN），在五个来自孟加拉国的小规模真实图像数据集上表现出高准确率、快速收敛和低计算开销，验证了轻量级CNN在小样本图像分类任务中的有效性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: CNN虽在图像识别中表现优异，但复杂架构易在小数据集上过拟合；需探索适合小规模、真实场景图像分类的轻量高效模型。

Method: 设计并评估一个紧凑型CNN，在五个孟加拉国公开真实图像数据集（涵盖城市侵占、车辆检测、道路损坏、农作物识别等）上进行训练与测试，并结合定量指标与显著性分析评估其性能。

Result: 该紧凑CNN在多个小规模真实数据集上实现了高分类精度、高效收敛和低计算开销；显著性分析表明其能有效捕捉判别性特征，并在多样化场景下稳健泛化。

Conclusion: 轻量级CNN架构适用于小类别、小样本的真实图像分类任务，兼顾性能、效率与泛化能力。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [42] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 本文提出一种干预表示空间的新范式，通过正交低秩投影建模并移除伪造无关的虚假相关特征子空间，从而提升伪造检测模型的泛化能力与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以逐一识别和消除由不可观测混杂因素引发的多种虚假相关，导致模型泛化性能受限。

Method: 将虚假相关特征统一建模为低秩子空间，利用正交低秩投影进行分解，并在训练中去除该子空间，仅保留其正交补空间以学习真实伪造线索。

Result: 仅用0.43M可训练参数，在多个基准上达到SOTA性能，展现出优异的鲁棒性与泛化能力。

Conclusion: 低秩子空间干预是一种高效且通用的去偏策略，能有效解耦虚假相关与真实伪造特征，显著提升模型泛化性。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [43] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 本文提出了一种利用Gabor滤波器作为预处理器来提升边缘设备上CNN在机器人视觉任务中准确率和泛化能力、同时减小模型规模的方法。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需兼顾小模型尺寸与在有限数据下高效训练以实现现场物体识别的需求；而视觉神经系统（VNS）具备少样本学习能力，可作为启发来源。

Method: 将Gabor滤波器（模拟VNS特征提取器）作为CNN输入预处理模块，并在多类CNN架构上对比有无该预处理的性能；构建含不同相机位姿的图像数据集，评估模型在跨距离条件下的泛化能力。

Result: Gabor预处理显著提升了CNN在小样本训练下的泛化性能，并有助于减小CNN模型尺寸。

Conclusion: 引入生物启发的Gabor滤波器预处理是一种有效提升边缘CNN鲁棒性、效率与紧凑性的可行策略。

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [44] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: 本文提出SupScene方法，通过子图训练策略和DiVLAD聚合器学习面向SfM重叠图像对匹配的全局描述符，在GL3D数据集上显著优于NetVLAD。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像检索方法多关注语义相似性，而SfM中更需识别几何可匹配图像对；当前批量二分类监督方式难以刻画重叠关系的细粒度差异。

Method: 提出SupScene：1）基于子图的加权训练策略，利用真实几何重叠关系和软监督对比损失提供细粒度监督；2）设计DINO启发的DiVLAD聚合器，结合ViT最后一层多头注意力图与视觉特征，并引入可学习门控机制自适应融合。

Result: 在GL3D数据集上达到SOTA性能，显著超越NetVLAD，且仅引入极少额外可训练参数；新训练策略对多种聚合方法均带来一致提升。

Conclusion: SupScene有效提升了面向SfM的图像检索精度，其子图监督与注意力引导的聚合机制为几何匹配导向的描述符学习提供了新思路。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [45] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: 本文提出了一种语言引导与运动感知的步态识别框架LMGait，以解决现有方法易受静态噪声干扰且难以有效捕捉动态运动区域的问题。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法依赖复杂架构直接从图像中提取特征并进行池化，易过拟合于静态噪声（如衣物），且难以有效建模动态运动区域。

Method: 提出LMGait框架，利用设计的步态相关语言线索来捕获步态序列中的关键运动特征。

Result: 提升了步态识别对动态运动区域的建模能力，并缓解了由静态噪声引起的过拟合问题。

Conclusion: 语言引导与运动感知的结合为步态识别提供了新思路，有助于提升模型鲁棒性与判别性。

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [46] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

TL;DR: 本文提出了一种名为分层密集注意力网络（HDAN）的新型3D分割神经网络，通过空间-通道注意力机制与注意力引导的密集上采样策略，有效提升了早产儿MRI中白质与灰质等低对比度组织的分割精度，并验证了其在揭示早产相关神经发育延迟中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 早产儿脑部MRI中白质与灰质信号强度相近（等信号），导致传统深度学习分割方法难以准确区分，亟需提升低对比度体积数据的特征判别能力。

Method: 提出分层密集注意力网络（HDAN），融合3D空间-通道注意力机制与注意力引导的密集上采样策略，增强对等信号组织的特征表达与分割精度。

Result: 在定量实验中，HDAN显著优于现有最先进方法；应用于临床数据证实早产儿白质与灰质体积显著低于足月儿，为神经发育延迟提供影像学证据。

Conclusion: HDAN有效解决了早产儿脑MRI中等信号组织分割难题，具备临床转化潜力，有助于早期识别和干预神经发育风险。

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [47] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 本文提出Decoder Gradient Shields (DGSs)防御机制，以抵御针对box-free模型水印解码器的梯度泄露攻击，通过重定向和重缩放水印通道梯度，在保证图像质量的同时实现100%防御成功率。


<details>
  <summary>Details</summary>
Motivation: 现有box-free模型水印研究主要关注编码器鲁棒性，而忽视了解码器易受基于查询响应梯度的水印移除攻击的问题。

Method: 提出三类Decoder Gradient Shields（DGS-O、DGS-I、DGS-L），分别作用于解码器输出、输入和中间层；其中DGS-O有闭式解，所有DGS均有理论性能保证；核心是联合重定向与重缩放来自水印通道梯度泄露查询的梯度。

Result: 在去雨和图像生成任务中，对当前最优box-free水印方案实现100%防御成功率，且不损害解码器输出图像质量。

Conclusion: DGSs能有效阻止水印移除器收敛至低损失值，为box-free水印解码器提供了可靠、可证明、实用的梯度级防护。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [48] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种面向边缘设备（树莓派5）的实时多模态视觉框架，通过自适应调度机制动态激活目标检测、人脸识别和情绪识别模块，在降低65%计算负载的同时保持高性能（AP 0.861、人脸识别准确率88%、情绪识别AUC达0.97），验证了上下文感知调度对低成本边缘智能感知的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务，缺乏基于上下文触发的统一自适应运行时调度器，导致在低功耗边缘设备上整体理解能力与效率受限。

Method: 构建集成目标检测（YOLOv8n）、所有者特定人脸识别（定制FaceNet嵌入系统）和情绪检测（DeepFace CNN）的统一多模态流水线，并设计自适应调度机制，在树莓派5上实现按需模块激活。

Result: 系统在树莓派5上达到5.6 FPS；目标检测AP为0.861，人脸识别准确率为88%，情绪检测AUC最高达0.97；计算负载相比连续处理降低65%。

Conclusion: 上下文感知的自适应调度是实现在低成本边缘硬件上部署复杂多模态AI的关键，可提升智能感知的可及性与隐私保护性。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [49] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: 本文提出了一种自适应视觉文档内检索（AVIR）框架，通过轻量级检索、自适应聚类与阈值筛选来减少MP-DocVQA任务中所需处理的页面数量，在显著降低计算开销的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答（MP-DocVQA）因长文档导致计算资源紧张和大视觉语言模型（LVLM）注意力机制效果下降而具有挑战性。

Method: 提出AVIR框架：先用轻量检索模型对每页打分；依据分数分布聚类并自适应选择相关页面；再通过Top-K进一步压缩上下文；对短文档则改用相关性概率阈值筛选；最终仅将筛选出的页面输入冻结的LVLM生成答案，无需微调。

Result: 在MP-DocVQA数据集上平均页面使用量减少70%，ANLS达84.58%，超越先前方法且计算成本显著更低；在SlideVQA和DUDE基准上也验证了有效性。

Conclusion: AVIR是一种高效、免微调的多页文档VQA解决方案，兼顾精度、效率与泛化能力。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [50] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: 本文提出了RADAR框架，首次实现了对未见新闻视频的测试时自适应(fake news video detection, FNVD)，通过检索引导的自适应范式提升模型在新兴事件和未知主题上的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设训练和测试阶段的新闻主题分布一致，无法有效检测与新兴事件和未见主题相关的虚假新闻视频。

Method: 提出RADAR框架，包含熵选择检索机制、稳定锚点引导对齐模块和目标域感知自训练范式，利用目标域中稳定样本指导不稳定样本的鲁棒自适应。

Result: 实验表明RADAR在测试时FNVD任务上性能优越，能快速适应未见虚假新闻视频主题。

Conclusion: RADAR是首个支持测试时自适应的虚假新闻视频检测框架，显著提升了模型对新兴事件和未知主题的泛化能力。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [51] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI-IoT的低成本、多模态智能轮椅系统，融合手势控制、YOLOv8目标检测与超声避障、以及多参数生理监测与远程告警功能，显著提升残障及老年用户的自主性、安全性和独立性。


<details>
  <summary>Details</summary>
Motivation: 应对日益增长的残障及老年群体对经济、智能、健康集成型轮椅的需求，解决传统轮椅功能单一、智能轮椅成本高、单模态、健康监测缺失等问题。

Method: 构建模块化低功耗AI-IoT系统：采用手套式手势识别实现免手导航；集成YOLOv8实现实时目标检测+语音反馈避障；辅以超声波传感器实现即时碰撞规避；同步采集心率、血氧、ECG、体温等生理信号，上传ThingSpeak并触发邮件预警。

Result: 手势控制成功率95.5%；超声避障准确率94%；YOLOv8检测精度91.5%、召回率90.2%、F1-score 90.8%；系统实现生理数据实时上传与临界告警。

Conclusion: 该多模态、可扩展、低成本方案有效弥合了前沿研究与实际落地之间的鸿沟，为个性化辅助技术提供了实用范例。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [52] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

TL;DR: 本文提出了一种融合解剖先验的结构化图推理框架，用于可解释的视觉诊断。将卷积特征图重新解释为补丁级图，节点编码外观与空间坐标，边反映局部结构邻接关系；引入定制化的结构传播机制，显式建模相对空间关系，使图成为结构化推理的归纳偏置；支持病变感知的节点级预测和诊断级图推理，并通过学习到的节点重要性分数实现内在可解释性。在胸部X光数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提升医学影像视觉诊断的可解释性与结构感知能力，克服传统图神经网络缺乏对空间关系显式建模、依赖后处理可视化等局限。

Method: 将CNN特征图建模为节点含外观与空间坐标的补丁级图，设计基于相对空间关系的自定义结构传播机制，实现图作为归纳偏置的结构化推理；联合优化节点级病变预测与图级诊断决策，并输出节点重要性分数以实现内在可解释性。

Result: 在胸部X光诊断任务中，该方法提升了诊断性能与推理可解释性，节点重要性分数能自然揭示关键病灶区域，无需后处理技术；框架具有跨领域适用性。

Conclusion: 结构化图推理框架通过嵌入解剖先验与显式空间建模，实现了兼具高性能与内在可解释性的视觉诊断，推动图作为结构感知与可解释学习计算基底的发展。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [53] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

TL;DR: 本文提出DAOS数据集和AOR-Net模型，通过建模驾驶员动作与相关物体之间的细粒度关系，提升驾驶行为识别精度。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶行为监测数据集缺乏准确的物体位置标注，且未将物体与对应动作关联，导致动作识别性能受限。

Method: 构建包含多模态、多视角数据的DAOS数据集，并提出AOR-Net模型，融合多级推理、动作链提示机制及‘思维混合’模块以动态选择关键知识。

Result: 所提方法在多个数据集上超越当前最优方法。

Conclusion: 引入物体协同关系建模对提升驾驶员动作识别鲁棒性与准确性至关重要，DAOS数据集和AOR-Net为该方向提供了新基准与有效解决方案。

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [54] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 本文提出了一种从粗到细的鲁棒场景挖掘方法SMc2f，用于提升自动驾驶车辆在罕见安全关键场景中的检索性能，通过结合视觉语言模型（VLM）、少样本提示的LLM和文本-轨迹对比学习，克服了RefAV等现有方法依赖轨迹标签、忽略图像-语言对齐及受检测误差影响等问题。


<details>
  <summary>Details</summary>
Motivation: 现有场景挖掘方法（如RefAV）依赖轨迹标签而非原始图像，且易受上游3D检测与跟踪误差影响，难以准确进行时空定位；需更鲁棒、图像感知的检索机制。

Method: 提出SMc2f框架：1）用VLM进行粗粒度图像-文本过滤；2）基于RefAV成功案例构建数据库，并用其进行少样本提示以增强LLM检索鲁棒性；3）引入文本-轨迹对比学习，在共享嵌入空间中优化匹配精度。

Result: 在公开数据集上实验表明，SMc2f显著提升了场景检索的质量与效率，优于RefAV等基线方法。

Conclusion: SMc2f通过融合多模态对齐、少样本提示与对比学习，实现了更鲁棒、高效且图像感知的自动驾驶长尾场景挖掘，为安全验证提供了新范式。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [55] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeepSegFusion的混合深度学习模型，用于SAR图像中的油污泄漏分割，通过融合SegNet与DeepLabV3+并引入注意力机制提升边界精度和上下文理解，在多个SAR数据集上取得高精度（94.85%）和低误检率（降低64.4%），适用于近实时海洋油污监测。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的方法因风浪、船尾迹等“类油污”现象导致高误报率，亟需更鲁棒的油污检测方法。

Method: 提出DeepSegFusion模型，融合SegNet与DeepLabV3+架构，并引入注意力机制进行多尺度特征融合，专用于SAR图像油污分割。

Result: 在ALOS PALSAR等SAR油污数据集上达到94.85%准确率、IoU为0.5685、ROC-AUC为0.9330；误检数比基线模型减少超三倍，总体降低64.4%。

Conclusion: DeepSegFusion具有强泛化性与稳定性，适用于多种海洋环境下的近实时油污监测任务。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [56] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS是一种数据高效框架，仅用约10张图像即可实现高保真次表面散射（SSS）材质的神经重建，通过微调扩散模型并引入几何先验，在稀疏监督下显著降低真实采集需求。


<details>
  <summary>Details</summary>
Motivation: 传统神经渲染建模次表面散射需大量多视角、多光源图像（常超100视角+112个OLAT），采集成本高、难以普及；亟需一种数据高效的稀疏监督重建方法。

Method: 提出DIAMOND-SSS框架：1）基于估计几何微调扩散模型，用于新视角合成与重光照；2）仅用<7%原始数据训练；3）引入光照无关几何先验——多视角轮廓一致性损失和多视角深度一致性损失以稳定稀疏/合成监督下的重建。

Result: 在各类稀疏程度下均达到可重光照高斯渲染（relightable Gaussian rendering）的SOTA质量；相较SSS-3DGS，最多减少90%真实图像采集量；生成的增强图像可替代95%缺失采集。

Conclusion: DIAMOND-SSS证明了极稀疏监督（如仅10图）下高质量SSS重建的可行性，其几何先验与扩散增强策略为数据受限的神经材质建模提供了新范式。

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [57] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic是一种模型无关的可解释性框架，通过逻辑表达式量化视觉模型决策过程中的关键区域（视觉焦点），并提供精度、召回率和发散度等定量指标来评估模型行为。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法要么依赖白盒模型访问，要么缺乏定量严谨性，难以满足高风险应用场景的需求。

Method: 提出FocaLogic框架，识别影响预测的最小可视区域（视觉焦点），将其转化为紧凑精确的逻辑表达式，并设计聚焦精度、召回率和发散度等定量评估指标。

Result: 实证分析表明FocaLogic能揭示训练导致的注意力集中、泛化提升焦点准确性，以及在偏差和对抗攻击下的异常焦点。

Conclusion: FocaLogic为视觉模型提供了系统性、可扩展且定量的可解释性解决方案。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [58] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出了一种名为Masked Jigsaw Puzzle（MJP）的框架，通过随机打乱token顺序并使用可学习的未知位置嵌入（unk PE）掩盖打乱token的位置信息，从而破坏局部空间信息、增强Transformer模型对梯度攻击的鲁棒性，并提升CV与NLP任务性能。


<details>
  <summary>Details</summary>
Motivation: Transformer中位置嵌入（PE）的梯度易泄露输入数据，导致隐私风险；同时模型过度依赖局部空间信息可能限制泛化与鲁棒性。

Method: 提出Masked Jigsaw Puzzle（MJP）：先随机打乱token顺序，再用可学习的'unknown'位置嵌入替代被扰动token的位置嵌入，以扰乱位置编码所承载的局部空间结构信息。

Result: MJP在ImageNet-1K图像分类、Yelp/Amazon文本情感分析等任务上均提升模型性能；显著增强对梯度攻击（如梯度反演）的防御能力；适用于多种Transformer架构，具有跨模态统一性。

Conclusion: MJP是一种简单有效、跨CV与NLP的通用防御机制，兼顾隐私保护与模型性能提升，为联邦学习中Transformer的安全高效部署提供了新思路。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [59] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: 本文提出TDP-CR框架，通过任务驱动的多模态联合云去除与地物分类，结合Prompt-Guided Fusion机制与两阶段高效训练策略，在保持高视觉质量的同时显著提升语义可用性。


<details>
  <summary>Details</summary>
Motivation: 现有云去除方法侧重低层保真度，易平滑关键纹理与边界，导致视觉效果好但语义实用性差，难以满足分析就绪数据（ARD）需求。

Method: 提出任务驱动的TDP-CR框架，包含Prompt-Guided Fusion（PGF）机制——利用可学习退化提示编码云厚度与空间不确定性，并融合SAR信息；采用参数高效的两阶段训练策略解耦重建与语义表征学习。

Result: 在LuojiaSET-OSFCR数据集上，PSNR比SOTA基线高0.18 dB且仅用15%参数，mIoU较多任务方法提升1.4%，显著提升分析就绪性能。

Conclusion: TDP-CR成功弥合了云去除中视觉保真与语义可用性的鸿沟，为遥感影像提供真正面向下游任务的分析就绪数据。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [60] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

TL;DR: 本文提出AUTO-DIP方法，通过基于图像元数据（如显微镜类型、样本）的参数迁移，实现无需优化的深度图像先验（DIP）去噪，在荧光显微图像上优于原始DIP和变分去噪方法，尤其对强噪声图像效果显著。


<details>
  <summary>Details</summary>
Motivation: DIP性能依赖网络结构和迭代停止点，逐图调参耗时，限制其在需处理大量图像场景（如荧光显微成像）中的应用；作者假设相似图像共享相近最优DIP参数，可实现免优化参数迁移。

Method: 构建含110张图像的校准集与55张图像的验证集，搜索适配荧光图像的U-Net架构及最优停止点；评估多种图像相似性准则（元数据vs.定量图像特征）；设计AUTO-DIP自动参数迁移流程，并与原始DIP和先进变分去噪方法对比。

Result: 仅依据图像元数据（如显微镜类型、样本）进行参数迁移，效果优于基于定量图像相似性的迁移；AUTO-DIP在多个开源测试数据集（含高噪声图像）及本地采集图像上均超越原始DIP和变分去噪方法。

Conclusion: 对于荧光显微图像，基于元数据的轻量级参数迁移策略足以实现高性能、免优化的DIP去噪，AUTO-DIP为实际应用提供了高效可靠的解决方案。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [61] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

TL;DR: 本文提出了一种语言驱动的序列级模态不变表征学习方法（LSMRL），通过空间-时间特征学习（STFL）、语义扩散（SD）和跨模态交互（CMI）三个模块，结合模态级损失，提升可见光-红外视频行人重识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP语言提示的方法在时空建模效率、跨模态交互充分性及模态级损失引导方面存在不足。

Method: 提出LSMRL框架，包含：1）轻量修改CLIP构建的STFL模块实现高效时空建模；2）SD模块将共享语言提示扩散至双模态特征以建立初步模态一致性；3）CMI模块利用双向跨模态自注意力消除残余模态差异；4）引入两种模态级损失增强判别性与泛化性。

Result: 在大规模VVI-ReID数据集上实验表明，LSMRL显著优于当前最优方法（AOTA）。

Conclusion: LSMRL通过语言驱动与多模块协同设计，有效提升了视频级可见光-红外行人重识别中模态不变表征的学习效果。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [62] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于随机桥模型的视频对象移除方法，将任务重构为视频到视频的翻译，利用原始视频作为强结构先验，并引入自适应掩码调制策略，在保持背景保真度的同时提升大物体移除能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频对象移除方法从高斯噪声出发，丢失了原始视频中的结构与上下文先验，导致擦除不完整或生成违背物理逻辑的内容。

Method: 将视频对象移除建模为视频到视频的随机桥过程，直接建立含物体视频到无物体视频的随机路径；并设计自适应掩码调制策略，动态调整输入嵌入以平衡保真度与生成灵活性。

Result: 在视觉质量和时间一致性上显著优于现有方法。

Conclusion: 基于随机桥的视频对象移除框架能更有效地利用输入视频先验，结合自适应掩码调制可兼顾大物体移除与背景一致性，是一种更鲁棒、更合理的视频编辑范式。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [63] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

TL;DR: 本文提出ARMARecon，一种结合ARMA图滤波与重建目标的图学习框架，利用白质FA直方图特征建模局部与全局连接性，有效缓解过平滑，在ADNI和NIFD数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和额颞叶痴呆（FTD）沿白质以图依赖方式传播，亟需早期检测以延缓病情进展；传统方法难以同时建模其局部与全局连接模式。

Method: 提出ARMARecon框架：融合自回归滑动平均（ARMA）图滤波与重建驱动目标；输入为20-bin FA直方图特征；通过ARMA滤波增强图信号表达能力并抑制过平滑。

Result: 在多中心dMRI数据集ADNI和NIFD上，ARMARecon在AD/FTD分类任务中性能优于当前最优方法。

Conclusion: ARMARecon能更有效地建模白质网络的局部与全局拓扑特性，提升神经退行性疾病早期识别的准确率与鲁棒性。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [64] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 本文提出了RS-RVOS Bench首个大规模遥感视频指代表达分割基准，并设计了MQC-SAM方法，通过运动一致性校准初始记忆、质量感知的动态记忆更新机制，显著提升弱显著性目标在复杂动态场景下的分割鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 遥感视频中目标显著性弱、视觉信息截断严重，且缺乏大规模专用基准；现有方法受初始记忆偏差和无差别记忆累积（引入噪声）影响，导致定位不准与误差传播。

Method: 1）构建RS-RVOS Bench：111个视频序列、2.5万帧、21.3万条时序指代表达标注，采用因果感知策略（仅基于首帧目标状态生成语言描述）；2）提出MQC-SAM框架：含时间运动一致性模块用于初始记忆校准，及解耦注意力+动态质量评估的记忆融合机制，选择性更新高置信特征、过滤不可靠信息。

Result: 在RS-RVOS Bench上实验表明，MQC-SAM达到当前最优性能。

Conclusion: 该工作从数据与算法双路径推进RS-RVOS发展：高质量因果标注基准填补领域空白，记忆质量可控的在线分割框架有效缓解误差传播，提升了遥感动态场景下指代表达分割的鲁棒性与精度。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [65] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: 本文提出EmoLat，一种新型情绪潜在空间，通过建模文本语义与视觉情绪特征间的跨模态关联，实现细粒度、文本驱动的图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以实现细粒度、可控的图像情感编辑，尤其缺乏对文本引导下跨模态情绪语义一致性的建模。

Method: 构建情绪语义图以刻画情绪、物体与视觉属性间关系；引入对抗正则化对齐跨模态情绪潜在分布；设计基于EmoLat的跨模态情感迁移框架，并采用多目标损失（语义一致性、情绪对齐、对抗正则）进行优化；构建大规模基准数据集EmoSpace Set。

Result: 在EmoSpace Set上实验表明，该方法在定量指标和定性迁移保真度上均显著优于现有SOTA方法。

Conclusion: EmoLat为文本驱动的可控图像情感编辑提供了新范式，推动了跨模态情绪理解与生成的发展。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [66] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: 本文提出Foreground Consistent Learning模型（FCLM），通过深度感知蒸馏、域不变学习和面向对象解码器，提升高精度场景解析（如图像抠图、二值分割）在真实场景中的泛化性与交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法多针对显著单前景物体，交互式方法类别不可知、泛化差，且依赖低质量合成数据，导致真实场景性能不佳。

Method: 提出FCLM模型：1）深度感知蒸馏策略迁移深度知识以增强前景表征；2）将合成数据处理建模为域适应问题，采用域不变学习聚焦前景；3）设计支持视觉与语言提示的面向对象解码器实现交互预测。

Result: 实验表明该方法在定量与定性指标上均优于当前SOTA方法。

Conclusion: FCLM有效缓解了高精度场景解析中类别泛化弱、合成到真实域迁移难及交互灵活性不足等问题。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [67] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文提出HistoCRF框架，通过改进条件随机场（CRF）用于组织病理图像分析，无需额外训练即可提升视觉-语言模型（VLM）的零样本预测性能，在多个数据集上显著提高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLM）在组织病理图像分析中虽具强零样本能力但预测不完美，需无需再训练的后处理方法提升其性能。

Method: 提出HistoCRF框架，将条件随机场（CRF）适配至组织病理学任务，设计新型成对势函数以促进标签多样性并融合专家标注；开展三类实验：无标注、有专家标注、人机协同迭代标注。

Result: 在五个不同器官与疾病的数据集上，相比零样本预测，平均准确率提升16.0%（无标注）、27.5%（仅100个专家标注）、32.6%（人机协同迭代标注）。

Conclusion: HistoCRF是一种高效、无需再训练的后处理方法，能显著增强VLM在组织病理图像分析中的预测性能，尤其在少量标注或人机协同场景下效果突出。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [68] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

TL;DR: 本文提出了一种针对工业场景中箱体（bins）的6DoF位姿估计新方法，利用其长方体几何特性，通过扩展LeTR网络检测3D线段并结合几何推理实现鲁棒位姿估计，无需实例级CAD模型，且在真实扫描数据上达到3 cm平移误差和8.2°旋转误差。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法依赖大量训练数据或CAD模型，在工业实际场景中受限于数据稀缺和物体实例多变；亟需一种轻量、不依赖CAD、适用于特定常见工件（如bins）的位姿估计方法。

Method: 扩展2D线段检测网络LeTR以处理结构化点云，检测箱体顶部边缘对应的3D线段；再通过简单几何流程（如交点与方向约束）从线段中稳健解算6DoF位姿。

Result: 在扩展后的公开数据集上验证，融合合成数据训练显著提升真实扫描精度；达到3 cm平移误差和8.2°旋转误差，显著优于当前SOTA方法，且推理时不需实例CAD模型。

Conclusion: 该方法专为工业箱体设计，兼顾精度、鲁棒性与实用性，摆脱对CAD模型的依赖，为数据受限场景提供了可行解决方案。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [69] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

TL;DR: 本研究通过知识蒸馏和集成学习，将大型CNN模型的知识迁移到轻量级CNN模型上，实现了在资源受限设备上的高效咖啡叶病害诊断，显著降低了能耗和碳足迹。


<details>
  <summary>Details</summary>
Motivation: 咖啡产量依赖于对病害的及时准确诊断，但田间叶片病害评估面临挑战；尽管AI视觉模型精度高，但受限于设备能力和网络连接不稳定性，难以广泛应用。

Method: 采用知识蒸馏技术，将数据中心训练的高容量CNN模型通过集成学习（EL）向紧凑型CNN模型迁移知识；并进一步通过优化的密集微型模型对集成，提升精度同时满足严格的计算与能耗约束。

Result: 在自建咖啡叶数据集上，蒸馏后的微型集成模型在精度上媲美先前工作，同时显著降低能耗与碳足迹。

Conclusion: 经过适当蒸馏与集成的轻量级模型可为物联网（IoT）应用提供实用、可持续的病害诊断解决方案。

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [70] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

TL;DR: 本文提出了一种以真实图像为中心的检测网络RCDN，通过聚焦真实人脸图像的一致性而非伪造图像的多样性，在跨域场景下显著提升了深度伪造检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在同域场景下性能优异，但在面对新出现的、未见过的伪造技术（跨域场景）时鲁棒性严重下降，难以应对快速演化的AI伪造威胁。

Method: 提出Real-Centered Detection Network（RCDN），采用Xception骨干网络，结合频域-空域卷积结构；设计双分支架构与‘真实中心损失’（real-centered loss），将特征表示空间锚定在真实图像上，弱化对伪造模式的依赖。

Result: 在DiFF数据集（涵盖FE、I2I、T2I三类伪造）上，RCDN不仅达到最优的同域检测精度，更显著缩小跨域性能下降（generalization gap），获得最高的跨域/同域稳定性比率。

Conclusion: 以真实图像为中心的学习范式可有效提升伪造检测模型对分布偏移和未知伪造类型的鲁棒性与泛化能力，为构建实用、可持续的深度伪造防御系统提供了新思路。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [71] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

TL;DR: 本文提出了一种基于大语言模型（LLM）和多模态视觉模型（LVM）的智能体框架，用于在运行时动态生成和调整行为树（BT），以提升自动驾驶车辆在复杂、不可预测环境中的自适应决策能力。


<details>
  <summary>Details</summary>
Motivation: 传统行为树静态且依赖人工调参，难以满足SAE Level 5全自动驾驶对实时适应性的要求。

Method: 设计三个专用智能体：Descriptor评估场景关键性，Planner通过上下文学习生成高层子目标，Generator生成可执行的XML格式BT子树；系统集成于CARLA+Nav2仿真中，仅在基线BT失效时触发。

Result: 成功实现无干预绕行突发障碍（如道路堵塞），验证了动态BT生成的有效性与泛化潜力。

Conclusion: 该框架是迈向高适应性、低人工依赖的自动驾驶行为规划的重要探索，为动态任务规划提供了新范式。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [72] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: 本文提出了CARLA-Round——一个结构化、多模态的仿真圆环场景轨迹预测数据集，涵盖5种天气与5级交通密度组合（共25种可控场景），具备真实驾驶行为混合与显式标注；实验表明交通密度对预测难度具有强单调影响，而天气影响呈非线性；最佳模型在真实rounD数据集上ADE达0.312m，验证了仿真到现实的有效迁移。


<details>
  <summary>Details</summary>
Motivation: 圆环场景下车辆轨迹预测因道路几何特殊性、频繁交互及无信号控制而极具挑战；现有真实数据受限于观测不全与混杂因素干扰，缺乏可靠、多模态、结构化的专用数据集。

Method: 基于CARLA仿真平台构建结构化数据集CARLA-Round，系统组合5类天气与5级交通密度（LoS A–E），生成25种可控场景；每场景包含多样化真实驾驶行为建模与精细轨迹标注；采用LSTM、GCN、GRU+GCN等基线模型进行验证分析。

Result: 实验发现交通密度是主导预测难度的因素，呈现强单调效应；天气影响呈非线性；最佳模型在真实rounD数据集上取得0.312m平均位移误差（ADE），证实sim-to-real迁移有效性；该结构化设计可量化现实中无法分离的因子影响。

Conclusion: CARLA-Round填补了圆环场景轨迹预测高质量仿真数据集的空白，其结构化设计支持对关键影响因子的解耦分析，为算法鲁棒性评估与改进提供了新基准；代码与数据已开源。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [73] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

TL;DR: 本文提出了一种基于V2I的自动驾驶车辆数字孪生系统CD-TWINSAFE，包含车载驾驶栈（含立体视觉感知与定位）和基础设施端数字孪生栈（Unreal Engine 5场景建模与安全预警），通过ROS2/UDP/4G实现数据实时交互，并在多种驾驶场景中验证了其实时性与有效性。


<details>
  <summary>Details</summary>
Motivation: 提升自动驾驶车辆的安全性与可监控性，利用数字孪生技术实现对真实交通场景的实时虚拟映射与风险预警。

Method: 构建双栈架构：车载端运行定位与双目视觉感知模块（20fps，输出目标检测、速度、航向角及TTC/THW等安全指标）；基础设施端基于Unreal Engine 5构建动态同步场景，接收并解析ROS2定制消息（经UDP/4G传输）驱动孪生体更新，并生成安全警报。

Result: 系统在多种驾驶场景测试中展现出良好的实时响应能力与架构有效性，实现了真实车辆状态与数字孪生环境间的高保真同步及安全预警功能。

Conclusion: CD-TWINSAFE为V2I协同下的自动驾驶安全增强提供了可行框架，验证了轻量化车载感知与云端孪生仿真协同的潜力。

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [74] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: 本文提出SAMA，一个轻量级的SAM扩展模型，通过多视角定位编码器（MVLE）和定位适配器（Local-Adapter），统一支持高精度交互式图像分割与抠图任务，并在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: SAM虽具零样本泛化能力，但掩码精度不足；现有细化模块未能在一个统一框架内同时高精度完成分割与交互式图像抠图；而分割与抠图存在强相关性，启发统一建模。

Method: 提出Segment And Matte Anything（SAMA）：引入Multi-View Localization Encoder（MVLE）提取局部细节特征，Localization Adapter（Local-Adapter）恢复边界细节，并增设双预测头分别输出分割掩码与alpha抠图。

Result: SAMA在多个分割与抠图基准上达到SOTA性能，验证了其在下游任务中的有效性与泛化能力。

Conclusion: SAMA成功将高质量交互式分割与抠图集成于轻量统一框架中，仅需极少额外参数，为通用视觉基础模型拓展了新范式。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [75] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: 本文提出DC-VLAQ框架，通过残差引导的互补融合与向量局部聚合查询（VLAQ）机制，融合DINOv2和CLIP等视觉基础模型的互补特征，并提升全局表征在大视角变化、光照变化和域偏移下的鲁棒性与判别力。


<details>
  <summary>Details</summary>
Motivation: 现有VPR方法多依赖单一视觉基础模型，忽略不同模型间的互补性；而直接融合会改变token分布，破坏现有基于查询的全局聚合稳定性。

Method: 提出DC-VLAQ：1）残差引导的互补融合，以DINOv2为锚点，用可学习残差注入CLIP语义；2）向量局部聚合查询（VLAQ），利用局部token对可学习查询的残差响应进行稳定聚合。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED、AmsterTime等多个标准VPR基准上达到SOTA，尤其在严重域偏移和长期外观变化场景下优势显著。

Conclusion: 融合互补视觉基础模型并设计稳定的查询-残差聚合机制，能有效提升VPR系统在复杂现实条件下的鲁棒性与泛化能力。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [76] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

TL;DR: 本文提出了一种基于主成分分析（PCA）的太赫兹（THz）自监督去噪与去模糊网络（THz-SSDD），通过Recorrupted-to-Recorrupted自监督策略和PCA重建，无需标签即可同时处理THz图像中的低频模糊与高频噪声。


<details>
  <summary>Details</summary>
Motivation: 太赫兹系统固有地引入频率相关的退化效应，导致幅度图像中低频模糊和高频噪声并存；传统方法难以兼顾二者，且缺乏明确的去噪/去模糊边界，常需人工干预。

Method: 提出THz-SSDD网络：采用Recorrupted-to-Recorrupted自监督学习策略，利用重复加噪下的不变性建模噪声特性；结合PCA分解与重建，分别恢复低频（去模糊）与高频（去噪）分量。仅需少量未标注噪声图像进行训练。

Result: 在四类不同样品上验证有效；跨材料属性与测量模式测试表现鲁棒；定量分析表明图像质量提升，同时保持原始信号物理特性。

Conclusion: THz-SSDD是一种无需成对数据或先验知识、适用于多样化THz成像场景的端到端自监督图像复原方法，兼具去噪与去模糊能力。

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [77] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: 本文提出FiCoP框架，通过细粒度的块级对应匹配替代全局匹配，提升开放词汇6D物体位姿估计的鲁棒性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D位姿估计方法依赖全局匹配，在开放世界场景中易受背景干扰，导致目标特征混淆。

Method: 提出FiCoP框架：1）物体中心解耦预处理以分离语义目标与环境噪声；2）跨视角全局感知（CPGP）模块融合双视角特征并进行显式上下文推理；3）块相关性预测器（PCP）生成块级关联图作为空间滤波器，实现细粒度、抗噪匹配。

Result: 在REAL275和Toyota-Light数据集上，平均召回率分别提升8.0%和6.1%，显著优于当前最优方法。

Conclusion: FiCoP有效缓解了开放世界中背景干扰问题，提升了机器人在复杂无约束环境下的感知鲁棒性与泛化能力。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [78] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种空间和时间高效的大分辨率全切片图像（WSI）推理策略，通过空间感知的邻近块稀疏化注意力机制和基于全局注意力分数过滤非信息性token，显著降低GPU内存占用和运行时间，同时保持甚至提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型受限于固定输入尺寸（如224×224），难以高效处理高分辨率全切片图像（WSI）；直接放大输入导致GPU内存爆炸，而下采样则损失关键形态学细节。

Method: 提出一种高效的推理策略：利用空间感知的邻近块进行注意力稀疏化，并基于全局注意力分数过滤非信息性token。

Result: 在ROI分类任务上最高提升7.67%，分割任务性能保持相当；显著降低GPU内存与推理时间，支持更高分辨率推理。

Conclusion: 该方法在不增加硬件成本前提下，有效突破了病理模型对输入尺寸的限制，提升了WSI分析的效率与精度。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [79] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: 本文提出FantasyVLN，一种统一的隐式推理框架，通过将想象的视觉标记编码为紧凑潜在空间，避免显式链式推理（CoT）的令牌开销，在保持推理能力的同时实现视觉-语言导航（VLN）的实时性。


<details>
  <summary>Details</summary>
Motivation: 现有VLN中的链式推理方法存在两大问题：纯文本CoT缺乏空间定位且易过拟合；多模态CoT因生成想象视觉观测导致严重令牌膨胀，难以实时导航。

Method: 提出FantasyVLN框架，利用预训练视觉自回归模型（VAR）将想象视觉token编码至紧凑潜在空间，并在统一多CoT策略下联合学习文本、视觉和多模态CoT模式；推理时直接指令到动作映射，同时保留推理感知表征。

Result: 在LH-VLN基准上，该方法实现了推理感知与实时导航兼顾，成功率达提升，推理延迟比显式CoT方法降低一个数量级。

Conclusion: 隐式推理框架FantasyVLN有效克服了现有CoT方法在空间接地性和计算效率上的瓶颈，为人类水平的VLN提供了新路径。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [80] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

TL;DR: 本文提出了一种结合持久同调先验的协同逆向渲染方法，用于从多视角图像中鲁棒地重建高亏格3D物体，通过引入拓扑约束（如隧道环、手柄环）来缓解几何与拓扑歧义，并在网格优化框架下实现更准确、更鲁棒的重建。


<details>
  <summary>Details</summary>
Motivation: 3D物体重建本质上是病态问题，存在几何、外观和拓扑上的歧义，尤其难以恢复高亏格表面结构（如隧道、手柄），易发生拓扑崩溃。

Method: 在基于网格的逆向渲染框架中，采用梯度优化而非神经网络，融合多视角光度一致性损失与基于持久同调的拓扑先验（刻画隧道环、手柄环等关键特征），实现协同优化。

Result: 在Chamfer Distance和Volume IoU指标上优于现有网格基方法，显著提升几何精度并有效避免拓扑失败（如隧道坍塌、高亏格结构丢失）。

Conclusion: 拓扑先验（特别是持久同调）可作为强正则化工具，在无神经网络的优化框架中显著增强高亏格物体重建的准确性与鲁棒性。

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [81] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: 本文提出了VIRTUE，一种基于多模态大语言模型（MLLM）的通用视频检索框架，通过对比对齐视觉与文本嵌入，在零样本视频检索、片段定位和组合式多模态查询任务上均取得优异性能，且仅需少量数据高效微调。


<details>
  <summary>Details</summary>
Motivation: 现有专用视频检索系统虽性能强但无法处理组合式多模态查询；而MLLM方法支持丰富查询形式却检索性能较差。本文旨在弥合二者鸿沟，构建兼具灵活性与高性能的统一框架。

Method: 提出VIRTUE框架：采用共享MLLM主干网络生成视觉与文本嵌入，通过对比学习对齐；使用LoRA在700K图文对上高效训练嵌入模型；支持零样本检索与片段定位，并结合嵌入检索+重排序策略提升精度。

Result: 在零样本视频检索上超越其他MLLM方法；零样本片段检索达有竞争力水平；零样本组合式视频检索达SOTA；经重排序后整体性能媲美需海量数据训练的专用模型。

Conclusion: VIRTUE证明了MLLM架构在不牺牲检索性能前提下，可统一支持多种视频检索任务与复杂多模态查询，显著提升实用性与泛化能力。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [82] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: 本文提出SurgRef框架，利用运动线索而非静态外观实现手术视频中基于自然语言描述的器械指代表达与分割，解决了现有方法泛化能力差的问题，并构建了首个面向运动的多机构手术视频数据集Ref-IMotion。


<details>
  <summary>Details</summary>
Motivation: 现有手术视频中的指代表达分割方法依赖静态视觉特征和预定义器械名称，难以应对遮挡、歧义及术语不熟悉等挑战，缺乏对动态手术场景的建模能力。

Method: 提出运动引导的SurgRef框架，将自然语言表达与器械运动模式对齐；构建Ref-IMotion数据集，包含密集时空掩码和以运动为中心的语言描述。

Result: SurgRef在多种手术流程中实现了最先进的准确率与泛化性能，显著优于以往方法。

Conclusion: 基于运动理解语言驱动的手术视频分割是可行且有效的，为智能手术室和自主手术机器人提供了新范式。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [83] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 本文提出DiffusionQC，一种基于扩散模型的数字病理图像质量控制方法，仅需干净图像进行训练，无需像素级标注或预定义伪影类型，通过对比学习增强伪影与干净图像的分布分离，实现高效、泛化性强的伪影检测。


<details>
  <summary>Details</summary>
Motivation: 传统监督模型需要大量带标注的数据，资源消耗大且难以泛化到新型伪影；而数字病理图像中的制片和数字化伪影会影响下游分析可靠性，亟需更灵活、低标注依赖的质量控制方法。

Method: 提出DiffusionQC方法，利用扩散模型将伪影视为干净图像分布的异常值进行检测；引入对比学习模块，显式扩大伪影图像与干净图像在特征空间中的分布距离。

Result: 实验表明该方法性能优于现有最先进方法，具备跨染色泛化能力，且所需数据量和标注量显著减少。

Conclusion: DiffusionQC为数字病理图像质量控制提供了一种低标注依赖、高泛化性的新范式，有效缓解了标注瓶颈并提升了模型鲁棒性。

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [84] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

TL;DR: 本文提出PRISM框架，通过自适应视觉采样、标签驱动关键帧锚定和大语言模型上下文验证，实现语义 grounded 的视频摘要，在保持84%语义内容的同时仅采样不到5%的帧，性能优于基线最高达33%。


<details>
  <summary>Details</summary>
Motivation: 视频摘要对高风险领域（如外科培训）至关重要，现有方法从基础视觉特征发展到预训练视觉-语言模型，但仍需更精准捕捉程序性语义与时间流。

Method: 提出三阶段框架PRISM：1）自适应视觉采样；2）标签驱动的关键帧锚定；3）基于大语言模型的上下文验证，确保所选帧反映有意义的过程性转换并过滤泛化或幻觉内容。

Result: 在 instructional 和 activity 数据集上评估，仅采样<5%帧即保留84%语义内容，较基线提升最高达33%，且在语义对齐与精度上表现优异。

Conclusion: PRISM具有跨程序性和领域特异性视频任务的泛化能力，能生成上下文连贯、语义扎实的视频摘要。

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [85] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

TL;DR: 本文提出了一种融合金字塔自适应空洞卷积（PAAC）与Transformer架构的新型乳腺癌病灶检测框架，通过多尺度特征融合和Dice+Focal混合损失函数，在INbreast、MIAS和DDSM数据集上实现了98.5%准确率等优异性能，显著优于多种基线模型。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性中最常见的癌症之一，其准确及时诊断对改善治疗效果至关重要；现有方法在复杂场景和大规模数据下仍存在分类误差和长程依赖建模不足的问题。

Method: 提出融合PAAC与Transformer的框架，采用多尺度特征融合增强良恶性组织特征提取，并结合Dice Loss与Focal Loss优化二分类学习过程；数据来自INbreast、MIAS和DDSM，经数据增强、对比度增强及统一缩放到227×227进行训练。

Result: 在综合数据集上达到准确率98.5%、敏感性97.8%、特异性96.3%、F1-score 98.2%、精确率97.9%，性能优于BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet和SegFormer等模型。

Conclusion: 该模型具有高精度、高效率和强泛化能力，可作为可靠的辅助诊断工具集成至临床医疗系统。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [86] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: 本文提出FedDCG方法，在联邦学习框架下联合解决视觉语言模型（如CLIP）的类别泛化与域泛化问题，通过域分组训练、可学习网络增强类别泛化、知识解耦提升域泛化，并在多个数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有高效微调方法通常单独处理未见类别或未见域问题，缺乏联合解决二者的一致框架，尤其在联邦学习场景下更显不足。

Method: 提出FedDCG：1）域分组策略，组内训练类别泛化网络以避免决策边界混淆；2）使用可学习网络增强类别泛化能力；3）引入解耦机制分离通用与域特异性知识；4）基于域相似度聚合推理结果，融合类别与域泛化知识。

Result: 在多个数据集上的实验表明，FedDCG在准确率和鲁棒性方面均优于当前最优基线方法。

Conclusion: FedDCG为视觉语言模型在联邦学习环境下的类别与域联合泛化提供了有效且实用的新范式，兼顾效率与泛化能力。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [87] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

TL;DR: 本文提出AgenticPruner框架，利用大语言模型（LLM）实现乘加（MAC）操作约束下的神经网络剪枝，通过三个协同代理（Profiling、Master、Analysis）进行迭代策略学习，在保持或提升精度的同时精准控制计算量。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法主要关注参数量减少，难以满足部署中对推理延迟（即MAC操作数）的严格预算要求，缺乏直接控制计算成本的能力。

Method: 提出AgenticPruner框架，包含三个专用代理：Profiling Agent分析模型结构与MAC分布；Master Agent协调流程并监控发散；Analysis Agent（基于Claude 3.5 Sonnet）通过上下文学习从历史尝试中学习最优剪枝策略；结合等构剪枝的图结构分组，并引入跨迭代的上下文感知自适应机制。

Result: 在ImageNet-1K上验证：ResNet-50达1.77G MACs且精度+0.91%；ResNet-101达4.22G MACs且精度+1.56%；ConvNeXt-Small获1.41x GPU/1.07x CPU加速与45%参数减少；ViT类模型可在用户设定容差范围内（通常±1%~±15%）稳定满足MAC预算。

Conclusion: AgenticPruner首次将LLM驱动的多智能体协同机制引入MAC约束剪枝，显著提升收敛成功率（48%→71%），实现了计算预算可控、精度不降甚至提升的高效剪枝，为边缘部署提供可靠保障。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [88] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 本文提出CytoCLIP，一种基于CLIP框架的视觉-语言模型，用于自动识别脑组织切片中的细胞构筑区域，显著提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: 手动划分人脑不同区域的细胞构筑耗时且依赖专家知识，亟需自动化方法辅助。

Method: 构建两个CytoCLIP变体：分别基于低分辨率全区域图像和高分辨率图像块进行训练，使用NISSL染色的胎儿脑组织切片数据（涵盖不同孕周），学习视觉与文本的联合表征。

Result: 在区域分类任务中，CytoCLIP达到0.87（全区域）和0.91（图像块）的F1分数，优于现有方法；并在跨模态检索及跨年龄、跨切面泛化实验中表现优异。

Conclusion: CytoCLIP为脑细胞构筑自动分析提供了高效、鲁棒的新范式，具备良好的泛化能力和实际应用潜力。

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [89] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: 本文提出SDiT，一种语义区域自适应的扩散Transformer，通过训练免费的框架（包括语义感知聚类、复杂度驱动的区域调度和边界感知细化）在不修改模型结构或重新训练的前提下，实现最高3.0倍加速，同时保持与全注意力推理几乎相同的感知和语义质量。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers (DiTs)虽在文本到图像合成中性能领先，但因去噪迭代性和全局注意力的二次计算成本而计算开销大；作者观察到去噪动态在空间上非均匀，背景区域收敛快，而边缘和纹理区域变化更活跃，因此希望根据区域复杂度分配计算资源。

Method: 提出SDiT方法，包含三部分：(1) 基于快速Quickshift分割的语义感知聚类；(2) 复杂度驱动的区域调度，选择性更新信息丰富区域；(3) 边界感知细化以维持空间一致性；整个框架无需训练。

Result: SDiT在不重训练、不修改模型架构前提下，实现最高3.0倍推理加速，且感知质量（如FID、CLIP Score）和语义保真度与全注意力基准几乎一致。

Conclusion: 区域自适应计算分配是提升DiT推理效率的有效途径，SDiT验证了无需训练即可显著加速扩散Transformer，同时保持高质量生成效果。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [90] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 本文提出了一种基于辐射场与参数化人脸模型结合的新表示方法，用于高效经典渲染逼真3D人脸头像，支持可控体绘制和轻量级动画，并兼容传统图形平台。


<details>
  <summary>Details</summary>
Motivation: 现有方法在渲染高质量3D人脸头像时往往依赖复杂神经渲染或定制硬件/软件，难以在传统图形平台上高效部署和流式传输。

Method: 利用锚定在参数化人脸模型上的辐射场学习一组3D辐射流形，从中提取显式的分层网格及外观与形变纹理；部署时通过线性混合与alpha合成在静态网格上控制动画。

Result: 实现了对头发、皮肤、眼睛等复杂面部特征的可控体绘制；生成的头像可高效在线流式传输，并能在传统mesh/shader渲染管线中实时渲染。

Conclusion: 该显式分层表示兼顾了神经辐射场的表达能力与经典渲染的效率和兼容性，为3D人脸头像在广泛设备上的实际应用提供了新路径。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [91] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: 本文提出PCBM-ReD方法，通过表示分解将预训练黑盒模型改造为概念瓶颈模型，利用多模态大语言模型自动提取、标注和筛选视觉概念，并借助CLIP实现概念嵌入的线性分解，在11个图像分类任务上实现了SOTA精度与更强可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在关键领域部署受限于其不透明性；现有基于概念的解释方法存在概念相关性不可靠、概念定义非可视化或人工成本高、以及假设模型或数据无关等问题。

Method: 提出Post-hoc Concept Bottleneck Model via Representation Decomposition（PCBM-ReD）：1）从预训练编码器中自动提取视觉概念；2）用多模态大语言模型（MLLMs）对概念进行视觉可识别性与任务相关性标注与筛选；3）通过重建引导优化选择独立概念子集；4）利用CLIP的图文对齐能力，将图像表征分解为概念嵌入的线性组合，适配CBM抽象。

Result: 在11个图像分类任务上达到SOTA准确率，显著缩小与端到端模型的性能差距，并展现出更优的可解释性。

Conclusion: PCBM-ReD是一种有效的后验式概念瓶颈建模框架，兼顾高性能与强可解释性，克服了传统CBM和post-hoc方法的关键缺陷。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [92] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为2S-GDA的两阶段全局多样性攻击框架，用于提升黑盒场景下视觉-语言预训练（VLP）模型的对抗攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言多模态攻击方法存在扰动多样性不足和多阶段流程不稳定的问题，尤其在黑盒场景下鲁棒性差。

Method: 2S-GDA分为两个阶段：第一阶段采用全局多样性策略进行文本扰动，结合候选文本扩展与全局感知替换；第二阶段通过多尺度缩放和块重排旋转生成图像级扰动以增强视觉多样性。

Result: 在多个VLP模型上的实验表明，2S-GDA在黑盒设置下攻击成功率显著优于当前最优方法，最高提升达11.17%；且该框架模块化，可与其他方法组合以进一步提升迁移性。

Conclusion: 2S-GDA是一种有效、稳定且可扩展的多模态对抗攻击框架，为黑盒环境下VLP模型的安全性评估提供了新思路。

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [93] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的自适应多尺度相关元网络（AMC-MetaNet），用于解决遥感图像少样本学习中的标注数据稀缺、域偏移大和地物多尺度三大挑战，仅用约60万参数即在多个遥感数据集上达到最高86.65%的5-way 5-shot分类精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像少样本学习面临标注数据稀缺、域偏移大以及地物具有多尺度特性三大挑战。

Method: 提出AMC-MetaNet框架，包含三个创新：(i) 相关性引导的特征金字塔以捕获尺度不变模式；(ii) 自适应通道相关模块（ACCM）学习动态跨尺度关系；(iii) 相关性引导的元学习，替代传统原型平均。模型从零训练，参数仅约60万。

Result: 在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等多个遥感数据集上，5-way 5-shot分类准确率最高达86.65%，单图推理时间<50ms，参数量仅为ResNet-18的1/20。

Conclusion: AMC-MetaNet是一种计算高效、尺度感知强的少样本遥感学习框架，适用于真实场景部署。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [94] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 本文提出CurConMix+框架，通过课程引导的对比学习与多分辨率时序Transformer，解决手术动作三元组识别中的类别不平衡、视觉差异细微及语义依赖问题，并发布新基准LLS48，实现跨层级泛化。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对临床工作流分析和技能评估至关重要，但受限于严重类别不平衡、细微视觉差异及三元组组件间的语义互依性，现有方法难以联合应对这些挑战。

Method: 基于CurConMix空间表征框架，引入课程引导的对比学习策略（含结构化难样本采样与特征级mixup）；进一步提出CurConMix+，集成多分辨率时序Transformer（MRTT），自适应融合多尺度时序特征并动态平衡时空线索；同时构建新基准LLS48，提供分层标注（步骤/任务/动作级）。

Result: 在CholecT45和LLS48上实验表明，CurConMix+在三元组识别上超越SOTA，并展现出强跨层级泛化能力——其细粒度特征可有效迁移至更高层的阶段与步骤识别任务。

Conclusion: CurConMix+框架与LLS48数据集共同为层次感知、可复现且可解释的手术工作流理解提供了统一基础。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [95] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为S²F-Net的跨模型AI生成图像检测框架，通过挖掘真实与合成图像在频谱域的固有差异（尤其是上采样操作留下的频率指纹），并引入可学习的频率注意力模块，显著提升了对未见生成模型的泛化检测能力，在AIGCDetectBenchmark上达到90.49%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法易过拟合于特定源模型，面对未知生成架构时泛化能力差，亟需具有强泛化能力的检测方案。

Method: 提出S²F-Net框架，聚焦频域伪影检测；设计可学习的频率注意力模块，融合空间纹理分析与频谱依赖关系，自适应加权并增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net跨域检测准确率达90.49%，显著优于多种基线方法。

Conclusion: 频域特征（尤其是上采样引入的频率指纹）是提升AI生成图像检测泛化能力的关键线索，S²F-Net通过建模频谱差异实现了对未知生成模型的有效识别。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [96] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 本文提出了一种语义调制、多尺度Transformer模型用于3D视线估计，通过CLIP全局特征与可学习原型库（光照、头部姿态、背景、方向）结合，并融合原型增强的全局向量、CLIP patch token和高分辨率CNN token，在统一注意力空间中建模；同时引入路由/共享的Mixture of Experts（MoE）替代部分FFN模块以提升条件建模能力。在多个主流数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D gaze estimation方法在复杂场景下泛化性不足，难以有效建模光照、姿态、背景等语义因素对视线的影响，亟需更鲁棒、更具条件表达能力的架构。

Method: 提出语义调制多尺度Transformer：1）用可学习原型库（illumination/head pose/background/direction）调制CLIP全局特征；2）将原型增强的全局向量与CLIP patch tokens及高分辨率CNN tokens在统一注意力空间中融合；3）用routed/shared Mixture of Experts替换部分FFN块以增强条件建模能力。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze上分别取得2.49°、3.22°、10.16°和1.44°的平均角误差，相较先前最优结果最高提升64%；消融实验证明原型调制、跨尺度融合、MoE及超参均带来显著增益。

Conclusion: 语义调制与多尺度特征融合结合MoE机制，能显著提升3D gaze estimation模型在复杂真实场景下的鲁棒性与精度，为基于视觉的视线估计提供了新范式。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [97] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

TL;DR: 本文提出了一种基于超网络的轻量级描述符学习架构，用于提升多模态图像块匹配性能，尤其在可见光-红外（VIS-IR）跨模态匹配中达到SOTA，并开源了大规模跨平台VIS-IR数据集GAP-VIR。


<details>
  <summary>Details</summary>
Motivation: 提升多模态（如可见光与红外）图像块匹配的鲁棒性，应对外观变化带来的域偏移问题，同时保持推理效率。

Method: 在Siamese CNN基础上引入超网络模块（实现通道自适应缩放与偏移）和条件实例归一化（支持浅层模态特异性适配），并采用三元组损失与难负样本挖掘进行训练。

Result: 在VIS-NIR及其他VIS-IR基准上达到SOTA；在其他数据集上性能持平或超越更高计算开销的先前方法；发布新数据集GAP-VIR（50万对跨平台VIS-IR图像块）。

Conclusion: 超网络与条件归一化的结合可有效增强多模态描述符的泛化能力与鲁棒性，在低开销前提下显著提升跨模态匹配性能，并为域偏移研究提供高质量数据支撑。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [98] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: 本文提出EmoKGEdit，一种无需训练的图像情感编辑框架，通过构建多模态情感关联知识图谱（MSA-KG）实现情感与结构的解耦编辑，在保持图像结构完整性的同时提升情感表达准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以在潜在表示中解耦情感线索与内容信息，导致情感表达弱、视觉结构失真。

Method: 构建多模态情感关联知识图谱（MSA-KG），显式建模物体-属性-情感因果链，并作为外部知识支持思维链推理；设计解耦的结构-情感编辑模块，在潜在空间中分离情感属性与布局特征。

Result: EmoKGEdit在情感保真度和内容保留两方面均优于当前最优方法，实验验证其有效性。

Conclusion: EmoKGEdit是一种高效、无需训练的图像情感编辑新范式，兼顾情感精准性与结构一致性。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [99] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 本文提出了一种基于流匹配的轻量级内在图像分解（IID）方法FlowIID，通过VAE引导的潜在空间与流匹配模块结合，实现单步、参数高效且稳定的albedo与shading分解，在多个基准上达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有IID模型参数量大，难以在实际应用中与其他模型集成，亟需更轻量、高效的解决方案。

Method: 提出FlowIID架构，基于潜在流匹配（latent flow matching），结合VAE引导的潜在空间与流匹配模块，实现单步推理的内在图像分解。

Result: FlowIID参数量显著减少，单步推理，且在多个基准上达到与或优于现有方法的分解质量。

Conclusion: FlowIID是一种参数高效、稳定可靠、适合资源受限和实时视觉任务部署的新型IID方法。

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [100] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的高光谱异常检测方法Turbo-GoDec，通过引入异常像素的‘簇稀疏性’先验（即异常在空间上呈小簇状分布），改进经典GoDec算法中的S步，并结合马尔可夫随机场与因子图消息传递建模该先验，显著提升了小目标异常的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多依赖低秩背景和稀疏异常假设，但对异常的稀疏性仅作简单处理；而实际高光谱图像中异常常以空间聚簇形式出现（簇稀疏性），该特性未被充分利用。

Method: 将簇稀疏性先验嵌入GoDec算法的S步，利用马尔可夫随机场建模异常空间聚簇结构，并通过因子图上的消息传递计算各像素的异常概率，高概率位置构成稀疏分量。

Result: 在三个真实高光谱数据集上的实验表明，Turbo-GoDec在小尺寸异常检测上优于原始GoDec（LSMAD）及当前主流方法。

Conclusion: 引入簇稀疏性先验可有效提升高光谱异常检测精度，尤其针对空间聚集的小异常目标；Turbo-GoDec为高光谱异常建模提供了新思路。

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [101] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

TL;DR: 本文提出了MMDeepResearch-Bench（MMDR-Bench），一个面向端到端多模态深度研究代理的新型基准，包含140个跨21个领域的专家构建任务，并配套提出FLAE、TRACE和MOSAIC三套可解释、细粒度的评估方法，揭示当前模型在生成质量、引用规范性与多模态对齐之间存在系统性权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要面向纯文本或短格式多模态问答，缺乏对端到端多模态证据使用能力的评测，难以支撑深度研究代理（DRAs）的真实能力评估。

Method: 构建了MMDeepResearch-Bench多模态深度研究基准；设计了三套统一且可解释的评估方法：FLAE（报告质量）、TRACE（引用-证据对齐）、MOSAIC（图文一致性）；在25个SOTA模型上开展系统评测。

Result: 实验发现模型在生成质量、引用规范性和多模态对齐三方面存在系统性权衡；强文本生成能力不等于忠实使用证据；多模态完整性仍是深度研究代理的关键瓶颈。

Conclusion: MMDR-Bench及配套评估框架为多模态深度研究代理提供了更真实、更细粒度的能力评测标准，推动该方向向证据可信、图文一致、引用可追溯的方向发展。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [102] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: 本文提出SimpleMatch框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现高效语义匹配，显著降低计算开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模预训练模型的语义匹配方法依赖高分辨率输入，导致计算开销大；深层下采样造成相邻关键点特征不可逆融合，影响匹配精度。

Method: 提出SimpleMatch框架，包括：1）轻量级上采样解码器，将深层特征逐步上采样至1/4分辨率；2）多尺度监督损失，保证上采样特征在不同空间尺度下的判别性；3）稀疏匹配与窗口定位策略，优化显存使用并减少51%内存消耗。

Result: 在252×252分辨率（比当前SOTA小3.3倍）下，SimpleMatch在SPair-71k数据集上达到84.1% PCK@0.1，性能优于当前SOTA。

Conclusion: SimpleMatch为语义匹配提供了一个实用、高效的低分辨率基准框架，兼顾性能与效率，推动后续研究向更轻量、更实用方向发展。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [103] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++ 是一个面向农田开放环境的作物分割基础模型，通过构建大规模跨物种、跨场景数据集（28,406张图像，覆盖30+作物种类、15种环境），结合改进的ViT-Adapter架构与两阶段自训练策略，在多个挑战性场景下实现SOTA性能（93.11% mIoU）。


<details>
  <summary>Details</summary>
Motivation: 现有作物分割模型受限于昂贵的像素级标注成本，泛化能力差，难以适应多物种、多环境的开放农田场景；而通用视觉基础模型（如SAM）在农业任务上表现不佳。

Method: 基于前作DepthCropSeg，构建大规模跨物种跨场景作物分割数据集；改进ViT-Adapter架构，引入动态上采样提升细节感知能力；采用两阶段自训练策略进行模型训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和SAM（+48.57%）；在夜间（86.90%）、高密度冠层（90.09%）和未见品种（90.09%）等挑战场景中表现突出。

Conclusion: DepthCropSeg++确立了作物分割领域的新SOTA，验证了面向特定垂直领域构建基础模型的有效性，为农业智能化提供可靠感知基础。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [104] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 本文提出ScoreAD方法，利用基于分数的生成模型（SGM）学习高光谱图像数据分布的梯度场（score），结合高光谱流形假设，通过检测偏离背景流形的异常光谱实现异常检测。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的高维光谱实际上由少数因素（如化学成分、光照）决定，满足流形假设；而异常光谱因独特光谱特征偏离背景流形，需有效建模背景分布以区分异常。

Method: 基于高光谱流形假设，训练分数生成模型（SGM）拟合整幅图像光谱的分布；测试时对每个光谱施加扰动，输入SGM估计其score，利用score在流形结构上的差异进行异常打分。

Result: 在四个高光谱数据集上验证了ScoreAD的有效性，性能优于现有方法。

Conclusion: ScoreAD通过SGM建模背景光谱流形并利用score作为异常判据，为高光谱异常检测提供了新思路，具备理论依据与实验支撑。

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [105] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 本文评估了10种基础模型在皮肤病变分层分类中的表现，发现通用医学基础模型（如MedImageInsights）擅长二分类恶性筛查，但在细粒度40类子型分类上性能显著下降；而皮肤科专用模型（如Derm Foundation、MONET）则更擅长细粒度区分，揭示了模型能力存在‘粒度鸿沟’。


<details>
  <summary>Details</summary>
Motivation: 现有皮肤科基准测试多简化为扁平二分类任务（如黑色素瘤vs良性痣），无法反映临床所需的细粒度鉴别诊断能力，亟需更符合真实诊疗流程的分层评估框架。

Method: 在DERM12345数据集（含40个病变子类）上，提取10个跨领域基础模型（通用CV、通用医学影像、皮肤科专用）的冻结嵌入，训练轻量适配器，并采用五折交叉验证；提出覆盖4个临床粒度层级（40子类、15主类、2/4超类、二元恶性判断）的分层评估框架。

Result: MedImageInsights在二元恶性检测中F1达97.52%，但在40类细粒度分类中降至65.50%；MedSigLip（69.79%）及皮肤科专用模型（Derm Foundation、MONET）在40类任务上表现更优，但宏观分类性能弱于MedImageInsights。

Conclusion: 通用医学基础模型适用于高层次筛查，而细粒度诊断支持需依赖领域专用建模策略；‘粒度鸿沟’提示应根据临床任务层级选择或定制模型。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [106] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 本文提出了一种Class-Partitioned VQ-VAE（CPVQ-VAE）模型，结合Latent-space Flow Matching Model（LFMM），实现端到端的、无需外部数据库检索的3D点云场景生成，显著降低Chamfer和Point2Mesh误差。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法依赖外部对象数据库检索，而扩散模型生成的潜在特征难以被当前自编码器准确解码为符合目标类别的点云对象，尤其在复杂多类别场景中表现不佳。

Method: 提出Class-Partitioned VQ-VAE（CPVQ-VAE），采用按类别划分的码本（class-partitioned codebook）及类感知的运行平均更新策略防止码本坍缩；联合专为场景生成设计的Latent-space Flow Matching Model（LFMM）共同生成对象特征与类别标签，并通过类感知逆查表完成点云解码。

Result: 在复杂客厅场景上，Chamfer误差和Point2Mesh误差分别降低70.4%和72.3%，实现了高质量、纯点云的端到端场景生成。

Conclusion: CPVQ-VAE有效解决了多类别3D场景中潜在特征解码不准确的问题，消除了对外部对象数据库的依赖，为高质量、类别一致的点云场景生成提供了新范式。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [107] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

TL;DR: 本文综述了基于面部表情的情绪检测方法，对比分析了三种主流神经网络模型在三个多样化数据集上的性能，揭示了现有方法在跨数据集泛化、情绪识别难度不均及相似情绪区分方面的不足。


<details>
  <summary>Details</summary>
Motivation: 情绪检测是人机交互中的关键机器学习问题，但现有方法繁多且性能差异大，亟需系统性评估与比较。

Method: 选取三种最具代表性的神经网络模型，在三个图像数量丰富、多样性高的数据集上进行训练，并开展跨数据集测试等系列实验以评估性能。

Result: 实验发现现有方法存在显著弱点：不同数据集间性能差异大、特定情绪识别难度不均、难以区分语义相近的情绪（如惊讶与恐惧）。

Conclusion: 当前面部情绪检测方法在泛化能力与细粒度区分能力方面仍存在明显局限，需针对数据偏差和情绪混淆问题提出改进方案。

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [108] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 本文提出了一种基于最优传输（OT）理论的无监督稀疏特征匹配方法，利用相机几何中的直线约束（如对极距离和3D射线距离）构建代价函数，将匹配问题建模为可高效求解的（部分）分配问题，并扩展至分层OT以实现无监督目标匹配；在人脸分析中成功应用于不同关键点标注规范间的匹配。


<details>
  <summary>Details</summary>
Motivation: 立体视觉中的稀疏特征匹配（如人脸关键点）因参数敏感、遮挡、运动和相机畸变等因素而病态，亟需鲁棒且无需标注的匹配方法。

Method: 将相机投影点建模为（半）直线，引入对极距离和3D射线距离作为匹配质量度量，并以此构建（部分）最优传输问题的代价函数，转化为高效可解的分配问题；进一步推广为分层最优传输以支持无监督对象匹配。

Result: 所提算法在数值实验中实现了高效、鲁棒的特征与对象匹配，在人脸分析任务中成功匹配了不同定义的关键点集。

Conclusion: 基于最优传输与几何距离建模的框架有效缓解了稀疏立体匹配的病态性，为无监督、几何驱动的匹配提供了新范式。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [109] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: 本文提出SkeFi框架，利用跨模态知识迁移（从RGB到无线传感器）解决LiDAR/mmWave等非侵入式无线传感器在骨架估计中数据稀缺和噪声大的问题，通过改进的TC-AGC图卷积与双时间卷积增强时序建模，实现高精度骨架估计与动作识别。


<details>
  <summary>Details</summary>
Motivation: RGB相机在暗光环境性能差且存在隐私问题，限制其在智能家庭和医院的应用；而LiDAR和mmWave等无线传感器虽具潜力，但面临训练数据少、骨架关键点噪声大两大挑战。

Method: 提出跨模态知识迁移方法，将RGB模态的丰富知识迁移到无线传感器模态；设计增强型时序相关自适应图卷积（TC-AGC），引入帧间交互增强以应对帧缺失/不连续；采用双时间卷积强化多尺度时序建模。

Result: SkeFi在mmWave和LiDAR数据集上均达到当前最优性能（state-of-the-art）。

Conclusion: SkeFi有效克服了无线传感器模态下骨架估计数据稀缺与噪声干扰问题，验证了跨模态迁移与鲁棒时序建模对无线骨架动作识别的有效性，为隐私敏感场景提供了可行方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [110] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文综述了视觉语言模型（VLMs）对抗攻击防御的三类主要策略：训练时防御、测试时自适应防御和免训练防御，并分析其优缺点与挑战。


<details>
  <summary>Details</summary>
Motivation: VLMs（如CLIP）易受难以察觉的对抗攻击，威胁跨模态任务的性能与系统安全，亟需有效防御方法。

Method: 系统梳理并对比分析三类主流防御范式：训练时防御（如对抗微调）、测试时自适应防御（推理时参数更新）和训练-free防御（输入或特征层面扰动抑制）。

Result: 归纳了各类防御方法的最新进展、适用场景、计算开销与泛化能力差异，指出当前鲁棒性提升仍面临通用性、效率与理论保障等挑战。

Conclusion: 三类防御策略各有取舍；未来需兼顾鲁棒性、效率与通用性，推动理论与实践结合的新型防御框架发展。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [111] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 本文提出一个大规模、多源的电子显微镜（EM）细胞器实例分割基准数据集，包含超10万张2D图像、多种细胞类型和五类细胞器，并设计了连通性感知的3D标签传播算法（3D LPA）进行标注；实验表明现有主流模型（如U-Net、SAM变体、Mask2Former）在异质EM数据及具有长程结构连续性的细胞器（如内质网）上泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 现有EM细胞器分割基准数据集规模小、多样性低，难以反映真实世界数据的异质性和大尺度空间上下文，导致基于图像块的方法性能受限。

Method: 构建大规模多源多类EM实例分割基准数据集（>10万张2D图像），提出连通性感知的3D标签传播算法（3D LPA）生成初始标注并经专家修正；对U-Net、SAM变体、Mask2Former等SOTA模型进行系统评测。

Result: 现有模型在跨细胞类型泛化、长程结构（如内质网）分割方面表现差，暴露局部建模与全局形态建模之间的根本矛盾。

Conclusion: 需发展能建模长程结构连续性、适应真实世界变异性的新方法；该基准与标注工具将开源以推动领域发展。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [112] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

TL;DR: 本文提出DCAC（动态类感知缓存）方法，无需训练，在测试时通过为每个ID类别维护独立缓存来校准模型预测，显著提升OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: OOD样本在被模型高置信预测为同一类别时，视觉上彼此更相似，而非与真实ID样本相似；这一类特定现象启发了类感知缓存机制的设计。

Method: 提出DCAC模块：在测试阶段为每个ID类别动态维护一个缓存，存储高熵样本的视觉特征和预测概率；利用轻量两层模块融合缓存信息以校准原始预测；完全无需训练且兼容多种OOD检测方法（含单模态与视觉语言模型）。

Result: 在多个OOD基准（如ImageNet OOD）上显著提升现有方法性能，例如与ASH-S结合时FPR95降低6.55%；计算开销极小，具备良好泛化性与即插即用特性。

Conclusion: DCAC是一种简单、高效、训练无关的测试时校准方法，通过类感知缓存机制有效缓解模型对OOD样本的过度自信，为OOD检测提供了新思路。

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [113] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了Histopath-C基准和LATTE方法，用于提升医学视觉语言模型在组织病理学图像中的鲁棒性与测试时适应能力。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像存在染色、污染、模糊和噪声等严重域偏移问题，导致现有视觉语言模型性能下降。

Method: 构建了模拟真实分布偏移的Histopath-C基准，并提出一种基于多文本模板的低秩转导式适应策略LATTE，用于测试时自适应。

Result: LATTE在多个组织病理学数据集上优于面向自然图像的先进测试时适应方法。

Conclusion: 针对组织病理学图像设计的测试时适应方法能显著提升视觉语言模型的鲁棒性与泛化能力。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [114] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 本文提出了一种基于移动无人机视频的密集人群计数与跟踪新方法，构建了大规模数据集MovingDroneCrowd++，并设计GD3A（密度图分解）与DVTrack（描述符投票跟踪）两个模型，在计数误差和跟踪性能上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有密集人群计数与跟踪方法依赖固定摄像头数据集，空间覆盖有限，难以应对大场景、高密度、动态视角等复杂条件；需面向移动无人机视频的新方法与基准数据集。

Method: 提出GD3A方法：基于全局密度图，利用最优传输与自适应‘尘 bin’分数建立跨帧像素级行人描述符对应关系，将密度图分解为共享、流入、流出三部分；进一步提出DVTrack，通过描述符投票机制实现从描述符匹配到实例级跟踪的转换。

Result: 在自建MovingDroneCrowd++数据集上，所提方法显著超越现有方法：计数误差降低47.4%，跟踪性能提升39.2%。

Conclusion: 基于移动无人机的视频级密集人群分析是可行且有效的；密度图分解与描述符关联策略能有效应对视角变化、遮挡与高密度挑战，为大范围动态人群理解提供了新范式。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [115] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为SDCoNet的多任务协同网络，通过隐式特征共享耦合超分辨率（SR）与目标检测任务，利用Swin Transformer编码器、多尺度显著性预测模块和梯度路由策略，显著提升了低质量遥感图像中小目标检测的精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中复杂背景、弱目标信号和小目标尺度导致检测困难，尤其在成像质量差时；传统串行SR+检测流程存在优化目标不一致、特征冗余及任务间交互不足等问题。

Method: 提出Saliency-Driven multi-task Collaborative Network（SDCoNet）：采用Swin Transformer共享编码器实现跨任务特征协作；引入多尺度显著性预测模块选择关键token以聚焦弱目标区域并抑制背景干扰；设计梯度路由策略，先稳定检测语义，再将SR梯度沿检测导向路径传播，使SR生成对检测有益的高频细节。

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split等公开数据集上，SDCoNet在保持计算效率的同时，显著优于现有主流方法，尤其在低质量遥感图像的小目标检测任务上性能突出。

Conclusion: SDCoNet通过任务协同建模、显著性引导注意力与检测导向的梯度优化，有效缓解了SR与检测之间的优化冲突与特征冗余问题，为低质遥感图像中小目标检测提供了高效且鲁棒的新范式。

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [116] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 本文提出了一种基于Cycle-GAN的无监督医学图像域自适应方法，用于解决MRI跨设备/机构成像差异导致的模型性能下降问题，无需配对数据即可实现保持解剖结构的双向域映射。


<details>
  <summary>Details</summary>
Motivation: MRI扫描在不同设备或机构间存在域偏移（硬件、协议、参数差异），导致源域训练的深度学习模型在目标域图像上性能下降。

Method: 提出一种基于Cycle-GAN的无监督域自适应模型，引入内容损失和差异损失，在无配对数据条件下学习源域与目标域间的双向映射，以保持图像解剖结构完整性。

Result: 在多个MRI数据集上的实验表明，该方法能有效实现无标签的双向域自适应；统计结果证实其提升了模型性能并降低了域相关变异性。

Conclusion: 该方法有助于提升医疗影像分析的精确性与一致性，并为提高临床诊断准确性提供了新路径。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [117] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: 本文提出XRefine，一种与检测器无关的亚像素关键点精化方法，通过交叉注意力机制仅基于图像块预测精化坐标，提升3D视觉任务中的几何估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有关键点检测器常产生空间不准确的匹配，而现有精化方法依赖特定检测器、需重新训练，缺乏通用性。

Method: 提出XRefine，一种基于交叉注意力的、仅输入匹配关键点中心图像块的检测器无关精化架构，可扩展至多视角特征轨迹。

Result: 在MegaDepth、KITTI和ScanNet上实验表明，XRefine持续提升几何估计精度，性能优于现有方法且保持运行高效。

Conclusion: XRefine实现了跨关键点检测器的通用、高效、高精度亚像素关键点精化，为稀疏关键点匹配提供了新范式。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [118] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 本文介绍了BirdsEye-RU数据集，一个包含2978张图像、八千多个标注人脸的俯视图像数据集，旨在解决高空图像中因尺度变化大和环境杂乱导致的人脸检测难题。


<details>
  <summary>Details</summary>
Motivation: 解决俯视图像中因极端尺度变化和环境杂乱带来的人脸检测困难问题。

Method: 构建并详细描述了BirdsEye-RU数据集，包含无人机和高海拔智能手机拍摄的图像，涵盖多种环境下的小而远的人脸。

Result: 发布了包含2978张图像、超八千个人脸标注的公开数据集，并提供Kaggle下载链接。

Conclusion: BirdsEye-RU数据集为高空场景下的人脸检测研究提供了重要资源，推动该方向的数据驱动方法发展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [119] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 本文提出了一种基于自监督眼动重建的新型注视检测模型，利用大規模未標註視頻數據進行預訓練，並在 Holocaust 幸存者視頻訪談中驗證其對情緒表達（如語音情緒方向、笑/哭/嘆氣）的預測能力，結果顯示預訓練效果與下游情緒任務表現呈正相關。


<details>
  <summary>Details</summary>
Motivation: 現有眼動-情緒關聯研究多依賴高精度專業設備，限制了實際應用範圍；本文旨在探索如何僅用自然、低分辨率視頻中的眼動信息來預測多模態情緒表達。

Method: 基於語言模型預訓練思想，設計自監督眼動重建任務以利用大量無標註視頻；提取模型編碼器嵌入，分別微調用於：1）將眼動與語音情緒方向對齊；2）預測笑、哭泣/嗚咽、嘆氣三種瞬時情緒行為。

Result: 所提模型能有效預測情緒相關下游任務；且預訓練階段的眼動重建性能與兩個情緒任務的表現均呈正相關。

Conclusion: 自監督眼動重建是一種有效編碼眼動所攜帶情感信號的方法，為低成本、可擴展的情緒分析提供了新途徑。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [120] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE is a physics-informed deep ghost imaging framework designed for low-bandwidth edge perception, enhancing classification accuracy and reducing variance through adjoint operator initialization and semantic guidance.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of low-bandwidth edge perception in ghost imaging.

Method: Combines adjoint operator initialization with semantic guidance within a physics-informed deep learning framework.

Result: Improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

Conclusion: PISE effectively enhances performance in low-bandwidth edge perception scenarios.

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [121] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: 本文提出了一种新的PnP算法PnP-ProCay78，用于平面场景下的相机位姿估计，结合Cayley旋转参数化与最小二乘优化，并通过确定性初值选择避免全局搜索，在精度上媲美SQPnP、略优于IPPE，同时结构更简洁、几何意义清晰、教学直观。


<details>
  <summary>Details</summary>
Motivation: 解决平面Perspective-n-Point（PnP）问题，尤其关注标定物体位姿的初始估计；现有方法常依赖耗时的解空间搜索或牺牲几何直观性。

Method: 提出PnP-ProCay78算法：采用Cayley参数化表示旋转，以二次型重构误差为基准构建目标函数；通过分析两个典型向量的重构误差，确定性地选取优化初值；并创新性地解析消去平移变量，形成投影误差与重构误差代理项融合的混合代价函数。

Result: 在RGB与低分辨率热成像（RGB-IR）数据上的实验表明，该算法投影精度与最优SQPnP相当、略高于IPPE，但算法结构显著简化；优化轨迹在Cayley空间中呈现良好收敛性与可解释性。

Conclusion: PnP-ProCay78是一种兼顾高精度、高效率、几何透明性与教学可用性的新型平面PnP求解器，为多传感器标定与轻量化视觉系统提供了实用新方案。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [122] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

TL;DR: 本文提出了一种线性空间ID机制，揭示了视觉语言模型（VLMs）如何通过将空间ID线性绑定到文本激活来编码物体位置并进行时空推理，并验证其因果作用与诊断价值。


<details>
  <summary>Details</summary>
Motivation: VLMs具备时空推理能力，但其内在机制尚不明确；作者假设视觉/几何与文本的空间结构表征需在某处融合，并试图定位并验证该融合点的因果解释力。

Method: 通过分析VLM内部表征，识别出线性绑定的空间ID机制；利用因果干预实验验证其在中间层对模型信念的调控作用；扩展至视频VLM，发现类似的时间ID机制。

Result: 证实VLMs以线性方式将空间ID绑定到文本激活以编码位置，并以此支持推理；空间ID具有跨层普遍性、可干预性和诊断价值；视频VLM中存在类比的时间ID机制。

Conclusion: 空间（及时间）ID是一种关键且可解释的内部机制，有助于提升VLM的可解释性、对齐性与能力设计。

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [123] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: 本文提出并分析了基于Swin-Transformer的U-Net模型（Swin-BathyUNet）用于卫星遥感测深，通过光谱消融、注意力可视化（A-CAM-R）和跨区域泛化实验，揭示其深度推理机制与可靠性边界，并给出提升鲁棒性和迁移能力的实用建议。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星遥感测深（SDB）在不同地点间难以稳健部署，亟需理解模型如何推断水深及其预测可信度。

Method: 采用Swin-Transformer增强的U-Net架构（Swin-BathyUNet）；开展留一谱段消融分析谱带重要性；提出面向回归任务的消融CAM（A-CAM-R）并用性能保留测试验证其可靠性；进行跨区域推理实验；分析注意力机制作用及深度依赖误差模式。

Result: 证实绿/蓝波段对浅水光学最敏感；A-CAM-R能准确定位模型依赖的关键像素；解码器中跳连引导的交叉注意力显著提升抗耀斑/泡沫鲁棒性；跨区域泛化性能随水深线性下降，双峰深度分布加剧中深层误差。

Conclusion: 模型性能高度依赖光谱信息质量、感受野大小与辐射保真度；需预滤近岸高亮噪声、精细调优目标站点并结合深度感知校准，方能实现可靠跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [124] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 本文提出了一种面向PointPillars的混合精度量化框架，通过敏感层识别与小样本校准缓解LIDAR点云数据分布宽、异常值多导致的量化性能下降问题，在保持检测精度的同时显著降低模型延迟和体积。


<details>
  <summary>Details</summary>
Motivation: LIDAR 3D目标检测需实时性，但直接量化易因点云数据数值分布广、异常值多而导致性能下降。

Method: 提出混合精度框架：先用PTQ逐层量化并评估AP以识别top-k敏感层（保留FP），再贪心搜索组合并分别采用PTQ或QAT微调；同时发现使用极少量校准数据可规避异常值、提升PTQ效果。

Result: PTQ流程无需训练即可生成混合精度模型；QAT流程达到接近全精度（FP）模型的性能；TensorRT部署下，模型延迟和体积分别减少至原来的1/2.35和1/2.26。

Conclusion: 该方法在不显著牺牲检测精度的前提下，有效提升了LIDAR 3D检测模型的推理效率与部署可行性。

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [125] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 本文探讨了在非独立同分布（non-IID）联邦学习场景下，针对癌症组织病理学图像的超参数迁移与聚合策略，提出一种简单有效的跨数据集配置融合方法，在卵巢癌和结直肠癌二分类任务中实现了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症组织病理学训练中面临临床数据隐私约束，联邦学习虽可保留数据本地性，但其性能高度依赖于非IID数据下的超参数选择，而现有优化方法缺乏跨数据集泛化能力。

Method: 采用集中式贝叶斯超参数优化获取单个数据集的最优配置，再将这些配置迁移至non-IID联邦学习环境；提出一种跨数据集聚合启发式方法——平均学习率、取众数优化器和批量大小。

Result: 所提出的组合配置在卵巢癌和结直肠癌的联邦二分类任务中达到具有竞争力的分类性能。

Conclusion: 针对non-IID联邦病理图像分析，特定数据集优化的超参数具有一定可迁移性，且简单聚合策略即可获得良好性能，为低开销FL部署提供了实用方案。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [126] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经隐式表示的单图像彩色光度立体方法，适用于近场照明和非朗伯表面，在单次拍摄下实现高精度表面重建，并通过自研光学触觉传感器验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有彩色光度立体方法多假设理想远场照明和朗伯反射，难以应对更实际的近场照明和非朗伯表面问题。

Method: 提出基于神经隐式表示的深度与BRDF联合建模框架，引入单色性假设（均匀色度与同质材质）缓解病态性，并设计紧凑型光学触觉传感器进行实验验证。

Result: 在合成与真实数据集上均实现了准确、鲁棒的表面重建效果。

Conclusion: 该方法突破了传统彩色光度立体对理想条件的依赖，显著提升了单图像动态场景表面重建的实用性与精度。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [127] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 本文研究了在联邦学习（FL）框架下，使用卷积神经网络（CNN）进行脑肿瘤MRI图像分类时，图像预处理与测试时增强（TTA）对模型性能的影响，发现TTA显著提升性能，预处理仅在结合TTA时带来额外增益。


<details>
  <summary>Details</summary>
Motivation: 高效准确的脑肿瘤诊断对早期治疗至关重要，但因病灶形态多变和医学影像复杂，实现困难；同时，医疗数据隐私限制使得联邦学习成为有前景的分布式训练范式，但其在MRI分类中的实际优化策略尚不明确。

Method: 在联邦学习设置下评估多种CNN模型，对比原始MRI图像与经过缩放、灰度化、归一化、滤波和直方图均衡化等预处理后的图像效果，并引入测试时增强（TTA）进行联合分析，采用统计检验（p值）验证性能差异显著性。

Result: 单独预处理带来的性能提升可忽略不计；而TTA显著且一致地提升了联邦学习下的MRI分类准确率（p<0.001）；轻量级预处理与TTA联用可进一步提供稳定、可靠的性能增益。

Conclusion: 在基于联邦学习的医学影像推理中，TTA应作为默认策略；若计算资源允许，可辅以轻量预处理以获得额外可靠提升。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [128] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: 本文提出VILTA框架，将视觉语言模型（VLM）嵌入自动驾驶闭环训练中，通过直接编辑周围智能体的未来轨迹来生成多样化、高挑战性的长尾场景，显著提升策略的安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶安全部署受长尾问题制约，即罕见但关键的驾驶场景在真实数据中严重不足；现有方法（如基于规则、重采样或离线训练的生成模型）难以生成足够多样和新颖的挑战性场景。

Method: 提出VILTA（VLM-In-the-Loop Trajectory Adversary）框架，将VLM直接嵌入AD闭环训练环，使其理解动态驾驶环境，并精细编辑周围智能体的未来轨迹，从而主动构造挑战性场景。

Result: VILTA能生成更丰富、更合理且更具挑战性的场景课程，显著提升自动驾驶策略在长尾关键事件中的安全性与鲁棒性。

Conclusion: 将VLM深度融入闭环训练而非仅作为场景描述生成器，可突破下游模型泛化瓶颈，为解决自动驾驶长尾问题提供新范式。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [129] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出了一种融合-恢复图像处理方法，用于抑制高温结构变形测量中热辐射和热晕引起的图像退化，从而提高数字图像相关法（DIC）的测量精度和有效性。


<details>
  <summary>Details</summary>
Motivation: 高温结构变形测量中，热辐射导致图像退化、热晕引入随机误差，限制了DIC测量的精度和有效性。

Method: 针对热辐射，采用基于图像分层表示的正负通道并行处理与多曝光图像融合优化图像质量；针对热晕引起的高频随机误差，以FSIM为优化目标函数迭代优化模型参数，并结合灰度平均算法均衡异常灰度值。

Result: 多曝光图像融合将欠曝光和过曝光图像的有效计算区域分别从26%提升至50%、32%提升至40%；图像恢复结合灰度平均算法使ε_xx、ε_yy和γ_xy的静态热变形测量误差分别降低85.3%、36.0%和36.4%。

Conclusion: 所提图像处理方法可有效抑制热辐射与热晕干扰，显著提升图像质量与变形测量精度，在热变形测量中具有应用潜力。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [130] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为GaussianTrimmer的在线边界修剪方法，用于提升基于3D高斯的场景分割效果，通过虚拟相机生成与像素级2D分割结果引导的高斯体素裁剪，实现对粗糙边界的精细化处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯的分割方法直接在高斯基元上进行，因高斯尺度变化大、易跨前景背景，导致分割边界锯齿状、不精确。

Method: 提出GaussianTrimmer：1）生成均匀覆盖的虚拟相机；2）基于各虚拟视角下的2D分割结果，在原始高斯基元层面进行裁剪。该方法为即插即用式后处理。

Result: 大量定量与定性实验证明，GaussianTrimmer能显著提升多种现有3D高斯分割方法的边界质量，且无需重新训练模型。

Conclusion: GaussianTrimmer是一种高效、通用、无需训练的后处理方案，有效缓解了3D高斯表示中因尺度差异导致的分割边界不准确问题，提升了3D场景语义分割的实用性。

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [131] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 本文提出了一种新的红外-可见光高斯融合（IVGF）框架，通过从多模态2D图像重建场景几何并直接渲染融合图像，解决了传统2D融合方法忽略场景几何理解而导致信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有2D红外-可见光融合方法局限于固定视角，缺乏对复杂场景的几何理解，导致关键场景信息丢失。

Method: 提出IVGF框架，包含跨模态调整（CMA）模块以调节高斯不透明度解决跨模态冲突，并设计融合损失函数指导CMA优化以保留双模态特征。

Result: 大量定性和定量实验验证了所提方法在融合效果上的有效性。

Conclusion: IVGF框架通过引入场景几何建模与高斯渲染机制，显著提升了红外-可见光图像融合的质量与信息保真度。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [132] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: 本文提出P2L-CA框架，通过Prompt-to-Label模块和Continuous Adapter模块实现参数高效、无记忆缓冲的多标签类增量学习，在MS-COCO和PASCAL VOC上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在计算开销大、存储负担重、特征混淆与域偏移难以缓解等问题。

Method: 提出P2L-CA框架：P2L模块利用类别特定提示解耦多标签表征并引入语言先验保障语义-视觉对齐；CA模块采用轻量适配器缓解预训练模型与下游任务间的域差距。

Result: 在MS-COCO和PASCAL VOC的标准及挑战性MLCIL设定下，P2L-CA大幅超越SOTA方法，同时具备强CIL泛化能力，仅需极少可训练参数且无需内存缓冲。

Conclusion: P2L-CA是一种高效、鲁棒且实用的多标签类增量学习新范式，兼顾性能、效率与可扩展性。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [133] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 本文提出了一种面向声纳图像小样本目标检测的教师-学生框架RSOD，通过可靠性评分、对象混合伪标签和可靠性引导的自适应约束，仅用5%标注数据即达到全监督基线性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像纹理少、噪声大，非专家难以精确标注，导致标注数据极度稀缺，亟需适用于极少量标签的检测方法。

Method: 提出RSOD教师-学生框架：1）基于教师模型多视角预测一致性计算可靠性得分；2）引入对象混合伪标签策略生成高质量伪标签；3）设计可靠性引导的自适应约束优化学生模型。

Result: 在UATD数据集上，仅使用5%标注数据即达到与100%标注基线模型相当的性能；并构建了一个新的声纳图像数据集。

Conclusion: RSOD有效缓解了声纳图像标注稀缺问题，显著提升了小样本条件下的检测性能，为水下探测提供了实用可行的技术方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [134] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一种面向移动端的流式视频生成扩散Transformer，通过混合高效注意力机制（LCHA与SSA）和“三明治”结构设计，在保持高保真度的同时显著提升推理效率，并借助2-in-1蒸馏框架将大模型能力迁移到轻量模型，实现在iPhone上超10 FPS的实时流式生成。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers（DiTs）虽提升了视频生成质量，但计算开销大，难以在移动设备上实时运行。

Method: 提出S2DiT：采用LinConv Hybrid Attention（LCHA）和Stride Self-Attention（SSA）构成的混合高效注意力；通过预算感知的动态规划搜索发现‘三明治’结构；设计2-in-1蒸馏框架，将大教师模型（如Wan 2.2-14B）能力迁移至紧凑的少步数三明治模型。

Result: S2DiT在iPhone上实现超10 FPS的流式视频生成，质量媲美当前最优服务器端视频模型。

Conclusion: S2DiT在移动硬件上实现了高效、高保真、流式视频生成的突破，验证了轻量化扩散Transformer架构与知识蒸馏协同优化的有效性。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [135] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: 本文提出KaoLRM方法，利用大型重建模型（LRM）的预训练3D先验，结合FLAME模型与2D高斯溅射技术，提升单图参数化3D人脸重建的跨视角一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于3DMM的人脸重建方法在不同视角下一致性差，尤其面对自遮挡和视角变化时性能下降。

Method: 将LRM预训练的三平面特征投影至FLAME参数空间以恢复几何结构，并用与FLAME网格紧密耦合的2D高斯原语建模外观；引入FLAME驱动的2D高斯溅射到LRM渲染流程中。

Result: 在受控及野外数据集上均显著优于现有方法，重建精度更高、跨视角一致性更强，对自遮挡和视角变化更鲁棒。

Conclusion: KaoLRM成功迁移LRM的强3D先验至参数化人脸重建任务，在保持FLAME可解释性的同时大幅提升重建质量与泛化能力。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [136] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种面向MRI图像的自监督预训练Transformer（SSPFormer），通过逆频率投影掩码和频域加权FFT噪声增强，有效学习医学图像的结构感知与伪影鲁棒特征，在分割、超分辨和去噪任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer直接迁移到MRI面临两大挑战：难以适应医学解剖结构特异性，以及医疗数据隐私性强、标注稀缺。

Method: 提出SSPFormer模型；引入逆频率投影掩码，优先重建高频解剖区域以实现结构感知表征学习；采用频率加权FFT噪声增强，在傅里叶域注入生理合理噪声以提升对真实MRI伪影的鲁棒性。

Result: 在MRI分割、超分辨率和去噪任务上均取得当前最优性能，验证了其对细粒度图像保真度的建模能力及临床适用性。

Conclusion: SSPFormer通过自监督方式从原始MRI扫描中学习到领域不变且抗伪影的特征表示，为医疗影像AI提供了高效、隐私友好的预训练范式。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [137] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出Moaw框架，通过监督训练提升视频扩散模型的运动感知能力，并实现零样本运动迁移。


<details>
  <summary>Details</summary>
Motivation: 受视频扩散模型在零样本任务（如光流预测和跟踪）中表现出的帧间特征对应能力启发，探索如何通过监督训练更充分地挖掘其跟踪能力。

Method: 提出Moaw框架：1）训练一个专用于运动感知的扩散模型，将模态从图像到视频生成转变为视频到稠密跟踪；2）构建运动标注数据集识别强运动信息特征；3）将这些特征注入结构相同的视频生成模型，利用网络同质性实现零样本运动迁移。

Result: 实现了无需额外适配器的零样本运动迁移，验证了视频生成与运动理解可统一建模。

Conclusion: 本工作为连接生成建模与运动理解提供了新范式，推动更统一、可控的视频学习框架发展。

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [138] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: 本文提出了一种去偏的无源目标检测（DSOD）框架，利用视觉基础模型（VFM）缓解源域偏差问题，通过统一特征注入（UFI）和语义感知特征正则化（SAFR）提升跨域泛化能力，并设计了无需VFM的蒸馏变体DSOD-distill。


<details>
  <summary>Details</summary>
Motivation: 现有无源目标检测（SFOD）方法存在源域偏差问题，导致模型在目标域上泛化能力差、自训练中误差累积。

Method: 提出DSOD框架：1）统一特征注入（UFI）模块，结合简单尺度扩展（SSE）和域感知自适应加权（DAAW），将VFM特征融入CNN主干；2）语义感知特征正则化（SAFR）约束特征学习以防止过拟合源域；3）为计算受限场景设计VFM-free变体DSOD-distill，采用双教师蒸馏机制。

Result: 在多个基准测试中超越现有SFOD方法：正常到雾天天气适应达48.1% AP，跨场景适应达39.3% AP，合成到真实数据适应达61.4% AP。

Conclusion: DSOD有效缓解了源域偏差，显著提升了无源跨域目标检测性能，且具备计算友好的变体设计，具有实用价值和推广潜力。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [139] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

TL;DR: 本文提出Spatial-VLN框架，通过空间感知增强与多专家推理模块，解决零样本视觉-语言导航中门交互、多房间导航和指令歧义等空间感知瓶颈，在VLN-CE基准和真实场景中均取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的零样本视觉-语言导航（VLN）方法在复杂连续环境中因空间感知能力不足，在门交互、多房间导航和模糊指令执行等关键空间任务上失败率高。

Method: 提出Spatial-VLN框架：1）空间感知增强（SPE）模块，融合全景过滤与专用门/区域专家，生成跨视角一致的空间表征；2）探索式多专家推理（EMR）模块，采用并行LLM专家分别处理航点语义与区域空间转移，并引入查询-探索机制主动消除感知歧义；另设计基于价值的航点采样策略以缩小仿真到现实差距。

Result: 在VLN-CE基准上达到SOTA性能，仅使用低成本LLM；真实世界实验验证了其在复杂环境中的强泛化性与鲁棒性。

Conclusion: Spatial-VLN通过感知引导的探索范式有效缓解了VLN中关键空间感知瓶颈，显著提升了零样本设置下在仿真与真实环境中的导航性能与实用性。

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [140] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

TL;DR: 本文提出了HVP-Net（分层视觉感知网络），通过从视觉编码器多个中间层提取并精炼特征，缓解视频冗余问题，提升视频-文本检索性能，在MSRVTT、DiDeMo和ActivityNet等基准上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP等预训练模型的视频-文本检索方法受限于视频固有的冗余性及仅使用粗粒度最终层特征，导致匹配精度不足。

Method: 提出HVP-Net框架，从视觉编码器多个中间层提取patch-token，并在不同语义层级上渐进式蒸馏显著视觉概念，以缓解冗余并保留对跨模态对齐关键的细节。

Result: 在MSRVTT、DiDeMo和ActivityNet等主流视频-文本检索基准上取得新的SOTA性能。

Conclusion: 利用视觉编码器的分层特征能有效提升视频-文本检索效果，验证了分层语义建模的重要性。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [141] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于单张图像实时生成可驱动3D全头动画头像的新框架，利用预训练3D GAN先验和UV空间高斯建模实现高质量重建与360°渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大视角变化下表现不佳，难以兼顾真实感与实时动画能力。

Method: 在UV空间中以高斯原语嵌入参数化人脸模型表面实现高效动画控制；利用预训练3D GAN提取全局全头特征并引入多视角监督；结合UV空间对称性融合局部图像特征与全局纹理。

Result: 实现了单次前向传播下的高质量3D全头建模、实时动画与360°同步渲染，显著提升说话头像真实感。

Conclusion: 该方法有效解决了单图生成可驱动全头3D头像的挑战，在重建质量、动画效率与视角自由度方面取得显著提升。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [142] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: 本文提出RetCLIP，一种基于检索增强的开放词汇全景分割方法，通过构建掩码片段特征数据库并在推理时进行相似性检索，结合CLIP得分提升对未见类别的分割性能，在ADE20k上显著超越基线。


<details>
  <summary>Details</summary>
Motivation: 现有全景分割模型在训练数据外的未见类别上泛化能力差，难以支持开放词汇场景下的灵活分割需求。

Method: 构建基于图像-文本配对数据的掩码片段特征数据库；推理时以输入图像的掩码片段特征为查询键，检索相似特征及对应类别标签，并基于相似度生成分类得分；将检索得分与CLIP得分融合得到最终输出；集成于SOTA方法FC-CLIP中。

Result: 在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线提升+4.5 PQ、+2.5 mAP、+10.0 mIoU。

Conclusion: RetCLIP通过检索增强机制有效提升了开放词汇全景分割对未见类别的泛化能力，验证了外部语义知识引入对视觉任务的重要作用。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [143] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为SKANet的认知深度学习框架，用于在复杂电磁环境中准确分类GNSS复合干扰信号。该框架采用双流结构融合时频图（TFI）和功率谱密度（PSD），结合选择性核（SK）模块、非对称卷积块（ACB）和Squeeze-and-Excitation（SE）机制，实现多尺度特征自适应提取与异构模态特征动态加权融合，在40.5万样本数据集上达到96.99%的分类准确率，尤其在低JNR下鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 现有单域深度学习方法难以兼顾瞬态突发信号与连续全局信号所需的冲突特征尺度，导致对复合干扰（多种干扰叠加）分类性能下降。

Method: 提出SKANet：基于双流架构融合时频图（TFI）和功率谱密度（PSD）；引入多分支选择性核（SK）模块与非对称卷积块（ACB）实现动态可调感受野；在融合阶段嵌入Squeeze-and-Excitation（SE）机制以自适应重标定异构模态特征贡献。

Result: 在405,000样本数据集上，SKANet整体分类准确率达96.99%，在低Jamming-to-Noise Ratio（JNR）条件下展现出优于现有方法的鲁棒性。

Conclusion: SKANet通过空间-时间自适应特征提取与异构模态智能融合，有效解决了复合干扰分类中多尺度特征冲突问题，为GNSS抗干扰提供了高性能认知识别新范式。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [144] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Jo-SNC的噪声鲁棒方法，通过联合样本选择与模型正则化（基于自一致性与邻居一致性）来应对标签噪声问题，尤其关注分布内/外噪声的区分与处理，并在多个基准数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 深度网络易受标签噪声影响，现有方法常忽略不同小批量中噪声分布的不平衡性，且对分布外噪声关注不足。

Method: 提出Jo-SNC方法：1）利用Jensen-Shannon散度结合最近邻信息评估样本清洁度；2）设计自适应、数据驱动的类别级阈值进行样本筛选；3）对清洁样本、分布内噪声样本和分布外噪声样本分别采用常规训练、部分标签学习和负学习；4）引入三重一致性正则化（自预测、邻居预测、特征一致性）。

Result: 在多个基准数据集上实验表明，该方法显著优于现有SOTA方法；消融研究验证了各模块的有效性。

Conclusion: Jo-SNC通过协同样本选择与多策略学习及一致性正则化，有效提升了模型在标签噪声下的鲁棒性与泛化能力。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [145] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: 本文提出PhyG-MoE框架，通过频谱引导的动态门控机制，按信号复杂度分配不同容量专家，实现高精度（97.58%）干扰识别并显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习干扰识别模型为静态结构，无法适配电磁信号物理熵的动态变化，导致简单与复杂信号处理资源严重不匹配。

Method: 提出PhyG-MoE（Physics-Guided Mixture-of-Experts），采用频谱特征纠缠程度驱动的动态门控机制，按需调用高容量TransNeXt专家或轻量级专家进行信号分类。

Result: 在21类干扰上达到97.58%整体识别准确率，显著降低计算开销且不牺牲性能。

Conclusion: PhyG-MoE成功解决了静态模型与动态电磁环境间的固有矛盾，为资源受限的认知接收机提供了可行方案。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [146] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 本文通过构建可控的一维图像-文本测试平台，探究了基于CLIP式对比学习的Transformer视觉与文本编码器如何习得左右空间关系理解能力，并揭示了标签多样性是泛化能力的关键驱动因素，以及位置嵌入与词元嵌入的交互形成水平注意力梯度，从而打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解仍是多模态模型的关键挑战，但尚不清楚模型是否真正习得该能力及其内在机制。

Method: 构建1D图像-文本测试床，训练轻量级Transformer视觉与文本编码器于单/双物体场景描述对上，系统调控标签与布局多样性，并结合注意力分解分析机制。

Result: 对比学习能习得左右关系；标签多样性比布局多样性更关键地促进泛化；位置嵌入与词元嵌入交互产生水平注意力梯度，破坏左右对称性；消融该成分显著削弱左右判别能力。

Conclusion: CLIP式模型在特定训练条件下可习得关系理解能力，其机制源于嵌入交互诱导的注意力不对称性。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [147] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文提出了首个面向3D高斯点阵（3DGS）的率失真优化压缩与语义分割统一框架，通过轻量隐式神经超先验和压缩引导的分割学习，在降低传输开销的同时保持高质量渲染与强分割性能。


<details>
  <summary>Details</summary>
Motivation: 3DGS在实时渲染和语义理解中均有效，但此前压缩与分割任务被独立处理，缺乏联合优化；同时，现有压缩方法多依赖计算昂贵的网格超先验，且难以支持解码端高级应用（如场景编辑）。

Method: 提出统一框架：1）基于轻量隐式神经表示的超先验，实现颜色与语义属性的高效熵编码；2）设计压缩引导的分割学习，包括量化感知训练提升特征可分性，以及质量感知加权机制抑制不可靠高斯原语。

Result: 在LERF和3D-OVS数据集上，显著降低传输成本，同时保持高渲染质量与强分割性能。

Conclusion: 该工作首次实现了3DGS压缩与语义分割的率失真联合优化，为解码端场景编辑等新应用提供了可行基础，并验证了轻量超先验与压缩引导学习的有效性。

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [148] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

TL;DR: 本文提出了SDF-HOLO，一种面向全身PET/CT的多模态基础模型，通过双流编码器与跨模态交互模块融合CT解剖结构与PET代谢信号，并结合分层上下文建模和体素-掩码-文本对齐策略，在肿瘤分割、低剂量病灶检测及多语言诊断报告生成等任务上显著优于现有方法，支持系统级代谢分析与精准肿瘤学应用。


<details>
  <summary>Details</summary>
Motivation: 现有医学AI模型难以应对全身PET/CT的异质性解剖与代谢信号、约2米轴向覆盖范围以及结构化放射科语义等挑战，因其通常假设单模态输入、局部视野和粗粒度图像-文本对齐。

Method: 提出SDF-HOLO模型：采用双流编码器分别学习CT与PET表征；引入跨模态交互模块实现解剖引导的PET聚合与代谢驱动的形态推理；使用分层上下文建模（局部窗口+全局注意力）捕获全身体长程依赖；以解剖分割掩码为语义锚点，进行体素-掩码-文本对齐预训练。

Result: 在肿瘤分割、低剂量病灶检测和多语言诊断报告生成任务上超越强任务专用及临床参考基线，降低定位误差与幻觉发现；支持系统级代谢谱分析，揭示肿瘤相关的器官间代谢网络指纹。

Conclusion: SDF-HOLO为全身PET/CT提供了可扩展的计算基础，推动从局灶解读迈向系统级精准肿瘤学。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [149] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: 本文提出TreeDGS方法，利用3D高斯泼溅（3D Gaussian Splatting）从航拍图像中高精度重建树干几何结构，并实现胸径（DBH）的直接测量，RMSE达4.79 cm，优于LiDAR基线。


<details>
  <summary>Details</summary>
Motivation: 航拍遥感虽适合大范围调查，但在复杂自然场景中难以准确直接测量对象级参数（如树木胸径DBH）；现有重建方法因树干在航拍图像中像素稀疏、观测弱，导致胸高处几何约束不足。

Method: 基于SfM-MVS初始化和高斯优化，采用RaDe-GS的深度感知累积不透明度积分从高斯场提取稠密点云，并为每个点赋予多视角不透明度可靠性评分；再对树干点进行不透明度加权的实心圆拟合以估计DBH。

Result: 在10个实测样地上的DBH估计RMSE为4.79 cm（约2.6像素），显著优于LiDAR基线（7.91 cm）。

Conclusion: 基于稠密化的高斯泼溅几何表示可实现低成本、高精度的航拍DBH直接测量，突破了传统航拍重建在细长目标几何建模上的瓶颈。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [150] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 本文评估了Grad-CAM在肺部癌症图像分类中的解释可靠性，发现其在卷积网络中表现较好，但在Vision Transformer中因非局部注意力机制而显著退化，揭示了当前基于热图的XAI方法在医学影像中的关键局限。


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学图像分析中广泛应用，但其对深度模型内部决策过程的忠实性和可靠性仍存疑，尤其在临床关键场景下亟需严谨验证。

Method: 基于IQ-OTH/NCCD数据集，对ResNet-50/101、DenseNet-161、EfficientNet-B0和ViT-Base共五种主流模型，构建融合定位精度、扰动忠实性与解释一致性的定量评估框架，系统评测Grad-CAM的跨模型可解释性。

Result: Grad-CAM在多数CNN架构中能有效高亮肿瘤区域，但在ViT中因非局部注意力导致解释保真度显著下降；不同模型间显著存在显著的显著性定位差异，说明其解释未必反映模型真实诊断依据。

Conclusion: 当前基于热图的XAI方法（如Grad-CAM）在医学影像中存在模型依赖性强、临床可信度不足等根本局限，亟需发展模型适配、计算稳健且临床可解释的新型可解释性方法。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [151] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

TL;DR: 本文提出了一种频率引导的任务平衡Transformer（FGTBT）框架，用于提升复杂场景下的面部关键点检测性能，通过细粒度多任务平衡损失（FMB-loss）和频率引导结构感知模型（FGSA）增强面部几何结构建模与多数据集联合训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的面部关键点检测方法在大姿态、光照和表情变化等挑战性场景下难以准确捕捉面部几何结构；同时，数据集规模小、多样性不足限制了模型鲁棒性。

Method: 提出Frequency-Guided Task-Balancing Transformer（FGTBT）框架，包含两个核心组件：1）Fine-Grained Multi-Task Balancing loss（FMB-loss），基于各关键点在多个数据集中的出现频率动态加权；2）Frequency-Guided Structure-Aware（FGSA）模型，利用频域信息注入和正则化来约束面部结构学习。

Result: 在主流基准数据集上实验表明，FGTBT集成FMB-loss与FGSA后性能达到当前最优水平（state-of-the-art）相当。

Conclusion: 频率域建模与细粒度任务平衡策略可有效提升面部关键点检测在复杂场景下的鲁棒性和准确性，为多源数据统一训练提供了新思路。

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [152] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需对抗训练的异构代理迁移（HPT）框架，利用CLIP不同变体间的内在代理对抗鲁棒性进行知识蒸馏，并通过泛化-枢纽解耦（GPD）策略平衡零样本自然泛化与对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统基于蒸馏的对抗鲁棒性迁移在视觉-语言模型（如CLIP）上面临教师模型构建计算成本过高的问题。

Method: 发现并定义了CLIP变体间的‘代理对抗鲁棒性’现象，据此提出异构代理迁移（HPT）框架；为缓解HPT导致的零样本泛化下降，进一步设计基于学习率调度差异的泛化-枢纽解耦（GPD）策略。

Result: 在15个零样本数据集上验证了HPT-GPD方法的有效性，显著提升了对抗鲁棒性且不损害自然泛化能力。

Conclusion: 代理对抗鲁棒性是一种可迁移的内在属性，HPT-GPD提供了一种高效、低开销的VLM鲁棒性增强新范式。

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [153] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架THFEM，将音频驱动的说话头生成（AD-THG）模型与语音保留式面部表情操纵（SPFEM）结合，以提升唇部同步精度和表情保真度；通过邻帧学习策略微调AD-THG模型，显著改善生成图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有SPFEM方法在唇部同步上表现不佳，因其难以处理面部表情与口型之间的复杂耦合关系。

Method: 提出THFEM框架，融合AD-THG模型（用于从音频生成精确唇动）与SPFEM（用于表情编辑），并引入邻帧学习策略对AD-THG进行微调，使其能联合预测连续帧以提升质量。

Result: 实验表明THFEM能有效保持表达操纵过程中的口型准确性，同时提升生成图像的真实感和表情保真度。

Conclusion: 将AD-THG与SPFEM有机结合，并辅以邻帧学习策略，是提升语音保留式表情编辑性能的有效途径。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [154] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

TL;DR: YOLO26通过去除NMS后处理，采用端到端学习策略，在速度与精度上均超越YOLOv1–YOLO11及RTMDet、DAMO-YOLO等先进模型，实现边缘视觉检测的新范式。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO系列受限于NMS带来的延迟和超参敏感性，亟需一种不依赖启发式后处理的高效端到端检测框架。

Method: 提出YOLO26架构，核心包括MuSGD优化器（稳定轻量骨干网络）、STAL（小目标感知标签分配）和ProgLoss（动态监督损失函数），彻底摒弃NMS。

Result: 在官方基准测试中，YOLO26在推理速度和检测精度上均达到新Pareto前沿，显著优于YOLOv1–YOLO11、RTMDet和DAMO-YOLO。

Conclusion: YOLO26通过解耦表征学习与启发式后处理，成功打破实时检测中延迟与精度的历史权衡，标志着边缘计算机视觉的下一代演进方向。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [155] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种集成VGG16、ResNet50和InceptionV3的深度学习框架，通过加权平均实现牛结节性皮肤病（LSD）和口蹄疫（FMD）的同步高精度检测，在多源图像数据集上达到98.2%准确率，有效解决症状重叠导致的诊断难题。


<details>
  <summary>Details</summary>
Motivation: LSD和FMD临床症状高度重叠，且易与昆虫叮咬、化学灼伤等良性病变混淆，导致延误防控；亟需一种能区分多病共现、适用于资源有限地区的自动化诊断工具。

Method: 构建包含10,516张专家标注图像的多国数据集（印度、巴西、美国18个农场），设计融合VGG16、ResNet50和InceptionV3的集成深度学习模型，并采用优化加权平均策略进行多标签分类。

Result: 模型达到98.2%准确率，宏平均精确率、召回率、F1分数均为98.1%–98.2%，AUC-ROC达99.5%，显著优于现有单模型方法。

Conclusion: 该集成框架可实现LSD与FMD的早期、精准、自动化鉴别诊断，具备向基层兽医系统部署的潜力，有助于提升全球畜牧业疫病防控能力与可持续发展水平。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [156] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

TL;DR: 本文提出TwoHead-SwinFPN模型，结合Swin Transformer、FPN与UNet解码器及CBAM模块，通过双头架构联合优化伪造检测与定位任务，在FantasyIDiap数据集上取得高精度分类与定位性能，并验证其跨设备、多语言泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型的快速发展加剧了身份证件中人脸替换和文本修复等合成篡改攻击的风险，亟需能同时检测并精确定位篡改区域的鲁棒方法。

Method: 提出TwoHead-SwinFPN：以Swin Transformer为骨干网络，融合FPN与UNet风格解码器，并引入CBAM增强特征表达；采用双头结构联合优化二分类（是否篡改）与分割（定位篡改区域），使用不确定性加权的多任务学习策略。

Result: 在FantasyIDiap数据集上达到84.31%分类准确率、90.78% AUC、57.24%平均Dice分数及88.61% F1-score；支持FastAPI部署，具备跨设备与10种语言泛化能力。

Conclusion: TwoHead-SwinFPN是一种高效、鲁棒且可部署的统一框架，显著提升了ID文档篡改检测与定位性能，具备实际应用潜力。

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [157] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

TL;DR: 本文提出了一种名为Supervision-by-Hallucination-and-Transfer（SHT）的弱监督框架，通过结合面部幻觉（face hallucination）和面部姿态迁移（facial pose transfer）任务，提升低分辨率图像下的高精度人脸关键点检测（FLD）性能。


<details>
  <summary>Details</summary>
Motivation: 现有FLD方法受限于低分辨率输入、特征压缩、训练数据不足及标注不精确等问题，导致精度下降。

Method: 提出SHT框架，包含两个协同增强模块：Dual Hallucination Learning Network（DHLN）用于从低分辨率输入学习高分辨率表示并生成更优热图；Facial Pose Transfer Network（FPTN）通过姿态迁移进一步优化热图与幻觉图像。

Result: 在人脸幻觉和关键点检测任务上均超越当前最先进方法。

Conclusion: SHT是首个将面部幻觉与姿态迁移融入弱监督FLD的框架，显著提升了低质图像下的检测鲁棒性与精度。

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [158] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种双流协同Transformer（DSCT）模型，通过融合区域特征和分割特征，并利用模式特异性互注意力编码器（PSMAE）与动态提名解码器（DND），提升图像描述生成的准确性与描述性，首次实现动态融合多模态特征以缓解语义不一致与空间错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于区域特征的图像描述生成方法易产生无关描述，主要因缺乏上下文信息及过度依赖已生成的部分文本预测后续词。

Method: 提出双流协同Transformer（DSCT），整合区域与分割特征；设计模式特异性互注意力编码器（PSMAE）进行双向特征强化；引入动态提名解码器（DND）动态匹配学习模块并利用同质特征生成描述。

Result: 在主流基准数据集上，DSCT性能优于当前最优图像描述模型。

Conclusion: 动态融合不同模式特征可有效缓解语义不一致与空间错位问题，提升图像描述生成质量；DSCT为多源视觉特征协同建模提供了新思路。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [159] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 本文提出了一种针对目标识别领域的成员推断测试（MINT）架构，利用卷积层建模训练激活模式，在三个公开数据集（>174K图像）上实现了70%-80%的推断精度，并分析了影响MINT性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 在目标识别领域，缺乏针对成员推断测试（MINT）的专用架构，难以高效、准确地判断样本是否参与模型训练。

Method: 设计并实现面向目标识别的MINT专用架构，结合目标检测模型、嵌入提取器与MINT模块；利用卷积层建模训练过程中的激活模式；在三个公共数据集上开展实验验证。

Result: 在超过174K图像的三个数据集上，MINT精度达70%–80%，精度受目标检测模块输入层深度影响；同时识别出影响MINT性能的关键训练因素。

Conclusion: 所提MINT架构能有效适配目标识别任务，在精度与可解释性间取得平衡，为模型数据隐私评估提供了定制化解决方案。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [160] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: 本文提出Quality-Guided K-Adaptive Slot Attention（QASA），通过解耦槽选择与重建、设计无监督槽质量度量及质量引导的槽选择机制，显著提升动态槽数量下的对象中心表征性能，尤其在真实数据集上超越固定槽数方法。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应Slot Attention方法存在两个问题：未显式约束槽绑定质量，导致特征归属模糊；槽数量惩罚与重建保真度目标冲突，性能落后于固定K基线。

Method: 提出QASA：1）解耦槽选择与重建；2）设计无监督Slot-Quality指标评估单个槽质量；3）基于该指标实现质量引导的槽选择，并输入门控解码器重建；4）推理时通过槽注意力的token级竞争实现K自适应。

Result: QASA在真实和合成数据集上均显著优于现有K自适应方法，并在真实数据集上超越强K固定基线。

Conclusion: 解耦优化目标并引入质量引导机制是提升K自适应Slot Attention性能的关键，QASA为无监督对象中心学习提供了更鲁棒、更灵活的框架。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [161] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD是一种基于扩散模型的单图像3D视线估计方法，将视线建模为距眼睛固定距离的额外人体关节点，联合估计3D视线与人体姿态，实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理单图像中视线估计的不确定性，且视线与人体姿态存在强相关性，但多数方法未联合建模二者。

Method: 提出GazeD方法，利用扩散模型生成多个3D视线与姿态假设；将3D视线表示为距眼睛固定距离的额外关节，并以2D姿态、主体周围区域和场景上下文为条件进行去噪。

Result: 在三个基准数据集上达到3D视线估计的SOTA性能，甚至超越依赖时序信息的方法。

Conclusion: 将视线作为额外关节并联合建模姿态与视线，结合扩散模型对不确定性的建模能力，可显著提升单图像3D视线估计精度。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [162] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba架构的图像风格迁移方法StyMam，通过残差双路径条带扫描机制和通道重加权空间注意力模块，兼顾局部纹理与全局依赖建模，在保持内容结构的同时生成高质量、无伪影的风格化图像，并在质量和速度上均优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有GAN方法难以同时建模局部与全局依赖，易产生伪影；SD方法虽缓解伪影但内容保持差、推理慢。

Method: 提出基于Mamba的生成器StyMam，包含残差双路径条带扫描机制（捕获局部纹理）和通道重加权空间注意力模块（建模全局依赖）。

Result: 在定性和定量实验中均优于当前最先进方法，兼具更高图像质量与更快推理速度。

Conclusion: Mamba架构可有效替代CNN/Transformer或SD用于风格迁移，平衡内容保持、风格保真与效率。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [163] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 本文提出了一种空间亲和组件，用于在遥感领域中结合高分辨率（HR）与中分辨率（MR）图像进行自监督预训练，从而提升MR图像表征学习及下游分割任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感自监督预训练多依赖易获取的中分辨率图像，而新发布的高分辨率数据尚未被有效利用；本文旨在探索如何融合HR数据以增强MR图像的表征学习能力。

Method: 设计了一个可嵌入现有自监督学习框架的空间亲和组件，利用HR影像指导MR影像的表征学习。

Result: 该组件在两个自监督框架上验证有效，性能优于仅用HR或仅用MR图像预训练的模型。

Conclusion: 引入HR图像通过空间亲和机制能显著提升MR图像的自监督表征学习效果及下游分割性能。

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [164] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

TL;DR: 本研究提出了一种基于TabTrans架构的新型方法，用于早期2型糖尿病（T2DM）风险预测，利用纵向电子健康记录（EHR）与DXA骨密度数据，在Qatar BioBank队列上实现优于传统机器学习和主流大模型（如GPT-4、Claude 3.5、Gemini Pro）的预测性能（AUC ≥ 79.7%），并识别出VAT、Ward BMD/BMC等关键生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效建模纵向健康数据中的长程依赖关系，且对多模态（EHR+DXA） tabular 数据缺乏高效建模能力；同时，T2DM早期风险预测在特定人群（如卡塔尔成人）中亟需更精准、可解释的工具。

Method: 采用Tabular Transformer（TabTrans）架构处理纵向患者tabular数据（EHR + DXA）；结合SMOTE与SMOTE-ENN解决类别不平衡；对比评估包括传统ML模型及生成式AI模型（Claude 3.5 Sonnet、GPT-4、Gemini Pro）；通过特征重要性分析进行可解释性研究。

Result: TabTrans在QBB队列（n=1382）上达到AUC ≥ 79.7%，显著优于对比模型；VAT质量/体积、Ward区BMD/BMC、T/Z评分及L1-L4骨密度为最重要预测因子。

Conclusion: TabTrans在多模态tabular医疗数据分析中展现出优越性能与可解释性，为卡塔尔人群T2DM的主动防控与个体化临床干预提供了有力新工具。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [165] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: 本文提出AsyncBEV模块，通过估计并补偿多传感器间的时间偏移导致的特征错位，提升BEV 3D目标检测模型在异步传感器输入下的鲁棒性，尤其对动态物体效果显著。


<details>
  <summary>Details</summary>
Motivation: 实际自动驾驶中传感器难以完美同步，时间偏移会损害多模态感知性能，尤其是动态物体检测。

Method: AsyncBEV是一个轻量、可训练的通用模块，受场景流估计启发，基于已知时间偏移估计双模态BEV特征间的2D流，并用该流对特征图进行空间扭曲与对齐，可即插即用地集成到各类BEV检测器（如CMT、UniBEV）中。

Result: 在CMT（token-based）和UniBEV（grid-based）上验证有效，尤其在0.5秒最坏时间偏移下，动态物体NDS分别提升16.6%和11.9%，显著优于仅做自车运动补偿的基线。

Conclusion: AsyncBEV是一种简单高效且架构无关的方案，能显著增强BEV检测器对传感器异步的鲁棒性，为实际部署提供更强可靠性。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [166] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出Think3D框架，通过结合3D重建模型与VLMs，实现无需额外训练的交互式3D空间推理，显著提升多视角和空间理解任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉大模型（VLMs）本质是2D感知器，在真实3D空间推理方面存在局限，亟需增强其空间智能。

Method: 提出Think3D框架，利用3D重建模型从图像/视频中恢复点云与相机位姿，支持基于相机的操作与主/全局视角切换，将空间推理转化为交互式3D思维链；对小模型引入强化学习策略以自主选择有效视角与操作。

Result: 在BLINK Multi-view和MindCube上平均提升+7.8%，VSI-Bench上+4.7%；小模型经RL增强后工具增益从+0.7%升至+6.8%。

Conclusion: 无需训练、工具增强的空间探索是实现更灵活、类人3D推理的有效路径，拓展了多模态智能的新维度。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [167] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: 本文介绍了GridNet-HD，一个用于架空电力设施3D语义分割的多模态数据集，结合高密度LiDAR与高分辨率倾斜影像，并提供基线模型验证多模态融合的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集缺乏同时具备高密度LiDAR、高分辨率倾斜影像及电力设施3D语义标注的数据，限制了相关研究发展。

Method: 构建GridNet-HD多模态数据集（7694张图像、25亿点云，11类标注），设计单模态（仅LiDAR/仅图像）与多模态融合基线模型，并采用mIoU评估性能。

Result: 多模态融合模型在GridNet-HD上较最优单模态基线提升+5.55 mIoU，验证了几何与外观信息的互补性。

Conclusion: GridNet-HD填补了电力基础设施多模态3D语义分割数据集的空白，为后续研究提供了重要资源和基准。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [168] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

TL;DR: 本文提出了一种结合Retinex理论与少样本学习的双分支原型学习网络，用于低光照环境下的混凝土裂缝分割，显著提升了在低光条件下的分割精度并减少了对大量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现实中的裂缝常出现在隧道、桥底等低光照环境中，导致现有计算机视觉分割方法精度下降；同时，低光照裂缝图像的像素级标注耗时巨大，而大多数深度学习方法依赖大量高亮度标注数据。

Method: 提出双分支原型学习网络：1）基于Retinex理论提取反射分量，指导光照不变的全局表征学习；2）引入跨相似性先验掩码生成模块，计算查询与支持样本特征间的高维相似性以定位裂缝；3）设计多尺度特征增强模块，融合多尺度特征与先验掩码以缓解空间不一致性；4）结合度量学习降低对大规模标注数据的依赖。

Result: 在多个基准数据集上实验表明，该方法在低光照条件下持续达到最优性能。

Conclusion: 该方法有效解决了低光照下裂缝分割精度低和标注成本高的问题，为实际工程应用提供了可行方案。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [169] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: 本文提出HyperAdapt框架，通过患者条件化自适应机制，在保持共享诊断模型整体性能的同时提升子群体可靠性，避免因抑制敏感属性导致的诊断精度下降。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI模型在不同患者群体间表现不均，而传统公平性方法通过抑制敏感属性可能损害关键诊断信息，影响高风险场景下的准确性和可靠性；临床决策则明确结合患者背景信息，启发设计兼顾 subgroup-aware 与诊断效能的新方法。

Method: 提出HyperAdapt：将年龄、性别等临床相关属性编码为紧凑嵌入，驱动超网络式模块生成低秩、瓶颈化的小规模残差调制参数，动态调节共享骨干网络的部分层，实现患者特异性适配。

Result: 在多个公开医学影像基准上，该方法显著提升子群体（尤其代表性不足群体）性能，且不牺牲整体准确率；在PAD-UFES-20数据集上，召回率和F1分数分别超越最强基线4.1%和4.4%。

Conclusion: HyperAdapt为医疗AI提供了兼顾公平性与诊断效能的新范式，证明在保留敏感属性诊断价值的前提下，可通过轻量级条件化适配有效缓解亚群性能差异。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [170] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: 本文提出了SANDesc，一种基于注意力机制的轻量级关键点描述符提取网络，通过改进U-Net结构并引入注意力模块与残差路径，在不改变关键点检测器的前提下显著提升匹配性能，且仅含240万参数。


<details>
  <summary>Details</summary>
Motivation: 现有关键点描述符在匹配性能和计算效率之间存在权衡，需在不修改检测器前提下提升描述能力。

Method: 提出Residual U-Net Blocks with Attention结构，结合卷积块注意力模块（CBAM）和残差连接；采用改进的三元组损失与课程学习启发的难负样本挖掘策略进行训练。

Result: 在HPatches、MegaDepth-1500和IMC2021等基准上，SANDesc在多个匹配任务中优于原始描述符；在新提出的4K城市数据集上也取得显著性能提升，同时模型仅含2.4M参数。

Conclusion: SANDesc是一种高效、轻量且通用的关键点描述符网络，可即插即用地提升现有检测器的匹配性能，适用于资源受限场景。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [171] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 本文提出PhaseMark，一种单次、无需优化的水印框架，通过直接调制VAE潜在空间频域中的相位来实现高效且鲁棒的图像水印，显著优于现有后处理方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代优化或反演的后处理水印方法速度过慢，难以应对潜在扩散模型生成的超真实图像的水印需求。

Method: PhaseMark在VAE潜在空间的频域中直接调制相位，采用四种调制变体，在不损害图像质量的前提下实现单次嵌入。

Result: PhaseMark比基于优化的方法快数千倍，在再生等严重攻击下仍保持最先进的鲁棒性，同时不降低图像质量。

Conclusion: PhaseMark开创了一种新范式：利用潜在表示的内在特性，实现高效且强鲁棒性的水印。

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [172] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer is a new framework that combines 3D Gaussian Splatting with Vision-Language Models to enable question-driven exploration and reasoning in 3D scenes, outperforming prior methods on embodied tasks.


<details>
  <summary>Details</summary>
Motivation: Existing language-embedded 3DGS methods struggle with complex, compositional language queries, and object-centric RGB-D memory approaches are limited by fixed viewpoints.

Method: GaussExplorer integrates Vision-Language Models (VLMs) with 3D Gaussian Splatting (3DGS); it first retrieves query-relevant pre-captured images and then synthesizes novel viewpoints to enhance visual input for VLM reasoning.

Result: GaussExplorer achieves superior performance over existing methods on multiple benchmarks for embodied exploration and reasoning tasks.

Conclusion: Integrating VLM-based reasoning with 3DGS effectively addresses limitations of prior approaches and advances embodied language understanding in 3D environments.

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [173] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: 本文提出CLASP框架，利用CLIP生成多级语义伪标签，并结合Prompt-Controlled MoE模块和多任务预训练策略，实现面向人体中心视觉分析的通用无监督预训练。


<details>
  <summary>Details</summary>
Motivation: 现有大规模未标注人体图像数据集催生了对能支持多样化下游任务的通用无监督预训练模型的需求。

Method: 提出CLASP框架：1）利用CLIP生成低层（如身体部位）和高层（如属性）语义伪标签；2）引入Prompt-Controlled Mixture-of-Experts（MoE）模块动态适配特征提取；3）采用多任务预训练策略，以部件级和属性级伪标签指导表征学习。

Result: 在多个基准测试上，CLASP持续优于现有无监督预训练方法。

Conclusion: CLASP通过融合多级语义信息与任务自适应机制，显著提升了人体中心视觉分析中无监督预训练模型的表达能力与泛化能力。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [174] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: 本文提出TVWorld，一个基于图的电视导航抽象框架，并构建了两个评估基准TVWorld-N和TVWorld-G，揭示了现有大视觉语言模型在拓扑感知长程电视导航上的不足；为此设计了拓扑感知训练框架，并推出专用模型TVTheseus，在TVWorld-N上达到68.3%成功率，超越Gemini 3 Flash等强基线，达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在设备控制中多聚焦于点选交互，而日常电视遥控（RC）这一常见交互形式缺乏系统研究，亟需可复现、免部署的评估框架与针对性建模方法。

Method: 构建离线图结构TVWorld以抽象真实电视导航；设计TVWorld-N（拓扑感知导航）和TVWorld-G（焦点感知定位）两个互补基准；提出Topology-Aware Training框架，将拓扑信息注入LVLM；基于该框架训练专用模型TVTheseus。

Result: TVTheseus在TVWorld-N上成功率达68.3%，显著优于Gemini 3 Flash等闭源强基线，达到SOTA；基准分析揭示了现有代理在焦点驱动、长时序电视导航中拓扑感知能力不足的关键缺陷。

Conclusion: 拓扑感知能力是实现鲁棒电视遥控交互的核心，TVWorld为TV-use agent提供了标准化评估范式，Topology-Aware Training与TVTheseus验证了显式建模导航结构对提升LVLM设备控制能力的有效性。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [175] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: 本文提出了ICo3D方法，用于生成交互式、可对话且逼真的3D虚拟人像，结合多视角捕捉、动态高斯建模与大语言模型，实现真实感强、实时响应的虚拟人交互系统。


<details>
  <summary>Details</summary>
Motivation: 构建一个能实时交互、具备自然对话能力且视觉上高度逼真的3D虚拟人，以支持游戏、虚拟助手、个性化教育等沉浸式应用场景。

Method: 基于多视角图像构建可驱动的3D人脸（HeadGaS++）和动态3D身体（SWinGS++）模型，均采用高斯泼溅渲染；融合二者并接入大语言模型（LLM），利用语音音频驱动面部动画以实现音画同步。

Result: 实现了高保真、无融合伪影的完整3D虚拟人系统，支持实时语音/文本交互，并在多个用例中完成演示。

Conclusion: ICo3D提供了一种端到端、可扩展的虚拟人构建框架，在真实感、交互性与实用性之间取得良好平衡，具有广泛的应用前景。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [176] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 本文提出了一种基于U-Net CNN架构并融合解剖先验与神经影像学领域知识的高效模型，在MICCAI 2025的SSL3D和FOMO25两项3D脑MRI基础模型挑战赛中均获第一名；相比Transformer方案，训练速度快1-2个数量级、模型体积小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发适用于医学影像分析的基础模型至关重要，尤其需应对放射学任务（如3D脑MRI）的独特挑战。

Method: 采用U-Net CNN架构，并结合解剖先验和神经影像学领域知识进行建模与优化。

Result: 在MICCAI 2025的SSL3D和FOMO25两项挑战赛中均排名第一；训练速度比Transformer方法快1–2个数量级，模型体积仅为后者的十分之一。

Conclusion: 基于CNN的轻量高效方案在3D脑MRI基础模型任务中显著优于大型Transformer模型，验证了融入领域知识的架构设计的有效性与实用性。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [177] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: 本文提出GTPred基准，用于评估多模态大语言模型（MLLMs）在地理-时间联合预测任务中的能力，发现当前模型在世界知识和时空推理方面仍存在局限，但引入时间信息可显著提升定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位基准忽略了图像中蕴含的时间信息，而时间信息可进一步约束地理位置推断；因此需要构建能同时评估地理与时间推理能力的新基准。

Method: 构建包含370张跨越120年、全球分布图像的GTPred基准；设计联合年份与层级位置序列匹配的评估指标，并利用人工标注的真实推理链评估中间推理过程。

Result: 在8个闭源和7个开源MLLM上的实验表明，尽管模型视觉感知能力强，但在世界知识和地理-时间推理方面仍不足；加入时间信息可显著提升定位准确率。

Conclusion: 地理-时间联合建模对精准定位至关重要，GTPred为评估和推动MLLM在时空理解能力方面提供了新标准。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [178] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

TL;DR: 本文提出Additive U-Net，用可学习的非负标量门控加性跳跃连接替代U-Net中标准的拼接跳跃连接，以提升图像去噪性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 标准U-Net中拼接跳跃连接会加倍通道维度、模糊信息流，并导致噪声不受控传递。

Method: 提出加性跳跃连接，每个跳跃路径由可学习的非负标量缩放，避免通道膨胀并提供对编码器贡献的显式控制。

Result: 在Kodak-17数据集上，Additive U-Net在σ=15/25/50噪声水平下达到有竞争力的PSNR/SSIM；无需显式下采样/上采样或强制多尺度结构，模型仍能自然学习高频→带通→低频特征演化。

Conclusion: 加性跳跃连接是一种轻量、可解释的拼接替代方案，有助于高效网络设计和理解重建网络中的多尺度信息传递。

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [179] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 本文提出了首个面向对象注意力评估的虚拟现实街景过马路导航数据集\dataset~，并设计了新的评估指标oSIM和模型SUMGraph，显著提升了对象级注意力预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有计算视觉注意力模型缺乏面向对象注意力的数据集和评估指标，而认知科学已证实人类视觉注意力具有对象基础性。

Method: 构建了包含120名参与者的虚拟现实街景过马路导航数据集\dataset~，具备精确眼动数据、完整对象状态空间表示、多级场景复杂度及丰富标注（全景分割、深度、车辆关键点）；提出对象相似度指标oSIM；设计基于Mamba U-Net与图结构编码车辆对象的SUMGraph模型。

Result: 实验表明，显式优化对象注意力不仅提升oSIM指标，也改善通用指标性能；SUMGraph在多个SOTA方法上取得进一步提升。

Conclusion: 对象级建模对视觉注意力预测至关重要；\dataset~、oSIM和SUMGraph为对象注意力研究提供了新基准与工具。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [180] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 本文提出了BLEMORE数据集，用于多模态混合情绪识别，并评估了多种现有模型在混合情绪存在性预测和相对显著性预测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频情绪识别方法主要针对单一情绪，难以处理混合情绪及其相对显著性；缺乏标注丰富混合情绪样本及显著性信息的数据集。

Method: 构建了包含3000多个视频片段的BLEMORE多模态数据集（视频+音频），涵盖58名演员、6种基本情绪和10种混合情绪，每种混合情绪有3种显著性配置（50/50、70/30、30/70）；并在两个任务上评测了多种单模态与多模态模型。

Result: 单模态模型在验证集上最高达29%存在性准确率和13%显著性准确率；多模态模型表现更优，如ImageBind+WavLM达35%存在性准确率，HiCMAE达18%显著性准确率；测试集上最佳模型分别为VideoMAEv2+HuBERT（33%）和HiCMAE（18%）。

Conclusion: BLEMORE填补了混合情绪识别领域高质量标注数据集的空白，为建模复杂、真实的情绪表达提供了重要基础。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [181] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

TL;DR: 本文提出了一种结合CNN与Mamba-SSM的混合深度学习模型ConvMambaNet，用于提升EEG信号中癫痫发作的自动检测精度，在CHB-MIT数据集上达到99%准确率，并对类别不平衡具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 癫痫自动检测因EEG信号时序复杂性而面临挑战，亟需更有效的时序建模方法。

Method: 提出ConvMambaNet模型，将Mamba结构化状态空间模型（SSM）嵌入CNN框架中，协同提取EEG信号的空间特征和长程时序动态。

Result: 在CHB-MIT头皮EEG数据集上实现99%分类准确率，且在严重类别不平衡下表现稳健。

Conclusion: ConvMambaNet在癫痫发作检测中展现出高精度与强鲁棒性，具备临床实时自动化监测的应用潜力。

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [182] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 本文提出了一种针对视觉-语言模型（VLMs）在雨天场景下的对抗攻击框架，通过两阶段、基于语义解耦的参数化天气扰动模型，揭示了降雨对跨模态语义对齐的稳定性和决策边界的破坏作用。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在标准视觉条件下表现良好，但其在真实天气（如降雨）下的鲁棒性及跨模态语义对齐的稳定性尚缺乏研究。

Method: 提出两阶段参数化扰动模型：第一阶段用低维全局调制模拟降雨整体效应，弱化语义决策边界；第二阶段建模多尺度雨滴外观与降雨引起的光照变化，并在非可微天气空间中优化以诱导稳定语义偏移；整个过程在非像素参数空间操作，确保物理合理性和可解释性。

Result: 实验表明，即使物理上合理且约束严格的天气扰动，也能显著破坏主流VLMs的语义对齐；消融实验证实光照建模和多尺度雨滴结构是导致语义偏移的关键因素。

Conclusion: 该工作揭示了VLMs在现实天气条件下面临的安全与可靠性风险，强调需提升其在结构化自然扰动下的鲁棒性。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [183] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 本文提出了一种基于新型固态3D超声传感器Calyo Pulse的、用于恶劣环境下的学习型3D语义分割框架，并采用3D U-Net进行训练，验证了3D超声作为自动驾驶中可靠感知补充模态的潜力。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、高可靠的感知系统是自动驾驶的核心挑战；现有LiDAR与相机方案在成本、鲁棒性及恶劣条件下的性能存在权衡，亟需新感知模态。

Method: 提出基于Calyo Pulse（模块化固态3D超声传感器）的3D语义分割框架，采用3D U-Net架构对超声体数据进行体素级分割训练。

Result: 实验表明该框架在Calyo Pulse数据上实现了鲁棒的3D分割性能；进一步提升可通过更大数据集、更精确真值标注及加权损失函数实现。

Conclusion: 3D超声传感是一种有前景的互补感知模态，可增强自动驾驶系统在恶劣与杂乱环境中的可靠性。

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [184] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity 是首个开源、大规模、多领域工程图纸数据集，具备全面的结构化标注，旨在支持自动图纸解析及AI辅助科学发现。


<details>
  <summary>Details</summary>
Motivation: 当前AI难以理解工程图纸中的视觉-结构知识，阻碍其在科学工作流（如假设生成、实验设计）中发挥作用，亟需一个高质量、多领域、结构化标注的工程图纸数据集。

Method: 构建Enginuity数据集，涵盖多领域工程图纸，并提供层次化组件关系、连接结构和语义元素等结构性标注。

Result: 发布首个开源、大规模、多领域、带综合结构标注的工程图纸数据集，支持结构化图纸解析、跨模态信息检索和AI辅助工程仿真等下游任务。

Conclusion: Enginuity将推动AI for Scientific Discovery发展，使AI系统能真正理解并操作工程图纸中蕴含的视觉-结构知识，突破当前AI参与科学发现的关键瓶颈。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [185] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 本文提出了CausalSpatial基准测试，揭示了多模态大语言模型在因果空间推理任务上的严重不足，并提出COW框架通过生成假设动态视频来增强模型对物理因果关系的视觉 grounding。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs局限于静态空间感知，无法回答3D场景中的'what-if'问题，缺乏因果空间推理能力。

Method: 构建CausalSpatial诊断基准（含Collision、Compatibility、Occlusion、Trajectory四任务）；分析模型失败原因；提出COW框架，通过生成假设运动视频实现因果模拟与视觉 grounding。

Result: 人类准确率为84%，GPT-5仅54%；COW显著提升模型在因果空间推理任务上的表现。

Conclusion: MLLMs当前严重依赖脱离视觉证据的语言链式推理，需借助显式视觉因果模拟（如COW）来提升物理世界推理能力。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [186] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: 本文提出MultiST框架，通过跨注意力融合空间拓扑、基因表达与组织形态学信息，提升空间域边界的解析能力，并在13个空间转录组数据集上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组方法常未能有效整合组织形态学与分子图谱，导致空间域边界模糊，限制了对组织结构和细胞互作的深入解析。

Method: 提出MultiST：基于图的基因编码器结合对抗对齐学习空间表征，并融合颜色标准化的组织学特征，通过跨注意力机制实现多模态联合建模。

Result: 在13个涵盖人脑皮层和乳腺癌组织的数据集上，MultiST生成的空间域边界更清晰连贯，伪时间轨迹更稳定，细胞互作模式更具生物学可解释性。

Conclusion: MultiST通过深度融合多模态信息显著提升了空间域划分精度与生物学可解释性，为原位组织解析提供了新范式。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [187] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 本文提出了一种在高杂波、多尘环境中生成可控多级粉尘浓度的新方法，并构建了融合相机与LiDAR的4D毫米波雷达数据集；进一步设计了基于阈值的噪声滤波框架和规则驱动的聚类级分类流程，实现了无需大量领域训练的实时行人检测，显著提升了粉尘环境下毫米波雷达系统的鲁棒性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 在地下矿井、公路隧道或坍塌建筑等封闭恶劣环境中，粉尘导致毫米波传播严重受限且感知性能下降，亟需可重复的实验条件与鲁棒的感知方法。

Method: 1）构建可控多级粉尘浓度生成系统；2）采集并发布多模态（mmWave雷达+相机+LiDAR）4D雷达数据集；3）提出基于RCS、速度、方位角、俯仰角的阈值噪声滤波框架；4）设计基于雷达语义（速度、RCS、体积分布）的规则式聚类分类 pipeline 实现行人检测。

Result: 所提方法在粉尘密集的矿井环境中显著提升了杂波抑制能力、检测鲁棒性及系统整体韧性，实现了无需大量领域特定训练的实时行人检测。

Conclusion: 该集成方案为恶劣粉尘环境下的毫米波雷达感知提供了可复现的实验基础与实用性强、低依赖训练的实时检测框架，具有重要工程应用价值。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [188] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于球面几何表示和扩散模型的文本到3D人脸生成方法，通过将人脸几何约束在球面上实现规则点分布与稳健网格重建，并利用2D展开图协同生成几何与纹理，显著提升几何质量、文本保真度和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D人脸生成方法难以建模3D顶点在空间中任意复杂的分布，导致连接性差、几何质量低。

Method: 提出球面几何表示（将人脸几何锚定于均匀球坐标）以保证点分布规则，并可展开为2D映射；在此基础上构建球面几何扩散模型，联合建模几何与纹理，几何显式引导纹理合成。

Result: 在文本到3D生成、人脸重建和文本驱动3D编辑等任务上均取得优异性能，几何质量、文本保真度和推理效率显著优于现有方法。

Conclusion: 将3D人脸几何约束于球面并映射至2D，可有效简化建模难度，结合扩散模型实现高质量、可控、高效的文本到3D人脸生成。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [189] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 本文提出了一种全模型驱动的4D毫米波雷达感知框架，专为嵌入式边缘硬件实时运行设计，仅依赖雷达模态，在粉尘弥漫、能见度极低的封闭工业及地下环境中实现稳定行人检测，性能优于失效的相机和LiDAR。


<details>
  <summary>Details</summary>
Motivation: 工业与地下环境中的尘埃、烟雾、狭小空间和金属结构严重削弱光学与LiDAR感知能力，亟需一种鲁棒性强、适用于恶劣可视条件下的替代感知方案。

Method: 提出全模型驱动的4D毫米波雷达感知框架，包含领域感知多阈值滤波、自运动补偿的时间累积、KD树欧氏聚类与多普勒感知优化、以及基于规则的3D分类器。

Result: 在充满粉尘的封闭拖车和真实地下矿道中验证，雷达检测器在相机与LiDAR完全失效时仍保持稳定行人识别。

Conclusion: 该模型驱动方法具备鲁棒性、可解释性与计算高效性，适用于恶劣工业与地下环境中的安全关键感知任务。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [190] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 本文对三种先进的半监督目标检测（SSOD）方法（MixPL、Semi-DETR 和 Consistent-Teacher）在不同标注数据量下的性能进行了系统比较，实验涵盖 MS-COCO、Pascal VOC 和自建 Beetle 数据集，分析了准确率、模型大小与推理延迟之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺场景下提升目标检测性能，尤其关注少量标注数据结合大量无标注数据的半监督学习范式。

Method: 对 MixPL、Semi-DETR 和 Consistent-Teacher 三种主流 SSOD 方法进行统一实验评估，使用 MS-COCO、Pascal VOC 和自定义 Beetle 数据集，在不同标注样本数量下对比其检测性能、模型大小和推理延迟。

Result: 揭示了不同 SSOD 方法在准确率、模型复杂度和推理速度之间的权衡关系，为低数据场景下的方法选择提供了实证依据。

Conclusion: 没有单一方法在所有指标上占优；应根据具体应用场景（如对精度、模型轻量化或实时性要求）选择合适的 SSOD 方法。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [191] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: 本文提出ORACLE-CT模型，一种器官感知、编码器无关的CT影像分类头，在胸腹部CT数据集上实现监督学习SOTA性能，兼顾校准预测与空间证据定位。


<details>
  <summary>Details</summary>
Motivation: 急需对高通量CT影像进行高效分诊与分类，以提升诊疗质量并缓解放射科医生疲劳；现有视觉语言模型（VLM）在3D解剖建模、扫描协议差异及报告噪声监督下表现不佳。

Method: 基于两大公开胸部CT数据集（CT-RATE和RADCHEST-CT），构建精细调优的监督基线（全局平均池化头），并在此基础上提出ORACLE-CT：包含器官掩码注意力（按器官掩码限制的池化以提供空间证据）与器官标量融合（融合归一化体积与平均HU值）。

Result: 在CT-RATE上胸部分诊AUROC达0.86；在MERLIN腹部数据集（30种发现）上，监督基线已超越复现的零样本VLM，加入ORACLE-CT后进一步提升至AUROC 0.85。

Conclusion: ORACLE-CT在统一评估协议下实现了胸腹部CT监督分类的最先进性能，兼具高精度、可解释性（空间证据）与泛化性，代码已开源。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [192] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 本文提出了一种基于Transformer的3D雷达目标检测架构，使用新型Transformer解码器直接回归3D边界框和类别得分，并通过金字塔标记融合（PTF）模块整合多尺度雷达特征，将检测建模为集合预测问题，避免了密集候选框生成和复杂NMS后处理。


<details>
  <summary>Details</summary>
Motivation: 现有雷达目标检测方法依赖密集候选框生成和大量非极大值抑制（NMS）调参，难以有效建模长程时空相关性和跨尺度特征交互。

Method: 提出基于Transformer的检测架构，核心包括：1）新型Transformer解码器作为预测头；2）金字塔标记融合（PTF）模块，将多尺度雷达特征金字塔转换为统一、尺度感知的标记序列；3）以可学习对象查询和位置编码建模检测为集合预测问题。

Result: 在RADDet数据集上显著超越当前最先进的纯雷达基线方法。

Conclusion: 所提方法通过端到端集合预测范式，提升了3D雷达目标检测精度与效率，减少了对人工设计后处理的依赖。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [193] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: 本文提出DIP-ℓ₀框架，利用深度图像先验和ℓ₀梯度正则化实现无需训练数据的高质量图像平滑，在边缘保持和平滑JPEG伪影方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 构建合适的图像平滑训练数据集困难，现有深度学习方法依赖大量标注数据，而传统方法在结构保持与细节去除间难以兼顾。

Method: 提出基于深度图像先验（DIP）并嵌入ℓ₀梯度正则化的无监督框架DIP-ℓ₀；为优化非凸、非光滑的ℓ₀损失函数，设计结合现成ℓ₀梯度最小化求解器的交替方向乘子法（ADMM）。

Result: 在边缘保持图像平滑和JPEG伪影去除任务上，DIP-ℓ₀显著优于多种主流图像平滑算法。

Conclusion: DIP-ℓ₀证明了无需训练数据即可实现高质量图像平滑的可行性，为无监督低级视觉任务提供了新思路。

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [194] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 本文提出SQuID数据集和QVLM模型，通过解耦视觉分析与语言理解、保留像素级精度，显著提升VLM在定量空间推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）因视觉编码器压缩图像导致像素级信息丢失，难以完成计数与测量等定量空间推理任务。

Method: 1）构建SQuID卫星图像定量推理基准数据集（2000个问答对，含数值范围与类别答案，分三级难度）；2）提出QVLM模型，采用代码生成架构：不直接嵌入图像，而是生成可执行代码调用分割模型获取像素掩码，并在掩码上进行后续空间计算。

Result: QVLM（以GPT-5为代码生成器）在SQuID上准确率达42.0%，显著高于基线VLM的28.1%。

Conclusion: 对于定量空间推理，将视觉分析与语言理解在架构上解耦、保持像素级空间索引，能有效提升模型准确性。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [195] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 本文提出了一种针对黑盒深度神经网络的可解释性方法，通过将局部和全局解释建模为单调析取范式（MDNF）逻辑公式，以人类可识别的原始概念来解释模型决策，兼顾高保真度与高覆盖率。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽在图像分类上效果显著，但缺乏可解释性，难以理解其决策依据。

Method: 提出基于单调析取范式（MDNF）的逻辑公式化解释方法，分别构建单张图像的局部解释和图像集合的全局解释，并扩展为支持多类分类的单调解释列表。

Result: 所提方法在多个挑战性视觉数据集上实现了高保真度（fidelity）和高覆盖率（coverage），同时保持简洁与可解释性。

Conclusion: 基于MDNF的逻辑解释方法能有效提升黑盒模型的可解释性，在保证人类可理解的前提下，不显著牺牲对原模型行为的忠实还原能力。

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [196] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 本文研究了使用深度学习（ResNet-18）预测结肠胶囊内镜（CCE）图像清洁度质量的方法，通过结构化剪枝实现高稀疏性（79%）与高准确率（88%）的平衡，并结合多种CAM方法与ROAD评估可解释性，最后采用改进的温度缩放法进行外部数据集校准。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内镜（CCE）图像清洁度评估主观性强、耗时且依赖专家经验；亟需自动、高效、可解释的AI辅助工具以提升临床实用性与可信度。

Method: 基于14名临床医生标注的500张CCE图像（Leighton-Rex四级标准），采用ResNet-18模型与分层K折交叉验证训练分类器；引入迭代结构化剪枝优化模型效率；利用Grad-CAM等五种CAM方法及ROAD框架评估可解释性；并提出自适应温度缩放变体对剪枝模型进行外部数据校准。

Result: 剪枝后模型达到88%交叉验证准确率与79%参数稀疏率，优于原始模型（84%准确率）；ROAD评估揭示了不同CAM方法在CCE图像上的解释一致性差异；校准后模型在外部队列中可靠性提升。

Conclusion: 结构化剪枝可在显著压缩模型的同时保持甚至提升CCE清洁度分类性能；可解释性分析对临床部署至关重要，但ROAD等通用评估方法在医学图像任务中存在适配挑战；校准策略增强了模型泛化能力。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [197] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 本文探索了扩散模型作为通用特征编码器的潜力，通过冻结扩散模型主干并利用其去噪过程中的中间特征进行细粒度识别任务，在浮游生物监测的实际应用中表现出色，尤其在分布偏移情况下仍保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽在图像生成方面表现出色，但其作为通用特征编码器的潜力尚未被充分挖掘；本文旨在验证其在无监督预训练下能否有效捕捉多层次结构信息，并应用于实际细粒度识别任务。

Method: 冻结预训练扩散模型主干，提取不同网络层和去噪时间步的中间特征，为每组（层，时间步）特征训练一个线性分类器，并在浮游生物数据集上进行评估。

Result: 冻结的扩散特征在平衡与长尾数据设置下均优于其他自监督方法，媲美有监督基线；在时空分布偏移的OOD测试中仍保持高准确率和Macro F1。

Conclusion: 扩散模型可作为强大的自监督特征编码器，无需微调即可支持下游细粒度识别任务，尤其具备良好的泛化性和鲁棒性。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [198] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: 本文提出SGW-GAN，首次将切片Gromov Wasserstein（SGW）引入视网膜图像增强，兼顾视觉质量与临床结构保真度，在糖尿病视网膜病变分级等下游任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有GAN和扩散模型虽提升感知质量，但会扭曲类内几何结构，损害疾病分类和病灶检测等临床下游任务。

Method: 提出SGW-GAN框架，将计算高效的Sliced Gromov Wasserstein（SGW）距离嵌入生成对抗网络，以在分布对齐过程中保持类内结构一致性。

Result: 在公开数据集上，SGW-GAN在视觉质量、糖尿病视网膜病变分级准确率及按疾病标签计算的GW差异度指标上均优于对比方法。

Conclusion: SGW-GAN在保证高效性的同时，显著提升了无配对医学图像增强的临床可信度与结构保真度，为医疗图像增强提供了新范式。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [199] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 本文全面分析了基于视觉-语言模型（VLMs）的异常检测方法，重点评估了WinCLIP、AprilLab等架构在异常分类与分割任务中的性能，并探讨其特征提取、图文对齐、提示工程等关键因素。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测依赖大量标注数据或缺陷样本，而VLMs（如CLIP）通过图文对齐实现零样本/少样本检测，亟需系统性分析其适用性与局限性。

Method: 系统调研并实验对比多种VLM-based范式（如WinCLIP、AprilLab框架、组合式提示集成），在MVTec AD和VisA等基准上评估特征提取、对齐策略、提示工程、零/少样本权衡、计算效率及跨域泛化能力。

Result: 明确了不同VLM方法在分类准确率、分割精度和推理效率上的表现差异，提炼出影响性能的关键设计因素，并识别出现有方法在工业质检中应用的主要限制。

Conclusion: VLMs为异常检测提供了强大且灵活的零样本/少样本能力，但其实际效果高度依赖于特征对齐质量、提示设计与任务适配方式；本研究为方法选型与未来改进提供了理论基础与实践指南。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [200] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 本文提出了一种基于物理的处理流程，将事件相机输出的异步事件流映射为像素级对数光强及其导数估计，并嵌入具有时变点扩散函数的动态线性系统模型中，从而支持直接从事件数据进行逆滤波（如频域Wiener反卷积），并在仿真与真实天文观测数据上验证了其在动态光学系统中的源定位与可分性能力。


<details>
  <summary>Details</summary>
Motivation: 事件相机输出非线性的稀疏异步事件流，难以与传统基于线性前向模型的计算成像和光学系统设计兼容。

Method: 构建物理驱动的处理流程，将事件流映射为每像素对数光强及强度导数估计，并嵌入含时变点扩散函数的动态线性系统模型；在此基础上采用频域Wiener反卷积进行逆滤波。

Result: 在仿真中成功处理单个及重叠点光源在调制离焦下的情形；在真实可调焦望远镜采集的星场事件数据上实现了准确的光源定位与可分性。

Conclusion: 该框架为事件感知与面向动态光学系统的基于模型的计算成像之间提供了实用桥梁。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [201] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 本文提出DIS2方法，通过重构解耦学习与知识蒸馏的协同机制（DLKD），结合类特定特征学习模块（CFLM）和多分辨率分层融合结构（HF），有效应对遥感图像中模态缺失、数据异质性与尺度变化大的挑战。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习因模态缺失、数据高度异质性和尺度变化巨大而效果受限；传统解耦学习和知识蒸馏方法难以适应其独特数据特性。

Method: 提出DIS2框架，核心包括：(1) 基于DLKD机制的有原则缺失信息补偿；(2) 类特定模态贡献建模（CFLM模块）；(3) 多分辨率分层混合融合（HF）结构；三者协同实现对缺失模态的主动、引导式特征补偿与判别性表征学习。

Result: 在多个遥感基准上显著超越当前最先进方法，验证了DIS2在模态缺失场景下的鲁棒性与有效性。

Conclusion: DIS2为遥感多模态学习提供了一种专为其数据特性定制的新范式，突破了传统依赖模态共享特征或盲目模仿的局限，实现了更精准、自适应的跨模态语义对齐与补偿。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [202] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: 本文提出了首个面向多层虚拟试衣（ML-VTON）任务的方法GO-MLVTON，通过引入服装遮挡学习模块和基于Stable Diffusion的服装形变与适配模块，实现多层服装的真实变形与分层渲染，并构建了MLG数据集及新评价指标LACD。


<details>
  <summary>Details</summary>
Motivation: 现有图像虚拟试衣方法主要关注单层或多服装但非分层场景，忽略了真实穿衣中多层服装间的遮挡与形变关系，尤其是内外层服装的遮挡建模问题。

Method: 提出GO-MLVTON框架：1）Garment Occlusion Learning模块学习内外层服装间的遮挡关系；2）基于Stable Diffusion的Garment Morphing & Fitting模块实现多层服装的形变与人体拟合；3）构建MLG多层试衣数据集与新指标Layered Appearance Coherence Difference（LACD）。

Result: 在MLG数据集上实验表明，GO-MLVTON显著优于现有方法，达到多层虚拟试衣任务的SOTA性能。

Conclusion: GO-MLVTON是首个系统解决多层虚拟试衣问题的方法，有效建模了服装层间遮挡与形变，推动了VTON向更真实、更复杂穿衣场景的发展。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [203] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: 本文提出了DiffFace-Edit数据集，包含两百万张细粒度区域编辑的AI生成人脸图像，覆盖8个面部区域及多种编辑组合，并首次系统研究了真实与伪造样本拼接产生的检测器规避样本对检测模型的影响。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成人脸数据集缺乏细粒度区域操纵样本，且尚无研究关注真实与伪造样本拼接（splice attacks）所生成的检测器规避样本对检测器的实际影响。

Method: 构建DiffFace-Edit数据集，包含超两百万张AI生成人脸图像，支持8个面部区域的单区域与多区域编辑；设计跨域评估框架，结合IMDL方法分析detector-evasive样本对检测模型的影响。

Result: 发布了大规模、细粒度、多区域编辑的DiffFace-Edit数据集；揭示了detector-evasive样本显著降低当前检测器性能；验证了跨域IMDL评估的有效性。

Conclusion: 细粒度区域编辑和splice攻击生成的detector-evasive样本对现有检测器构成严峻挑战，亟需新方法提升鲁棒性；DiffFace-Edit为该方向研究提供了关键基准。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [204] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 本文提出ChartVerse框架，通过RPE指标引导生成高复杂度图表，并采用答案先行的逆向QA合成方法确保推理严谨性，最终在图表推理任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源视觉语言模型在图表推理任务中受限于高质量训练数据的缺乏，合成图表过于简单重复，且问答对存在幻觉、缺乏深度推理能力。

Method: 提出ChartVerse框架：1）引入Rollout Posterior Entropy（RPE）度量图表复杂度，指导生成多样、高复杂度的可执行图表程序；2）采用truth-anchored逆向QA合成，即先从源代码提取确定性答案，再生成问题并严格验证一致性，并基于模型失败率筛选样本、蒸馏高质量CoT推理链。

Result: 构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，训练出的ChartVerse-8B模型在图表推理任务上达到SOTA，显著超越教师模型Qwen3-VL-30B-A3B-Thinking，并媲美更强的Qwen3-VL-32B-Thinking。

Conclusion: ChartVerse为图表推理提供了高质量、高复杂度、强推理性的开源训练范式，有效缓解了VLM在该领域因数据瓶颈导致的发展滞后问题。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [205] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: 本文提出CARPE框架，通过引入视觉集成层和上下文感知集成策略，提升LVLM在图像分类等视觉任务上的性能，同时保持其多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLMs）在图像分类等视觉中心任务上表现不如其基础视觉编码器（如CLIP），需提升其对视觉信息的利用能力。

Method: 提出CARPE框架：包含视觉集成层与上下文感知集成策略，使模型能自适应地权衡视觉与文本模态，并优先选择更合适的图像表征或语言模型推理路径。

Result: 在图像分类及多种视觉-语言基准测试中均取得一致性能提升；可无缝适配主流开源LVLM架构。

Conclusion: CARPE是一种模型无关、可扩展的通用增强框架，有效弥合LVLM在纯视觉任务上的性能差距，同时不损害其多模态能力。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [206] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为EGM（Efficient visual Grounding language Models）的方法，通过在推理时扩展小规模视觉语言模型（VLM）的生成token数量来提升其视觉定位能力，从而在保持低延迟和高部署友好性的同时，使其性能媲美甚至超越大型VLM。


<details>
  <summary>Details</summary>
Motivation: 小型VLM在视觉定位任务上落后于大型VLM，主因是语言理解能力不足而非视觉编码器性能差；而大型VLM模型体积大、推理慢、部署成本高，亟需一种高效替代方案。

Method: 提出EGM方法，即在测试阶段扩展小模型（如Qwen3-VL-8B）的生成token数以增强其语言建模与推理能力，从而弥补其与大模型（如Qwen3-VL-235B）在定位性能上的差距，同时保持视觉编码器不变。

Result: 在RefCOCO基准上，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟仅737ms（比235B快5.9倍），优于235B的90.5 IoU/4320ms；在新提出的非模态（amodal）定位任务中也显著提升小模型性能，达到或超越大模型水平。

Conclusion: 通过扩展测试时计算（而非模型参数量），可高效提升小型VLM的视觉定位与非模态定位能力，为轻量化、高时效性视觉语言理解提供了可行路径。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [207] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 本文提出了一种在人脸-语音关联任务中引入最大类间分离作为归纳偏置的新方法，显著提升了多模态表征的判别能力，并在两个任务设定上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 以往的人脸-语音关联方法主要依赖损失函数学习嵌入表示，而分类任务中证明最大类间分离能增强嵌入判别性，该思想尚未应用于人脸-语音关联领域。

Method: 提出一种新方法，在人脸与语音的多模态表征中显式施加不同说话人之间的最大类间分离作为归纳偏置，并结合类间正交性损失进行优化。

Result: 在两种人脸-语音关联任务设定下均达到SOTA性能；消融实验表明，该归纳偏置与类间正交性损失联合使用时效果最佳。

Conclusion: 本工作首次将最大类间分离作为归纳偏置应用于多模态学习，验证其有效性，为该领域建立新范式奠定基础。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [208] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: 本文提出了VIAFormer模型，用于多视角图像引导的体素修复任务，通过图像索引、校正流目标和混合流Transformer实现跨模态鲁棒融合，在合成与真实噪声场景下均达到SOTA性能，并验证了其在实际3D生成管线中的实用性。


<details>
  <summary>Details</summary>
Motivation: 解决不完整或含噪体素的修复问题，利用标定的多视角图像作为引导，提升基于体素的3D重建质量，尤其在大模型与大数据背景下增强体素方法的实用性。

Method: 提出VIAFormer：包含提供3D空间定位的图像索引（Image Index）、学习直接体素修复轨迹的校正流目标（Correctional Flow objective）以及支持鲁棒跨模态融合的混合流Transformer（Hybrid Stream Transformer）。

Result: 在严重合成噪声和真实世界伪影修复任务上均取得新SOTA；成功集成到真实3D创作流程中，验证了其工程可靠性与泛化能力。

Conclusion: VIAFormer为多视图引导的体素精细化提供了高效、鲁棒的跨模态建模范式，推动体素表示在大模型时代下的实用化落地。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [209] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

TL;DR: 本文提出了一种融合CNN与LSTM或DeiT Transformer的多任务架构，用于蔬菜分类、腐败检测和保质期预测，并在自建数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 减少农业供应链中的食物浪费，需准确检测和预测食品腐败，从而延长供应链管理寿命。

Method: 提出两种融合架构：CNN+CNN-LSTM 和 CNN+DeiT Transformer，同步完成蔬菜分类、腐败检测与货架期预测；构建涵盖新鲜至完全腐败全过程的蔬菜图像数据集；结合LIME进行可解释性分析，并在噪声图像上验证鲁棒性。

Result: CNN+DeiT Transformer在蔬菜分类和腐败检测中F1-score分别达0.98和0.61，腐败预测的MSE为3.58、SMAPE为41.66%；融合模型整体优于CNN、VGG16、ResNet50、胶囊网络和单独DeiT等模型。

Conclusion: 融合CNN与序列/Transformer建模能力的架构能有效提升多任务性能，尤其在腐败预测等时序相关任务中展现出优势，且具备一定鲁棒性和可解释性。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [210] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: 本文提出了一种名为ClaSP PE的主动学习查询策略，用于3D生物医学图像分割，通过类别分层采样和对数尺度功率噪声衰减调度，有效缓解类别不平衡与早期查询冗余问题，在多个数据集上稳定超越改进的随机采样基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于不确定性的主动学习方法在3D生物医学图像分割中难以持续优于适配3D数据的增强随机采样基线，主因是未解决类别不平衡和早期查询冗余问题。

Method: 提出Class-stratified Scheduled Power Predictive Entropy（ClaSP PE）：结合类别分层查询以覆盖稀疏结构，并引入带衰减调度的对数尺度功率噪声以提升早期多样性、后期聚焦利用。

Result: 在nnActive基准的24种实验设置（4个3D数据集）中，ClaSP PE唯一稳定显著超越增强随机基线；且在4个未见数据集上无需调参即实现鲁棒泛化。

Conclusion: ClaSP PE是一种简单、有效、即插即用的主动学习策略，首次在贴近实际部署的场景中系统性证明了AL方法可一致优于适配3D分割的随机基线，具备实用推广价值。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [211] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: 本文提出了一种新型线性注意力机制DyDiLA，用于提升线性扩散变换器（LiTs）的生成质量，通过动态投影、动态测度核和令牌微分算子缓解过平滑问题，并构建了改进模型DyDi-LiT，在多项指标上超越当前SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有线性扩散变换器（LiTs）为降低自注意力的二次计算成本而牺牲生成性能，常导致注意力权重过平滑，限制模型表达能力。

Method: 提出动态微分线性注意力（DyDiLA），包含三个核心设计：(i) 动态投影模块，解耦token表征；(ii) 动态测度核，动态分配核函数以捕捉细粒度语义差异；(iii) token微分算子，基于动态测度核输出的信息冗余增强query-to-key检索鲁棒性；并据此构建改进模型DyDi-LiT。

Result: DyDi-LiT在多个评估指标上持续超越当前最先进（SOTA）模型。

Conclusion: DyDiLA有效缓解LiTs中的过平滑问题，显著提升生成质量，DyDi-LiT展现出强实用性与先进性。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [212] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 本文综述了视觉谜题在评估大视觉语言模型（LVLMs）推理能力中的作用，按归纳、类比、算法、演绎和几何/空间等推理机制对现有基准进行分类，并指出当前模型在泛化性、感知-推理耦合及解释与执行一致性方面的局限。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题能以低先验知识依赖的方式揭示抽象、规则发现和系统性推理能力，因而被用作评估LVLMs推理能力的可控、可验证诊断工具。

Method: 提出统一的视觉谜题抽象框架，按五类核心推理机制（归纳、类比、算法、演绎、几何/空间）组织现有基准，并综合实证研究结果分析模型表现。

Result: 发现当前LVLMs存在脆性泛化、感知与推理紧密耦合、流利解释与忠实执行之间存在鸿沟等一致缺陷。

Conclusion: 应将视觉谜题定位为诊断仪器而非普通任务格式，以此推动更严谨的推理评估基准与推理感知型多模态系统的发展。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [213] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

TL;DR: 本文提出ParkingTwin，一种无需训练、轻量级的在线流式3D重建系统，用于构建高保真停车场数字孪生体，解决AVP中几何病态、动态遮挡与光照鲁棒性差、神经渲染计算开销大等难题；其核心包括OSM先验几何构建、几何感知动态滤波与CIELAB空间光照鲁棒融合，在入门级GPU上实现实时性能，并显著优于3DGS。


<details>
  <summary>Details</summary>
Motivation: 自动化代客泊车（AVP）需高保真停车场数字孪生体作为路径规划、碰撞检测与感知验证的先验，但现有机器人导向重建面临三难困境：前向稀疏视角导致几何病态、动态遮挡与极端光照影响纹理融合稳定性、神经渲染依赖昂贵离线优化，难以满足边缘端流式处理需求。

Method: ParkingTwin包含三部分：1）基于OpenStreetMap语义拓扑的先验驱动几何构建，直接生成度量一致TSDF，避免盲目搜索与优化；2）基于法向/高度/深度四模态一致性约束的几何感知动态滤波，实时剔除移动车辆与瞬态遮挡；3）在CIELAB色彩空间中进行光照鲁棒融合，通过自适应L通道加权与深度梯度抑制缓解光照突变导致的拼接伪影。

Result: 在68,000 m²真实数据集上，SSIM达0.87（提升16.0%），端到端速度提升约15倍，GPU显存占用降低83.3%，在GTX 1660上达30+ FPS；输出兼容Unity/Unreal的显式三角网格。

Conclusion: ParkingTwin是一种高效、鲁棒、边缘友好的停车场数字孪生重建方案，突破了传统神经渲染对高端硬件与离线优化的依赖，为AVP实际部署提供了可行技术路径。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [214] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: 本文提出Attention-space Contrastive Guidance (ACG)方法，通过在自注意力层中构建视觉-语言与纯语言两条注意力路径，以单次前向传播实现对比引导，缓解大视觉语言模型中的幻觉问题，显著提升生成结果的忠实性与质量，同时降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（LVLMs）常因语言先验压倒视觉证据而产生幻觉，导致物体误识别和视觉不一致描述，亟需高效、轻量的幻觉缓解机制。

Method: 提出Attention-space Contrastive Guidance（ACG），在单次前向传播中于自注意力层内并行构建视觉-语言与纯语言注意力路径，并引入正交化校正去除语言路径干扰分量，增强视觉贡献。

Result: 在CHAIR和POPE基准上达到SOTA的忠实性与描述质量，计算延迟相比多步对比解码方法最高降低2倍。

Conclusion: ACG为LVLM幻觉缓解提供了一种原理清晰、嵌入式、高效率的单通对比引导新范式。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [215] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

TL;DR: 本文提出MVGD-Net，利用玻璃表面反射/透射物体运动速度慢于真实物体这一运动不一致性线索，实现视频中玻璃表面检测，并构建了含312个场景、19268帧的大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在视觉系统（如机器人、无人机导航）中普遍存在且易造成误判，需有效检测；现有方法未充分利用视频中玻璃反射/透射层与真实场景间的运动差异这一关键线索。

Method: 提出MVGD-Net网络，包含跨尺度多模态融合模块（CMFM）、历史引导注意力模块（HGAM）、时序交叉注意力模块（TCAM）以增强时空特征，以及时空解码器（TSD）生成玻璃区域掩码；同时构建大规模视频玻璃检测数据集。

Result: 在多个指标上显著优于当前主流方法，验证了运动不一致性线索的有效性及MVGD-Net的优越性能。

Conclusion: 运动不一致性是视频玻璃表面检测的有效判据，MVGD-Net通过深度融合时空与多模态特征，实现了更鲁棒、精准的玻璃检测。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [216] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D面部网格序列的时空图（STGraph）表示方法及轻量级图卷积网络MeshPhys，用于面部远程光电容积描记（rPPG），实现了表面对齐的生理信号估计，在多个数据集上达到SOTA或具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有面部rPPG方法未显式将其感受野与三维面部表面（即rPPG信号的空间支撑）对齐，导致建模不准确。

Method: 提出面部时空图（STGraph）表示，编码3D面部网格序列中的颜色与结构信息；设计轻量级时空图卷积网络MeshPhys，在STGraph上进行表面对齐的生理信号估计。

Result: 在四个基准数据集的组内和跨数据集设置中均达到最优或具竞争力的性能；消融实验表明，将感受野约束于面部表面作为强结构先验，且表面对其的3D感知节点特征对鲁棒编码面部颜色至关重要。

Conclusion: STGraph与MeshPhys共同构成一种新颖、原理清晰的面部rPPG建模范式，提升了估计的鲁棒性、可解释性与泛化能力。

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [217] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 本文提出了一种适用于小卫星的星上洪水检测系统HiT-Prithvi，通过History Injection机制在Transformer模型中高效保留历史上下文，大幅降低存储需求（减少99%以上），同时保持检测精度，并在Jetson Orin Nano上实现43 FPS实时推理，支持不依赖地面设施的连续灾害监测。


<details>
  <summary>Details</summary>
Motivation: 自然灾难（如洪水）需通过卫星持续观测进行监测，但小卫星受限于星上内存与算力，难以部署多时相变化检测模型；现有方法依赖地面处理，无法满足实时性与自主性需求。

Method: 提出History Injection for Transformer（HiT）机制，在轻量级Prithvi-tiny模型中嵌入历史状态缓存与增量更新策略，避免存储完整历史影像；模型专为星上部署优化，适配Jetson Orin Nano等嵌入式硬件。

Result: 在STTORM-CD洪水数据集上，HiT-Prithvi保持与双时相基线相当的检测精度；在Jetson Orin Nano上达43 FPS推理速度；历史数据存储减少超99%。

Conclusion: HiT机制为小卫星提供了高效、低资源消耗的多时相变化检测新范式，验证了星上实时自然灾害监测的可行性，推动遥感系统向自主化、实时化演进。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [218] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: 本文介绍了DermaBench，一个由临床医生标注的皮肤病学视觉问答（VQA）基准数据集，旨在全面评估多模态视觉语言模型在皮肤病学中的图像理解、语言对齐和临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有皮肤病学数据集主要聚焦于图像级分类任务，无法充分评估视觉语言模型在细粒度形态分析、临床推理和语言生成等方面的综合能力，亟需更全面的VQA基准。

Method: 基于Diverse Dermatology Images（DDI）数据集，采用分层标注方案，由皮肤科专家对656张临床图像（涵盖Fitzpatrick I-VI型肤色）进行多维度标注，包括22类单选、多选及开放式问题，覆盖诊断、解剖部位、皮损形态等，并生成叙述性描述与摘要。

Result: 构建了包含约14,474条VQA式标注的DermaBench基准，以元数据形式发布于Harvard Dataverse，兼顾版权合规与公开可用性。

Conclusion: DermaBench填补了皮肤病学领域高质量VQA评估基准的空白，为推动医疗视觉语言模型的临床适用性评估提供了重要基础设施。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [219] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: 本文提出PREGEN框架，通过冻结预训练视觉语言模型（VLM）并提取其各层最后一词元的隐藏状态，结合轻量编码器生成紧凑语义嵌入，实现高效、免微调的组合视频检索（CoVR），显著提升Recall@1性能并具备强零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoVR方法未能充分利用现代视觉语言模型（VLM），或采用过时架构，或依赖计算昂贵的微调和慢速字幕生成。

Method: 提出PREGEN框架：冻结预训练VLM，输入查询视频与修改文本，提取每层最后一词元的隐藏状态；用轻量编码器对这些池化表征进行训练，生成语义丰富且紧凑的检索嵌入，无需任何VLM微调。

Result: 在标准CoVR基准上大幅超越所有先前方法，Recall@1提升达+27.23和+69.59；在不同VLM主干上鲁棒，并展现出对复杂文本修改的强零样本泛化能力。

Conclusion: PREGEN是一种高效、免微调、语义能力强的CoVR新范式，推动了该领域性能与实用性的发展。

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [220] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: 本文提出了首个专注于多图像推理安全性的基准MIR-SafetyBench，发现多图像推理能力越强的多模态大语言模型（MLLMs）在该基准上反而更易出现安全问题，并揭示了unsafe生成具有更低注意力熵这一内部风险信号。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型（MLLMs）在多图像复杂指令推理能力上的提升，其潜在的安全风险亟需系统评估，但此前缺乏专门针对多图像推理安全性的基准。

Method: 构建首个面向多图像推理安全性的基准MIR-SafetyBench（含2676个样本、9类多图像关系），对19个MLLM进行大规模评测，并分析攻击成功率、响应安全性、注意力熵等指标。

Result: 发现更强的多图像推理能力与更高安全风险正相关；大量‘安全’响应实为误解或回避性回答；unsafe生成平均注意力熵显著低于safe生成。

Conclusion: 多图像推理能力提升可能以牺牲安全为代价，低注意力熵可作为潜在内部风险指标，提示模型过度聚焦任务求解而忽视安全约束。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [221] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: 本文提出了Insight模型，一种语言对齐的概念基础模型，能够从图像中自动提取细粒度、人类可解释且空间定位的概念，并通过概念间局部共现关系提升命名和解释质量，在分类与分割任务上达到与不透明基础模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言对齐视觉基础模型的表征难以解释，虽有工作尝试分解为可解释概念，但缺乏空间定位能力且局限于图像分类任务。

Method: 提出Insight模型，结合分层稀疏自编码器与强语义表征的基础模型，自动提取多粒度概念；利用概念局部共现依赖建模概念关系，进而优化概念命名与解释生成。

Result: 在基准数据集上，Insight在图像分类与分割任务中性能媲美黑箱基础模型，同时提供细粒度、高质量、空间定位的概念级解释。

Conclusion: Insight实现了语言对齐、空间接地与概念可解释性的统一，为理解视觉基础模型决策提供了新范式。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [222] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种名为Colorspace Discriminant Analysis (CSDA) 的新型多维非线性判别分析算法，用于优化图像分割前的颜色表征。该方法将线性判别分析扩展至深度学习框架，通过广义判别损失最大化类间可分性并最小化类内差异，并引入三种替代损失以实现端到端训练。在风力涡轮叶片数据上的实验验证了其显著提升分割精度的效果。


<details>
  <summary>Details</summary>
Motivation: 亚优的颜色表征常阻碍图像分割的准确性，而许多现代算法忽视了这一关键预处理步骤。

Method: 提出Colorspace Discriminant Analysis (CSDA)，一种扩展线性判别分析至深度学习的多维非线性判别分析算法；通过广义判别损失最大化多维带符号类间可分性、最小化类内变化；引入三种替代损失以支持端到端优化颜色空间与分割过程。

Result: 在风力涡轮叶片数据集上实验表明，该方法显著提升了分割精度。

Conclusion: 针对特定领域的图像分割，定制化的颜色预处理至关重要；CSDA为联合优化颜色表征与分割提供了有效新范式。

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [223] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

TL;DR: 本文提出了一种名为\OURS的前馈式方法，仅需少量输入图像即可生成高质量、可实时动画的3D高斯头像，通过Transformer融合多特征、轻量MLP预测形变，并利用预训练大模型点图进行几何监督。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯的头像建模方法依赖多视角采集或单目视频的逐身份优化，导致扩展性差、难以泛化到未见人物。

Method: 提出\OURS：1）前馈式像素级高斯表示学习；2）基于Transformer的编码器融合DINOv3与Stable Diffusion VAE特征；3）为高斯添加每高斯特征并设计轻量MLP动态网络预测表情驱动的3D形变；4）利用预训练大重建模型输出的点图作为几何平滑监督。

Result: 在渲染质量与推理效率上显著优于现有方法，并支持实时动态头像动画。

Conclusion: \OURS实现了高效、高质量、可动画的高斯头像生成，解决了现有方法在泛化性、可扩展性与实时性方面的关键瓶颈。

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [224] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: 本文介绍了DisasterVQA——一个面向灾害响应场景的视觉问答基准数据集，包含1395张真实灾害图像和4405个专家标注的问答对，覆盖洪水、野火、地震等多类事件，并基于人道主义框架设计问题类型；实验评估了7种主流视觉语言模型，发现其在细粒度定量推理、物体计数和上下文敏感理解方面表现不足，尤其在代表性不足的灾害场景中；该数据集旨在推动更鲁棒、更具操作意义的灾害响应视觉语言模型发展。


<details>
  <summary>Details</summary>
Motivation: 现有视觉问答（VQA）模型在通用领域表现良好，但在灾害响应这类复杂、安全关键的场景中，其感知与推理能力尚不明确，亟需专门的基准来评估和推动模型在真实危机情境下的实用性。

Method: 构建DisasterVQA基准数据集：收集1395张真实灾害图像，由专家标注4405个涵盖二值、多选与开放式问题的问答对，问题设计依据FEMA ESF与OCHA MIRA等人道主义框架，覆盖情景感知与行动决策任务；并对7种SOTA视觉语言模型进行系统性评测，分析其在不同题型、灾害类型、地域及人道任务上的性能差异。

Result: 模型在二值判断类问题上准确率较高，但在细粒度定量推理、物体计数及上下文敏感解释方面表现显著下降，尤其在代表性不足的灾害场景中泛化能力弱；各模型性能在不同维度上存在明显波动，凸显当前方法的局限性。

Conclusion: DisasterVQA为灾害响应中的视觉语言理解提供了首个兼具真实性、专业性与挑战性的公开基准，揭示了现有模型在安全关键推理任务上的短板，为开发更鲁棒、可部署的AI系统指明方向。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [225] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出深度判别分析（DDA）及其概率化扩展PDDA，通过深度网络直接优化Fisher准则，解决线性判别分析在非线性可分数据上的局限，并首次将其应用于风力叶片图像分割任务，显著提升性能与一致性。


<details>
  <summary>Details</summary>
Motivation: 线性判别分析（LDA）难以处理非线性可分数据，需引入深度学习方法增强判别能力并提升稳定性。

Method: 提出DDA，直接在深度网络中优化Fisher准则；引入符号化类间方差、Sigmoid输出约束和乘法转加法策略以稳定训练；设计两种稳定DDA损失函数，并融合概率损失形成PDDA。

Result: PDDA有效减小类内方差、降低类别重叠，输出高置信度预测；在风力叶片分割任务中展现出显著的性能提升与结果一致性。

Conclusion: DDA/PDDA为判别式深度学习提供了新范式，首次成功拓展至图像分割领域，尤其适用于对鲁棒性和一致性要求高的工业视觉应用。

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [226] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: 本文提出OCCAM，首个无需训练、不依赖额外信息（如视觉示例或文本提示）的类无关目标计数（CAC）方法，支持单图多类别同时计数，基于SAM2和改进的FINCH聚类算法，在FSC-147和CARPK上取得有竞争力的结果，并构建了合成多类数据集与F1评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有CAC方法大多假设单图单类、需大量训练、依赖额外信息，难以扩展到真实场景中的多类任意计数需求。

Method: 利用SAM2基础模型生成高质量分割掩码，结合自定义阈值版FINCH层次聚类算法对掩码进行无监督分组，从而实现无需训练、无需示例/提示的多类目标计数。

Result: 在FSC-147和CARPK基准上达到有竞争力性能；提出合成多类数据集及更适合CAC任务的F1分数作为新评估指标。

Conclusion: OCCAM首次实现了真正类无关、训练自由、多类共存的目标计数，为CAC提供了更通用、轻量且实用的新范式。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [227] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出MTV多任务视觉预训练框架，融合视觉-语言对比学习、自监督学习和密集空间监督，利用大模型生成伪标签，实现全局语义理解与细粒度空间推理的统一提升。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表征学习存在割裂：视觉-语言模型擅长全局语义对齐但缺乏空间精度，自监督方法捕捉局部结构却难以建模高层语义；二者本质互补，亟需统一框架整合。

Method: 提出MTV框架，在共享骨干网络上联合优化视觉-语言对比、自监督重建与密集空间预测三类目标；利用Depth Anything V2、OWLv2等专家模型自动生成大规模密集伪标签，避免人工标注。

Result: MTV在细粒度空间推理能力显著提升的同时，不损害全局语义理解，实现‘两全其美’性能；系统分析揭示了各任务的边际增益、协同/干扰效应及不同规模下的扩展规律。

Conclusion: 多任务学习结合高质量伪监督是构建更通用视觉编码器的一条可扩展路径。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [228] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 本文提出OmniOVCD框架，利用SAM 3的解耦输出头设计SFID策略，实现无需训练的开放词汇变化检测，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇变化检测（OVCD）方法依赖多模型（如CLIP+DINO），存在特征对齐困难和系统不稳定问题；而新兴的SAM 3具备一体化分割与识别能力，为OVCD提供了新思路。

Method: 提出OmniOVCD框架，基于SAM 3的语义、实例和存在性三类解耦输出，设计协同融合—实例解耦（SFID）策略：先融合生成土地覆盖掩码，再解耦为单个实例掩码用于变化比对。

Result: 在LEVIR-CD、WHU-CD、S2Looking和SECOND四个公开数据集上取得SOTA性能，类别平均IoU分别为67.2、66.5、24.5和27.1。

Conclusion: OmniOVCD是一种端到端、无需训练的OVCD新范式，兼顾高类别识别精度与跨图像实例一致性，显著提升变化检测准确性。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [229] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 本文提出了一种可解释的深度统计检验框架，用于无标签的两样本检验，能同时提供样本级和特征级解释，尤其适用于生物医学影像分析。


<details>
  <summary>Details</summary>
Motivation: 深度神经两样本检验虽有强检验效能，但其黑盒特性限制了在生物医学分析中的可解释性和实际应用；现有后验解释方法大多依赖类别标签，不适用于无标签的统计检验场景。

Method: 提出一种增强型深度两样本检验框架，融合样本级与特征级解释机制，识别对组间差异贡献最大的个体样本和输入特征（如图像区域）。

Result: 在生物医学影像数据上验证了该框架能有效识别关键样本，并高亮解剖学上有意义的疾病相关区域。

Conclusion: 该工作弥合了统计推断与可解释AI之间的鸿沟，支持医学影像中可解释、无标签的人群差异分析。

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [230] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 本文提出了一种利用2D图像平面旋转等变性来提升单目3D人体姿态估计性能的方法，通过数据增强实现旋转等变，无需显式设计等变网络结构，效果优于显式等变设计的SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D人体姿态估计（HPE）方法在处理图像平面内旋转输入时表现不佳；作者认为学习具有旋转等变性的人体姿态比直接学习点对点映射更自然、更符合几何直觉，且隐式学习等变性比显式约束参数空间更简单有效。

Method: 采用数据增强方式（对训练图像及其2D关节点标注施加随机2D平面旋转）使模型隐式学习旋转等变性，不修改网络结构或施加显式等变约束；基于标准两步流程（2D检测+2D-to-3D提升），在提升模块中引入该增强策略。

Result: 在主流HPE基准（如Human3.6M、MPI-INF-3DHP）上验证了所提方法的有效性：仅靠旋转增强即可显著提升模型对旋转姿态的泛化能力，性能超越显式设计的旋转等变方法。

Conclusion: 2D图像平面旋转等变性本身对单目3D HPE有实质性增益；该性质可通过简单高效的数据增强方式隐式习得，无需复杂等变网络设计，是一种更实用、更有效的提升泛化能力的策略。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [231] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: 本文提出TrackletGPT，一种类语言GPT框架，利用‘tracklets’（亚流线段）重新引入序列信息，实现白质纤维束的自动、跨数据集泛化分割，在多个指标和数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对脑结构连接、神经疾病和神经外科研究至关重要，但因纤维束个体间及条件间差异大、而三维结构又具相似性，任务复杂。

Method: 提出TrackletGPT框架，将纤维束划分为细粒度的‘tracklets’作为token，建模其序列关系，扩展并精细化GPT模型用于纤维束分割。

Result: 在TractoInferno和HCP数据集上，TrackletGPT在平均DICE、Overlap和Overreach指标上均优于当前最优方法，且具备跨数据集泛化能力。

Conclusion: TrackletGPT是一种全自动、可泛化、高精度的白质纤维束分割新范式，成功将大语言模型思想迁移到神经影像结构分析中。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [232] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: 本文提出Glance-or-Gaze（GoG）框架，通过选择性注视机制和双阶段训练策略，提升大视觉语言模型在知识密集型视觉问答中的检索准确性与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型受限于静态参数化知识，难以应对长尾实体和动态信息；而当前检索增强方法存在图像级检索冗余噪声大、缺乏深度迭代反思等问题。

Method: 提出GoG框架，包含Selective Gaze机制（动态决定全局浏览或局部聚焦）和双阶段训练：1）监督微调对齐GoG行为；2）复杂度自适应强化学习提升复杂查询的迭代推理能力。

Result: 在六个基准上达到SOTA性能；消融实验证明Selective Gaze与复杂度自适应RL均至关重要。

Conclusion: GoG实现了从被动感知到主动视觉规划的范式转变，显著提升了知识密集型视觉理解任务的效果。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [233] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: 本文提出了VTONGuard，一个包含77.5万张真实与合成虚拟试穿图像的大规模基准数据集，并基于该数据集系统评估了多种检测方法，提出了一种结合辅助分割的多任务框架以提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，虚拟试穿（VTON）内容日益逼真，引发真实性与负责任使用问题，亟需可靠的检测手段。

Method: 构建VTONGuard大规模基准数据集；在统一协议下系统评估多种检测范式；设计融合辅助分割的多任务检测框架以增强边界感知特征学习。

Result: 揭示了各检测方法的优缺点及跨范式泛化难题；所提多任务框架在VTONGuard上取得最佳整体性能。

Conclusion: VTONGuard为虚拟试穿内容检测提供了公平评估基准，推动更鲁棒检测模型的发展，促进VTON技术的安全、负责任落地。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [234] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 本文提出DExTeR，一种基于Transformer的点到框回归模型，用于弱半监督医学图像目标检测，通过类引导可变形注意力、CLICK-MoE结构和多点训练策略，显著提升重叠解剖结构下的定位精度，降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 医学图像中解剖结构重叠、尺度变化大、结构隐匿，导致现有基于点标注的弱半监督检测方法难以准确推断边界框，亟需适配医学影像特性的新方法。

Method: 基于Point-DETR构建DExTeR模型：1）引入类引导的可变形注意力机制，利用点坐标与类别标签指导特征采样；2）设计CLICK-MoE模块，解耦类级与实例级表征以缓解邻近/重叠实例混淆；3）采用多点训练策略增强对点标注变异的鲁棒性。

Result: 在内窥镜、胸部X光和内镜超声三个跨域医学数据集上达到SOTA性能，显著优于现有WSSOD方法。

Conclusion: DExTeR有效应对医学图像特殊挑战，在仅需单点标注条件下实现高精度定位，为低标注成本的临床辅助诊断提供了可行技术路径。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [235] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: 本文提出了一种无需参考的视频帧采样质量评估指标STEC，结合空间信息熵（STFE）、时间覆盖度与非冗余性，用于诊断不同采样策略在资源受限下的表现，不预测下游任务精度，但具备实用诊断价值。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标多关注感知质量或重建保真度，难以衡量采样帧是否充分、代表性地捕获视频内容信息。

Method: 提出Spatio-Temporal Entropy Coverage（STEC）指标：基于每帧的空间熵（STFE）刻画结构复杂度，并联合建模时间分散性与帧间非冗余性，实现轻量、无参考的采样质量评估。

Result: 在MSR-VTT test-1k上，STEC能清晰区分随机、均匀、内容感知等采样策略；且可揭示单个视频层面的鲁棒性模式，超越平均性能分析。

Conclusion: STEC是一种原理清晰、计算高效、任务无关的帧采样诊断工具，适用于资源受限场景下的视频理解系统分析与优化。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [236] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 本文提出了一种面向跨域泛化能力的统一信息处理流程，用于提升水下入侵物种检测在不同海域场景中的鲁棒性，并揭示了场景结构因素比视觉退化更主导性能下降，同时验证了其在边缘设备上的实时可行性。


<details>
  <summary>Details</summary>
Motivation: 现有水下生物检测方法在新环境部署时性能急剧下降，难以满足大范围、多地点海洋生物多样性监测的实际需求。

Method: 构建统一信息处理流程（Unified Information Pipeline），标准化异构数据；在受控跨域协议下评估固定检测器；分析结构与视觉因素对性能的影响；在低成本边缘硬件上进行推理基准测试。

Result: 发现场景构成、目标密度和上下文冗余等结构性因素比浑浊度等视觉退化更显著影响跨域性能；稀疏场景会引发‘上下文崩溃’失效模式；边缘设备经运行时优化后可支持远程监测所需的采样率。

Conclusion: 应将研究重点从图像增强转向结构感知的可靠性建模，该方法为海洋生态系统评估提供了可普及、一致性强的检测工具。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [237] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种无需监督信号的图像去雾新框架EID，利用图像信号对称性与 haze 物理建模结合，显著提升科学成像（如显微、内窥镜）和自然图像的去雾效果。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法依赖人工设计先验或大量无雾真值标签，成本高且在科学成像中难以获取。

Method: 提出无监督的等变图像去雾框架（EID），通过约束雾一致性与系统性等变性，并引入对抗学习建模未知雾物理过程。

Result: 在细胞显微、医学内窥镜及自然图像去雾基准上显著优于当前最优方法。

Conclusion: EID将等变学习与雾物理建模统一，为科学成像中的鲁棒、高效去雾提供了新范式。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [238] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

TL;DR: 本文将基于扩散模型的单图像逆问题求解方法推广到多图像超分辨率（MISR）MRI重建，提出无需修改模型或增加计算开销的可分离梯度校正策略，并在各向异性降质MRI上取得SOTA性能，同时支持从常规2D多层扫描重建近各向同性解剖结构。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的逆问题方法主要针对单图像，而MRI等模态常获取多个互补的低分辨率测量（沿不同轴），需适配多图像超分辨率（MISR）场景。

Method: 将DPS等扩散采样方法推广至MISR，利用DPS似然校正实现跨独立测量的精确可分离梯度分解，无需构造联合算子、修改扩散模型或增加网络评估次数；并推导出MISR版本的DPS、DMAP、DPPS及扩散PnP/ADMM。

Result: 在4×/8×/16×各向异性退化下显著优于单图像超分辨率（SISR）方法；达到各向异性MRI体积超分辨率的SOTA水平；首次实现从常规2D多层扫描中重建高质量近各向同性解剖结构。

Conclusion: 所提方法为多测量成像模态（如MRI）提供了高效、通用且无需重训练的扩散模型扩展框架，显著提升了临床可行的各向同性重建能力。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [239] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: 本文提出了一种简单但有效的奖励模型HuDA，用于评估和提升视频生成中的人体运动质量，无需额外训练，仅依赖现成模型，在复杂人体动作生成上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在处理复杂非刚性运动（如体育、舞蹈等）时表现不佳，常出现肢体缺失/多余、姿态扭曲或物理不合理等问题，亟需一种有效评估和优化人体运动质量的方法。

Method: 提出HuDA奖励模型，结合人体检测置信度（衡量外观质量）与时间提示对齐得分（衡量运动真实性），完全基于现成模型，无需额外训练；并将其用于Group Reward Policy Optimization（GRPO）进行视频模型后训练优化。

Result: HuDA在复杂人体动作生成任务上显著提升性能，胜率高达73%，超越Wan 2.1等SOTA模型；同时泛化至动物视频和人-物交互生成，提升整体生成质量。

Conclusion: 一个轻量、免训练、基于多源信号融合的奖励模型HuDA，可有效驱动视频生成模型优化复杂人体运动，并具备跨类别泛化能力，为视频生成的可控性与真实性提供了新思路。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [240] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 本文首次发现并修正了自动驾驶数据集中3D框标注因动态场景和传感器扫描时序导致的系统性误差，提出离线估计方法实现物理合理、时空一致的标注校正，并定义新评估指标，在多个数据集上提升标注质量超17%，同时证明错误标注对性能评估的影响远超SOTA方法的改进幅度。


<details>
  <summary>Details</summary>
Motivation: 准确的真值标注对自动驾驶系统的监督学习和性能评估至关重要；但现有基于LiDAR等主动传感器的3D框标注在动态场景中因对象在不同时间戳位置变化而易引入系统性误差，且该问题此前未被识别和量化。

Method: 提出一种新颖的离线估计方法，通过建模物体运动轨迹，使3D框标注满足物理可行性，并与传感器数据在空间和时间上保持一致性；同时首次为该问题定义了专门的评估指标。

Result: 在Argoverse 2、MAN TruckScenes及自研数据集上，标注质量提升超17%；量化发现原始标注最大偏移达2.5米，高动态物体受影响最严重；进一步验证表明标注误差对基准测试结果的影响大于当前SOTA方法相对于前一代的性能提升。

Conclusion: 3D框标注中的时序不一致问题真实存在且影响显著，必须加以校正；高质量、时空一致的标注是正确评估和推动自动驾驶算法发展的基础。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [241] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 本文提出了一种通用、模块化的放弃机制（abstention）框架，用于提升医学图像分割中噪声标签下的鲁棒性，通过引入有指导的正则项和基于幂律的自动调优算法，将其与多种损失函数结合，显著提升了在高噪声数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声普遍存在且影响模型泛化，而现有去噪方法研究不足，放弃机制在分类中有效但在分割中尚未验证。

Method: 提出一种通用、模块化的放弃机制框架，包含两个创新点：1）有指导的正则项以引导放弃行为；2）基于幂律的自动调优算法优化放弃惩罚项；并将其分别与三种损失函数结合，构建GAC、SAC和ADS三种新损失变体。

Result: 在CaDIS和DSAD医学数据集上实验表明，所提方法在各类噪声水平下均显著优于基线方法，尤其在高噪声场景下优势更明显。

Conclusion: 允许模型选择性忽略被污染样本是一种强大且可推广的策略，能有效提升医学图像分割模型的鲁棒性与可靠性。

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [242] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 本文提出联邦平衡学习（FBL），通过客户端侧的样本平衡（利用边缘生成模型进行知识填充与采样）来防止非独立同分布（non-iid）场景下的客户漂移问题，并引入知识对齐与知识丢弃策略提升泛化性，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习的non-iid设定下，全局模型易受客户漂移影响，而以往方法多在模型已偏离后修正，忽视了客户端样本分布不均的根本原因。

Method: 提出联邦平衡学习（FBL）：在客户端受限样本量前提下，利用边缘侧生成模型实现知识填充与知识采样以达成样本平衡；设计知识对齐策略弥合合成数据与真实数据差异，知识丢弃策略用于正则化；支持异构客户端灵活适配并可扩展。

Result: 大量实验表明FBL在多个基准上显著优于当前最优基线方法。

Conclusion: 从客户端样本平衡入手预防客户漂移是有效且可行的路径，FBL为non-iid联邦学习提供了新思路与实用框架。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [243] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出WeatherQA气象多模态推理基准和LoCo-RFT逻辑一致强化微调方法，构建首个具备逻辑可信性的气象推理视觉语言模型Weather-R1，显著提升推理准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 主流强化微调方法在气象领域易引发自相矛盾推理（Self-Contra），而气象是高风险领域，要求推理结果与答案严格一致，现有VLM存在域差距和推理可信度差距。

Method: 构建气象多模态推理基准WeatherQA；提出逻辑一致性强化微调方法LoCo-RFT，通过引入逻辑一致性奖励抑制自相矛盾推理；基于此训练出气象专用推理VLM Weather-R1。

Result: Weather-R1在WeatherQA上较基线提升9.8个百分点，优于监督微调和常规RFT，甚至超越原始Qwen2.5-VL-32B。

Conclusion: LoCo-RFT能有效缓解气象VLM中的自相矛盾推理问题，Weather-R1验证了逻辑一致性建模对高风险领域VLM推理可信度的关键作用。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [244] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: 本文提出MM-OOD方法，利用多模态大语言模型（MLLMs）的多轮对话与多模态推理能力，改进零样本OOD检测，尤其在近端和远端OOD任务上均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的零样本OOD检测方法过度依赖文本空间知识，忽视图像空间中OOD样本检测的固有挑战。

Method: 提出MM-OOD框架：(1) 近端OOD任务直接输入ID图像与文本提示至MLLMs进行判别；(2) 远端OOD任务采用‘草图-生成-详述’三阶段框架，结合文本引导的OOD草图、视觉样本生成与多模态提示精炼。

Result: 在Food-101等多模态数据集上性能显著提升，并在ImageNet-1K上验证了可扩展性。

Conclusion: MM-OOD通过融合多模态推理与多轮交互，有效缓解纯文本先验带来的偏差，提升了OOD检测的鲁棒性与泛化性。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [245] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

TL;DR: SVGFormer是一种无需解码器的3D医学图像分析新范式，通过语义超体素图与分层编码器（结合Patch级Transformer和超体素级GAT）实现高效特征学习与双尺度可解释性，在BraTS数据集上取得优异分类与回归性能。


<details>
  <summary>Details</summary>
Motivation: 传统3D医学影像骨干网络依赖参数密集的编解码结构，大量参数用于空间重建而非特征学习，导致效率低且缺乏可解释性。

Method: 提出SVGFormer：首先通过内容感知分组将体积分割为语义超体素图；然后采用分层编码器——底层用Patch级Transformer建模局部细节，上层用超体素级图注意力网络（GAT）建模区域间依赖；全程无解码器，所有参数专用于特征编码。

Result: 在BraTS数据集上，节点级分类模型F1达0.875，肿瘤比例回归模型MAE为0.028；模型具备从patch到region的双重可解释性。

Conclusion: 基于图的纯编码器范式可在保持高精度的同时，显著提升3D医学图像表征的效率与内在可解释性，为临床辅助诊断提供更可靠、透明的深度学习方案。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [246] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出POCI-Diff，一种基于扩散模型的文本到图像生成方法，支持一致且交互式的3D布局控制与编辑，通过联合建模3D几何约束和实例级语义绑定，实现无扭曲的多对象合成与编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖2D线索或迭代复制-扭曲-粘贴策略，易导致物体几何失真且难以保持跨编辑的一致性。

Method: 提出POCI-Diff框架，结合Blended Latent Diffusion实现文本描述与3D包围盒的语义绑定，并引入基于IP-Adapter的参考图像条件化机制；设计无扭曲的生成式编辑流程，支持对象插入、删除与变换。

Result: 实验表明POCI-Diff在视觉质量与3D布局一致性上优于现有方法，消除了扭曲引起的几何伪影。

Conclusion: POCI-Diff为文本到图像生成提供了更鲁棒、可控且一致的3D交互编辑能力。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [247] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种细粒度零样本组合图像检索方法CVSI，通过互补的视觉-语义集成提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有ZS-CIR方法难以捕捉细粒度变化，且在融合视觉与语义信息方面效果不佳，常依赖单一文本化查询或大语言模型生成描述，丢失互补视觉信息和完整语义上下文。

Method: CVSI包含三部分：(1) 视觉信息提取——提取全局图像特征并用预训练映射网络生成伪token，结合修改文本与最可能添加的对象；(2) 语义信息提取——用预训练caption模型生成参考图像多组caption，再用LLM生成修改后caption及可能添加对象；(3) 互补信息检索——融合查询与数据库图像信息进行目标图像检索。

Result: 在CIRR、CIRCO和FashionIQ三个公开数据集上，CVSI显著优于现有SOTA方法。

Conclusion: CVSI通过协同建模视觉与语义细粒度信息，有效提升了零样本组合图像检索的准确性和鲁棒性，为该任务提供了新思路。

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [248] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: 本文提出了一种名为VERIDAH的新算法，用于自动识别脊椎节段数目异常（如胸椎或腰椎数量变异），在T2加权MRI和CT图像上均显著优于现有方法，并支持任意视野图像。


<details>
  <summary>Details</summary>
Motivation: 脊椎节段数目异常具有临床意义（如影响慢性背痛诊疗和手术规划），但临床上常被忽视，且现有深度学习方法缺乏对这类异常的自动识别能力。

Method: 提出VERIDAH算法，采用多分类头结合加权椎体序列预测策略，实现椎体标注及数目异常检测。

Result: 在T2w MRI上全椎体正确标注率达98.30%（对比94.24%，p<0.001）；CT上达99.18%（对比77.26%，p<0.001）；胸椎异常检出率分别为87.80%（T2w）和96.30%（CT），腰椎异常为94.48%（T2w）和97.22%（CT）。

Conclusion: VERIDAH有效填补了自动识别脊椎数目异常的技术空白，具备高精度、跨模态与广适配性，代码已开源。

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [249] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种无需标签和任务边界的无监督视频类增量学习（uVCIL）方法，通过特征提取与渐进式深度聚类实现知识迁移，在多个视频动作识别数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有监督类增量学习方法依赖标签和任务边界，成本高且不现实，亟需一种无需标签的无监督视频类增量学习范式。

Method: 采用深度特征提取网络获取各任务代表性视频特征，不假设类别或任务信息；基于提取特征逐步构建深度聚类；利用前序任务训练模型作为当前任务初始化，实现知识迁移。

Result: 在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集（忽略标签）上，该方法显著优于所有对比基线。

Conclusion: 所提无监督视频类增量学习方法简单有效，能有效缓解遗忘问题，适用于真实场景中无标签、无任务边界的持续视频学习。

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [250] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 本文提出了一种旋转等变的变分自编码器（VAE），用于建模球面上的自然光照环境，通过引入SO(2)-等变全连接层和Vector Neuron Vision Transformer（VN-ViT）编码器及等变条件神经场解码器，实现了对环境光照的更鲁棒、更平滑的潜在空间表示。


<details>
  <summary>Details</summary>
Motivation: 现有逆向渲染方法忽视了光照环境在球面上的旋转等变性，或未能提供良好行为的潜在空间，导致建模不准确或插值不平滑。

Method: 提出一种旋转等变的变分自编码器，使用新型Vector Neuron Vision Transformer（VN-ViT）作为编码器，结合SO(2)-等变全连接层（Vector Neuron扩展）降低SO(3)到SO(2)等变性；解码器采用旋转等变的条件神经场，全程不依赖2D投影。

Result: 所提SO(2)-等变全连接层在该框架下优于标准Vector Neurons；模型在潜在空间中支持更平滑插值，潜在空间更规整、更易控。

Conclusion: 该方法有效建模了球面光照的SO(2)-旋转等变结构，提升了逆向渲染中光照先验建模的表达能力与几何一致性。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [251] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的双流Transformer视频分类器，结合内容帧与光流信息，利用自注意力机制提取时空特征，在多个视频动作识别数据集上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 运动表征在视频理解中至关重要，而现有方法在有效融合时空信息方面仍有提升空间。

Method: 设计了一个双流Transformer架构，分别处理RGB帧和光流输入，并在联合的光流-时间帧域中建模自注意力特征关系，通过Transformer编码器整合时空信息。

Result: 在三个主流人体活动视频数据集上实现了优秀的分类性能。

Conclusion: 所提出的双流Transformer模型能更有效地捕捉视频中的运动模式，验证了其在动作识别任务中的有效性与优越性。

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [252] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 本文研究了基于课程学习的训练策略，以提升动作识别模型在未见真实航拍视角数据上的泛化能力，不使用任何真实航拍数据进行训练；通过结合合成航拍数据与真实地面数据，并设计两阶段和多阶段渐进式课程学习策略，在REMAG数据集上验证了其在保持精度（top-1准确率下降<3%）的同时显著减少训练迭代次数（最高达37%）。


<details>
  <summary>Details</summary>
Motivation: 现有动作识别模型在地面视角数据上训练后难以泛化到差异巨大的航拍视角，而获取和标注真实航拍数据成本高；因此亟需无需真实航拍数据即可提升跨视角泛化能力的方法。

Method: 提出两种课程学习策略：（1）两阶段直接微调（先用合成航拍数据预训练，再用真实地面数据微调）；（2）多阶段渐进式课程（逐步扩大数据多样性后再微调）；在REMAG数据集上，分别在SlowFast（CNN）和MViTv2（Transformer）架构上评估。

Result: 两种课程策略均优于单域训练；相比简单拼接两域数据，两阶段法使SlowFast和MViTv2迭代次数分别减少37%和30%；多阶段法进一步减少9%（SlowFast）和30%（MViTv2）；top-1准确率下降控制在3%以内。

Conclusion: 课程学习是提升跨视角动作识别泛化能力且兼顾训练效率的有效范式，尤其适用于缺乏目标域真实数据的场景。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [253] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: 本文提出Interp3D，一种无需训练的纹理化3D形变框架，通过生成先验与渐进对齐策略，联合保持几何一致性、纹理对齐与过渡鲁棒性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D形变方法要么仅处理几何忽略纹理，要么将2D插值扩展至3D导致语义模糊、结构错位和纹理模糊，亟需联合保持几何、纹理与过渡质量的方法。

Method: 提出无训练框架Interp3D：1）在条件空间进行语义对齐插值；2）采用SLAT（结构化潜在空间）引导结构插值保障几何一致性；3）通过细粒度纹理融合传递外观细节。

Result: 在自建多难度数据集Interp3DData上评估，定量指标与用户研究均表明Interp3D在保真度、过渡平滑性和合理性方面显著优于先前方法。

Conclusion: Interp3D有效解决了纹理化3D形变中几何与纹理协同保持的难题，为3D生成与内容创作提供了实用、鲁棒的新范式。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [254] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: 本文提出PMCE框架，通过多粒度语义与字幕引导增强，在少样本学习中提升原型估计的鲁棒性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，基于少量样本估计的原型存在偏差且泛化能力差；现有语义方法多仅作用于支持集，未改善查询样本表示。

Method: PMCE构建非参数知识库（含类别视觉统计与CLIP编码的基类名称嵌入）；测试时检索相关基类并聚合为类别先验，通过MAP更新融合到支持集原型；同时利用冻结BLIP生成图像描述，轻量增强器在归纳协议下联合优化支持原型与查询特征，并引入一致性正则化缓解字幕噪声。

Result: 在四个基准上持续超越强基线，在MiniImageNet 1-shot设置下比最强语义竞争方法绝对提升7.71%。

Conclusion: 多粒度语义与无标签字幕引导的协同建模可显著提升少样本分类性能，验证了先验引导与查询端语义增强的有效性。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [255] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 本文提出了一种硬件感知的灰度图像压缩方法GIC-DLC，利用可学习的查找表结合神经网络灵活性与布尔运算高效性，在保持高压缩效率的同时显著降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 神经图像编解码器虽压缩率高，但计算开销大，难以部署在智能手机、相机、无人机等能量受限的边缘设备上。

Method: 提出Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC)，通过训练查找表实现可微逻辑电路，融合神经网络的表达能力与布尔运算的硬件高效性。

Result: 在灰度基准数据集上，GIC-DLC在压缩效率上优于传统编解码器（如PNG、JPEG-XL），同时大幅降低能耗和延迟。

Conclusion: 证明了学习型压缩方法可以兼顾性能与硬件友好性，为边缘设备上的低功耗图像压缩提供了新方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [256] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: 本文提出了MIRACLE深度学习架构，通过融合术前临床与影像数据，预测肺癌手术后并发症风险，并结合干预式模块提升预测可解释性与临床实用性。


<details>
  <summary>Details</summary>
Motivation: 术后并发症是临床实践中的关键问题，影响患者预后并增加医疗成本，亟需精准、可解释的风险预测工具。

Method: MIRACLE采用超球面嵌入空间融合异构数据（结构化临床记录与高维影像），并引入干预式深度学习模块以增强预测精度与可解释性。

Result: 在包含3094例患者的POC-L真实世界数据集上，MIRACLE优于传统机器学习模型及多种大语言模型变体，实现个性化、可解释的术后风险管理。

Conclusion: MIRACLE为肺癌手术并发症风险预测提供了高性能、可交互、临床可用的新范式，推动AI在围术期决策支持中的落地应用。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [257] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于双域细节感知模块与特征引导扩散网络的高保真稀疏视图新视角合成框架，解决了ViT-based 3DGS方法在高分辨率输入和跨视角结构一致性上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT的3D高斯泼溅（3DGS）方法受限于低分辨率输入，且生成式增强方法缺乏3D感知能力，导致未见区域跨视角结构不一致。

Method: 设计双域细节感知模块以支持高分辨率图像处理并增强高斯点高频细节表征；构建特征引导扩散网络用于保持高频细节；采用统一训练策略联合优化ViT几何骨干网络与扩散细化模块。

Result: 在多个数据集上验证了该方法在生成质量上的优越性，尤其在高分辨率与跨视角一致性方面表现突出。

Conclusion: 所提框架有效克服了稀疏输入下高保真NVS的关键挑战，实现了几何精度与纹理细节的协同提升，为3DGS与生成模型融合提供了新思路。

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [258] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

TL;DR: 本文提出了一种名为ASBA的血流感知网络，用于从高度稀疏采样的原始A-scan中重建高质量ODT图像，通过A-line ROI状态空间模型和B-line相位注意力机制提升血流信号重建精度，并在真实动物数据上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有ODT技术依赖密集采样以保证图像质量，导致扫描时间长、存储需求高、难以捕捉快速血流动态；稀疏采样方法受限于保守采样率和对流动/背景信号的均匀建模。

Method: 提出ASBA网络：1）A-line ROI状态空间模型，提取A线方向稀疏分布的血流特征；2）B-line相位注意力机制，基于相位差捕获B线方向长程血流信号；3）血流感知加权损失函数，优先保障血流信号重建精度。

Result: 在真实动物数据上的大量实验表明，该方法显著优于现有最先进重建方法。

Conclusion: ASBA网络能有效实现高保真ODT图像重建，支持更高稀疏度采样，在提升成像效率的同时保障血流动力学分析精度。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [259] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 本文提出了一种仅依赖低剂量CT（LDCT）图像的新型自监督训练策略，通过逐步盲点去噪机制和添加高斯噪声来提升去噪性能，在Mayo数据集上表现优于现有自监督方法，媲美甚至超越部分有监督方法。


<details>
  <summary>Details</summary>
Motivation: 缓解自监督学习中对配对正常剂量CT（NDCT）数据的依赖，而这类数据在临床实践中难以获取。

Method: 提出仅基于LDCT图像的自监督训练策略，包括逐步盲点去噪机制（实现渐进式条件独立）和向LDCT图像添加高斯噪声以正则化模型、防止过拟合。

Result: 在Mayo LDCT数据集上的大量实验表明，该方法持续优于现有自监督方法，并达到或超过若干代表性有监督去噪方法的性能。

Conclusion: 仅使用LDCT图像的自监督去噪是可行且有效的，所提策略通过结构化噪声建模与正则化显著提升了模型泛化能力与去噪效果。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [260] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: 本文提出IIR-VLM，通过引入预训练的ILR专家模型作为辅助视觉编码器，增强VLM在上下文中的实例级识别能力，实现一次性学习新实例，并提升对熟悉人物和物体的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型（VLMs）在实例级识别（ILR）任务上表现不佳，远逊于专用ILR模型，限制了其在需识别特定人物或物体等实际场景中的应用。

Method: 提出IIR-VLM框架，将预训练的ILR专家模型作为辅助视觉编码器，为VLM提供细粒度实例特征，支持上下文内的一次性（one-shot）新实例学习，并实现实例感知的视觉理解。

Result: 在现有实例个性化基准和新构建的多类别、多难度ILR基准（涵盖人、人脸、宠物和通用物体）上，IIR-VLM均展现出优于现有方法的ILR性能。

Conclusion: IIR-VLM有效弥补了通用VLM在实例级识别上的短板，无需大量实例专属数据与训练，即可实现高效、细粒度的上下文实例学习与理解。

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [261] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种自适应的1D离散视觉分词器，能根据图像复杂度动态调整输出token数量，并通过保持概率的单调性约束与图像复杂度对齐，从而提升因果自回归视觉生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉分词器固定长度输出与图像结构复杂度不匹配的问题，提升因果自回归（AR）视觉生成模型的生成质量与可扩展性。

Method: 提出Soft Tail-dropping Adaptive Tokenizer（STAT），将图像编码为带每token保留概率的离散码序列；引入单调递减约束和图像级复杂度对齐正则化。

Result: 在ImageNet-1k上，STAT赋能的因果AR模型在视觉生成质量上达到或超越其他概率生成模型家族，且展现出更优的缩放行为。

Conclusion: STAT实现了长度自适应的1D视觉token表示，为因果AR视觉生成提供了更高效、更鲁棒的基础分词方案。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [262] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: 本文提出了OmniTransfer，一个统一的时空视频迁移框架，通过多视角信息增强外观一致性，并利用时间线索实现细粒度时间控制，从而在多种视频迁移任务中实现了高保真和灵活的视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法依赖参考图像或特定任务的时间先验，未能充分利用视频中丰富的时空信息，导致灵活性和泛化能力受限。

Method: OmniTransfer包含三个关键设计：任务感知的位置偏差（Task-aware Positional Bias）、参考解耦的因果学习（Reference-decoupled Causal Learning）和任务自适应的多模态对齐（Task-adaptive Multimodal Alignment），以统一各类视频迁移任务。

Result: 实验表明，OmniTransfer在外观（身份和风格）和时间迁移（相机运动和视频效果）方面优于现有方法，并在不使用姿态信息的情况下达到与姿态引导方法相当的动作迁移效果。

Conclusion: OmniTransfer建立了一种新的灵活、高保真视频生成范式，显著提升了视频迁移的通用性与表现力。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [263] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的端到端多语言视觉-语言模型，能直接从文档图像（如PDF）中提取结构化、自然排序的文本，并支持图像定位；相比SOTA模型更小更快，且开源模型、数据集与新评测基准。


<details>
  <summary>Details</summary>
Motivation: 避免传统OCR流程的脆弱性，提升多语言（尤其法语、科学文献）文档解析质量与效率，并增强图像定位能力与模型鲁棒性。

Method: 基于大规模高质量蒸馏数据集训练端到端多语言VLM；引入resume策略在预训练中加入定位任务，并用IoU奖励的RLVR优化；采用检查点平均与任务算术融合提升鲁棒性。

Result: 在OlmOCR-Bench上达到SOTA，体积仅为此前最佳模型的1/9、推理显著更快；新增图像归一化边界框预测能力；发布模型、数据集及新评测基准LightOnOCR-bbox-bench。

Conclusion: LightOnOCR-2-1B验证了轻量级端到端文档理解模型的可行性与优越性，兼顾性能、效率与可扩展性，并通过开源推动社区发展。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [264] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4 是一种前馈式框架，能从单目视频和可选的3D参考网格合成高质量4D动态对象，通过解耦静态形状生成与运动重建来解决单目4D重建的数据稀缺与歧义性难题。


<details>
  <summary>Details</summary>
Motivation: 4D合成因训练数据有限及单目视角下几何与运动恢复固有的歧义性而极具挑战性。

Method: 将4D合成分解为静态3D形状生成和运动重建两部分；利用规范参考网格学习紧凑的运动隐空间表示，并预测逐帧顶点轨迹以恢复完整且时间一致的几何；引入可扩展的逐帧Transformer以适应不同长度序列。

Result: 在标准基准和新构建的具有精确真值几何的数据集上，Motion 3-to-4 在保真度和空间一致性方面均优于先前方法。

Conclusion: Motion 3-to-4 有效缓解了单目4D内容生成中的关键瓶颈，为高质量、时序一致的动态3D建模提供了实用可行的新范式。

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [265] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: 本文提出VideoMaMa模型，利用预训练视频扩散模型将粗略分割掩码转换为精确的alpha matte，实现零样本泛化；并构建了包含5万多个真实视频的MA-V数据集，通过伪标签提升视频抠图性能。


<details>
  <summary>Details</summary>
Motivation: 解决视频抠图模型在真实世界视频中泛化能力差的问题，主要受限于标注数据稀缺。

Method: 提出VideoMaMa模型，基于预训练视频扩散模型，将粗分割掩码转化为高精度alpha matte；设计可扩展的伪标签流水线，构建大规模真实视频抠图数据集MA-V；并在其上微调SAM2得到SAM2-Matte。

Result: VideoMaMa在纯合成数据训练下即可对真实视频实现强零样本泛化；MA-V数据集覆盖多样场景与运动；SAM2-Matte在野外视频上鲁棒性优于在现有抠图数据集上训练的同类模型。

Conclusion: 大规模伪标签视频抠图数据集结合生成先验与易得的分割线索，可有效推动视频抠图研究的可扩展发展。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [266] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新型统一模型，通过隐式神经表示（INR）超网络学习既能用于识别任务（如分类、检测、分割），又能用于生成任务（高质量图像重建）的紧凑图像表征。结合知识蒸馏提升泛化能力，在保持极小嵌入尺寸的同时达到SOTA级多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像表征学习模型通常只针对识别或生成单一目标设计，缺乏兼顾二者的能力，本文旨在统一这两个方向。

Method: 提出基于隐式神经表示（INR）的超网络架构，将图像映射为重建网络的权重；并引入知识蒸馏增强泛化性。

Result: 学习到高度压缩且信息丰富的嵌入空间，在识别任务上媲美SOTA方法，同时支持高质量图像生成。

Conclusion: 该模型首次实现了识别与生成能力的有机统一，兼具高性能与高效率，为通用视觉表征学习提供了新范式。

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [267] [Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths](https://arxiv.org/abs/2601.11564)
*Ahilan Ayyachamy Nadar Ponnusamy,Karthic Chandran,M Maruf Hossain*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在处理大量无关上下文时的性能与质量权衡，发现KV缓存增长导致非线性性能下降，并指出MoE架构在高token量下受基础设施瓶颈影响而掩盖其优势。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口扩大，处理大量无关和干扰性上下文带来的计算开销和性能下降问题亟待研究。

Method: 对Llama-3.1-70B和Qwen1.5-14B等稠密Transformer模型进行实验分析，重点考察KV缓存规模扩展对系统性能的影响；同时对比分析MoE架构在不同上下文尺度下的行为异常。

Result: 发现KV缓存增长引发非线性性能退化；MoE架构在高token量下表现出独特异常，其固有优势被基础设施瓶颈所掩盖。

Conclusion: 单纯扩大上下文窗口未必提升模型实用性，需协同优化模型架构与底层基础设施以缓解长上下文带来的性能瓶颈。

Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.

</details>


### [268] [Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings](https://arxiv.org/abs/2601.11565)
*Pakorn Ueareeworakul,Shuman Liu,Jinghao Feng,Ling Hu,Zhantang Shi,Chengqi Sun,Liang Yao,Panyi Ouyang,Haibo Zhang,Anxiang Zeng*

Main category: cs.CL

TL;DR: 本文提出了Compass-Embedding v4，一种专为东南亚电商场景优化的高效多语言嵌入框架，通过Class-Aware Masking、合成数据增强和推理优化等技术，在低资源语言语义表示任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 全球电商向新兴市场扩张过程中，低资源语言缺乏高质量语义表示，已成为检索、推荐与搜索系统的瓶颈。

Method: 提出Class-Aware Masking（CAM）改进InfoNCE目标以缓解假负例问题；构建融合合成数据生成、跨语言翻译和结构化电商数据的多样化训练语料；结合大批次鲁棒训练、球面模型融合、vLLM与FP8量化提升部署效率与泛化性。

Result: 在东南亚主要语言的多语言基准与内部电商任务上均达SOTA，显著优于通用嵌入模型，且在高资源语言上保持竞争力。

Conclusion: Compass-Embedding v4有效应对了低资源语言数据稀缺、监督噪声大及生产约束严苛三大挑战，为电商场景下的多语言语义建模提供了实用且可扩展的解决方案。

Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.

</details>


### [269] [Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology](https://arxiv.org/abs/2601.11567)
*Vanessa D'Amario,Randy Daniel,Alessandro Zanetti,Dhruv Edamadaka,Nitya Alaparthy,Joshua Tarkoff*

Main category: cs.CL

TL;DR: 本文评估了六种小型开源医学大语言模型在儿科内分泌学领域的表现，发现高一致性并不意味着高正确性，且模型存在自我评估偏差和对提示微小变化的敏感性，强调需建立更全面的诊断框架以应对临床决策支持中的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 现有小型开源医学大语言模型的评估多局限于多项选择题准确率，缺乏对其一致性、鲁棒性和推理行为的系统考察，难以支撑其在真实临床场景中的可靠应用。

Method: 结合多项选择题测试、人类评估与临床专家评审，分别在确定性（prompt变化、自评偏差）和随机性（输出变异性、一致性与正确性关系）设置下，对六种模型进行多维评估，并分析系统级扰动（如CUDA版本差异）的影响。

Result: HuatuoGPT-o1-8B综合性能最优且一致性最高，但高一致性不保证高正确性；多个模型存在自我评估偏差和选项顺序依赖；专家评审发现错误推理中混有临床可接受回答与实质性疏漏；微小prompt扰动及CUDA构建差异均可导致统计显著的输出变化。

Conclusion: 当前小型医学LLM评估范式存在严重局限，prompt微小扰动即引发输出大幅波动，威胁结果可复现性；需构建涵盖一致性、鲁棒性、推理质量与系统稳定性的多维诊断框架，方能支撑其向临床决策支持的安全落地。

Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.

</details>


### [270] [An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT](https://arxiv.org/abs/2601.11573)
*Muhammad Muneeb,David B. Ascher*

Main category: cs.CL

TL;DR: 本文提出了一种可复现的九步流水线，用于在专业生物信息学数据上高效微调大语言模型（LLM），并在两个用例（PRSGPT和BioStarsGPT）中验证了其有效性；Qwen2.5-7B表现最优，生成高质量、可本地部署、隐私保护的生物信息学助手。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通常缺乏复杂生物信息学应用所需的专业知识，亟需一种可复现、可扩展、兼顾质量与隐私的领域适配方法。

Method: 构建九步微调流水线：整合多源数据、结构化预处理、基于Gemini的提示式问答生成、自然语言推理（NLI）质量控制、语义去重、聚类驱动的数据划分，以及采用LoRA的参数高效微调；在PRSGPT（PRS工具）和BioStarsGPT（社区论坛）两个任务上实施，并在14+指标及人工评估中全面评测。

Result: Qwen2.5-7B在BLEU-4和ROUGE-1上分别提升82%/70%（PRSGPT）和6%/18%（BioStarsGPT）；PRSGPT人工评估准确率61.9%，媲美Gemini且具更优方法细节与引用；BioStarsGPT概念准确率达59%；开源28,000+和154,282条QA数据集。

Conclusion: 该流水线支持可扩展、隐私保护、本地部署的领域专用LLM微调，为生物信息学AI助手的实际落地提供了系统性方法论，并讨论了挑战与缓解策略。

Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.

</details>


### [271] [Concept Attractors in LLMs and their Applications](https://arxiv.org/abs/2601.11575)
*Sotirios Panagiotis Chytas,Vikas Singh*

Main category: cs.CL

TL;DR: 本文提出了一种基于迭代函数系统（IFS）理论的新视角，解释了大语言模型（LLMs）中语义相似提示在特定层产生相似内部表征的现象，并利用‘概念吸引子’设计出无需训练的简单干预方法，在翻译、去幻觉、安全护栏和合成数据生成等任务上媲美甚至超越专用微调方法。


<details>
  <summary>Details</summary>
Motivation: 解释LLM中语义相关提示映射到相似内部表征的现象，并寻求无需训练、高效通用的干预方法。

Method: 将LLM各层建模为迭代函数系统（IFS）中的压缩映射，识别并利用层内概念特定的‘吸引子’（Attractors），设计训练-free的直接操作吸引子的方法。

Result: 在语言翻译、幻觉减少、安全护栏和合成数据生成等任务上，所提吸引子干预方法匹配或超越专用基线模型，且泛化性强、计算高效。

Conclusion: LLM的中间表征具有由吸引子主导的几何结构，基于此结构的无训练干预是一种高效、通用、可解释的新范式，可替代部分重参数化微调。

Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.

</details>


### [272] [LimAgents: Multi-Agent LLMs for Generating Research Limitations](https://arxiv.org/abs/2601.11578)
*Ibrahim Al Azher,Zhishuai Guo,Hamed Alhoori*

Main category: cs.CL

TL;DR: 本文提出LimAgents，一种多智能体大语言模型框架，用于生成实质性研究局限性分析，通过整合OpenReview评论、作者声明的局限性及引用文献，系统识别显式、隐式、同行评审视角和文献背景下的局限性，并引入基于LLM的逐点评估协议提升评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本大语言模型在识别论文局限性时往往流于表面、重复作者已陈述的浅层问题，缺乏对方法论缺陷和上下文缺口的深入分析；同时作者常仅披露部分或琐碎的局限性，加剧该问题。

Method: 提出LimAgents多智能体框架：包含多个角色化智能体（如限制提取、方法论分析、同行评审模拟、引用分析、裁判整合等），采用RAG增强与多智能体协同机制；并设计基于LLM-as-a-Judge的点式评估协议，替代传统BLEU/ROUGE等重叠度指标。

Result: 实验表明，RAG+多智能体GPT-4o mini配置相较零样本基线提升15.51%覆盖度，Llama 3 8B多智能体配置提升4.41%。

Conclusion: LimAgents能更系统、深入、多角度地识别论文局限性，其多智能体架构与新型评估协议显著提升了局限性分析的质量与可靠性，为科研透明性与严谨性提供了新工具。

Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.

</details>


### [273] [Bielik 11B v3: Multilingual Large Language Model for European Languages](https://arxiv.org/abs/2601.11579)
*Krzysztof Ociepa,Łukasz Flis,Remigiusz Kinas,Krzysztof Wróbel,Adrian Gwoździej*

Main category: cs.CL

TL;DR: Bielik 11B v3 是一个专为波兰语优化的110亿参数开源大模型，基于 Mistral 7B v0.2 深度扩展而来，经四阶段训练（持续预训练、监督微调、直接偏好优化、强化学习），在多项任务上超越更大参数量模型，兼顾多欧语能力与硬件部署友好性。


<details>
  <summary>Details</summary>
Motivation: 提升波兰语等资源较少语言的大模型性能与可用性，解决其在主流模型中代表性不足的问题，并追求参数效率与跨语言能力的平衡。

Method: 基于 Mistral 7B v0.2 架构，采用深度上采样扩展至 11B 参数；实施四阶段训练流程：持续预训练、监督微调（SFT）、直接偏好优化（DPO）和强化学习；支持多种量化方案以适配不同硬件。

Result: 在多项基准测试中显著超越其他波兰语专用模型，并优于参数量达其2–6倍的诸多大模型，涵盖基础语言理解到复杂推理任务；具备优异的参数效率与跨欧洲语言泛化能力。

Conclusion: Bielik 11B v3 代表了面向低资源语言构建高效、高性能大模型的新范式，为波兰语AI应用树立新标杆，也为其他小语种模型开发提供可复用方法论。

Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.
  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.
  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.

</details>


### [274] [Speculative Decoding: Performance or Illusion?](https://arxiv.org/abs/2601.11580)
*Xiaoxuan Liu,Jiaxiang Yu,Jongseok Park,Ion Stoica,Alvin Cheung*

Main category: cs.CL

TL;DR: 本文首次在生产级推理引擎vLLM上系统评估了推测解码（SD）技术，涵盖多种SD变体、不同工作负载与模型规模，揭示了验证阶段主导延迟、接受长度高度不均等关键现象，并指出实测性能与理论加速上限存在显著差距，从而提出新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码（SD）评估多基于研究原型和小批量设置，缺乏在真实生产环境（如vLLM）下的系统性分析，导致其实际有效性不明。

Method: 在生产级推理引擎vLLM上，对n-gram、EAGLE/EAGLE-3、Draft-Model、Multi-Token Prediction等多种SD变体，开展跨模型规模、请求批次大小和数据集的实证评测；分析性能瓶颈、接受长度分布，并推导SD理论加速上限。

Result: 发现目标模型的验证阶段是主要性能瓶颈；接受长度在不同token位置、请求及数据集间差异显著；实测加速比远低于理论上限，存在明显优化空间。

Conclusion: 推测解码在真实部署中尚未充分发挥潜力，需针对验证开销与接受率不稳定性设计新机制，本研究为后续SD优化指明了关键方向。

Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.

</details>


### [275] [ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System](https://arxiv.org/abs/2601.11854)
*Yifei Zhang,Hooshang Nayyeri,Rinat Khaziev,Emine Yilmaz,Gokhan Tur,Dilek Hakkani-Tür,Hari Thadakamalla*

Main category: cs.CL

TL;DR: 本文提出ATOD基准和ATOD-Eval评估框架，用于系统评估具备多目标协调、记忆、适应性与主动性的任务导向对话系统中的智能体行为。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对大型语言模型驱动的、具备长程推理与主动行为能力的任务导向对话系统中智能体行为的系统性评估支持。

Method: 构建了ATOD合成对话生成流水线及配套的ATOD-Eval多维细粒度评估框架，并设计了一个基于智能体记忆的强效评估器。

Result: ATOD-Eval实现了对任务完成度、智能体能力与响应质量的全面评估；所提记忆型评估器在准确率与效率权衡上优于现有基于记忆和LLM的评估方法。

Conclusion: ATOD及其评估体系填补了先进任务导向对话系统中智能体行为评估的空白，为未来研究提供了可复现、可扩展的评测基础。

Abstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.

</details>


### [276] [Enhancing the QA Model through a Multi-domain Debiasing Framework](https://arxiv.org/abs/2601.11581)
*Yuefeng Wang,ChangJae Lee*

Main category: cs.CL

TL;DR: 本研究针对QA模型在复杂查询和对抗条件下的偏差问题，提出了一种多领域去偏框架，结合知识蒸馏、去偏技术和领域扩展，在SQuAD v1.1及对抗数据集上实现了EM和F1指标最高提升2.6个百分点。


<details>
  <summary>Details</summary>
Motivation: QA模型在机器阅读理解中虽取得进展，但在复杂查询和对抗条件下常因词汇偏差、数值推理和实体识别等错误而表现不佳，亟需针对性的去偏策略以提升鲁棒性与可靠性。

Method: 在ELECTRA-small模型基础上，评估其在SQuAD v1.1、AddSent和AddOneSent上的表现；识别三类典型错误，并构建融合知识蒸馏、去偏技术与域扩展的多领域去偏框架。

Result: 在所有测试集（含对抗场景）上，Exact Match（EM）和F1分数最高提升2.6个百分点。

Conclusion: 针对特定偏差类型的定制化去偏策略可显著增强自然语言理解系统的鲁棒性与可靠性。

Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.

</details>


### [277] [Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents](https://arxiv.org/abs/2601.11585)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 本文提出了一种基于信息论的上下文工程方法Entropic Context Shaping（ECS），通过衡量上下文对模型答案分布向正确答案偏移的程度来评估其实际效用，而非依赖词重叠等表面相似性；在多轮上下文选择任务中显著优于TF-IDF等传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有上下文工程方法（如基于词重叠的TF-IDF）难以区分语义上有用的信息与误导性干扰项，缺乏对‘上下文是否真正有助于回答问题’这一实用目标的建模。

Method: 提出Entropic Context Shaping（ECS），将上下文效用定义为引入该上下文前后模型答案分布的有符号变化（即KL散度方向性变化），并从信息论角度进行理论分析，证明无关上下文引起的分布偏移趋近于零。

Result: 在LongMemEval（会话级）和LoCoMo（回合级）基准上验证ECS；在细粒度回合选择任务中，Llama-3.1-8B+ Abrams实现F1=0.265，相较TF-IDF（F1=0.154）提升71.83%。

Conclusion: 上下文的实用效用应以对答案分布的实际影响为衡量标准，ECS提供了一种可计算、理论可解释且实践有效的替代方案，尤其适用于高精度上下文筛选场景。

Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.

</details>


### [278] [Towards AGI A Pragmatic Approach Towards Self Evolving Agent](https://arxiv.org/abs/2601.11658)
*Indrajit Kar,Sammy Zonunpuia,Zonunfeli Ralte*

Main category: cs.CL

TL;DR: 本文提出了一种分层自演化多智能体框架，使LLM智能体能够自主扩展能力、生成新工具并持续进化，通过课程学习、奖励学习和遗传算法实现不同场景下的高效自我提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的智能体在部署后是静态的，无法自主扩展能力、生成新工具或进化推理能力。

Method: 构建包含基础LLM、操作型小模型智能体、代码生成LLM和教师LLM的分层自演化多智能体框架；任务失败时依次触发工具合成与三种演化机制（课程学习、奖励学习、遗传算法）；在TaskCraft数据集上评估。

Result: 课程学习实现快速恢复与强泛化，奖励学习在高难度任务中表现最优，遗传算法带来高行为多样性；所有演化后的智能体均显著优于原始智能体。

Conclusion: 该框架实现了鲁棒、自主、自改进的智能体演化，验证了LLM智能体持续自主进化的可行性。

Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.

</details>


### [279] [RAC: Retrieval-Augmented Clarification for Faithful Conversational Search](https://arxiv.org/abs/2601.11722)
*Ahmed Rayane Kebir,Vincent Guigue,Lynda Said Lhadj,Laure Soulier*

Main category: cs.CL

TL;DR: 本文提出RAC（检索增强式澄清）框架，通过检索增强和对比偏好优化，生成基于语料库的、可回答的澄清问题，显著提升澄清问题在语料中的忠实性与可回答性。


<details>
  <summary>Details</summary>
Motivation: 现有澄清问题生成方法缺乏对底层语料库的 grounding，导致生成的问题可能无法从可用文档中回答；需提升问题的语料忠实性和可回答性。

Method: 提出RAC框架：1）比较多种索引策略以优化检索；2）微调大语言模型，使其有效利用检索到的研究上下文并生成证据支持的问题；3）应用对比偏好优化，使模型偏好有检索段落支持的问题而非无根据的问题。

Result: 在四个基准数据集上，RAC显著优于基线方法；引入基于NLI和data-to-text的新评估指标，验证其在语境锚定与忠实性上的持续提升；LLM-as-Judge评估也证实效果提升。

Conclusion: RAC通过检索增强与对比优化，有效实现了澄清问题的语料库忠实生成，为可解释、可回答的对话式搜索提供了新范式。

Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.

</details>


### [280] [LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction](https://arxiv.org/abs/2601.13352)
*Yuxing Lu,J. Ben Tamo,Weichen Zhao,Nan Sun,Yishan Zhong,Wenqi Shi,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: 本文提出LLM-as-RNN框架，将冻结的大语言模型转化为基于自然语言记忆的循环预测器，在不更新参数的前提下实现推理时的在线学习与错误修正。


<details>
  <summary>Details</summary>
Motivation: 标准大语言模型推理依赖不可变上下文，缺乏在生成出错后动态更新记忆以改进后续预测的能力。

Method: 将LLM隐藏状态表示为结构化系统提示形式的自然语言记忆，并在每步通过反馈驱动的文本重写更新该记忆，从而在固定token预算下实现推理时的在线学习。

Result: 在医疗、气象、金融三大序列任务上，LLM-as-RNN在Llama、Gemma、GPT系列模型上平均提升预测准确率6.5%，显著优于零样本、全历史和MemPrompt等基线方法，并生成可解释的人类可读学习轨迹。

Conclusion: LLM-as-RNN证明了仅通过推理机制设计即可赋予冻结LLM类RNN的循环学习能力，为无参数更新的在线学习提供了新范式。

Abstract: Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

</details>


### [281] [Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era](https://arxiv.org/abs/2601.11739)
*Xinyu Pi,Qisen Yang,Chuong Nguyen,Hua Shen*

Main category: cs.CL

TL;DR: 本文提出一个4×4的分析框架，用于评估LLM在定性研究中不同层次的意义建构与建模能力，并指出当前系统普遍偏向低层次、低承诺的输出，进而呼吁发展更具可解释性、可选择性与可治理性的LLM系统。


<details>
  <summary>Details</summary>
Motivation: 现有LLM支持定性研究的系统输出差异大、缺乏统一标准，难以评估其意义建构与建模深度，亟需结构化分析框架揭示能力缺口。

Method: 构建横跨四个意义建构层级（描述性、类别性、解释性、理论性）与四个建模层级（静态结构、阶段/时间线、因果路径、反馈动态）的4×4分析景观，并应用于评估已有LLM自动化研究工作。

Result: 发现当前LLM系统严重偏向低层次意义建构（如描述性）与低承诺建模（如静态结构），极少可靠实现解释性/理论性推断或动态建模。

Conclusion: 应推动LLM系统显式表达、允许用户选择并可控治理其解释性与建模承诺，形成新的研究与系统构建议程。

Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.

</details>


### [282] [LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text](https://arxiv.org/abs/2601.11746)
*George Mihaila,Suleyman Olcay Polat,Poli Nemkova,Himanshu Sharma,Namratha V. Urs,Mark V. Albert*

Main category: cs.CL

TL;DR: 本文提出LIME-LLM框架，通过假设驱动的受控扰动替代传统LIME中的随机掩码，在NLP中生成语义有效、流利且在流形上的邻域样本，从而提升局部解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有LIME等局部解释方法在NLP中依赖随机token掩码，易产生语义无效、分布外样本，降低代理模型保真度；而新兴生成式方法（如LLiMe）虽用大模型生成邻域，但无约束改写引入混杂变量，难以分离特征贡献。

Method: 提出LIME-LLM：采用'单掩码-单样本'协议，结合中性填充与边界填充两种策略，实现假设驱动、可控、语义合理的扰动生成，构建高质量局部邻域。

Result: 在CoLA、SST-2和HateXplain三个基准上，以人工标注理由为真值，LIME-LLM在解释保真度上显著优于LIME、SHAP、Integrated Gradients及LLiMe。

Conclusion: LIME-LLM为黑盒NLP可解释性设定了新基准，验证了受控、假设驱动扰动对提升局部解释质量的关键作用。

Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.

</details>


### [283] [Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation](https://arxiv.org/abs/2601.11758)
*Arnab Das Utsa*

Main category: cs.CL

TL;DR: 本文提出了一种基于Reddit数据的可解释、鲁棒性强的社交媒介焦虑检测方法，采用语言学特征驱动的逻辑回归模型，并通过多维度验证（如关键词掩蔽、跨域临床数据比对）证明其可靠性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 全球焦虑症患者众多但大规模筛查受限；现有社交媒介检测模型缺乏可解释性、关键词鲁棒性验证及严格的用户级数据完整性保障。

Method: 基于Reddit帖子构建高质量数据集，使用精心筛选的子版块划分训练/验证/测试集；采用逻辑回归建模，结合特征消融、关键词掩蔽、密度差异分析及临床访谈数据外部验证。

Result: 模型在移除情感词或掩蔽关键词后仍保持高准确率；仅用少量发帖历史即可显著优于随机分类；跨域分析与临床诊断结果高度一致。

Conclusion: 基于透明语言特征的建模方法可实现可靠、可泛化且关键词鲁棒的焦虑检测，为在线心理健康筛查提供了可复现的可解释基线框架。

Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.

</details>


### [284] [Industry-Aligned Granular Topic Modeling](https://arxiv.org/abs/2601.11762)
*Sae Young Moon,Myeongjun Erik Jang,Haoyan Luo,Chunyang Xiao,Antonios Georgiadis,Fran Silavong*

Main category: cs.CL

TL;DR: 本文提出了TIDE框架，一种基于大语言模型（LLM）的新型粒度化主题建模方法，并集成长文档摘要、主题父子关系构建与知识蒸馏等功能，显著优于现有主题建模方法，适用于工业级商业场景。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法对业务应用中至关重要的‘粒度’支持不足，缺乏提供深层次业务洞察的能力。

Method: 提出基于大语言模型（LLM）的粒度化主题建模方法，并构建集成文档摘要、主题 parenting 和 distillation 功能的 TIDE 框架。

Result: 在多个公开及真实商业数据集上的实验表明，TIDE 的主题建模性能优于现代主流方法，其辅助组件有效支撑工业级业务需求。

Conclusion: TIDE 是首个系统性融合 LLM 与粒度化主题建模并面向商业落地的框架，已启动开源进程。

Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.

</details>


### [285] [Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models](https://arxiv.org/abs/2601.11776)
*Kaituo Zhang,Zhimeng Jiang,Na Zou*

Main category: cs.CL

TL;DR: 本文提出了一种完全自反思的去毒化框架，利用大语言模型（LLM）内在的自我识别与修正能力，无需外部模块或人工标注，实现高效、一致且语义保真的毒性内容检测与修正。


<details>
  <summary>Details</summary>
Motivation: 现有去毒化方法依赖外部模块、大量人工标注或人为干预，难以扩展且缺乏一致性；而LLM已展现出自我纠正与自我奖励等内生调节能力，尚未被有效用于去毒化任务。

Method: 提出‘毒性信号检测器’作为内部自识别机制，并设计系统性干预流程将毒性文本迭代转化为非毒性文本，生成对比式去毒数据集用于模型微调。

Result: 在DetoxLLM和ParaDetox等基准数据集上，该方法在去毒效果上优于当前最优方法，同时保持更高语义保真度。

Conclusion: LLM具备内在自去毒能力；本工作揭示并验证了其可被激发与强化，为构建真正自监管、负责任的语言生成系统提供了新路径。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.

</details>


### [286] [Translation as a Scalable Proxy for Multilingual Evaluation](https://arxiv.org/abs/2601.11778)
*Sheriff Issaka,Erick Rosas Gonzalez,Lieqi Liu,Evans Kofi Agyei,Lucas Bandarkar,Nanyun Peng,David Ifeoluwa Adelani,Francisco Guzmán,Saadia Gabriel*

Main category: cs.CL

TL;DR: 本文探讨了翻译质量能否作为大语言模型多语言能力的代理指标，发现翻译性能与下游任务表现高度相关，可作为低成本、高效率的初步筛选工具。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽声称具备多语言能力，但缺乏非机器翻译构建的全面多语言评测基准，传统基准构建面临成本高、专家稀缺和数据污染等问题。

Method: 系统评估14个不同参数规模的模型在9个多样化基准和7种翻译指标上的表现，分析翻译质量与下游任务性能之间的相关性。

Result: 翻译性能（如MetricX、xCOMET、SSA-COMET）与下游任务成功显著正相关（中位Pearson r达0.87–0.91），表明翻译能力可有效反映多语言理解能力。

Conclusion: 翻译质量是衡量模型多语言能力的有效、廉价的第一步代理指标，支持‘翻译优先’的筛选策略，并辅以特定任务的针对性验证。

Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.

</details>


### [287] [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/abs/2601.11791)
*Laya Iyer,Pranav Somani,Alice Guo,Dan Jurafsky,Chen Shani*

Main category: cs.CL

TL;DR: 本文提出概念级预测（concept-level prediction）替代传统的下一个词预测（NTP）目标，通过将语义等价的表面形式（如“mom”“mother”）映射到统一概念（如MOTHER），使模型学习更符合人类语义抽象的训练信号；实验表明该方法降低困惑度、提升跨域鲁棒性及多项NLP任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统NTP目标在token层面惩罚所有偏离参考续写的输出，即使语义等价（如“mom”vs.“mother”），导致模型偏向表层形式而非深层语义，与人类语义抽象不一致。

Method: 提出概念级预测框架，将多个表面形式聚类为同一概念（如“mom”“mother”→MOTHER），并设计多种将概念监督融入LLM训练的方法。

Result: 概念感知模型在困惑度、领域迁移鲁棒性及多个NLP基准任务上均优于NTP基线模型。

Conclusion: 概念级监督是一种更优的训练信号，能更好对齐LLM与人类语义抽象能力。

Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.

</details>


### [288] [Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs](https://arxiv.org/abs/2601.12034)
*Ziyi Zhao,Chongming Gao,Yang Zhang,Haoyan Liu,Weinan Gan,Huifeng Guo,Yong Liu,Fuli Feng*

Main category: cs.CL

TL;DR: 本文提出Prompt-level User Migration Adapter (PUMA)，一种轻量级框架，用于在不兼容的大模型间高效迁移用户个性化软提示，避免昂贵的全量重训练，显著降低计算成本并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 用户特定的软提示在基础模型升级后会失效，导致需高成本的全量重训练，亟需一种能跨模型迁移个性化提示的高效方法。

Method: 提出PUMA框架，包含参数高效的适配器以弥合语义差距，并结合基于组的用户选择策略以大幅降低训练开销。

Result: 在三个大规模数据集上的实验表明，该方法性能媲美甚至超越从头重训练，计算成本最高可降低98%，且在多种模型架构及链式、聚合迁移等复杂场景中表现出强泛化性与鲁棒性。

Conclusion: PUMA实现了用户个性化资产与底层模型的解耦，为个性化AI的可持续演进提供了实用路径。

Abstract: Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.

</details>


### [289] [TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit](https://arxiv.org/abs/2601.11819)
*Shirlene Rose Bandela,Sanjeev Parthasarathy,Vaibhav Garg*

Main category: cs.CL

TL;DR: 本文提出一个名为TWeddit的Reddit数据集，专门标注了与女性相关的主要触发性经历（如流产、性暴力等），并分析了这些故事在主题和道德基础方面的语言特征。


<details>
  <summary>Details</summary>
Motivation: 由于Reddit上许多用户在分享流产、性暴力等创伤经历时未添加触发警告，导致读者可能意外接触令人不安的内容；同时，目前缺乏针对此类触发性经历标注的Reddit数据集。

Method: 构建了一个经过人工筛选和标注的Reddit数据集TWeddit，涵盖与女性密切相关的主要触发性经历，并进行了主题建模和道德基础分析。

Result: TWeddit数据集展示了标注故事在话题分布和道德基础表达上的显著差异，验证了其在情感计算、内容安全与心理健康支持等研究中的潜在价值。

Conclusion: TWeddit填补了触发性内容标注数据集的空白，为自动触发警告生成、伦理敏感NLP建模及社会支持机制设计提供了可靠资源。

Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.

</details>


### [290] [Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization](https://arxiv.org/abs/2601.12078)
*Linfeng Du,Ye Yuan,Zichen Zhao,Fuyuan Lyu,Emiliano Penaloza,Xiuying Chen,Zipeng Sun,Jikun Kang,Laurent Charlin,Xue Liu,Haolun Wu*

Main category: cs.CL

TL;DR: 本文提出PURPLE框架，通过上下文赌博机方法优化用户档案以实现大语言模型个性化，利用Plackett-Luce排序模型建模记录间依赖，并以生成质量为反馈信号进行训练，在九个个性化任务上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义相关性的检索增强方法在个性化中不可靠，因语义相似不等于对生成质量有实际帮助，甚至可能因冗余或冲突信息损害效果。

Method: 提出PURPLE——一种上下文赌博机框架，将用户档案构建视为集合生成过程，采用Plackett-Luce排序模型建模记录间依赖关系，并以参考响应似然作为密集反馈信号进行训练，使检索直接对齐生成质量。

Result: 在九个个性化任务上，PURPLE在有效性和效率上均持续超越强启发式及检索增强基线方法。

Conclusion: PURPLE为用户档案优化提供了原理清晰、可扩展的解决方案，推动了大语言模型个性化中检索与生成协同优化的发展。

Abstract: Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.

</details>


### [291] [The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization](https://arxiv.org/abs/2601.11846)
*Natalia Tomashenko,Xiaoxiao Miao,Pierre Champion,Sarina Meyer,Michele Panariello,Xin Wang,Nicholas Evans,Emmanuel Vincent,Junichi Yamagishi,Massimiliano Todisco*

Main category: cs.CL

TL;DR: 2024年VoicePrivacy挑战赛聚焦语音匿名化技术，旨在隐藏说话人身份的同时保留语言内容和情感状态，并系统评估了隐私保护与效用。


<details>
  <summary>Details</summary>
Motivation: 推动语音匿名化技术发展，平衡隐私保护（隐藏说话人身份）与语音效用（保留语言内容和情感状态）。

Method: 组织2024年VoicePrivacy挑战赛，定义任务、构建数据集、设定攻击模型与评估指标（隐私性与实用性），提供六个基线系统并分析参赛方案。

Result: 全面总结挑战框架、基线系统及参赛创新方法，提炼关键洞察，为未来挑战设计和语音匿名化研究提供指导方向。

Conclusion: 语音匿名化需兼顾隐私与效用；挑战赛有效推动技术进步，并揭示了评估标准化、多维度效用保持及鲁棒性防御等关键研究方向。

Abstract: We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.

</details>


### [292] [BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models](https://arxiv.org/abs/2601.12632)
*Kriti Bhattarai,Vipina K. Keloth,Donald Wright,Andrew Loza,Yang Ren,Hua Xu*

Main category: cs.CL

TL;DR: 本文介绍了BioPulse-QA，一个面向最新生物医学文献（如药品标签、临床试验方案和指南）的新型问答基准，旨在解决现有基准静态、过时、易数据泄露及忽视语言鲁棒性与偏见等问题；实验评估了四类主流LLM，发现GPT-o1表现最优，而临床试验类问题最具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学LLM基准存在静态/过时、数据泄露风险高、缺乏对语言变异鲁棒性和人口统计偏见考量等局限，难以反映真实高风险临床场景需求。

Method: 构建BioPulse-QA基准，包含2280个专家验证的问答对及扰动变体，覆盖药品标签、临床试验协议和临床指南三类新发布文档；采用提取式与生成式QA格式；在发布日期前训练的四个LLM（GPT-4o、GPT-o1、Gemini-2.0-Flash、LLaMA-3.1 8B Instruct）上进行评估。

Result: GPT-o1在药品标签任务中取得最高宽松F1分（0.92），Gemini-2.0-Flash次之（0.90）；临床试验任务最难，提取式F1低至0.36；模型对改写扰动比拼写错误更敏感，偏见测试显示差异可忽略。

Conclusion: BioPulse-QA提供了一个动态、临床相关、可扩展的评估框架，能更真实地衡量生物医学LLM在实际应用中的能力与局限。

Abstract: Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.
  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.
  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.
  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.

</details>


### [293] [CORE-T: COherent REtrieval of Tables for Text-to-SQL](https://arxiv.org/abs/2601.13111)
*Hassan Soliman,Vivek Gupta,Dan Roth,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出CORE-T框架，通过LLM生成的表用途元数据和预计算的轻量级表兼容性缓存，在开放书场景下高效选择可连接的多表，显著提升表选择F1和多表执行准确率，同时降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 现实文本到SQL流程常需连接多张表，而在缺乏数据库标识等清晰范围信号的大规模异构表集合中，准确检索相关表是端到端性能的关键瓶颈。

Method: CORE-T是一个无需训练的可扩展框架：利用LLM生成表用途元数据以丰富表信息，并预计算轻量级表兼容性缓存；推理时先用稠密检索获取top-K候选表，再通过一次LLM调用选出连贯且可连接的子集，最后用简单的加性调整步骤恢复强兼容表。

Result: 在Bird、Spider和MMQA数据集上，CORE-T将表选择F1最高提升22.7点，检索表数量最多减少42%；多表执行准确率在Bird和MMQA上分别提升5.0和6.9点；相比LLM密集型基线，token使用量减少4–5倍。

Conclusion: CORE-T在保持高召回的同时显著抑制干扰项，实现了高效、低开销、高精度的多表检索，适用于开放书式文本到SQL任务。

Abstract: Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

</details>


### [294] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种跨分词器的偏好蒸馏框架CTPD，用于在分词器不同的教师-学生模型间迁移人类对齐行为，包含对齐跨度投影、跨分词器重要性采样和教师锚定参考三项创新，理论与实验均验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令微调中广泛应用，但在人类偏好对齐尤其是跨分词器场景下研究不足；教师与学生模型分词方案不兼容，阻碍了细粒度白盒偏好信息蒸馏。

Method: 提出Cross-Tokenizer Preference Distillation（CTPD）框架，包含：(1) 对齐跨度投影（映射到共享字符级跨度）；(2) 跨分词器Token级重要性采样（TIS-DPO）；(3) 教师锚定参考（DPO风格目标中直接利用教师偏好）；理论基础为重要性采样。

Result: 在多个基准上显著优于现有方法，验证了CTPD在不同分词器间进行偏好蒸馏的有效性与泛化性。

Conclusion: CTPD是首个统一的跨分词器偏好蒸馏框架，为异构分词器下语言模型的高效、可及对齐提供了实用通用解决方案。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [295] [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115)
*Fengran Mo,Yifan Gao,Sha Li,Hansi Zeng,Xin Liu,Zhaoxuan Tan,Xian Li,Jianshu Chen,Dakuo Wang,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种新型对话式智能体，通过在多轮对话中交替进行搜索与推理，并利用面向用户目标演化的强化学习奖励机制进行训练，显著提升了多轮对话中的上下文理解与动态响应能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用静态的重写-检索-生成流程，忽视了多轮对话中用户意图动态演化的特点；而当前深度搜索智能体虽能联合优化检索与生成，但仅适用于单轮场景，难以应对多轮交互需求。

Method: 提出一种交错执行搜索与推理的对话智能体，通过强化学习（RL）进行端到端训练，设计面向用户目标演化的定制化奖励函数，支持探索性与自适应行为。

Result: 在四个主流对话式检索基准上，该方法显著优于多个强基线模型。

Conclusion: 交错搜索与推理的RL训练范式能更有效地建模多轮对话中的动态用户意图，为构建真正上下文感知的对话式AI提供了新思路。

Abstract: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

</details>


### [296] [Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving](https://arxiv.org/abs/2601.11866)
*Kie Shidara,Preethi Prem,Jonathan Kim,Anna Podlasek,Feng Liu,Ahmed Alaa,Danilo Bernardo*

Main category: cs.CL

TL;DR: 本文评估了多个大型语言模型在医学抽象与推理语料库（mARC）上的临床推理灵活性，发现强推理能力的模型能更好规避Einstellung效应导致的思维定势，达到人类水平表现。


<details>
  <summary>Details</summary>
Motivation: 探究当前先进推理型大语言模型是否提升了在临床场景中的认知灵活性，尤其是应对因思维定势（Einstellung效应）导致的错误推理能力。

Method: 在对抗性医学问答基准mARC上，系统评测OpenAI、Grok、Gemini、Claude和DeepSeek等系列推理模型的表现，并对比其与医师在易错题目上的作答准确率与置信度。

Result: 强推理模型比弱推理模型更少陷入Einstellung陷阱，在mARC上达到人类水平；在医师最常答错的问题上，前5名模型以高置信度实现55%–70%的正确率。

Conclusion: 强推理能力的大语言模型展现出更优的临床推理灵活性，对Einstellung效应的敏感性低于人类，具备潜在临床辅助价值。

Abstract: Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.

</details>


### [297] [GloCTM: Cross-Lingual Topic Modeling via a Global Context Space](https://arxiv.org/abs/2601.11872)
*Nguyen Tien Phat,Ngo Vu Minh,Linh Van Ngo,Nguyen Thi Ngoc Diep,Thien Huu Nguyen*

Main category: cs.CL

TL;DR: 本文提出了GloCTM框架，通过构建统一的语义空间实现跨语言主题建模，利用词义扩展、局部与全局编码器对齐以及CKA损失对齐多语言上下文嵌入，显著提升了主题连贯性与跨语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言主题模型在独立语言空间中学习主题，依赖词典等浅层对齐机制，难以捕捉深层语义，且未充分利用多语言预训练表示中的丰富语义信号。

Method: 提出GloCTM框架：1）扩展词袋为跨语言词汇邻域以增强输入表示；2）使用局部和全局编码器推断主题比例，并通过内部正则化对齐其隐表示；3）定义覆盖全部词汇的全局主题-词分布以结构化同步跨语言主题含义；4）引入中心核对齐（CKA）损失，将隐主题空间与多语言上下文嵌入对齐。

Result: 在多个基准数据集上实验表明，GloCTM显著提升主题连贯性和跨语言对齐性能，优于强基线方法。

Conclusion: GloCTM通过端到端统一语义空间建模，有效解决了跨语言主题对齐难题，为多语言理解提供了更鲁棒、语义更一致的主题建模新范式。

Abstract: Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.

</details>


### [298] [Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence](https://arxiv.org/abs/2601.11886)
*Kaijie Mo,Siddhartha Venkatayogi,Chantal Shaib,Ramez Kouzy,Wei Xu,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 本文构建了一个名为MedCounterFact的反事实医学问答数据集，用于评估大语言模型（LLM）在面对反事实或对抗性医学证据时的行为与推理能力；结果表明现有模型会盲目接受危险或不合理的反事实证据，并给出自信且无警示的回答，暴露出‘忠实性’与‘安全性’之间尚无有效边界。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，模型需忠实于上下文，但当上下文违背模型先验知识或安全规范时，其行为缺乏研究；本文旨在探究LLM在面对反事实甚至对抗性医学证据时是否仍盲目忠实，从而揭示忠实性与安全性之间的潜在冲突。

Method: 构建MedCounterFact数据集：基于临床比较类问答，将真实医学干预措施系统替换为四类反事实刺激（如未知词、有毒物质等）；在多个前沿LLM上进行评测，分析其对反事实证据的接受程度、回答置信度及是否给出警示。

Result: 现有LLM在反事实证据下普遍不加质疑地接受危险或荒谬内容，给出高置信度、无警示的回答；未表现出基本的安全判断或对上下文合理性的质疑能力。

Conclusion: 当前LLM在医学场景中缺乏对上下文安全性的内在判断机制，‘忠实于上下文’与‘保障用户安全’之间尚无明确边界，亟需引入安全感知的推理机制。

Abstract: In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such "evidence" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.

</details>


### [299] [A Systematic Analysis of Chunking Strategies for Reliable Question Answering](https://arxiv.org/abs/2601.14123)
*Sofia Bennani,Charles Moslonka*

Main category: cs.CL

TL;DR: 本文系统评估了文档分块策略对工业级RAG系统可靠性的影响，发现句子分块最具成本效益，重叠无明显收益，且上下文长度存在约2.5k token的质量拐点。


<details>
  <summary>Details</summary>
Motivation: 工业实践中文档分块常依赖启发式方法，缺乏系统性评估；需明确不同分块策略对RAG性能与成本的影响以指导高效部署。

Method: 在Natural Questions数据集上进行端到端评估，系统性地改变分块方式（token/句子/语义/代码）、分块大小、重叠量和上下文长度；采用SPLADE检索器与Mistral-8B生成器的标准工业配置。

Result: （i）分块重叠无显著性能增益但增加索引开销；（ii）句子分块在成本效益上最优，性能媲美语义分块（≤5k tokens）；（iii）上下文超过约2.5k tokens时质量急剧下降（'context cliff'）；（iv）最优上下文长度取决于任务目标：语义质量在小上下文下最优，精确匹配则需更大上下文。

Conclusion: 文档分块应避免盲目使用重叠，优先选用句子分块，并根据下游任务目标精细调控上下文长度，以实现RAG系统的成本与性能平衡。

Abstract: We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

</details>


### [300] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

TL;DR: 本文提出PPA-Plan，一种面向长上下文推理的主动式规划策略，通过在规划生成前识别并规避逻辑陷阱与错误假设（以负约束形式），提升大语言模型在稀疏相关信息场景下的推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有plan-and-execute框架因依赖表层线索生成计划，易产生基于错误假设的不可靠计划，且事后修正困难，难以应对长上下文推理中信息稀疏分布的挑战。

Method: PPA-Plan通过主动识别潜在逻辑陷阱和错误假设，将其建模为负约束，并在规划生成阶段显式地条件化避免这些约束，从而实现前置性错误预防。

Result: 在多个长上下文问答基准上，PPA-Plan生成的计划经执行后，性能持续优于现有plan-and-execute方法及直接提示法。

Conclusion: 主动将负约束注入规划过程可显著提升长上下文推理的可靠性与有效性，为大语言模型的可控推理提供了新范式。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [301] [LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding](https://arxiv.org/abs/2601.11913)
*Yichen Jiang,Peng Ye,Jiakang Yuan,Chongjun Tu,Lei Bai,Tao Chen*

Main category: cs.CL

TL;DR: 本文提出了一种受LSTM启发的多智能体系统LSTM-MAS，用于提升大语言模型在长文本理解中的性能，通过分层信息流与门控记忆机制有效缓解错误累积和幻觉传播问题，并在多个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有单LLM方法在处理长上下文时面临计算开销大或扩展上下文长度受限的问题；多智能体框架虽有所改进，但仍易出现错误累积与幻觉传播。

Method: 设计了类LSTM结构的多智能体系统LSTM-MAS，包含链式架构下的worker、filter、judge和manager四类代理，分别模拟LSTM的输入门、遗忘门、恒定误差循环单元和输出门，实现可控信息传递与选择性长程依赖建模。

Result: 在NarrativeQA、Qasper、HotpotQA和MuSiQue四个问答数据集上，相比最优多智能体方法CoA，分别提升40.93%、43.70%、121.57%和33.12%。

Conclusion: LSTM-MAS通过借鉴LSTM的门控与记忆机制，为长上下文理解提供了更鲁棒、可扩展的多智能体范式，显著抑制了错误传播与幻觉生成。

Abstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.

</details>


### [302] [Enhancing LLM-Based Data Annotation with Error Decomposition](https://arxiv.org/abs/2601.11920)
*Zhen Xu,Vedant Khatri,Yijun Dai,Xiner Liu,Siyan Li,Xuanming Zhang,Renzhe Yu*

Main category: cs.CL

TL;DR: 本文提出了一种诊断性评估范式，用于区分大语言模型（LLM）在主观标注任务中的错误来源（模型特有 vs. 任务固有）和错误类型（边界模糊 vs. 概念误识别），并评估其对下游分析的影响。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将所有标注错误简单归为单一对齐指标，掩盖了不同错误类型对分析结论的差异化影响，尤其在涉及心理构念等主观标注任务中，LLM表现不稳定。

Method: 提出包含三部分的诊断范式：（1）基于‘来源’与‘类型’两维的错误分类体系；（2）轻量级人工标注测试以估计任务固有模糊性；（3）计算方法分解LLM观测错误。该范式在序数标注任务上细化并验证。

Result: 在四项教育领域标注任务上验证了该范式的概念有效性与实用价值，表明高对齐率在某些主观任务中不现实，单一对齐指标不足以反映LLM标注质量。

Conclusion: 该诊断范式可作为低成本工具，评估特定任务是否适合LLM标注，并为技术优化提供可操作洞见。

Abstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.

</details>


### [303] [Mapping the maturation of TCM as an adjuvant to radiotherapy](https://arxiv.org/abs/2601.11923)
*P. Bilha Githinji,Aikaterini Melliou,Xi Yuan,Dayan Zhang,Lian Zhang,Zhenglin Chen,Jiansong Ji,Chengying Lv,Jinhao Xu,Peiwu Qin,Dongmei Yu*

Main category: cs.CL

TL;DR: 本文对2000–2025年间69,745篇关于中药（TCM）作为放疗辅助治疗的文献进行大规模分析，揭示该领域呈现周期性演化特征，并识别出五大主题轴（癌种、支持治疗、临床终点、机制、方法学），反映其向患者中心、系统化与机制深入方向发展；同时指出研究已趋成熟，可能迎来新范式，且存在普遍的阳性报告偏倚。


<details>
  <summary>Details</summary>
Motivation: 在中西医结合肿瘤学制度化约25年后，亟需系统梳理中药作为放疗辅助治疗的证据演进轨迹，以评估其发展态势与潜在瓶颈。

Method: 基于69,745篇文献（2000–2025）开展大规模计量与主题建模分析，识别出版周期、国际合作、资助趋势等演化规律，并构建稳定主题结构以刻画研究焦点与知识组织方式。

Result: 发现出版量、合作与资助呈‘定义—构想—验证’循环模式；识别出五大主导主题轴，体现患者中心、科学严谨与机制探索并重；主题交叉融合呈系统导向；整体存在跨类型、跨主题、跨周期的均质化阳性报告倾向。

Conclusion: 该领域已基本完成当前研究议程的深化与专业化，处于范式转换临界点；需警惕阳性报告偏倚对证据质量的影响，并推动更平衡、机制驱动与临床转化导向的新阶段发展。

Abstract: The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.

</details>


### [304] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

TL;DR: 本文探讨了事件检测研究中的两个关键问题：解码器-only大语言模型（LLM）的单向性限制，以及Micro-F1评估指标对长尾事件类型的偏差；提出利用句子上下文增强和LoRA微调方法，显著提升Macro-F1分数，尤其改善长尾事件类型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决事件检测中解码器-only LLM缺乏双向上下文建模能力，以及Micro-F1指标掩盖长尾事件性能缺陷的问题。

Method: 引入句子级上下文增强输入，并采用Low-Rank Adaptation（LoRA）进行高效微调，以提升模型对长尾事件类型的建模能力。

Result: 增强上下文的模型在Macro-F1上显著优于基线解码器-only模型；LoRA微调特别提升了长尾事件类别的Macro-F1得分。

Conclusion: 双向上下文建模与LoRA微调是提升事件检测模型、尤其是长尾事件类型性能的有效策略；Macro-F1比Micro-F1更适合作为事件检测任务的评估指标。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [305] [Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence](https://arxiv.org/abs/2601.11956)
*Yuyin Lu,Ziran Liang,Yanghui Rao,Wenqi Fan,Fu Lee Wang,Qing Li*

Main category: cs.CL

TL;DR: 本文提出DoublyCal框架，通过双重校准原理（证据校准+模型校准）提升大语言模型在知识图谱增强推理中的准确性与置信度校准性，兼顾低开销。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱增强的大语言模型方法无法量化检索证据和模型推理中的认知不确定性，导致可信推理受限。

Method: 提出DoublyCal框架：先用轻量代理模型生成知识图谱证据并输出校准后的证据置信度；再将该证据及其置信度引导黑盒大语言模型进行推理，实现最终预测的准确性和置信度双重校准。

Result: 在知识密集型基准测试中，DoublyCal显著提升了黑盒大语言模型的准确率和置信度校准性，且令牌开销较低。

Conclusion: 双重校准机制能有效融合知识图谱的结构化可信证据与大语言模型的推理能力，在保持低计算成本的同时增强推理的可信性与可解释性。

Abstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.

</details>


### [306] [PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning](https://arxiv.org/abs/2601.11957)
*Bingxuan Li,Jeonghwan Kim,Cheng Qian,Xiusi Chen,Eitan Anzenberg,Niran Kundapur,Heng Ji*

Main category: cs.CL

TL;DR: 本文提出PEARL框架，通过强化学习增强语言代理，以解决日历冲突问题，在CalConflictBench基准上显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 日历重叠导致专业人士频繁决策，人工调度耗时且难以规模化，因此探索LLM或语言代理自动处理日历冲突具有现实意义和挑战性。

Method: 构建了面向长周期日历冲突解决的基准CalConflictBench，并提出PEARL框架：结合外部记忆模块与轮次优化奖励设计的强化学习方法，使代理能逐步推断并适应用户偏好。

Result: PEARL在CalConflictBench上实现0.76的错误率降幅，平均错误率较最强基线提升55%；而当前LLM代理（如Qwen-3-30B-Think）平均错误率达35%。

Conclusion: 单纯LLM代理在日历冲突解决任务中表现不佳，引入外部记忆与定制化强化学习机制（PEARL）可显著提升其偏好建模与动态适应能力。

Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.

</details>


### [307] [$\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969)
*Zecheng Tang,Baibei Ji,Ruoxi Sun,Haitian Wang,WangJie You,Zhang Yijun,Wenpeng Zhu,Ji Qi,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出了首个用于评估奖励模型（RMs）对大语言模型长时记忆管理能力评价效果的基准MemoryRewardBench，涵盖多种长上下文任务与记忆模式，并在13个前沿RM上进行了系统评测，揭示了当前RMs在该任务上的能力边界与局限性。


<details>
  <summary>Details</summary>
Motivation: 有效评估大语言模型长时记忆管理质量至关重要，而现有工作缺乏专门针对此能力的系统性基准；需借助奖励模型自动、可靠地衡量记忆质量。

Method: 构建首个专注记忆管理评估的基准MemoryRewardBench，包含10种不同记忆模式的长上下文理解与生成任务，上下文长度达8K–128K tokens；在13个前沿奖励模型上开展系统评测。

Result: 发现开源与闭源RM性能差距缩小，新一代模型普遍优于旧代（与参数量无关）；同时揭示了当前RMs在多样记忆场景下评估能力的显著局限。

Conclusion: MemoryRewardBench为RM评估记忆能力提供了标准化工具，实证表明现有RMs尚不能稳健覆盖复杂记忆管理过程，亟需针对性改进。

Abstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.

</details>


### [308] [Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning](https://arxiv.org/abs/2601.12019)
*Chaowei Zhang,Xiansheng Luo,Zewei Zhang,Yi Zhu,Jipeng Qiang,Longwei Wang*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLM）的‘迎合性’（sycophancy）而非消除它，通过生成正反立场推理对来提升点击诱饵检测效果的新方法——SORG框架与ORCD模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在点击诱饵检测中受sycophancy（迎合用户偏见、牺牲事实准确性）干扰；但作者认为可转而利用该特性生成对比性推理，无需人工标注即可增强检测鲁棒性。

Method: 提出Self-renewal Opposing-stance Reasoning Generation (SORG)框架，引导LLM自动生成针对新闻标题的‘支持’与‘反对’推理对；再构建基于三BERT编码器的ORCD模型，融合标题与双立场推理，并采用对比学习与LLM生成的软标签进行训练。

Result: 在三个基准数据集上，本方法持续优于纯LLM提示、微调的小型语言模型及当前最优点击诱饵检测基线。

Conclusion: sycophancy可被重构为一种有益资源；通过结构化激发对立推理并建模其对比关系，能显著提升无监督/弱监督下的点击诱饵检测性能。

Abstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.

</details>


### [309] [Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection](https://arxiv.org/abs/2601.12033)
*Muhammad Alif Al Hakim,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

TL;DR: 本文系统研究了静态和动态量化方法对大语言模型公平性和安全性的影响，发现量化会一致地损害这两方面性能，尤其是非英语场景下的安全性；为此提出了一种无需重训练的关键权重保护技术来缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 量化虽被广泛用于降低大语言模型计算成本，但其对公平性和安全性（尤其在动态量化和多语言场景下）的影响尚缺乏系统研究。

Method: 在多种语言（英、法、荷、西、土评估公平性；英、韩、阿评估安全性）上，系统评估静态与动态量化对内在/外在偏见及安全对齐的影响，并提出‘关键权重保护’技术以识别并保留对公平性和安全性至关重要的权重。

Result: 量化普遍降低模型的公平性与安全性，其中动态量化比静态更稳定；公平性退化存在语言差异，安全性退化在非英语语境中尤为严重；所提方法可有效缓解退化，且无需重训练或对齐。

Conclusion: 量化在提升效率的同时可能损害模型可信度，需在设计中兼顾公平性与安全性；关键权重保护是一种高效、实用的缓解策略。

Abstract: Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.

</details>


### [310] [Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation](https://arxiv.org/abs/2601.12061)
*Jinsook Lee,Kirk Vanacore,Zhuqian Zhou,Jeanine Grutter,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 本文提出了一种基于对话行为（DA）标注需求的代码本注入分段方法，通过将边界决策与下游标注标准绑定，提升分段一致性；实验表明DA感知分段在内部一致性上优于纯文本基线，但全局对话流变化检测仍弱于基于连贯性的基线；不同分段器各有优劣，分段设计应针对下游任务优化而非追求单一指标。


<details>
  <summary>Details</summary>
Motivation: 传统对话行为标注将意图局限于单个话语或轮次，导致标注者对行为类型一致但对边界划分分歧大，降低了表观可靠性，亟需更契合下游标注目标的分段方法。

Method: 提出代码本注入分段（codebook-injected segmentation），使边界决策依赖于下游DA标注标准；构建LLM-based分段器，并与标准及检索增强基线对比；设计无金标评估指标：跨度一致性、区分度、人-AI分布一致性。

Result: DA感知分段在段内一致性上显著优于纯文本基线；LLM擅长构建构念一致的片段，但连贯性基线更擅捕捉全局对话流变化；两数据集上无单一最优分段器；段内连贯性提升常以边界区分度和人-AI分布一致性为代价。

Conclusion: 分段不是预设步骤而是关键设计选择，应依据具体下游任务目标进行优化，而非追求统一性能指标。

Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.

</details>


### [311] [Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset](https://arxiv.org/abs/2601.12068)
*Rowzatul Zannat,Abdullah Al Shafi,Abdul Muntakim*

Main category: cs.CL

TL;DR: 本文构建了一个包含85种疾病和758个症状-疾病关系的孟加拉语症状-疾病数据集，并基于该数据集评估多种机器学习模型，软硬投票集成方法达到98%准确率，旨在提升孟加拉语人群的健康信息可及性与早期疾病检测能力。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语使用者缺乏可靠疾病预测资源的问题，提升非英语人群获取可信健康信息的能力。

Method: 构建并公开发布一个涵盖85种疾病、758个唯一症状-疾病关系的孟加拉语数据集；在此基础上评估多种机器学习模型，并采用软/硬投票集成策略融合最优模型。

Result: 软投票和硬投票集成方法均达到98%的准确率，展现出优异的鲁棒性与泛化能力。

Conclusion: 该工作为孟加拉语疾病预测提供了首个基础性数据资源，推动本地化健康信息学与诊断工具发展，促进孟加拉语社区在早期疾病检测和医疗干预方面的公平可及。

Abstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.

</details>


### [312] [To Copy or Not to Copy: Copying Is Easier to Induce Than Recall](https://arxiv.org/abs/2601.12075)
*Mehrdad Farahani,Franziska Penzkofer,Richard Johansson*

Main category: cs.CL

TL;DR: 本文提出了一种机制性方法，通过提取‘仲裁向量’来研究语言模型在检索增强场景中如何在参数化知识与上下文信息之间做选择，并验证了其在不同架构和任务上的可迁移干预效果。


<details>
  <summary>Details</summary>
Motivation: 语言模型在检索增强（RAG）中需权衡自身参数化知识与输入上下文，但该决策机制尚不清晰，亟需可解释的机制分析。

Method: 构建特制数据集以分离无关上下文（触发参数化回忆）与相关但错误上下文（触发复制），据此计算残差流中两类情形的激活中心差作为‘仲裁向量’；在指定层和token位置注入该向量，实现Copy→Recall（抑制上下文使用）与Recall→Copy（诱导任意上下文复制）两种定向干预。

Result: 在decoder-only与encoder/decoder两种架构及两个开放域QA基准上，干预引发一致的行为偏移；机制分析揭示：诱导复制是鲁棒的‘再激活’过程，而恢复回忆是脆弱的、依赖于目标token的‘抑制’过程。

Conclusion: 模型对上下文使用的仲裁具有可定位、可干预的向量表征，且两类行为调控存在本质不对称性，为RAG可控性与可解释性提供了新路径。

Abstract: Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\rightarrow$Recall (suppressing context use) and Recall$\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.

</details>


### [313] [Large language models struggle with ethnographic text annotation](https://arxiv.org/abs/2601.12099)
*Leonardo S. Goodall,Dor Shilton,Daniel A. Mullins,Harvey Whitehouse*

Main category: cs.CL

TL;DR: 本文评估了7种最先进的大语言模型在人类学文本标注任务中的表现，发现其性能远低于人类专家水平，尤其在处理长文本、序数区分和模糊概念时表现更差，因此目前尚不能替代人类进行民族志文本的自动标注。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能够加速跨文化研究，特别是通过从民族志文本中提取结构化数据来实现自动化文本标注。

Method: 评估7种最先进大语言模型在标注567段民族志摘录中121个仪式特征的任务上的表现，并与人类编码员的信度进行对比。

Result: LLM性能有限，远低于可靠自动标注所需水平；长文本、需序数区分的特征及模糊概念尤其困难；人类编码员间信度为LLM准确率的近似上限；即使在人类高度一致的特征上，模型仍逊于人类。

Conclusion: 大语言模型目前尚不能替代人类专业知识进行民族志文本标注。

Abstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.

</details>


### [314] [Powerful Training-Free Membership Inference Against Autoregressive Language Models](https://arxiv.org/abs/2601.12104)
*David Ilić,David Stanojević,Kostadin Cvejoski*

Main category: cs.CL

TL;DR: 本文提出EZ-MIA，一种新型成员推断攻击方法，利用模型在错误预测位置对训练数据的异常高概率响应（即‘错误区’现象），通过与预训练模型对比计算EZ分数，实现无需训练、仅两次前向传播的高效隐私风险审计，在多个基准上显著超越现有SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有成员推断攻击（MIA）在低误报率下检测率有限，难以满足实际隐私审计需求；而微调语言模型存在因记忆训练数据而泄露敏感信息的严重隐私风险，亟需更灵敏、实用的审计方法。

Method: 提出EZ-MIA：基于‘记忆主要发生在错误预测位置’的观察，定义Error Zone（EZ）分数——衡量模型在错误token处相对于预训练参考模型的概率偏移方向不平衡性；该方法仅需两次前向传播，无需任何额外训练。

Result: 在WikiText+GPT-2上，1% FPR下TPR达66.3%（较SOTA提升3.8倍）；0.1% FPR下TPR达14.0%（提升8倍）；在AG News+Llama-2-7B上1% FPR下TPR为46.7%（提升3倍）；AUC达0.98。

Conclusion: 微调语言模型的实际隐私风险远超以往认知；EZ-MIA为高效、免训练、高灵敏度的隐私审计提供了新范式，对模型部署与合规评估具有重要实践意义。

Abstract: Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.

</details>


### [315] [Bengali Text Classification: An Evaluation of Large Language Model Approaches](https://arxiv.org/abs/2601.12132)
*Md Mahmudul Hoque,Md Mehedi Hassain,Md Hojaifa Tanvir,Rahul Nandy*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在孟加拉语新闻文章分类任务中的有效性，使用Prothom Alo报纸数据集，对比了Qwen 2.5、LLaMA 3.1和LLaMA 3.2三种指令微调模型，Qwen 2.5以72%准确率最优，尤其在“体育”类别表现突出。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语NLP面临标注数据和预训练模型稀缺的挑战，亟需探索适用于低资源语言的大模型应用潜力。

Method: 在统一分类框架下，对三个指令微调的LLM（Qwen 2.5 7B Instruct、LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct）进行零样本或少样本分类评估，使用Kaggle提供的Prothom Alo新闻数据集。

Result: Qwen 2.5达到72%最高准确率，显著优于LLaMA 3.1（53%）和LLaMA 3.2（56%），且在‘Sports’类别上表现最强。

Conclusion: 尽管孟加拉语NLP资源匮乏，LLMs仍展现出良好分类能力；Qwen系列模型在该任务中更具适配性；后续需拓展模型探索、缓解类别不平衡及优化微调策略。

Abstract: Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.

</details>


### [316] [Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs](https://arxiv.org/abs/2601.12154)
*Teodor-Călin Ionescu,Lifeng Han,Jan Heijdra Suasnabar,Anne Stiggelbout,Suzan Verberne*

Main category: cs.CL

TL;DR: 本研究利用BERTopic和Top2Vec结合LLM（GPT-4）对13位癌症患者的访谈文本进行主题建模，发现BioClinicalBERT嵌入显著提升主题精度与可解释性，识别出两大主导主题：癌症照护管理中的协调与沟通、癌症治疗旅程中的患者决策。


<details>
  <summary>Details</summary>
Motivation: 从患者叙事数据中挖掘有意义的主题，以支持以患者为中心的医疗实践。

Method: 采用BERTopic和Top2Vec进行单访谈主题提取与关键词抽取，并用GPT-4进行主题标注；通过小规模人工评估（连贯性、清晰度、相关性）筛选模型；进一步对比三种临床导向嵌入模型（含BioClinicalBERT），最终对全部13次访谈做全局主题分析。

Result: BioClinicalBERT嵌入下的BERTopic表现最优，主题精度与可解释性最高；全局分析揭示两大跨访谈主导主题：'癌症照护管理中的协调与沟通'与'癌症治疗旅程中的患者决策'。

Conclusion: 神经主题建模（尤其是BERTopic）结合临床预训练嵌入，可有效从患者访谈中提取高价值主题，辅助临床文档导航并增强患者声音在医疗流程中的作用。

Abstract: This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.

</details>


### [317] [Tolerance Principle and Small Language Model Learning](https://arxiv.org/abs/2601.12179)
*Adam E. Friedman,Stevan Harnad,Rushen Shi*

Main category: cs.CL

TL;DR: 本研究检验了容差原则（Tolerance Principle）在Transformer模型BabyBERTa上的适用性，发现其语法泛化行为与人类婴儿不同，不遵循该原则。


<details>
  <summary>Details</summary>
Motivation: 探究现代语言模型（如BabyBERTa）学习抽象语法规则所需的最小数据量和质量，并验证Yang（2016）提出的容差原则是否适用于神经网络模型。

Method: 使用人工语法训练优化小数据场景的Transformer模型BabyBERTa，系统调节训练集规模、句型多样性及规则/例外比例，评估其语法泛化能力。

Result: BabyBERTa的学习动态不符合容差原则的预测，即其规则泛化不随例外比例和样本量呈该原则所定义的阈值关系。

Conclusion: 容差原则虽能刻画人类婴幼儿的语法规则学习，但不能直接迁移至当前Transformer架构的语言模型，提示人类与模型的归纳偏置存在本质差异。

Abstract: Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.

</details>


### [318] [CTC-DID: CTC-Based Arabic dialect identification for streaming applications](https://arxiv.org/abs/2601.12199)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

TL;DR: 本文提出了一种受CTC损失函数启发的方言识别（DID）方法（CTC-DID），将DID建模为有限词表ASR任务，用方言标签序列表示语音，并通过语言无关启发式（LAH）或预训练ASR模型估计标签重复；在低资源阿拉伯方言识别（ADI）任务上，基于自监督学习（SSL）的CTC-DID模型优于微调Whisper和ECAPA-TDNN，在零样本Casablanca数据集上亦表现更优，且对短语音鲁棒、适合流式实时应用。


<details>
  <summary>Details</summary>
Motivation: 解决低资源场景下方言识别（DID）性能受限的问题，借鉴ASR中成熟的CTC框架以提升建模能力和泛化性。

Method: 提出CTC-DID方法，将方言识别建模为有限词汇ASR任务，方言标签作为语音序列的输出标签；使用语言无关启发式（LAH）或预训练ASR模型估计方言标签在转录中的重复次数；采用SSL预训练模型作为特征提取器，并端到端优化CTC损失。

Result: 在阿拉伯方言识别（ADI）任务上，CTC-DID在有限数据下显著优于微调Whisper和ECAPA-TDNN；在Casablanca数据集零样本评估中同样领先；对短语音更鲁棒，且支持流式实时推理，性能下降极小。

Conclusion: CTC-DID是一种有效、鲁棒且实用的方言识别新范式，尤其适用于低资源与实时应用场景，验证了将ASR建模范式迁移至DID任务的可行性与优势。

Abstract: This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.

</details>


### [319] [CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement](https://arxiv.org/abs/2601.12208)
*Yunzhe Li,Richie Yueqi Feng,Tianxin Wei,Chin-Chia Hsu*

Main category: cs.CL

TL;DR: 本文提出CoReflect框架，通过对话模拟与评估的协同进化循环，实现对多轮对话系统的自适应、迭代式评估，减少人工干预并提升评估的覆盖度与诊断精度。


<details>
  <summary>Details</summary>
Motivation: 传统多轮对话系统评估方法依赖人工定义的固定评估标准和静态对话上下文，难以覆盖对话模型多样且涌现的行为模式。

Method: CoReflect框架结合对话规划器（生成结构化模板引导用户模拟器开展多样化目标导向对话）与反思分析器（识别行为模式并自动优化评估标准），并通过反馈机制形成协同进化循环。

Result: 实现了评估用例复杂性与评估标准诊断精度的同步提升，支持低人工干预下的可扩展、自优化评估流程。

Conclusion: CoReflect为快速演进的对话模型提供了动态适配、自我完善的评估范式，推动了多轮对话系统评估方法的自动化与智能化发展。

Abstract: Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.

</details>


### [320] [Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models](https://arxiv.org/abs/2601.12247)
*Miao Li,Hanyang Jiang,Sikai Chen,Hengyu Fu,Yuhang Cai,Baihe Huang,Tinghan Ye,Xuanzhou Chen,Pascal Van Hentenryck*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的文本生成新范式Plan-Verify-Fill（PVF），用于提升扩散语言模型（DLMs）的解码效率，通过分层骨架构建与结构化验证机制，在不牺牲准确率的前提下显著降低函数评估次数（NFE）达65%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型的解码策略多为被动式，未能充分利用全局双向上下文来引导整体生成轨迹。

Method: 提出Plan-Verify-Fill（PVF）范式：首先主动构建以高杠杆语义锚点为核心的分层骨架（Plan），再通过验证协议判断是否应停止细化（Verify），最后填充细节（Fill）；全程无需额外训练。

Result: 在LLaDA-8B-Instruct和Dream-7B-Instruct模型上，PVF相较基于置信度的并行解码，NFE最多降低65%，且保持生成准确性。

Conclusion: PVF是一种高效、通用、训练无关的DLM解码框架，通过量化验证驱动的主动规划，显著提升生成效率与可控性。

Abstract: Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.

</details>


### [321] [Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers](https://arxiv.org/abs/2601.12263)
*Yixuan Du,Chenxiao Yu,Haoyan Xu,Ziyi Wang,Yue Zhao,Xiyang Hu*

Main category: cs.CL

TL;DR: 本文提出了一种针对视觉-语言模型（VLM）产品搜索系统的新型多模态对抗攻击方法MGEO，通过联合优化图像微小扰动和文本后缀，实现对目标商品的不公平排名提升，揭示了VLM在跨模态耦合下的潜在安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽验证了VLM的强大能力，但其在竞争性排序场景中面对对抗操纵的鲁棒性尚未被充分探索，尤其在电商搜索等实际应用中存在安全隐患。

Method: 提出Multimodal Generative Engine Optimization（MGEO），采用交替梯度优化策略，协同生成不可察觉的图像扰动与流畅文本后缀，以利用VLM内部深层跨模态耦合关系。

Result: 在真实数据集和SOTA VLM上的实验表明，MGEO显著优于仅文本或仅图像的基线攻击方法，能有效提升目标商品排名且绕过常规内容过滤机制。

Conclusion: VLM的多模态协同优势可被恶意利用，威胁搜索系统公平性与完整性，亟需设计针对性防御机制。

Abstract: Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.

</details>


### [322] [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269)
*Xucong Hu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种基于温度调节的MCMC采样方法，无需微调即可从基础自回归语言模型中显著提升其理论心智（ToM）能力。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型被批评仅优化局部连贯性（表面似然），而忽视全局连贯性（潜在状态表征），因此被认为难以完成依赖潜态推理的Theory of Mind（ToM）任务。

Method: 基于近期的power-sampling方法（Karan & Du, 2025），采用马尔可夫链蒙特卡洛（MCMC）对序列级（而非词元级）概率分布进行锐化采样，并引入退火策略，使温度从高到低渐进变化。

Result: 该方法在不更新权重、不额外验证的前提下，显著提升了基座模型的ToM性能，优于固定温度的power sampling。

Conclusion: 采样层面的优化（如退火式power sampling）是一种强大且轻量的方式，可有效释放语言模型中已存在但未被常规解码激活的潜在能力。

Abstract: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.

</details>


### [323] [Conversational Context Classification: A Representation Engineering Approach](https://arxiv.org/abs/2601.12286)
*Jonathan Pan*

Main category: cs.CL

TL;DR: 本文提出了一种结合表示工程（RepE）与一类支持向量机（OCSVM）的方法，用于在大语言模型（LLM）隐藏状态空间中识别特定上下文对应的子空间，从而检测偏离上下文的响应（如话题偏移、事实错误或幻觉），并在Llama和Qwen模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: LLM易生成脱离上下文的响应（如幻觉、事实错误），而传统异常检测难以直接建模语义上下文，亟需能刻画上下文内在表征的检测机制。

Method: 利用Representation Engineering提取LLM各层隐藏状态，结合One-Class SVM在标注的上下文内样本上建模隐空间边界；通过搜索最优层，定位对目标上下文最敏感的内部状态子空间。

Result: 在Llama和Qwen两个开源LLM上成功识别出与特定上下文强相关的隐状态子空间，展现出良好的上下文一致性判别能力。

Conclusion: 该方法不仅可有效检测对话是否偏离上下文，还为理解LLM内部语义表征结构提供了可解释的新路径。

Abstract: The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.

</details>


### [324] [Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies](https://arxiv.org/abs/2601.12369)
*Ming Zhang,Jiabao Zhuang,Wenqing Jing,Ziyu Kong,Jingyi Deng,Yujiong Shen,Kexin Tan,Yuhang Zhao,Ning Luo,Renzhe Zheng,Jiahui Lin,Mingqi Wu,Long Ma,Yi Zou,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了TaxoBench，一个用于评估深度研究代理（Deep Research Agents）撰写综述能力的新基准，发现当前代理在关键能力（检索核心论文与组织知识结构）上远未达到人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注语言流畅性或引用准确性，缺乏对深度研究代理核心能力（即检索关键文献并构建连贯知识结构）的评估。

Method: 构建了基于72篇高被引计算机科学综述的TaxoBench基准，人工提取包含3815个精确定类引用的专家级分类树作为真值；设计两种评测模式：Deep Research模式（端到端检索与组织）和Bottom-Up模式（仅测试组织能力）。

Result: 评估7个主流深度研究代理和12个前沿大语言模型，结果表明：最优代理仅能召回20.9%的专家选定论文；即使输入完全正确的论文集，最优模型在组织任务上的调整兰德指数（ARI）仅为0.31。

Conclusion: 当前深度研究代理在综述写作的核心能力上仍远逊于人类专家，TaxoBench为未来研究提供了可公开使用的诊断性评估工具。

Abstract: Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.

</details>


### [325] [A Scalable Entity-Based Framework for Auditing Bias in LLMs](https://arxiv.org/abs/2601.12374)
*Akram Elbouanani,Aboubacar Tuo,Adrian Popescu*

Main category: cs.CL

TL;DR: 本文提出了一种基于命名实体的大规模偏见审计框架，发现当前大语言模型存在系统性政治、地域和行业偏见，且模型规模增大反而加剧偏见，指令微调可缓解但不能根除，多语言提示也无法消除西方中心倾向。


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见评估方法在生态效度与统计控制之间难以兼顾：人工提示缺乏现实代表性，自然任务又难以规模化和标准化。

Method: 构建基于命名实体的可扩展偏见审计框架，利用合成数据验证其对真实文本偏见模式的复现能力，并在1.9亿数据点、多维度（实体类型/任务/语言/模型/提示策略）上开展最大规模偏见审计。

Result: 发现系统性偏见：对右翼政客惩罚、左翼政客偏好；偏好西方及富裕国家，贬低全球南方；偏好西方企业；惩罚国防与制药行业企业；指令微调降低偏见，但模型规模增大加剧偏见；中/俄语提示无法削弱西方中心偏好。

Conclusion: 大语言模型在部署于高风险场景前必须经过严格、大规模、多维的偏见审计。

Abstract: Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.

</details>


### [326] [LR-DWM: Efficient Watermarking for Diffusion Language Models](https://arxiv.org/abs/2601.12376)
*Ofek Raban,Ethan Fetaya,Gal Chechik*

Main category: cs.CL

TL;DR: 本文提出了一种适用于扩散语言模型（DLMs）的轻量级水印方案LR-DWM，通过利用左右邻接token信息嵌入水印，在几乎不增加计算和内存开销的前提下实现高检测率。


<details>
  <summary>Details</summary>
Motivation: 现有针对自回归大模型的水印方法不适用于非顺序生成的扩散语言模型（DLMs），而近期为DLMs设计的水印方法存在显著计算或内存开销。

Method: 提出Left-Right Diffusion Watermarking（LR-DWM），在DLM生成过程中，当左右邻接token可用时，基于它们联合偏置当前token选择，从而嵌入稳定水印信号。

Result: LR-DWM在标准评估下实现了高检测可靠性，同时保持与无水印DLM相近的运行效率和内存占用，显著降低开销。

Conclusion: 扩散语言模型可以高效地被水印化，LR-DWM为DLMs提供了一种低开销、高检测性的实用水印方案。

Abstract: Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.

</details>


### [327] [NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages](https://arxiv.org/abs/2601.12389)
*Lakshya Tomar,Vinayak Abrol,Puneet Agarwal*

Main category: cs.CL

TL;DR: 本文提出NADIR，一种新型非自回归（NAR）模型，用于多语言音译任务，在保持较高准确率的同时实现13倍加速，并显著降低各类错误率。


<details>
  <summary>Details</summary>
Motivation: 并非所有序列到序列任务都需要自回归（AR）模型的强归纳偏置；某些任务（如音译、代码重构等）依赖局部依赖，AR模型可能过重，带来高精度与高推理延迟之间的权衡。

Method: 提出NADIR架构，融合微分Transformer与专家混合（MoE）机制，实现无需顺序依赖的复杂字符映射建模。

Result: 在Indic语言音译任务上，NADIR相比SOTA AR基线提速超13倍；字符错误率（CER）为15.78%，优于标准NAR（21.88%），略逊于AR（14.44%）；重复、替换、遗漏、插入错误分别降低49.53%、24.45%、32.92%、16.87%。

Conclusion: NADIR为构建快速且可靠的NAR系统提供了实用范式，有效弥合了AR模型精度与实时大规模部署需求之间的鸿沟。

Abstract: In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.

</details>


### [328] [Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification](https://arxiv.org/abs/2601.12419)
*Mahammad Namazov,Tomáš Koref,Ivan Habernal*

Main category: cs.CL

TL;DR: 本文提出了一种模型无关的可解释性技术比较框架，用于法律领域的大语言模型结果预测，通过合理性提取方法、可信度与合理性评估，发现模型的推理与法律专家存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 法律领域对大语言模型的可解释性要求高，但目前尚不清楚哪种可解释技术在法律结果预测中效果最佳。

Method: 提出模型无关的可解释性技术比较框架，采用两种理由提取方法，并通过归一化充分性与全面性指标（faithfulness）及法律专家评估（plausibility）进行对比；同时探索LLM-as-a-Judge的可行性。

Result: 模型给出的‘理由’与法律专家判断存在显著差异，尽管其定量指标表现良好且下游分类性能合理。

Conclusion: 单纯依赖定量可解释性指标可能具有误导性，需结合领域专家评估以确保法律场景下解释的可靠性与实用性。

Abstract: Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.

</details>


### [329] [System-Mediated Attention Imbalances Make Vision-Language Models Say Yes](https://arxiv.org/abs/2601.12430)
*Tsan Tsai Chan,Varsha Suresh,Anisha Saha,Michael Hahn,Vera Demberg*

Main category: cs.CL

TL;DR: 本文提出了一种系统介导的视角来解释视觉语言模型（VLM）幻觉现象，指出系统模态中功能冗余的权重会削弱对图像和文本输入的注意力，从而导致如‘是偏差’等幻觉；通过因果性地将注意力从系统模态重分配至图像和文本模态，可显著抑制该偏差，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLM幻觉缓解策略多偏向图像中心主义，忽视系统模态和文本模态的作用；本文旨在从更整体、系统介导的角度重新审视跨模态注意力失衡问题。

Method: 提出系统介导的注意力失衡框架，分析系统模态中冗余权重对图像与文本注意力的抑制作用，并通过因果干预方式重分配系统模态的注意力至图像和文本输入，评估其对yes-bias等幻觉现象的抑制效果。

Result: 因果重分配系统模态注意力能显著抑制yes-bias，常优于现有方法；并发现该失衡促使模型依赖粗糙输入表征，导致任务适应性下降。

Conclusion: 系统模态注意力是VLM幻觉的关键因素，调控系统注意力为缓解幻觉提供了新且有效的干预杠杆。

Abstract: Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.

</details>


### [330] [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465)
*Miao Peng,Weizhou Shen,Nuo Chen,Chenliang Li,Ming Yan,Jia Li*

Main category: cs.CL

TL;DR: 本文提出DeepReasonQA和LongPAS方法，解决RLVR在长上下文推理中因‘几乎成功’现象导致的性能下降问题，通过知识图谱驱动的数据合成与细粒度优势塑形提升模型长程推理能力。


<details>
  <summary>Details</summary>
Motivation: RLVR在长上下文推理中表现下降，存在‘几乎成功’现象（轨迹基本正确但最终步失败），主因是长上下文QA数据推理密度不足，且传统RL训练中对部分正确轨迹的粗粒度惩罚丢失了关键学习信号。

Method: 提出DeepReasonQA——基于知识图谱可控生成高难度、多跳、具内在推理链的长上下文问答对；并提出Long-context Process Advantage Shaping（LongPAS）——沿‘有效性’和‘相关性’两个维度对推理步骤进行细粒度信用分配，从‘几乎成功’轨迹中提取有效学习信号。

Result: 在三个长上下文推理基准上显著超越RLVR基线，性能媲美前沿大模型，同时参数量大幅减少；分析验证了方法在增强长上下文推理能力与保持RL训练稳定性上的双重有效性。

Conclusion: 通过提升数据推理密度与改进过程式奖励建模，可有效突破长上下文强化学习推理瓶颈，为LLM长程推理提供新范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.

</details>


### [331] [Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty](https://arxiv.org/abs/2601.12471)
*Sravanthi Machcha,Sushrita Yerra,Sahil Gupta,Aishwarya Sahoo,Sharmin Sultana,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: 本文提出MedAbstain，一个面向医疗多选问答任务的统一拒答（abstention）评估基准，强调在高风险场景中模型主动拒绝作答的重要性；实验表明显式提供拒答选项比模型规模扩大或提示工程更有效提升安全拒答能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估过度关注准确性，但在医疗等安全关键场景中，模型在不确定时主动拒答的能力对可信部署至关重要。

Method: 构建MedAbstain基准，融合共形预测、对抗性问题扰动和显式拒答选项，在医疗多选问答任务中系统评估开源与闭源大模型的拒答能力。

Result: 即使高准确率的最先进模型也常在不确定时未能拒答；显式提供拒答选项显著提升模型不确定性识别与安全拒答行为，而模型缩放或高级提示技术效果甚微。

Conclusion: 拒答机制是实现大语言模型可信部署的核心要素，显式拒答设计为高风险应用提供了切实可行的安全增强路径。

Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.

</details>


### [332] [Capability-Aware Early-Stage Research Idea Evaluation](https://arxiv.org/abs/2601.12473)
*Renlong Jie,Chen Chu,Zhen Wang*

Main category: cs.CL

TL;DR: 本文提出了一种能力感知的三路Transformer框架，仅利用作者信息和研究想法（无需全文或实验结果）预测论文接收率与评分，显著优于基于BERT微调的单路模型。


<details>
  <summary>Details</summary>
Motivation: 在科研构想初期（即大量资源投入前）预测其成果，有助于优化科研资源配置与规划；现有方法依赖已完成论文或同行评审，缺乏对早期想法的评估能力。

Method: 提出一种能力感知框架：1）通过两阶段架构从作者信息和研究想法中学习作者能力表征；2）构建融合作者信息、推断的能力表征和研究想法的三路Transformer，支持灵活融合机制。

Result: 实验表明，该方法显著优于基于bert-base和bert-large微调的单路模型；引入能力预测模块显著提升了最终预测准确率。

Conclusion: 所提方法可有效支持早期科研成果预测与科学资源分配决策，为科研管理提供新工具。

Abstract: Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.

</details>


### [333] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: 本文提出DoPE框架，通过在考试文档中嵌入语义诱饵来防御多模态大语言模型（MLLMs）对考试的自动解答，实现模型无关的预防与检测。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）可直接解析考试文档，威胁传统评估方式与学术诚信，亟需文档层防御机制。

Method: 提出DoPE（Decoy-Oriented Perturbation Encapsulation）框架，在PDF/HTML考试文档作者阶段嵌入语义诱饵，利用MLLM渲染-解析差异；设计FewSoRT-Q生成问题级诱饵，FewSoRT-D将其封装为水印文档；使用LLM-as-Judge进行检测评估。

Result: 在Integrity-Bench基准（1826份考试文档）上，对OpenAI和Anthropic黑盒MLLM实现91.4%检测率（8.7%假阳性）和96.3%的预防/诱饵对齐失败率。

Conclusion: DoPE是一种有效的、模型无关的文档层防御方案，兼顾AI作弊的预防与检测，并开源数据集与工具以推动学术诚信研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [334] [Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning](https://arxiv.org/abs/2601.12535)
*Ahmed Attia,Alham Fikri*

Main category: cs.CL

TL;DR: 本文提出了一种基于自监督强化学习和往返引导（round-trip bootstrapping）的低资源机器翻译微调方法，利用NLLB模型，在多个低资源语言上实现了BLEU和chrF++指标提升，并提升了译文流畅性与语义保真度。


<details>
  <summary>Details</summary>
Motivation: 低资源机器翻译虽受关注，但仍有大量潜在改进方法尚未探索；现有平行语料稀缺，需更有效的无监督/自监督微调策略。

Method: 采用自监督强化学习进行微调：以英语→低资源语言→英语的往返翻译构建重建句，用chrF++与BLEU联合奖励函数指导NLLB模型（600M/1.3B参数）优化；训练不依赖目标语言人工参考译文。

Result: 在NLLB-MD数据集上，对Central Aymara、Friulian、Wolof和Russian四种语言均观察到一致性能提升；定性分析显示译文更流畅、语义更准确。

Conclusion: 该往返引导式RL微调方法有效提升低资源MT性能，且具备良好的可扩展性——模型规模增大时能更好激活预训练知识，实现持续自优化。

Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.

</details>


### [335] [Benchmarking Concept-Spilling Across Languages in LLMs](https://arxiv.org/abs/2601.12549)
*Ilia Badanin,Daniil Dzenhaliou,Imanol Schlag*

Main category: cs.CL

TL;DR: 本文提出了一种评估多语言大语言模型语义鲁棒性的新框架，聚焦于‘语言溢出’现象（即模型在非英语生成中受其他语言表征干扰），通过多义词跨语言生成任务，以生成序列中何时开始借用主导语言含义作为相对性能指标，评估了多种多语言LLM，并构建了一个可扩展的基准与验证流程。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型虽具跨语言能力，但在非英语生成中常出现语义干扰（即‘语言溢出’），缺乏系统、可比、无需因果归因的语义鲁棒性评估方法。

Method: 提出基于多义词的跨语言意义生成任务，要求模型对100个高多义性英文词在9种语言中各生成5个含义；以‘首次借用主导语言含义的位置’作为相对性能指标，构建结构化评估框架与验证流水线。

Result: 在多个开源与闭源多语言LLM上验证发现：不同模型及语言间语义稳健性差异显著；该方法能提供无需错误归因的合理模型排序；并成功产出可扩展的基准与验证工具。

Conclusion: 该框架为多语言语义鲁棒性提供了可量化、可比较、实用性强的评估范式，所构建的基准与流水线是推动语言均衡AI系统发展的关键基础设施。

Abstract: Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

</details>


### [336] [Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models](https://arxiv.org/abs/2601.12555)
*Yihong Liu,Bingyu Xiong,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）在自然语境中而非直接提问时的事实回忆能力，发现上下文会显著降低多语言事实回忆性能，且不同关系间差异明显；更大模型对此更具鲁棒性，而真实姓名的影响则不一致。


<details>
  <summary>Details</summary>
Motivation: 现有事实回忆评测多基于显式命名实体的孤立查询，但自然语言中事实常通过上下文间接引入，因此需考察LLM在语境中介下的跨语言事实回忆能力。

Method: 构建控制性提示，保持事实不变但通过上下文句子引入指代中介；使用合成名与真实名对比，分离上下文效应与名称特异性关联；在五种语言中评估多个模型家族。

Result: 上下文中介持续削弱事实回忆性能，不同关系间退化程度差异显著；更大模型对上下文更鲁棒，性能下降更小；真实名称及其来源的影响混杂且无系统性。

Conclusion: 孤立事实回忆与语境依赖的语言理解之间存在显著差距，揭示当前多语言LLM在真实语言使用中事实获取能力的局限性。

Abstract: Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

</details>


### [337] [A Cloud-based Multi-Agentic Workflow for Science](https://arxiv.org/abs/2601.12607)
*Anurag Acharya,Timothy Vega,Rizwan A. Ashraf,Anshu Sharma,Derek Parker,Robert Rallo*

Main category: cs.CL

TL;DR: 本文提出了一种领域无关、模型无关的云原生LLM智能体工作流框架，作为科学助手，通过监督智能体协调多个功能专精的智能体，支持从文献综述到仿真运行等多级任务；在催化剂研究中验证了其有效性，任务路由准确率达90%，任务完成率在合成与真实任务中分别达97.5%和91%，且成本可控、精度媲美前沿模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）缺乏执行仿真或复杂决策的能力，限制了其在科研中的实用性；而现有LLM智能体系统在模型、云平台与外部资源间难以平衡，导致实现困难、效率低下。

Method: 设计了一个基于监督智能体（supervisor agent）协调多个专用智能体的云原生、领域无关、模型无关的代理式工作流框架；构建了面向催化剂研究的原型系统，并在自建合成基准、化学领域基准及专家评估中进行验证；同时提供详细的云服务成本分解。

Result: 系统任务路由准确率为90%；合成任务完成率达97.5%，真实世界任务完成率达91%；精度优于或媲美当前主流前沿模型；具备可复用性与跨学科扩展潜力。

Conclusion: 该框架为科研场景提供了高效、可部署、可复现的LLM智能体解决方案，验证了其在化学与材料科学等领域的可行性，并为其他科学领域提供了通用范式。

Abstract: As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.

</details>


### [338] [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618)
*Elham Tajik,Conrad Borchers,Bahar Shahrokhian,Sebastian Simon,Ali Keramati,Sonika Pal,Sreecharan Sankaranarayanan*

Main category: cs.CL

TL;DR: 本文提出利用大语言模型（LLM）代理生成的推理轨迹作为新型过程数据，通过余弦相似度量化代理间分歧，将其转化为可解释的分析信号，从而提升定性编码的信度与深度，并支持人机协同的教育研究方法论。


<details>
  <summary>Details</summary>
Motivation: 学习分析领域缺乏指导生成式AI参与定性数据分析的方法学标准，尤其是如何系统化利用AI的推理过程提升解释性。

Method: 采用多智能体LLM对人类辅导对话片段进行编码，提取其推理轨迹，用余弦相似度度量代理间语义推理一致性，并结合定量相似度与定性审查分析分歧与共识。

Result: 在近10,000组代理编码对中，推理轨迹相似度能稳健区分共识与分歧，且与人工编码信度显著相关；该指标还揭示了代码内部的教学子功能并支持代码本精细化。

Conclusion: LLM推理轨迹中的分歧是一种有价值的新类型分析信号，融合定量相似度与定性解读可提升编码效率、揭示解释模糊性，推动教育研究的方法严谨性与解释深度。

Abstract: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

</details>


### [339] [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639)
*Daniel Vennemeyer,Punya Syon Pandey,Phan Anh Duong,Michael Umeokoli,Samuel Ratnam*

Main category: cs.CL

TL;DR: 本文通过控制实验比较了六种微调目标对大语言模型安全性和能力的影响，发现目标选择在小规模训练时影响较小，但在大规模训练时成为决定对抗鲁棒性和隐式角色稳定性的重要因素。


<details>
  <summary>Details</summary>
Motivation: 尽管在良性数据上微调大语言模型（LLM）仍可能导致对齐性下降和对抗鲁棒性减弱，但目前尚缺乏对微调目标如何影响这些安全性结果的直接分析。

Method: 在数据、领域、架构和优化设置完全一致的前提下，对六种微调目标（监督微调、直接偏好优化、条件微调、接种提示、比值比偏好优化、KL正则化微调）进行受控对比实验，涵盖封闭式推理与开放式生成任务。

Result: 在小训练预算下各目标的安全性相近而能力不同；在大预算下，监督与基于偏好的微调使能力提升伴随对抗脆弱性与角色漂移加剧，而ORPO与KL正则化等约束学习信号的目标显著缓解二者。

Conclusion: 微调目标在小规模训练中对安全性影响有限，但随训练规模增大，成为影响对抗鲁棒性与隐式角色稳定性的主要因素。

Abstract: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.

</details>


### [340] [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648)
*Nafiz Imtiaz Khan,Kylie Cleland,Vladimir Filkov,Roger Eric Goldman*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型（LLMs）能否从自由文本放射科报告中自动提取结构化操作病例日志信息，结果表明多种本地和商用LLM在提取任务中F1-score最高达0.87，可显著减轻住院医师文书负担并提升日志一致性。


<details>
  <summary>Details</summary>
Motivation: 放射科培训中程序性病例日志是核心要求，但手工填写耗时且易不一致，亟需自动化解决方案。

Method: 在414份由9名住院医师撰写的介入放射科报告上，评估多种本地与商用大语言模型，采用指令式提示和思维链提示进行结构化信息抽取，并以敏感性、特异性、F1分数、推理延迟和token效率综合评估性能。

Result: 最佳模型F1-score达0.87；不同模型在速度与成本间存在权衡；自动化方案可显著降低文书负担并提升日志一致性。

Conclusion: LLMs辅助病例日志生成在医学教育中具备可行性，但需跨机构与临床流程进一步验证。

Abstract: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.

</details>


### [341] [Augmenting Question Answering with A Hybrid RAG Approach](https://arxiv.org/abs/2601.12658)
*Tianyi Yang,Nashrah Haque,Vaishnave Jonnalagadda,Yuya Jeremy Ong,Zhehui Chen,Yanzhao Wu,Lei Yu,Divyesh Jadav,Wenqi Wei*

Main category: cs.CL

TL;DR: 本文提出了Structured-Semantic RAG（SSRAG），一种融合查询增强、智能体路由与结构化检索（向量+图）的混合架构，显著提升了问答任务中答案的准确性与信息丰富度。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在检索上下文相关性信息方面表现不佳，导致答案不完整或次优。

Method: 提出SSRAG架构，整合查询增强、agentic路由、向量与图联合的结构化检索机制，并进行上下文统一。

Result: 在TruthfulQA、SQuAD和WikiQA三个数据集上，对五种大语言模型的实验表明，SSRAG持续优于标准RAG方法。

Conclusion: SSRAG通过优化检索过程与增强上下文建模，有效提升了问答质量，为RAG范式提供了可扩展、鲁棒的新路径。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

</details>


### [342] [UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages](https://arxiv.org/abs/2601.12696)
*Tassallah Abdullahi,Macton Mgonzo,Mardiyyah Oduwole,Paul Okewunmi,Abraham Owodunni,Ritambhara Singh,Carsten Eickhoff*

Main category: cs.CL

TL;DR: 本文提出UbuntuGuard，首个面向非洲语言的基于政策的安全基准，由155位领域专家构建，用于评估守护模型在低资源、多语言及文化适配场景下的真实安全性。


<details>
  <summary>Details</summary>
Motivation: 现有守护模型以西方为中心、依赖固定安全类别，难以泛化至非洲等低资源语言及其多元社会文化语境，亟需灵活、可运行时执行、文化适配的安全评估基准。

Method: 构建UbuntuGuard基准：收集155位专家（含医疗等领域）撰写的对抗性查询，从中提炼语境相关的安全政策与参考响应；对13个模型（6个通用LLM + 7个守护模型，含静态/动态/多语言变体）进行政策对齐评估。

Result: 英文基准高估实际多语言安全性；跨语言迁移仅提供部分覆盖；动态模型虽能更好利用策略，但仍难以充分本地化非洲语言语境。

Conclusion: 必须建立多语言、文化扎根的安全基准，以推动面向低资源语言的可靠、公平守护模型发展。

Abstract: Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

</details>


### [343] [A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization](https://arxiv.org/abs/2601.12698)
*Qiuyi Qu,Yicheng Sui,Yufei Sun,Rui Chen,Xiaofei Zhang,Yuzhi Zhang,Haofeng Wang,Ge Lan,Ning Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种基于模板重写与搜索式自动调优相结合的GPU内核优化方法，通过将内核语义重构为显式可参数化的模板，并在硬件资源约束下进行搜索优化，显著提升了优化稳定性与性能（最高超3倍加速），且具备可解释性和跨平台扩展性。


<details>
  <summary>Details</summary>
Motivation: GPU代码优化仍是HPC和大模型训练/推理的关键性能瓶颈；现有LLM-agent方法多依赖隐式参数选择或人工干预，导致性能增益不稳定。

Method: 在agent驱动的迭代循环之上引入模板化重写层：先将CUDA内核语义重构为显式参数化模板，再结合profiling反馈，在硬件资源约束下进行搜索式自动调优。

Result: 在SGLang提取的真实CUDA内核上实现最高超3倍的加速；相比纯agent直接重写，显著降低优化随机性，提升可解释性与配置系统性。

Conclusion: 模板+搜索的设计范式能更稳定、高效、可解释地实现GPU内核自动优化，且可扩展至OpenCL、HIP等后端，适用于实际生产环境。

Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

</details>


### [344] [A Shared Geometry of Difficulty in Multilingual Language Models](https://arxiv.org/abs/2601.12731)
*Stefano Civelli,Pietro Bernardelle,Nicolò Brunello,Gianluca Demartini*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）中问题难度预测的多语言几何特性，发现难度信号在模型浅层（语言无关）和深层（语言相关）表征中分阶段出现，揭示了LLM元认知能力的分层抽象机制。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型如何内部表征和估计问题难度，特别是其在多语言场景下的泛化能力与表征结构。

Method: 在Easy2Hard基准的AMC子集（翻译为21种语言）上训练线性探针，分析不同层级内部表征中难度信号的分布与跨语言泛化性能。

Result: 发现难度信号在浅层表征中具有强跨语言泛化性但单语准确率较低，而在深层表征中单语准确率高但泛化差，表明存在先语言无关、后语言相关的两阶段难度表征。

Conclusion: LLM对问题难度的元认知估计遵循分层抽象机制：早期形成语言无关的抽象难度表征，后期细化为语言特定表征，这拓展了对LLM高层认知能力的理解。

Abstract: Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.

</details>


### [345] [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748)
*Bin Xie,Bingbing Xu,Xueyun Tian,Yilin Chen,Huawei Shen*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段框架来缓解过程奖励模型（PRM）中蒙特卡洛估计（MCE）带来的策略依赖性噪声问题，通过反思感知的标签校正和噪声感知的迭代训练，显著提升步骤级正确性判别能力。


<details>
  <summary>Details</summary>
Motivation: MCE方法产生的过程奖励具有策略依赖性，导致标签噪声（如错误地奖励错误步骤或惩罚正确步骤），限制了PRM在复杂推理中的性能。

Method: 提出两阶段框架：1）标注阶段——引入反思感知的标签校正机制，利用LLM作为裁判识别当前推理步的反思与自修正行为，抑制高估奖励；2）训练阶段——提出噪声感知的迭代训练框架，使PRM基于自身置信度逐步优化噪声标签。

Result: 在多个实验中，该方法显著提升了步骤级正确性判别能力，在平均F1指标上相较使用噪声监督训练的PRM最高提升27个百分点。

Conclusion: 策略无关的、更鲁棒的过程奖励建模需结合LLM判别能力与模型自校准机制，所提两阶段框架为降低PRM监督成本与提升泛化性提供了新思路。

Abstract: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

</details>


### [346] [VISPA: Pluralistic Alignment via Automatic Value Selection and Activation](https://arxiv.org/abs/2601.12758)
*Shenyan Zheng,Jiayou Zhong,Anudeex Shetty,Heng Ji,Preslav Nakov,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出VISPA框架，一种无需训练的多元化对齐方法，通过动态选择和内部模型激活引导实现价值观表达的直接控制，在医疗等多个领域展现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高风险领域的应用日益增多，其输出需反映多样化的观点而非平均人类偏好，但现有方法在价值观控制与表征方面存在局限。

Method: 提出VISPA——一种无需训练的多元化对齐框架，利用动态选择与内部模型激活引导来实现对价值观表达的直接控制。

Result: 在多个模型和评估设置的广泛实证研究中，VISPA在医疗及其他领域的所有多元化对齐模式下均表现优异；且对不同引导起点、模型或价值观具有适应性。

Conclusion: 多元化对齐可通过模型内部激活机制实现，为构建服务全体人群的语言模型提供了可扩展路径。

Abstract: As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

</details>


### [347] [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771)
*Keito Inoshita*

Main category: cs.CL

TL;DR: 本文提出LLM Associative Memory Agents (LAMA)框架，利用大语言模型的世界知识作为联想记忆，通过回忆同名名人并聚合其国籍进行间接推理，显著提升了99国国籍预测任务的准确率（0.817），优于传统提示方法和神经模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM提示方法依赖直接推理，在应用抽象语言规则时存在局限；而国籍与地域预测任务需结合语言、文化与历史背景知识，LLM的世界知识具有重要价值但尚未被有效激发。

Method: 提出LAMA框架，采用双智能体架构（人物智能体与媒体智能体）并行回忆同名名人，通过投票生成Top-1预测、条件补全生成Top-K预测，将国籍推断转化为基于实例回忆与聚合的间接推理过程。

Result: 在99国国籍预测任务中达到0.817准确率；验证了LLM在具体实例回忆上比抽象推理更可靠；召回式方法对低频国籍鲁棒；双智能体具有互补协同效应。

Conclusion: 基于检索与聚合LLM知识的多智能体系统，比传统推理式提示更有效；揭示了激活LLM世界知识的新范式——联想记忆而非逻辑推理。

Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

</details>


### [348] [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812)
*Sushant Kumar Ray,Gautam Siddharth Kashyap,Sahil Tripathi,Nipun Joshi,Vijay Govindarajan,Rafiq Ali,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出MEDASSESS-X框架，在推理时通过轻量级引导向量对齐模型激活，无需微调即可提升临床问答（CQA）性能，打破‘专业化谬误’。


<details>
  <summary>Details</summary>
Motivation: 挑战当前CQA系统中普遍认为必须依赖领域专用微调（如BioBERT等）的假设，指出其存在覆盖窄、成本高、适应性差等问题，并揭示‘专业化谬误’这一认知偏差。

Method: 提出MEDASSESS-X框架，采用推理时对齐（inference-time alignment）而非监督微调（SFT），利用轻量级转向向量（steering vectors）引导模型激活朝向医学一致的推理路径，不更新模型权重、无需领域重训练。

Result: 在各类LLM上均取得稳定提升：准确率最高提升+6%，事实一致性提升+7%，安全错误率最多降低50%。

Conclusion: 推理时对齐可有效替代领域微调，使通用与专用LLM在CQA任务中性能趋同，从而证伪‘专业化优于通用’的默认假设，为CQA工业部署提供更高效灵活的新范式。

Abstract: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

</details>


### [349] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

TL;DR: 本文提出JurisMMA框架和JurisMM数据集，用于提升法律判决预测（LJP）的准确性与适应性，尤其适用于多指控、多证据场景，并在JurisMM和LawBench上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法难以应对多指控、多样本证据及缺乏适应性等问题，亟需更系统化、可扩展的框架与高质量数据集。

Method: 提出JurisMMA框架，将审判任务分解为标准化、阶段化的流程；构建包含10万+中文司法记录（含文本与视频-文本多模态数据）的大规模数据集JurisMM。

Result: 在JurisMM和基准数据集LawBench上的实验表明，JurisMMA显著提升LJP性能，并展现出对更广泛法律任务的泛化能力。

Conclusion: JurisMMA框架与JurisMM数据集为法律AI提供了新范式，推动法律判决预测及下游法律应用的发展。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


### [350] [Rapport du Projet de Recherche TRAIMA](https://arxiv.org/abs/2601.12844)
*Julie Rançon,Jean-François Cerisier,Emilie Remond,Aurélien Nguyen,Andrew Peterson,Ladjel Bellatreche*

Main category: cs.CL

TL;DR: TRAIMA项目探索了在教育环境中自动处理多模态互动（如言语、副言语和非言语行为）的潜力，重点是法语作为外语/母语课堂中的解释性与协作性互动序列；项目未追求全自动系统，而是构建了一个融合话语分析、交互语言学与机器学习的严谨方法论框架，尤其关注转录规范、标注体系与理论自觉性。


<details>
  <summary>Details</summary>
Motivation: 教育与互动研究中，对言语、副言语和非言语数据的手动分析耗时且难以规模化，亟需自动化支持；同时，现有转录规范难以适配多模态课堂数据，存在理论立场依赖与实践变异性问题。

Method: 结合话语分析与交互语言学，提出解释性话语的三阶段结构（开场—核心—收尾）；系统梳理并比较ICOR、Mondada等主流转录规范；基于INTER-EXPLIC与EXPLIC-LEXIC语料库开展手动标注与实证分析；依托TechnéLAB平台采集多源同步数据（视频、音频、眼动、数字交互痕迹）。

Result: 明确了适配机器学习的转录规范、标注范畴与分析单位；揭示了转录实践的内在解释性与理论依赖性；刻画了教师手势、韵律等多模态资源在意义建构与学习理解中的功能；确立了面向教育多模态互动自动化的跨学科方法论基础。

Conclusion: TRAIMA不以开发即用型自动化系统为目标，而是致力于建立一个理论明确、方法严谨、兼顾研究者反思性的多模态教学互动自动处理框架，为教育学、话语分析、多模态研究与人工智能的交叉研究奠定基础。

Abstract: The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

</details>


### [351] [Race, Ethnicity and Their Implication on Bias in Large Language Models](https://arxiv.org/abs/2601.12868)
*Shiyue Hu,Ruizhe Li,Yanjun Gao*

Main category: cs.CL

TL;DR: 本文通过可复现的可解释性方法，探究大语言模型中种族与族裔信息的表征与运作机制，发现其在模型内部单元中分布广泛且跨模型差异显著；尽管部分神经元编码敏感或刻板印象关联，相同人口学线索却引发不同行为；干预虽能降低偏差但残留效应明显，表明行为层面而非表征层面的改变，呼吁更系统化的偏见缓解策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要记录大语言模型在高风险领域（如医疗）中基于种族/族裔的输出差异，但缺乏对其内部机制的理解。

Method: 在两个公开数据集（毒性生成与临床叙事理解）上，对三个开源大语言模型开展机制分析，结合探针分析、神经元级归因和定向干预的可复现可解释性流程。

Result: 发现种族/族裔信息在模型内部单元中呈分布式表征，跨模型差异大；部分神经元编码敏感或刻板印象关联，但相同人口学线索可导致定性不同的行为；抑制相关神经元可降低偏差，但仍存显著残余效应。

Conclusion: 偏差缓解需超越表征干预，转向更系统的行为层面治理策略。

Abstract: Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

</details>


### [352] [From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.12904)
*Jiahao Wang,Weiyu Xie,Mingxing Zhang,Boxing Zhang,Jianwei Dong,Yuening Zhu,Chen Lin,Jinqi Tang,Yaochen Han,Zhiyuan Ai,Xianglin Chen,Yongwei Wu,Congfeng Jiang*

Main category: cs.CL

TL;DR: FusionRAG是一种新型检索增强生成（RAG）推理框架，通过在离线预处理阶段嵌入相关文本块信息、在线重处理阶段选择性重计算关键token的KV缓存，在保持生成质量的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有RAG中KV缓存复用虽能加速推理，但因缺乏跨块上下文导致生成质量严重下降；需在缓存复用与生成质量间取得更好平衡。

Method: 提出FusionRAG框架：离线阶段为每块嵌入其他相关块信息；在线阶段仅重计算模型注意力聚焦的关键token的KV缓存。

Result: 在重计算比例相同下，生成质量显著优于SOTA方法；重计算<15% token时，归一化F1分数提升最高达70%，TTFT较全注意力减少2.66–9.39倍。

Conclusion: FusionRAG有效缓解了RAG中效率与质量的权衡难题，实现了高质量、低延迟的检索增强生成。

Abstract: Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

</details>


### [353] [Gated Differentiable Working Memory for Long-Context Language Modeling](https://arxiv.org/abs/2601.12906)
*Lingrui Mei,Shenghua Liu,Yiwei Wang,Yuyao Ge,Baolong Bi,Jiayu Yao,Jun Wan,Ziling Yin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文提出Gdwm框架，通过引入门控写入控制器和上下文效用度量，在测试时自适应地优化长上下文处理中的记忆整合，显著提升效率与性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文下Transformer存在注意力稀释、关键信息丢失及推理时难以适应新模态等问题；现有测试时自适应方法采用均匀写入策略，计算浪费且梯度方差高。

Method: 将测试时自适应重构为预算约束下的记忆整合问题，提出Gdwm框架：含门控写入控制器，基于信息论定义的'上下文效用'动态分配梯度更新步数，保障全局覆盖。

Result: 在ZeroSCROLLS和LongBench v2上，Gdwm以仅1/4的梯度步数达到与均匀基线相当或更优性能，确立了测试时自适应的新效率-性能帕累托前沿。

Conclusion: Gdwm通过有选择性的、效用驱动的记忆整合，有效缓解长上下文建模瓶颈，为高效测试时自适应提供了新范式。

Abstract: Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

</details>


### [354] [SciCoQA: Quality Assurance for Scientific Paper--Code Alignment](https://arxiv.org/abs/2601.12910)
*Tim Baumgärtner,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了SciCoQA数据集，用于检测科学论文与其代码库之间的差异，以确保实现的忠实性。该数据集包含611个论文-代码差异实例（81个真实，530个合成），涵盖AI、物理、定量生物学等多个计算科学领域。实验表明，现有大语言模型（如GPT-5）在该任务上表现有限，仅能检测出45.7%的真实差异。


<details>
  <summary>Details</summary>
Motivation: 确保科学论文与其开源代码实现之间的一致性，提升科研可复现性；当前缺乏系统性评估论文-代码一致性的基准数据集。

Method: 构建了SciCoQA数据集，结合真实GitHub issue和可复现性论文中的问题，并提出合成数据生成方法来扩展规模；定义并分析了论文-代码差异的类型与类别；对21种大语言模型进行了系统性评测。

Result: SciCoQA包含611个论文-代码差异（81真实+530合成），覆盖多学科；GPT-5在真实差异上的检测准确率仅为45.7%，凸显任务难度；多数LLM在遗漏细节、长上下文及域外数据场景下表现较差。

Conclusion: 论文-代码一致性检测是一项具有挑战性的新任务，现有LLM能力仍严重不足；SciCoQA为该方向提供了首个基准数据集和系统分析框架，推动可复现科学研究的发展。

Abstract: We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.

</details>


### [355] [Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs](https://arxiv.org/abs/2601.12921)
*Adimulya Kartiyasa,Bao Gia Cao,Boyang Li*

Main category: cs.CL

TL;DR: 本文提出了一种利用印尼社会科学研究期刊（IndoSoSci）注入印尼文化知识到大语言模型（LLMs）的新方法，结合事实提取与基于假设文档的检索增强生成（RAG），显著提升了IndoCulture基准测试性能，并联合印尼维基百科创下新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对印尼文化的理解不足，而本地社会科学研究期刊蕴含大量本土视角的文化知识，却长期被忽视。

Method: 构建印尼社会科学期刊文本数据集IndoSoSci（源自151种开源期刊），从中提取印尼文化相关事实，并采用LLM生成的假设文档作为查询，结合检索增强生成（RAG）将文化知识注入LLM。

Result: 该方法在IndoCulture基准上显著优于多个强基线；进一步融合IndoSoSci与印尼维基百科后，达到该基准最新最优准确率。

Conclusion: 本地学术文献是提升LLM文化理解能力的重要知识源，所提RAG策略与多源融合方法可有效增强模型对特定文化的表征与推理能力。

Abstract: Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

</details>


### [356] [A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits](https://arxiv.org/abs/2601.12945)
*Miao Xie,Siguang Chen,Chunli Lv*

Main category: cs.CL

TL;DR: This survey is the first to systematically review the bidirectional interaction between large language models (LLMs) and multi-armed bandit (MAB) algorithms, highlighting how MABs help address LLM challenges (e.g., pre-training, RAG, personalization) and how LLMs enhance MABs by redefining arms and environment modeling.


<details>
  <summary>Details</summary>
Motivation: To systematically explore and unify the emerging intersection of large language models and multi-armed bandits, addressing the lack of a comprehensive, component-level survey on their bidirectional synergy.

Method: A systematic literature review analyzing existing works on LLM-enhanced bandit systems and bandit-enhanced LLM systems, categorizing contributions by design, methodology, and performance; supplemented by a curated GitHub repository.

Result: Identification of bidirectional benefits: MABs improve LLM robustness and adaptability across stages (pre-training to RAG/personalization); LLMs enrich MABs via semantic arm definition and dynamic environment modeling. Key challenges and representative findings are summarized.

Conclusion: The integration of LLMs and MABs holds significant promise for adaptive AI systems; this survey establishes foundational understanding, taxonomy, and research directions for future work at their intersection.

Abstract: Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

</details>


### [357] [Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images](https://arxiv.org/abs/2601.12960)
*Ainhoa Vivel-Couso,Nicolás Vila-Blanco,María J. Carreira,Alberto Bugarín-Diz,Inmaculada Tomás,Jose M. Alonso-Moral*

Main category: cs.CL

TL;DR: 本文提出了一种结合不透明深度学习模型与可解释规则方法的牙科年龄估计系统，并通过自然语言生成模块为临床医生提供易懂的文字解释，经牙科专家验证具有高可信度和高质量。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗中的应用虽能实现个性化护理，但其黑箱特性引发信任问题，亟需提升模型透明度和可解释性。

Method: 构建一个融合不透明深度学习模型与透明规则方法的系统，利用自然语言生成（NLG）模块生成面向临床医生的文本解释；解释规则由牙科专家参与制定；采用问卷调查方式进行人工评估，并依据ALTAI可信度评估清单开展自评。

Result: 专家对生成解释在五个维度上的平均评分为4.77±0.12（满分5分）；ALTAI自评在七个维度上平均得分为4.40±0.27（满分5分）。

Conclusion: 该系统在保持高性能的同时显著提升了临床可解释性与AI可信度，验证了人机协同设计在医疗AI中的可行性与有效性。

Abstract: Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

</details>


### [358] [Pardon? Evaluating Conversational Repair in Large Audio-Language Models](https://arxiv.org/abs/2601.12973)
*Shuanghong Huang,Jinlei Xu,Youchao Zhou,Yanghao Zhou,Xuan Zhao,Chong Feng,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种面向修复能力的评估框架（EAR），用于评估大型音频-语言模型在口语问答任务中对可回答与不可回答语音输入的区分与修复能力，揭示了当前以准确率为中心的评估方式的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有口语问答评估主要关注答案准确性和抗声学扰动鲁棒性，隐含假设语音输入始终语义可回答，但现实中常因信息缺失导致不可回答，亟需能识别并修复此类问题的评估方法。

Method: 提出修复感知评估范式，定义‘可回答性’为输入固有属性，通过语义-声学掩码协议构建配对评估条件，并设计非补偿性指标EAR，联合评估可回答条件下的任务能力与不可回答条件下的修复行为。

Result: 在两个口语QA基准上对多种LALM的实验表明：模型在可回答输入上表现良好，但普遍无法识别语义不可回答性，亦不能发起恰当的对话修复；EAR得分显著低于准确率，暴露可靠性短板。

Conclusion: 当前准确率主导的评估范式存在缺陷；应将不可回答输入视为触发修复与持续交互的信号，推动评估向对话可靠性方向演进。

Abstract: Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.

</details>


### [359] [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974)
*Hongyang Ma,Tiantian Gu,Huaiyuan Sun,Huilin Zhu,Yongxin Wang,Jie Li,Wubin Sun,Zeliang Lian,Yinghong Zhou,Yi Gao,Shirui Wang,Zhihui Tang*

Main category: cs.CL

TL;DR: 本文提出SCMPE基准测试，评估大语言模型在牙科临床决策中的动态行为可靠性，发现模型在静态任务中表现良好，但在动态对话中存在信息收集和状态跟踪瓶颈，并指出RAG在动态场景中效果有限，强调需结合领域自适应预训练。


<details>
  <summary>Details</summary>
Motivation: LLMs从被动知识检索转向自主临床代理，需将评估重点从静态准确性转向动态行为可靠性，尤其在牙科这一强调患者参与决策的高价值AI应用领域。

Method: 构建标准化临床管理与性能评估（SCMPE）基准，涵盖知识导向的静态客观任务和基于工作流的多轮模拟患者交互；分析模型在指南遵循性与决策质量间的权衡；量化检索增强生成（RAG）在不同任务类型中的影响。

Result: 模型在静态任务中表现优异，但在动态临床对话中性能显著下降；主要瓶颈在于主动信息收集与动态状态跟踪，而非知识存储；普遍存在‘高效但不安全’的风险；RAG可缓解静态任务幻觉，但在动态流程中效果有限且不稳定。

Conclusion: 外部知识注入（如RAG）不足以弥补推理缺陷，必须结合牙科领域的自适应预训练，才能实现安全、可靠的自主临床实践。

Abstract: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

</details>


### [360] [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979)
*Qingyu Lu,Liang Ding,Kanjian Zhang,Jinxia Zhang,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文全面评估了扩散型大语言模型（dLLMs）在具身代理和工具调用代理两类任务中的表现，发现其因缺乏时序建模能力和符号精度而难以胜任核心代理角色，但适合作为记忆总结、工具选择等非因果性辅助模块；作者提出DiffuAgent框架，并指出需将因果、精确、逻辑化推理机制融入去噪过程，才能使dLLMs真正适用于代理任务。


<details>
  <summary>Details</summary>
Motivation: 探究扩散型大语言模型（dLLMs）是否真能作为高效且可靠的智能体主干，以突破自回归模型的序列延迟瓶颈。

Method: 在Agentboard和BFCL基准上，系统评测LLaDA、Dream等dLLMs在具身代理（长程规划）与工具调用代理（严格格式要求）两类范式下的行为表现；提出多智能体评估框架DiffuAgent，将dLLMs作为即插即用的认知核心进行模块化测试。

Result: dLLMs在两类代理任务中均表现不佳：（1）具身代理中无法响应时序反馈、反复失败；（2）工具调用中因扩散噪声破坏JSON等符号结构；仅在非因果任务（如记忆摘要、工具选择）中有效。

Conclusion: 当前dLLMs尚不能替代自回归模型作为代理主干；其潜力在于辅助性非因果角色；要实现真正可用的代理能力，必须在去噪过程中显式引入因果性、精确性与逻辑性推理机制。

Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.

</details>


### [361] [ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation](https://arxiv.org/abs/2601.12983)
*Jesus-German Ortiz-Barajas,Jonathan Tonglet,Vivek Gupta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出ChartAttack框架，用于评估多模态大语言模型（MLLMs）在图表生成中被滥用以大规模生成误导性图表的风险，并构建AttackViz数据集验证其有效性，实验表明该攻击显著降低MLLM与人类的图表理解准确率。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs被广泛用于自动图表生成，其潜在的误用风险（如生成误导性图表）亟需系统性评估。

Method: 提出ChartAttack框架，在图表设计中注入误导性元素；构建AttackViz图表问答数据集，包含带标注的误导项及诱导出的错误答案；在域内与跨域设置下评估MLLM读者性能，并开展人类实验验证影响。

Result: ChartAttack使MLLM读者在域内和跨域QA任务中准确率分别下降19.6和14.9个百分点；人类实验显示准确率平均下降20.2个百分点。

Conclusion: 研究揭示了MLLM图表生成系统的安全脆弱性，强调在设计、评估与部署中必须纳入鲁棒性与安全性考量。

Abstract: Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

</details>


### [362] [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995)
*Runxuan Liu,Xianhao Ou,Xinyan Ma,Jiyuan Wang,Jiafeng Liang,Jiaqi Li,Tao He,Zheng Chu,Rongchuan Mu,Zekun Wang,Baoxin Wang,Dayong Wu,Ming Liu,Shijin Wang,Guoping Hu,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出图推理范式（GRP）和过程感知分层裁剪组相对策略优化（PASC-GRPO），通过结构化、符号化的图表示与细粒度认知标签提升大语言模型的推理能力，缓解现有长链思维方法中的语义评估瓶颈、奖励作弊、训练成本高及泛化性差等问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的长链思维方法依赖非结构化文本推理，导致语义评估计算开销大，且存在监督粗粒度、奖励作弊、训练成本高和泛化差等问题。

Method: 提出图推理范式（GRP），用带步骤级认知标签的图结构表示推理过程；在此基础上设计PASC-GRPO算法，利用图结构结果奖励实现过程感知验证，并通过分层裁剪优势估计抑制奖励作弊。

Result: 在数学推理与代码生成任务上显著优于现有方法，验证了结构化推理与新优化算法的有效性。

Conclusion: 结构化、符号化的图推理范式及其配套优化算法能有效提升LLM推理质量与训练效率，为可解释、可验证的AI推理提供了新路径。

Abstract: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

</details>


### [363] [Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context](https://arxiv.org/abs/2601.13018)
*Ghislain Dorian Tchuente Mondjo*

Main category: cs.CL

TL;DR: 本文提出了一种新的多任务模型BiAtt-BiRNN-HateXplain，旨在提升仇恨言论检测的可解释性、稳定性与公平性，通过双向注意力与双向RNN结构增强对序列输入的建模，并在HateXplain数据集上验证了其在检测性能、解释一致性和减少无意偏见方面的改进。


<details>
  <summary>Details</summary>
Motivation: 现有基于HateXplain的多任务模型存在预测注意力波动大、解释不一致、预测不稳定及学习困难等问题；同时，黑盒模型（如大语言模型）虽强大但缺乏透明度，亟需更易解释且兼顾序列特性的轻量级可解释模型。

Method: 提出BiAtt-BiRNN-HateXplain模型：融合双向注意力机制与双向RNN层，实现分类与解释（token-level rationale prediction）的联合多任务学习，显式建模文本序列结构以提升解释稳定性。

Result: 在HateXplain数据集上实验表明，该模型显著提升了仇恨言论检测准确率，增强了注意力解释的一致性与可解释性，并有效降低了对特定社群的无意偏见。

Conclusion: 引入序列建模与稳定注意力机制的多任务框架，可在保证性能的同时提升模型透明度、鲁棒性与公平性，为可信赖的仇恨言论检测提供了新范式。

Abstract: Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.

</details>


### [364] [Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses](https://arxiv.org/abs/2601.13024)
*Chongyuan Dai,Yaling Shen,Jinpeng Hu,Zihan Gao,Jia Li,Yishun Jiang,Yaxiong Wang,Liu Liu,Zongyuan Ge*

Main category: cs.CL

TL;DR: 本文提出了CEDAR多模态基准，用于评估大语言模型在跨文化情感理解方面的能力，发现现有模型在文化对齐方面仍存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注陈述性知识（如地理事实或社会习俗），无法捕捉不同文化背景下主观情感解释的差异。

Method: 提出CEDAR基准，通过LLM生成初步标签筛选出跨文化情感差异明显的样本，并经严格人工评估获得可靠真值标注；基准包含七种语言、14种细粒度情绪类别，共10962个样本。

Result: 对17个代表性多语言模型的全面评估显示，语言一致性与文化对齐之间存在分离现象，表明当前模型在文化驱动的情感理解上仍严重不足。

Conclusion: CEDAR为衡量和提升大语言模型的文化敏感性提供了新工具，凸显了构建真正文化对齐AI系统的必要性与挑战性。

Abstract: Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

</details>


### [365] [SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification](https://arxiv.org/abs/2601.13035)
*Xu Xiaodan,Hu Xiaolin*

Main category: cs.CL

TL;DR: 本文提出SASA框架，通过分离注意力机制和语义感知的对比学习提升知识图谱三元组分类性能，在FB15k-237和YAGO3-10上分别提升准确率5.9%和3.4%。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的三元组分类方法忽略了知识图谱各组件间的有效语义交互，且多采用单一二分类目标，导致语义表征学习不足。

Method: 提出SASA框架：1）分离注意力机制，对三元组进行解耦上下文编码并更有效地融合；2）引入语义感知的分层对比学习作为辅助训练目标，兼顾局部与全局语义学习。

Result: 在FB15k-237和YAGO3-10两个基准数据集上，准确率分别比当前最优方法提升+5.9%和+3.4%。

Conclusion: SASA通过增强语义交互与多层次对比学习，显著提升了三元组分类模型的判别能力与泛化性能。

Abstract: Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\% on FB15k-237 and +3.4\% on YAGO3-10.

</details>


### [366] [Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition](https://arxiv.org/abs/2601.13044)
*Warit Sirichotedumrong,Adisai Na-Thalang,Potsawee Manakul,Pittawat Taveekitworachai,Sittipong Sripaisarnmongkol,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本文提出Typhoon ASR Real-time，一种基于FastConformer-Transducer的低延迟泰语语音识别模型，通过严格的文本归一化和两阶段课程学习，在显著降低计算成本的同时保持高精度，并发布标准化基准数据集以促进可复现研究。


<details>
  <summary>Details</summary>
Motivation: 现有大型离线ASR模型（如Whisper）在泰语语音识别中占主导，但高延迟使其不适用于流式场景，且缺乏高效、可复现的流式泰语ASR方案。

Method: 提出115M参数的FastConformer-Transducer模型；设计针对泰语特有现象（如数字读法、mai yamok重复标记）的文本归一化流程；采用两阶段课程学习进行Isan方言适配；构建并开源Typhoon ASR Benchmark基准数据集。

Result: 该模型相较Whisper Large-v3计算成本降低45倍，性能相当；文本归一化效果媲美模型缩放；成功兼顾Central Thai与Isan方言性能；发布首个符合泰语语言规范的高质量人工标注基准。

Conclusion: 文本归一化与架构优化可有效替代单纯模型放大，在资源受限场景下实现高效、准确、可复现的泰语流式ASR，为小语种低延迟语音识别提供新范式。

Abstract: Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

</details>


### [367] [Profiling German Text Simplification with Interpretable Model-Fingerprints](https://arxiv.org/abs/2601.13050)
*Lars Klöser,Mika Beele,Bodo Kraft*

Main category: cs.CL

TL;DR: 本文提出了一种名为“简化分析器（Simplification Profiler）”的诊断工具，用于生成简化文本的多维可解释指纹，以全面、高效、可复现地评估大语言模型在文本简化任务中的行为特征，尤其适用于数据稀缺的语言场景；该方法通过线性分类器识别不同模型配置生成的简化文本，验证其指纹对模型特性的敏感性，并在F1分数上显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽能生成精细的文本简化结果，但缺乏对其行为进行整体、高效且可复现诊断的工具，尤其在数据稀缺的语言中，为多样化目标群体构建灵活简化模型时问题更突出。

Method: 提出简化分析器，构建多维可解释的简化文本指纹；通过聚合多个简化输出形成模型指纹；采用元评估方式，用简单线性分类器识别不同模型配置（如提示策略、少样本示例等）生成的简化文本，无需大规模人工标注数据。

Result: 完整特征集在模型配置分类任务中达到最高71.9%的F1分数，比简单基线提升超48个百分点；能区分高层行为差异（如提示策略）和细粒度变化（如提示工程细节）。

Conclusion: 简化分析器为开发者提供了细粒度、可操作的分析手段，有助于构建更有效、真正自适应的文本简化系统。

Abstract: While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.

</details>


### [368] [Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs](https://arxiv.org/abs/2601.13099)
*Abdellah El Mekki,Samar M. Magdy,Houdaifa Atou,Ruwa AbuHweidi,Baraah Qawasmeh,Omer Nacar,Thikra Al-hibiri,Razan Saadie,Hamzah Alsayadi,Nadia Ghezaiel Hammouda,Alshima Alkhazimi,Aya Hamod,Al-Yas Al-Ghafri,Wesam El-Sayed,Asila Al sharji,Mohamad Ballout,Anas Belfathi,Karim Ghaddar,Serry Sibaee,Alaa Aoun,Areej Asiri,Lina Abureesh,Ahlam Bashiti,Majdal Yousef,Abdulaziz Hafiz,Yehdih Mohamed,Emira Hamedtou,Brakehe Brahim,Rahaf Alhamouri,Youssef Nafea,Aya El Aatar,Walid Al-Dhabyani,Emhemed Hamed,Sara Shatnawi,Fakhraddin Alwajih,Khalid Elkhidir,Ashwag Alasmari,Abdurrahman Gerrio,Omar Alshahri,AbdelRahim A. Elmadany,Ismail Berrada,Amir Azad Adli Alkathiri,Fadi A Zaraket,Mustafa Jarrar,Yahya Mohamed El Hadj,Hassan Alhuzali,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 本文介绍了Alexandria数据集，一个大规模、社区驱动、人工翻译的阿拉伯语方言机器翻译数据集，覆盖13个阿拉伯国家和11个关键领域，并提供城市级来源标注与性别配置标注，用于训练和评估MT及大语言模型在阿拉伯语多方言翻译中的能力。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有高度的语体差异（diglossia），日常交流多使用地方方言而非标准阿拉伯语，但现有机器翻译系统对方言输入泛化能力差，难以服务数百万使用者。

Method: 构建了名为Alexandria的大规模、人工翻译、多领域、多国家、城市级标注、含性别配置的阿拉伯语方言对话数据集（共107K样本），并开展自动与人工评估以检验当前阿拉伯语感知大模型的方言翻译能力。

Result: Alexandria成为训练与评估阿拉伯语MT和LLM的重要资源；评估揭示了当前模型在跨方言（尤其是子方言）翻译中仍存在显著挑战。

Conclusion: Alexandria填补了高质量、细粒度阿拉伯语方言翻译数据的空白，推动了对真实世界阿拉伯语变体建模的研究，但也凸显了现有模型在方言多样性建模上的不足。

Abstract: Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.

</details>


### [369] [Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification](https://arxiv.org/abs/2601.13105)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: 本研究结合LoRA微调大语言模型与检索增强生成（RAG）框架，自动识别英语双及物结构，在BNC标注数据上取得优于基线模型的二分类性能，且错误分析表明微调提升了语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 提升英语双及物结构自动识别的准确性与语义合理性，克服纯理论RAG或原始大模型在句法-语义接口任务上的局限。

Method: 采用LoRA对Qwen3-8B模型进行微调，并融合RAG框架，构建二分类系统，在英国国家语料库（BNC）标注数据上训练与评估。

Result: LoRA微调的Qwen3-8B显著优于原生Qwen3-MAX和纯理论RAG系统；错误分析显示模型判断从表层形式匹配转向更语义化的理解。

Conclusion: LoRA高效微调结合RAG能有效增强大语言模型对复杂语法构式的语义感知与判别能力，为构式语法计算建模提供新路径。

Abstract: This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

</details>


### [370] [Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137)
*Yuan Gao,Zhigang Liu,Xinyu Yao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种对抗对齐框架，通过持续预训练、指令微调和对抗训练提升大语言模型在敏感领域（如种族、社会、政治）中的价值观一致性，并构建了双语评测数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在敏感领域中存在偏见和价值观不一致问题，亟需提升其价值一致性。

Method: 提出对抗对齐框架，包括持续预训练、指令微调与三角色对抗训练（Attacker生成争议性查询，Actor生成价值观一致回复，Critic过滤并保障回复质量），并构建双语（中英）评测数据集。

Result: 所提出的VC-LLM在中英文测试中均优于现有主流模型，验证了方法的有效性。

Conclusion: 该对抗对齐框架能有效提升大语言模型在敏感领域的价值观一致性，具备实际应用潜力。

Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

</details>


### [371] [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155)
*Zimeng Wu,Donghao Wang,Chaozhe Jin,Jiaxin Chen,Yunhong Wang*

Main category: cs.CL

TL;DR: 本文提出SPTS框架，通过无需训练的自预测令牌跳过技术，在长上下文LLM推理中实现高效加速，兼顾速度与精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于令牌的剪枝和跳过方法存在加速潜力有限、代理信号过时及冗余干扰等问题，导致速度-精度权衡不佳。

Method: 提出SPTS（自预测令牌跳过）框架，包含三部分：1）Partial Attention Probing（PAP）用于多头注意力中选择信息量大的令牌；2）Low-rank Transformation Probing（LTP）用于前馈网络中构建低秩代理网络预测令牌变换；3）Multi-Stage Delayed Pruning（MSDP）跨层逐步裁剪冗余令牌并重分配跳过预算。

Result: 实验表明，SPTS在prefilling和端到端生成阶段分别实现最高2.46×和2.29×加速，同时保持SOTA模型性能。

Conclusion: SPTS是一种训练免费、通用性强的长上下文LLM高效推理方法，显著提升推理效率而不牺牲准确性。

Abstract: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

</details>


### [372] [Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages](https://arxiv.org/abs/2601.13178)
*Joseph Gatto,Parker Seegmiller,Timothy Burdick,Philip Resnik,Roshnik Rahat,Sarah DeLozier,Sarah M. Preum*

Main category: cs.CL

TL;DR: 本文提出了首个大规模公开数据集PMR-Bench，用于研究异步门诊患者门户消息的医学分诊任务，并将该任务建模为成对紧迫性判断问题；提出UrgentSFT和UrgentReward两种新模型，在PMR-Bench上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有医学分诊研究缺乏面向真实异步门诊场景（如患者门户消息）的大规模、高质量、含EHR上下文的公开基准数据集与适配方法。

Method: 将患者消息分诊建模为成对紧迫性比较任务；构建含1569条消息、2000+测试对的PMR-Bench基准；设计基于领域知识的自动化标注策略；训练UrgentSFT（监督微调）和UrgentReward（Bradley-Terry排序学习）两类模型。

Result: UrgentSFT-8B和UrgentReward-8B在收件箱排序指标上分别比同规模通用8B模型提升15和16分；UrgentSFT整体性能最优，UrgentReward在低资源下更具优势。

Conclusion: 成对紧迫性判断是建模门诊消息分诊的有效范式；结合EHR上下文与领域定制化训练目标（如排序学习或SFT）可显著提升LLM在该医疗AI任务中的实用性与鲁棒性。

Abstract: Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

</details>


### [373] [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183)
*Sergio Servantez,Sarah B. Lawsky,Rajiv Jain,Daniel W. Linna,Kristian Hammond*

Main category: cs.CL

TL;DR: 本文提出了OpenExempt框架与基准，用于对法律推理能力进行诊断性评估，通过专家构建的破产法符号表示动态生成自然语言推理任务及可计算答案，支持细粒度、可控的模型能力探测。


<details>
  <summary>Details</summary>
Motivation: 现有法律推理评测基准构建成本高、难以隔离具体失败模式，且静态问答对无法反映模型在复杂规则领域中的真实推理行为。

Method: 设计OpenExempt框架，利用专家编写的美国破产法条文符号表示，动态生成多样化、可验证的自然语言推理任务；据此构建含9765个样本、覆盖9个评测维度的OpenExempt Benchmark，并在13种语言模型上开展诊断性实验。

Result: 实验揭示了模型性能在长推理路径和干扰语句下出现显著断崖式下降，验证了该框架对细粒度推理能力探测的有效性。

Conclusion: OpenExempt为法律推理提供了可扩展、可解释、可复现的诊断评测范式，开源发布以推动下一代推理系统的研究与改进。

Abstract: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

</details>


### [374] [Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision](https://arxiv.org/abs/2601.13217)
*Bingsen Chen,Boyan Li,Ping Nie,Yuyu Zhang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: 本文提出了Mr Dre评估套件，首次将多轮报告修订作为深度研究代理（DRA）的新评估维度，并揭示了现有DRA在根据用户反馈修订报告时普遍存在内容退化和编辑破坏问题，且难以通过提示工程等推理时方法有效缓解。


<details>
  <summary>Details</summary>
Motivation: 现有DRA基准将报告生成视为单次写作任务，与人类研究人员通过多轮自省或同行反馈迭代修订报告的方式不符；DRA能否可靠地依据用户反馈进行多轮修订尚属未知。

Method: 构建了Mr Dre评估套件，包含：（1）覆盖全面性、事实性和呈现质量的统一长篇报告评估协议；（2）基于人工验证的反馈模拟流水线，支持多轮修订评估；并对五种主流DRA进行了系统实证分析。

Result: 发现所有被测DRA在响应用户反馈时均存在16–27%的内容与引用质量退化；多轮修订中持续破坏未被反馈提及的内容，且无法稳定保留先前编辑；提示工程与专用修订子代理等推理时方法效果有限。

Conclusion: 多轮报告修订是评估DRA真实研究能力的关键新维度；当前DRA在编辑稳定性与上下文一致性方面存在根本性缺陷，亟需新的建模机制而非仅靠工程优化。

Abstract: Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

</details>


### [375] [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228)
*Tianqi Du,Lizhe Fang,Weijie Yang,Chenheng Zhang,Zeming Wei,Yifei Wang,Yisen Wang*

Main category: cs.CL

TL;DR: 本文提出Any-order Any-subset Autoregressive modeling (A3)，将扩散模型的灵活性与自回归模型的建模深度结合，通过多组预测和双流注意力架构实现任意顺序、任意子集的生成，在多项任务上优于纯扩散模型。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽具任意顺序生成和双向条件能力，但单步依赖建模限制了深度，导致样本质量与稳定性不如自回归模型。

Method: 提出A3框架，扩展标准自回归分解至任意token组与生成顺序；采用双流注意力架构与渐进式适配策略，使预训练AR模型支持任意顺序预测。

Result: 在问答、常识推理和故事填空任务中，A3优于扩散模型，同时保持灵活解码能力。

Conclusion: A3提供了一种统一、灵活、高效且新颖的语言建模范式，弥合了自回归与扩散模型的优势。

Abstract: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.

</details>


### [376] [Aligning Agentic World Models via Knowledgeable Experience Learning](https://arxiv.org/abs/2601.13247)
*Baochang Ren,Yunzhi Yao,Rui Sun,Shuofei Qiao,Ningyu Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 本文提出WorldMind框架，通过构建符号化世界知识库来解决大语言模型在物理世界模拟中的‘物理幻觉’问题，利用环境反馈实现物理可行性与任务最优性的双重约束，在多个基准上展现出优异的跨模型与跨环境迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽具备丰富语义知识，但缺乏对物理世界规律的程序性理解，导致生成逻辑合理却物理不可行的计划（物理幻觉）；现有对齐方法依赖高成本训练，难以灵活适应开放多变的物理动态。

Method: 提出WorldMind框架，自主构建符号化‘世界知识库’：融合‘过程经验’（基于预测误差约束物理可行性）与‘目标经验’（基于成功轨迹引导任务最优性）。

Result: 在EB-ALFRED和EB-Habitat基准上，WorldMind显著优于基线方法，并展现出强跨模型与跨环境泛化能力。

Conclusion: WorldMind通过非参数化、反馈驱动的方式弥补了LLM与物理世界的模态断层，为构建具身可信的世界模型提供了新范式。

Abstract: Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.

</details>


### [377] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 本文提出了一种大规模语义聚类系统，通过构建高质量三元关系数据集、设计三分类语义关系判别器、以及引入软-硬聚类算法，有效区分同义词与反义词，生成290万个高精度语义簇，提升语义搜索与RAG在形态丰富及低资源语言中的性能。


<details>
  <summary>Details</summary>
Motivation: 神经嵌入难以可靠区分同义词与反义词，导致高相似度阈值下仍易将对立概念错误聚类，现有同义词库在形态丰富和低资源语言中覆盖不足。

Method: 构建84.3万对标注概念对（同义/反义/共下位）数据集；设计宏F1达90%的三路语义关系判别器；提出拓扑感知的两阶段（扩展-剪枝）软到硬聚类算法，结合拓扑投票机制，防止语义漂移与多义性混淆。

Result: 处理1500万词汇项，评估5.2亿潜在关系，生成290万个高精度语义簇；三分类判别器达90%宏F1；聚类结果支持高精度语义搜索与检索增强生成。

Conclusion: 该系统显著提升了语义关系建模的细粒度区分能力，尤其适用于缺乏高质量词汇资源的语言，为语义理解与下游NLP任务提供了可扩展、高鲁棒性的基础资源。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [378] [A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus](https://arxiv.org/abs/2601.13253)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 本文提出了一种混合方法，用于在低资源语言（以土耳其语为例）中大规模构建语义关系数据集，结合FastText聚类、Gemini 2.5-Flash自动分类与词典整合，生成84.3万对高质量语义关系对，显著提升现有资源规模并验证其下游任务有效性。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如土耳其语）在NLP领域语义关系数据稀缺的关键问题。

Method: 采用三阶段混合方法：1）使用FastText嵌入结合凝聚层次聚类发现语义簇；2）利用Gemini 2.5-Flash进行自动化语义关系分类；3）融合人工校验的权威词典资源。

Result: 构建了包含843,000个唯一土耳其语语义对（同义、反义、共下位）的大规模语义关系数据集，规模达现有资源的10倍，成本仅65美元；下游任务中嵌入模型达90% top-1检索准确率，分类模型达90% F1-macro。

Conclusion: 该可扩展协议有效缓解土耳其语NLP的数据瓶颈，并具备向其他低资源语言迁移的潜力；数据集与模型已开源。

Abstract: We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

</details>


### [379] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://arxiv.org/abs/2601.13260)
*Sawsan Alqahtani,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

TL;DR: 本文提出将分词（tokenization）视为大语言模型的核心建模决策，而非预处理步骤，倡导上下文感知的分词器与模型协同设计框架，并强调标准化评估与透明报告的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有子词分词方法（如BPE）虽具可扩展性，但常与语言结构不一致、加剧偏见、跨语言和领域浪费模型容量；分词长期被低估且设计不统一。

Method: 提出一种以语言学、领域及部署需求为指导的上下文感知分词框架，强调分词器与模型的协同设计，并呼吁建立标准化评估与透明报告机制。

Result: 推动将分词从技术附庸提升为核心设计问题，从而促进更公平、高效、适应性强的语言技术发展。

Conclusion: 分词不应是预处理环节，而应作为模型架构中可解释、可评估、可优化的关键组成部分。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [380] [Unlearning in LLMs: Methods, Evaluation, and Open Challenges](https://arxiv.org/abs/2601.13264)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: This survey provides a comprehensive overview of machine unlearning methods for large language models (LLMs), categorizing approaches and evaluating metrics, while identifying key challenges and future directions.


<details>
  <summary>Details</summary>
Motivation: The widespread deployment of LLMs raises concerns about privacy, copyright, security, and bias; machine unlearning offers a way to selectively remove knowledge or data without full retraining.

Method: A structured survey categorizing unlearning methods into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies; reviewing evaluation benchmarks, metrics, and datasets.

Result: A taxonomy of unlearning techniques, an overview of evaluation ecosystems, and identification of open challenges including scalability, formal guarantees, cross-language/multimodal unlearning, and adversarial robustness.

Conclusion: This paper serves as a roadmap for developing reliable and responsible unlearning techniques in LLMs by synthesizing current progress and highlighting critical open problems.

Abstract: Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.

</details>


### [381] [A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification](https://arxiv.org/abs/2601.13288)
*Gonzalo Ariel Meyoyan,Luciano Del Corro*

Main category: cs.CL

TL;DR: 本文提出了一种在大语言模型（LLM）生成过程中复用其隐藏状态进行分类任务（如安全检测、情感分析）的方法，通过轻量级探针（probes）实现单次前向传播中同时完成生成与分类，显著降低延迟、显存占用和系统复杂度。


<details>
  <summary>Details</summary>
Motivation: 生产环境中的大语言模型系统通常依赖独立的安全或分类模型，导致延迟高、显存占用大、运维复杂；本文旨在利用已计算的LLM隐藏状态，避免额外模型开销。

Method: 提出一种两阶段聚合器：（i）在每层内对token隐藏状态进行汇总；（ii）跨层汇总形成统一分类表征；具体实例包括直接池化、10万参数的打分注意力门、以及最多3500万参数的降维多头自注意力（MHA）探针。

Result: 在安全与情感分析基准上，所提探针优于仅复用logits的方法（如MULI），性能媲美更大规模的专用分类模型，同时保持接近服务级延迟，且无需额外VRAM与延迟开销。

Conclusion: 复用LLM隐藏状态并设计轻量、分层聚合的探针，是一种高效、低开销、高性能的端到端分类新范式，适用于生产级LLM系统。

Abstract: Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.

</details>


### [382] [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300)
*Yow-Fu Liou,Yu-Chien Tang,Yu-Hsiang Liu,An-Zi Yen*

Main category: cs.CL

TL;DR: 本文提出了一种名为'选项注入（option injection）'的新型基准测试方法，用于评估大语言模型（LLMs）在多选题问答中对误导性指令信号的鲁棒性，并构建了包含3000道题、覆盖多种指令类型的OI-Bench基准，实验揭示了不同模型在此类干扰下的显著脆弱性和异质鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明LLM决策易受社会线索、表述框架和指令等定向信号影响，而传统基准常忽略此类接口层面的干扰；需一种可扩展、结构化的方法系统评估模型在选择式界面中对误导性指令的敏感性。

Method: 提出'选项注入'方法：在标准多选题中加入一个含误导性定向信号（如社会顺从、威胁 framing 等）的虚假选项；构建OI-Bench基准（3000题，16类指令），并评估12个LLM在攻击成功率、行为响应及多种缓解策略（推理时提示、后训练对齐）下的表现。

Result: 实验显示各LLM普遍存在显著脆弱性，攻击成功率高，且鲁棒性呈现模型间异质性；部分缓解策略（如特定提示工程）仅带来有限提升，凸显对齐与接口设计的挑战。

Conclusion: 选项注入是一种有效揭示LLM在选择式交互中指令鲁棒性缺陷的新范式；OI-Bench为系统评估和提升模型抗定向干扰能力提供了标准化工具和实证基础。

Abstract: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

</details>


### [383] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的端到端主题发现框架，用于比较Meta付费广告与Bluesky公共帖子中的气候话语，揭示平台激励机制如何系统性影响主题结构、立场倾向与时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有计算研究常孤立分析不同平台的气候话语，难以区分机构信息传播与公众表达；需跨平台对比以理解平台结构与激励机制对气候叙事的影响。

Method: 构建基于语义聚类与大语言模型（LLM）生成可解释主题标签的端到端框架，并通过人工评估、LLM评估、立场预测和主题引导检索等多维度验证主题质量。

Result: 发现Meta广告与Bluesky公共帖子在主题分布、立场一致性及对重大政治事件的时间响应上存在系统性差异，印证平台激励机制深刻塑造气候叙事特征。

Conclusion: 平台结构性差异（如付费vs.有机传播）显著影响气候话语的主题组织与传播动态；所提框架可推广至异构传播环境的比较叙事分析。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [384] [Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology](https://arxiv.org/abs/2601.13319)
*Peter Sullivan,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 本文分析了方言阿拉伯语（DA）语音数据集的异质性问题，提出 Arab Voices 框架以统一31个数据集、14种方言，并提供标准化元数据与评估工具，同时为现代DA ASR建立强基线。


<details>
  <summary>Details</summary>
Motivation: 方言阿拉伯语语音数据在领域覆盖、方言标注方式和录音条件上差异巨大，导致跨数据集比较和模型评估困难，亟需超越粗粒度标签的标准化表征方法。

Method: 通过计算分析语言‘方言性’及音频质量客观指标，刻画主流DA语料库训练集的声学与语言特征异质性；设计并发布 Arab Voices 框架，整合31个数据集、14种方言，提供统一接口、协调元数据和评估工具；对多种最新ASR系统进行基准测试。

Result: 发现各DA数据集在声学条件和方言信号强度/一致性方面存在显著异质性；Arab Voices 成功实现多数据集统一接入与标准化；基准测试确立了当前DA ASR的强性能基线。

Conclusion: DA语音数据标准化刻不容缓；Arab Voices 为促进可复现评估、减少碎片化提供了实用框架，推动DA ASR研究向更严谨、可比的方向发展。

Abstract: Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

</details>


### [385] [Reducing Tokenization Premiums for Low-Resource Languages](https://arxiv.org/abs/2601.13328)
*Geoffrey Churchill,Steven Skiena*

Main category: cs.CL

TL;DR: 本文分析了十种流行大模型的分词器，发现低资源语言存在显著的分词开销（tokenization premium），即相比英语需要更多token编码相同语义内容；为此提出一种后置扩展词表的方法，将多token字符合并为单token，有效降低开销，并在12种低资源语言上验证其对Llama 3.2 1B模型隐藏状态影响微小。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在现代大模型中面临显著的tokenization premium，导致API成本、能耗上升及有效上下文窗口缩减，亟需系统分析与优化。

Method: 分析十个主流LM的分词器设计与跨语言tokenization premium；提出一种后置词表扩展机制，将多token字符合并为单token，以压缩输入长度。

Result: 该方法在12种低资源语言上成功降低tokenization premium；压缩前后输入在Llama 3.2 1B模型中产生的最后一层隐藏状态高度相似，表明语义保留良好。

Conclusion: tokenization premium是低资源语言应用大模型的关键瓶颈之一；通过轻量级、后置的词表扩展可显著缓解该问题，且不损害模型语义表征能力。

Abstract: Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.

</details>


### [386] [RegCheck: A tool for automating comparisons between study registrations and papers](https://arxiv.org/abs/2601.13330)
*Jamie Cummins,Beth Clarke,Ian Hussey,Malte Elson*

Main category: cs.CL

TL;DR: 本文介绍了RegCheck，一个基于大语言模型（LLM）的模块化工具，旨在辅助研究人员、审稿人和编辑自动比对研究注册文件与最终发表论文，提升科研透明度与可重复性；其核心设计强调人机协同，由用户定义比对维度，并提供相关文本片段供人工判断，同时支持生成可共享验证的报告。


<details>
  <summary>Details</summary>
Motivation: 研究注册虽被广泛认可有助于提升科研透明度和严谨性，但因人工比对耗时费力、跨格式跨领域难度大，实际中常被忽视，导致注册效果受限。

Method: 提出并设计了RegCheck——一个模块化、LLM驱动的辅助工具，支持用户自定义比对特征、提取并呈现对应文本片段，并生成带唯一ID的可共享报告；强调人在环路（human-in-the-loop），不替代而是增强人工判断。

Result: RegCheck已实现跨学科、跨注册与出版格式的适配能力，提供可扩展的基础设施原型，并通过示例用例验证其在促进可重复科学中的实用性。

Conclusion: RegCheck是一种兼顾灵活性、可解释性与实用性的新型科研诚信支持工具，有望成为推动注册-发表一致性核查与开放科学实践的重要基础设施。

Abstract: Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.

</details>


### [387] [AfroScope: A Framework for Studying the Linguistic Landscape of Africa](https://arxiv.org/abs/2601.13346)
*Sang Yun Kwon,AbdelRahim Elmadany,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 本文提出了AfroScope，一个用于非洲语言识别（LID）的统一框架，包括覆盖713种非洲语言的数据集AfroScope-Data和一系列高性能LID模型AfroScope-Models；针对易混淆语言，提出基于Mirror-Serengeti嵌入模型的分层分类方法，显著提升宏F1分数；并分析了跨语言迁移与领域效应，推动非洲语言数字景观的大规模测量。


<details>
  <summary>Details</summary>
Motivation: 现有非洲语言识别方法在支持语言数量和区分密切相关的语言变体方面仍存在局限。

Method: 构建AfroScope-Data数据集（覆盖713种非洲语言）和AfroScope-Models模型族；针对29种易混淆语言，采用基于Mirror-Serengeti嵌入模型的分层分类方法。

Result: 在易混淆语言子集上，所提分层方法相较最优基线模型提升宏F1达4.55；同时系统分析了跨语言迁移与领域效应。

Conclusion: AfroScope显著提升了非洲语言识别的广度与细粒度能力，为大规模测量非洲数字文本语言分布提供了基础工具，并开源全部数据与模型。

Abstract: Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

</details>


### [388] [Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection](https://arxiv.org/abs/2601.13359)
*Asen Dotsinski,Panagiotis Eustratiadis*

Main category: cs.CL

TL;DR: 本文提出了一种名为'sockpuppetting'的简单高效 jailbreak方法，通过在模型输出开头插入接受性序列（如'Sure, here is how to...'）来绕过安全对齐机制，无需优化且仅需一行代码，攻击成功率显著高于GCG等现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型能力增强，亟需理解其面对恶意提示的脆弱性；现有自动化越狱方法（如GCG）计算开销大、门槛高，需要更简单、低成本的攻击手段以评估真实风险。

Method: 提出'sockpuppetting'方法：在模型生成的助手响应起始处注入固定接受序列，并让模型续写；另设计混合策略——将对抗后缀优化置于助手消息块内而非用户提示中。

Result: sockpuppetting在Qwen3-8B上单提示攻击成功率比GCG高80%；混合策略在Llama-3.1-8B上prompt-agnostic设置下ASR比GCG高64%。

Conclusion: sockpuppetting是一种低门槛、高实效的越狱攻击，揭示了开源模型对输出前缀注入攻击的严重脆弱性，呼吁加强针对此类攻击的防御机制。

Abstract: As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.

</details>


### [389] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

TL;DR: 本文提出一种新方法，通过引入跨步骤注意力机制和隐藏置信度机制来评估大语言模型推理过程中的不确定性，从而提高答案的校准性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在使用链式思维等推理模块时表现优异，但缺乏对推理过程中各步骤不确定性（尤其是时间维度上的置信度传播）的有效评估，易导致整体置信度被高估并引发幻觉。

Method: 提出基于跨步骤注意力（inter-step attention）的语义相关性建模，并设计隐藏置信度机制以保留历史置信信息，将其与逐步置信度融合，生成更准确的整体置信估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上，该方法在负对数似然（NLL）和期望校准误差（ECE）指标上均优于现有最优方法，实现了预测质量与校准性的更好平衡。

Conclusion: 所提方法有效缓解了因忽略置信度时间传播而导致的过度自信问题，提升了大语言模型推理结果的可信度与鲁棒性。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [390] [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387)
*Zhenjiang Mao,Anirudhh Venkat,Artem Bisliouk,Akshat Kothiyal,Sindhura Kumbakonam Subramanian,Saithej Singhu,Ivan Ruchkin*

Main category: cs.CL

TL;DR: 本文提出了一种基于信号时序逻辑（STL）的分步置信度建模方法，用于提升大语言模型在多步推理任务中的置信度估计准确性与校准性。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法将整个推理过程压缩为单一标量分数，忽略置信度在生成过程中的动态变化，易受响应长度等表层因素干扰，难以区分正确推理与自信的错误推理。

Method: 利用信号时序逻辑（STL）刻画推理过程中的逐步置信信号；通过判别式STL挖掘发现能区分正确与错误响应的时序模式；进一步引入参数化超网络为STL模块提供问题敏感的数值参数。

Result: STL模式具有跨任务泛化性，数值参数对具体问题敏感；在多个推理任务上的实验表明，所提方法的置信度评分比基线更校准。

Conclusion: 分步建模置信度演化并结合STL与超网络可显著提升LLM推理置信估计的可靠性与细粒度判别能力。

Abstract: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.

</details>


### [391] [Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction](https://arxiv.org/abs/2601.13388)
*Sasha Ronaghi,Prerit Choudhary,David H Rehkopf,Bryant Lin*

Main category: cs.CL

TL;DR: 本研究利用大语言模型（LLM）从老年2型糖尿病患者的非结构化生活叙事中提取社会健康决定因素（SDOH）信息，生成可用于临床解读的定性摘要和用于风险预测的定量SDOH评分，并验证其对血糖控制水平的预测价值。


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素（SDOH）对2型糖尿病管理至关重要，但常缺失于电子病历和风险预测模型中；现有结构化筛查工具难以灵活、全面反映患者真实社会经历与需求。

Method: 收集65名≥65岁T2D患者的非结构化生活叙事访谈；采用检索增强生成（RAG）的LLM提取定性摘要与结构化SDOH评分；将评分单独或联合实验室指标输入多种机器学习模型（Ridge、Lasso、Random Forest、XGBoost）预测糖尿病控制；另用LLM直接基于脱敏访谈文本预测A1C分层（低/中/高）。

Result: LLM成功生成临床可用的定性摘要与结构化SDOH评分；结合SDOH评分可提升传统风险模型性能；LLM直接从文本预测糖尿病控制水平达60%准确率。

Conclusion: LLM能有效将非结构化SDOH叙事转化为结构化、可量化的临床洞察，为规模化增强风险预测与临床决策提供新路径。

Abstract: Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

</details>


### [392] [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392)
*Shlok Shelat,Jay Raval,Souvik Roy,Manas Gaur*

Main category: cs.CL

TL;DR: 本文提出了一种用于评估大语言模型（LLMs）在确定性有限自动机（DFA）构建任务中形式化推理能力的新基准，发现模型在已见任务上表现良好，但在未见、结构复杂的问题上出现系统性失败，揭示了其在语义正确性上的根本局限。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在形式语言任务中的表现究竟是源于真正的符号推理能力，还是仅依赖对熟悉模式的匹配。

Method: 构建了一个包含事实性问题、已见构造题和两类未见问题（手工设计多约束实例与基于Arden定理系统生成）的DFA构造基准，并结合多种提示策略（直接提示、思维链、树状思维）及三阶段提示纠错协议进行评估。

Result: 模型在事实性问题上准确率达100%，已见构造任务达84–90%，但在未见问题上准确率骤降30–64%；错误主要表现为对语言约束的系统性误读、Kleene星号语义处理错误及全局一致性缺失；三阶段提示可修正浅层错误，但无法可靠修复结构性或全局不一致的自动机。

Conclusion: LLMs能生成语法上看似合理的DFA，却缺乏可靠的语义正确形式推理能力，暴露了其在符号推理本质上的根本缺陷。

Abstract: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.

</details>


### [393] [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433)
*Priyanka Mary Mammen,Emil Joswin,Shankar Venkitachalam*

Main category: cs.CL

TL;DR: 本文研究了语言模型在推理任务中对不同权威性来源的背书（endorsement）的敏感性，发现模型存在‘权威偏差’：当高权威来源提供错误背书时，模型不仅更可能出错，且对错误答案置信度更高；该偏差具有内在机制基础，且可通过干预缓解。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型的推理性能受提示、暗示和背书影响，但背书来源的可信度（尤其是专业权威性）如何系统性影响模型行为尚不明确。

Method: 在数学、法律、医学四大推理数据集上，使用11个语言模型，设计代表各领域四个专业等级的‘角色’（personas）作为背书来源，系统评估模型对正确与错误背书的响应；并通过机制分析与干预实验验证偏差的内在性与可修正性。

Result: 模型表现出显著的权威偏差——随着背书者专业等级升高，其错误背书导致模型准确率下降更明显，且模型对错误答案的置信度反而上升；该偏差被证实是模型内部机制编码的，并可通过特定引导策略有效缓解。

Conclusion: 语言模型存在内生的权威偏差，这构成其推理鲁棒性的重要隐患；理解并校正此类社会性启发式偏差，对提升模型在关键领域（如医疗、法律）的可靠性至关重要。

Abstract: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.

</details>


### [394] [MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization](https://arxiv.org/abs/2601.13437)
*Adriana-Valentina Costache,Daria-Nicoleta Dragomir,Silviu-Florin Gheorghe,Eduard Poesina,Paul Irofti,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 本文提出了首个面向文本主题分类的多语言开放集学习与发现（MOSLD）基准数据集（含12种语言、96万样本），并设计了一个支持持续发现与学习新类别的多阶段框架，为文本领域的OSLD任务提供了新基准和基线方法。


<details>
  <summary>Details</summary>
Motivation: 开放集学习与发现（OSLD）在文本领域尚属新兴任务，缺乏标准化多语言基准和有效方法，而零样本学习已有较多研究；亟需构建真实、可扩展的多语言OSLD评测平台以推动该方向发展。

Method: （1）构建MOSLD多语言基准：整合现有数据集并新增新闻领域语料，覆盖12种语言共96万样本；（2）提出端到端多阶段OSLD框架，支持新类别的持续发现与增量学习；（3）系统评估多种语言模型（含自研模型）性能。

Result: 发布了首个公开、多语言、大规模的OSLD文本分类基准MOSLD-Bench，并在该基准上给出了多个语言模型的基线结果，验证了所提框架的有效性与可扩展性。

Conclusion: MOSLD-Bench填补了文本OSLD领域缺乏多语言基准的空白，所提框架为开放世界文本分类提供了可行技术路径，开源资源将促进该方向后续研究。

Abstract: Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.

</details>


### [395] [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453)
*Aditya Thole,Anmol Agrawal,Arnav Ramamoorthy,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文提出PhysicsSolutionAgent（PSA），一个能自动生成长达6分钟Manim动画视频以解释物理问题的自主代理，并设计了含15项量化指标与视觉语言模型反馈的评估流程；实验表明其在32个问题上完成率达100%，但存在布局不一致、视觉内容误解读等关键缺陷，揭示了多模态物理教学系统中视觉理解与评估的深层挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽擅于文本形式的物理问题求解，但在生成高质量、长时长可视化解释方面能力不足，而清晰的视觉推理对物理概念理解至关重要。

Method: 提出PhysicsSolutionAgent（PSA）代理，利用Manim生成物理问题解释视频；构建融合15项自动量化指标与视觉语言模型（VLM）反馈的迭代评估流水线。

Result: 在32个数值与理论物理问题上，PSA（基于GPT-5-mini）实现100%视频完成率，平均自动评分为3.8/5；但人工评估发现视觉布局不一致、VLM反馈中视觉内容误解读等显著问题。

Conclusion: 当前多模态代理在可靠生成Manim代码及视觉推理方面存在关键局限，亟需提升视觉理解能力、代码验证机制与更鲁棒的多模态评估框架。

Abstract: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

</details>


### [396] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: 本文提出Anonpsy框架，通过语义图引导的重写方法实现精神科叙事文本的去标识化，在保持临床诊断准确性的同时显著降低再识别风险。


<details>
  <summary>Details</summary>
Motivation: 现有去标识化方法（如PHI掩码和大语言模型合成重写）仅在文本层面操作，对语义元素的保留与修改缺乏可控性，难以兼顾隐私保护与临床信息完整性。

Method: Anonpsy将精神科叙事转化为语义图（含临床实体、时间锚点和类型化关系），在图结构约束下进行扰动以修改识别性上下文但保留关键临床结构，并通过图条件化的大语言模型生成去标识化文本。

Result: 在90份临床医生撰写的精神科病例上评估显示，Anonpsy在保持诊断保真度的同时，专家、语义及GPT-5评估下的再识别风险均显著低于强LLM基线方法。

Conclusion: 显式的结构化表征结合受控生成是精神科叙事去标识化的有效路径。

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [397] [When Wording Steers the Evaluation: Framing Bias in LLM judges](https://arxiv.org/abs/2601.13537)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Minwoo Lee,Kyomin Jung*

Main category: cs.CL

TL;DR: 本文研究了提示词表述（即'框架效应'）对大语言模型（LLM）在评估任务中判断稳定性与公正性的影响，发现不同措辞会导致显著偏差，表明当前LLM评估系统存在结构性的框架偏差。


<details>
  <summary>Details</summary>
Motivation: LLM在评估任务中应保持稳定和公正的判断，但其输出易受提示词细微变化影响；这种类似心理学中‘框架效应’的现象在LLM评估中的影响尚未被系统研究。

Method: 受心理学框架效应启发，设计四类高风险评估任务，采用谓词肯定与谓词否定形式的对称提示进行系统实验，并在14个LLM裁判模型上测试其判断一致性。

Result: 所有14个LLM裁判均表现出显著的框架偏差，不同模型家族在倾向‘同意’或‘拒绝’上呈现明显差异。

Conclusion: 框架偏差是当前LLM评估系统的结构性缺陷，亟需引入框架感知（framing-aware）的评估协议以提升可靠性。

Abstract: Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.

</details>


### [398] [HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations](https://arxiv.org/abs/2601.13547)
*Yujia Hu,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本文提出了HateXScore，一个用于评估仇恨言论检测模型解释质量的四组件指标套件，旨在揭示标准指标无法发现的可解释性缺陷和标注不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测的评估框架很少评估文本为何被视为仇恨言论，缺乏对模型解释质量的深入评估。

Method: 提出了HateXScore指标套件，包含四个组件：结论明确性、引用片段的保真度与因果依据、受保护群体识别（策略可配置）、各要素间的逻辑一致性，并在六个不同数据集上进行评估。

Result: HateXScore能有效揭示标准指标（如准确率或F1）无法发现的可解释性失败和标注不一致问题，且人类评估显示其具有高一致性。

Conclusion: HateXScore是一种实用、可信且透明的内容审核辅助工具，可作为传统评估指标的诊断补充。

Abstract: Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.
  \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

</details>


### [399] [Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews](https://arxiv.org/abs/2601.13575)
*Thanh-Lam T. Nguyen,Ngoc-Quang Le,Quoc-Trung Phu,Thi-Phuong Le,Ngoc-Huyen Pham,Phuong-Nguyen Nguyen,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: 本文提出SUDO数据集，用于从同一用户撰写的多篇评论中挖掘隐式比较观点，以推断用户偏好，并通过两类基线模型验证其挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有比较观点挖掘研究主要集中于显式比较表达，而现实中更常见的是隐式比较（即用户在不同评论中表达偏好），该问题尚未被充分探索。

Method: 构建了名为SUDO的新型隐式比较观点挖掘数据集，包含4150对同一用户的标注评论（共15191句），具有面向方面提及和面向评论偏好的双层结构；并采用传统机器学习与语言模型两类基线方法进行基准测试。

Result: 语言模型基线优于传统机器学习基线，但整体性能仍处于中等水平，表明该任务具有本质难度。

Conclusion: SUDO是一个具有挑战性和实用价值的新基准，为未来隐式比较观点挖掘研究提供了重要支撑。

Abstract: Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.

</details>


### [400] [TREX: Tokenizer Regression for Optimal Data Mixture](https://arxiv.org/abs/2601.13588)
*Inho Won,Hangyeol Yoo,Minkyung Cho,Jungyeul Park,Hoyun Song,KyungTae Lim*

Main category: cs.CL

TL;DR: 本文提出TREX框架，通过回归模型预测多语言分词器训练的最优数据混合比例，避免了传统方法中依赖启发式或大规模搜索的高成本问题，在压缩效率上显著优于LLaMA3和均匀分布基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在确定多语言分词器训练的数据语言比例时依赖启发式或昂贵的大规模搜索，难以兼顾精度与成本。

Method: TREX构建小规模代理分词器，在随机数据混合上训练并收集压缩统计量，训练回归模型以预测不同混合比例下的压缩性能，从而指导大规模分词器训练前的高效混合搜索。

Result: 基于TREX预测混合比例训练的分词器，在分布内和分布外压缩效率上比LLaMA3和均匀混合提升最多达12%。

Conclusion: TREX有效缓解了多语言分词器设计中精度与成本的权衡问题，具备良好的可扩展性、鲁棒性和实用效果。

Abstract: Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.

</details>


### [401] [Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions](https://arxiv.org/abs/2601.13590)
*Fan Huang,Haewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 本文系统评估了大型语言模型（LLMs）在SMCR传播框架下对说服的易感性，发现小模型极易被说服，元认知提示反而加剧信念崩塌，对抗微调对不同模型效果差异显著，揭示当前鲁棒性干预存在模型依赖性局限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在问答任务中广泛应用，但近期研究表明其易受说服影响并采纳反事实信念，亟需系统评估其信念稳定性与抗说服能力。

Method: 基于Source-Message-Channel-Receiver（SMCR）传播框架，在五个主流LLM上，跨事实知识、医学问答和社会偏见三个领域，分析不同说服策略对多轮交互中信念稳定性的影响；引入元认知提示（自报置信度）测试其对说服抵抗的作用；并评估对抗微调作为防御手段的有效性。

Result: 小模型表现出极端顺从性（80%以上信念变化发生在首轮说服，平均终止轮次1.1–1.4）；元认知提示非但未增强鲁棒性，反而加速信念崩塌；对抗微调对GPT-4o-mini（98.6%鲁棒）和Mistral 7B（35.7%→79.3%）效果显著，但Llama系列即使在自身失败案例上微调仍高度易感（<14%）。

Conclusion: 当前LLM的抗说服能力存在显著模型依赖性，鲁棒性干预措施效果不一，需针对模型架构特性设计更可信的改进路径。

Abstract: Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

</details>


### [402] [CauScientist: Teaching LLMs to Respect Data for Causal Discovery](https://arxiv.org/abs/2601.13614)
*Bo Peng,Sirui Chen,Lei Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: 本文提出CauScientist框架，结合大语言模型（LLM）生成假设与统计方法验证因果结构，显著提升因果发现性能。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法存在局限：纯数据驱动方法受统计不可分辨性和建模假设限制；基于LLM的方法则忽略统计证据或引入未经验证的先验，易导致错误结果。

Method: CauScientist采用协作框架：LLM作为‘数据科学家’生成假设，概率统计作为‘验证者’进行严格检验；通过混合初始化选取优质起始图，迭代式地由LLM提议结构修改并经统计准则验证，同时利用误差记忆引导高效搜索。

Result: 实验表明，CauScientist大幅超越纯数据驱动基线，F1分数最高提升53.8%，召回率从35.0%提升至100.0%；在37节点图上，相比Qwen3-32B，结构汉明距离（SHD）降低44.0%。

Conclusion: 融合LLM的假设生成能力与统计验证的严谨性，可有效克服各自短板，实现更鲁棒、可解释且高性能的因果发现。

Abstract: Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating "data scientists" with probabilistic statistics as rigorous "verifiers". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.

</details>


### [403] [Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models](https://arxiv.org/abs/2601.13630)
*Zhaopeng Zhang,Pengcheng Sun,Lan Zhang,Chen Tang,Jiewei Lai,Yunhao Wang,Hui Jin*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的激活空间锚定访问控制（AAAC）框架，利用LLM中间激活的几何可分性实现细粒度权限控制，显著降低权限违规率和攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识库问答中可能超出用户权限范围回答问题，导致敏感信息泄露，难以满足细粒度访问控制需求。

Method: 发现同一查询在不同权限范围下中间激活呈现几何聚类可分性，据此构建无需训练的AAAC框架：通过离线小样本建立每类权限对应的激活空间锚点，并在推理时采用多锚点引导机制将查询激活导向授权区域。

Result: 在三类LLM上实验表明，AAAC将权限违规率最高降低86.5%，提示攻击成功率降低90.7%，同时提升响应可用性且仅引入轻微推理开销。

Conclusion: AAAC是一种高效、轻量、无需微调的权限控制新范式，为知识库问答系统在安全敏感场景下的部署提供了可行方案。

Abstract: Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

</details>


### [404] [Towards Token-Level Text Anomaly Detection](https://arxiv.org/abs/2601.13644)
*Yang Cao,Bicheng Yu,Sikun Yang,Ming Liu,Yujiu Yang*

Main category: cs.CL

TL;DR: 本文提出了token-level异常检测的新范式，实现了文本内异常位置的细粒度定位，并构建了三个带token级标注的基准数据集，实验表明所提框架性能优于6个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测方法仅限于文档级分析，无法识别文本中具体哪些部分存在异常。

Method: 正式定义了文档级和token级的文本异常，并提出一个跨多层级的统一检测框架；同时构建了三个涵盖垃圾邮件、评论和语法错误的token级标注基准数据集。

Result: 所提框架在多个数据集上性能优于6个基线方法，验证了token级异常检测的有效性。

Conclusion: token-level异常检测为文本异常的精确定位提供了新思路，推动了该领域向更细粒度方向发展。

Abstract: Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.

</details>


### [405] [Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge](https://arxiv.org/abs/2601.13649)
*Xiaolin Zhou,Zheng Luo,Yicheng Gao,Qixuan Chen,Xiyang Hu,Yue Zhao,Ruishan Liu*

Main category: cs.CL

TL;DR: 本文研究了LLM-as-a-judge在多语言场景下的语言偏见问题，发现其在同语种和跨语种判断中均存在显著偏见，尤其偏向英语及欧洲语言，并指出该偏见不能仅由低困惑度偏差解释。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge存在与人类偏好不一致的语言偏见，需系统分析其表现形式与成因。

Method: 通过设计两类实验——同语言配对判断与跨语言配对判断——评估主流LLM在不同语言（尤其是欧洲与非洲语言）上的判断一致性与偏好；并检验语言偏见与模型困惑度之间的相关性。

Result: 1）同语言判断中，欧洲语言显著优于非洲语言，文化相关主题上偏见更明显；2）跨语言判断中，模型普遍偏好英语回答，且受答案语言影响大于问题语言；3）语言偏见与困惑度仅有弱相关，不能被其单独解释。

Conclusion: LLM-as-a-judge存在结构性语言偏见，需在评估框架与模型训练中引入语言公平性考量，不能简单归因于低困惑度偏差。

Abstract: Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

</details>


### [406] [Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation](https://arxiv.org/abs/2601.13658)
*Arthur Amalvy,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 本文提出了一种用于时序知识图谱抽取（TKGE）的新型合成评估数据集，通过时序知识图谱预测（TKGF）生成未来事实，并利用大语言模型（LLM）生成对应文本描述，从而避免训练-测试数据污染问题；实验表明，现有先进TKGE方法在该无污染数据集上性能显著下降，验证了其有效性与挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有TKGE数据集稀缺且存在训练-测试数据污染问题，导致LLM性能被高估，亟需构建无污染、面向未来的可靠评估基准。

Method: 采用两步法构建合成评估数据集：（1）利用时序知识图谱预测（TKGF）生成未来四元组，并按原始知识库模式过滤；（2）使用LLM将四元组转化为语义对齐的自然语言文本。

Result: 在新构建的4.2K未来事实数据集上，当前最优LLM-based抽取框架EDC性能明显下降，证实了现有方法在真正未见时序事实上的泛化能力不足；数据集及生成方法已开源。

Conclusion: 所提合成数据集有效消除了数据污染，为TKGE提供了长期、可扩展、无偏倚的评估基准，揭示了当前LLM在时序知识抽取中的真实局限性。

Abstract: The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.

</details>


### [407] [Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis](https://arxiv.org/abs/2601.13659)
*Chunlei Meng,Ziyang Zhou,Lucas He,Xiaojing Du,Chun Ouyang,Zhongxue Gan*

Main category: cs.CL

TL;DR: 本文提出TSDA方法，通过在跨模态交互前显式解耦各模态的时间动态与空间结构信息，并分别对齐时间特征与空间特征，辅以因子一致性对齐、因子特异性监督与去相关正则化，最终通过门控重耦模块完成任务，显著提升多模态情感分析性能。


<details>
  <summary>Details</summary>
Motivation: 现有主流多模态情感分析方法依赖时空混合建模，忽视了时空异质性，导致时空信息不对称和性能受限。

Method: 提出TSDA（Temporal-Spatial Decouple before Act）框架：对每种模态分别使用时间编码器和空间编码器解耦为时间流与空间流；通过因子一致的跨模态对齐实现时间-时间、空间-空间特征匹配；引入因子特异性监督和去相关正则化抑制因子间泄露；最后用门控重耦模块融合对齐后的双流进行下游任务。

Result: TSDA在多个基准数据集上超越现有基线方法；消融实验验证了各模块设计的必要性与可解释性。

Conclusion: 显式解耦并分别建模时空因素能有效缓解多模态情感分析中的时空信息不对称问题，提升模型性能与可解释性。

Abstract: Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.

</details>


### [408] [CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks](https://arxiv.org/abs/2601.13669)
*Jiayu Lin,Zhongyu Wei*

Main category: cs.CL

TL;DR: 本文提出社区级对齐作为大语言模型对齐的中间路径，既避免了统一价值假设对少数群体的边缘化，又克服了个体级对齐的高昂成本；为此构建首个大规模社区级对齐评测基准CommunityBench，并验证现有LLM在建模社区特异性偏好上的不足，同时探索其对个体建模的可扩展性与多元性价值。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法存在两极：统一价值假设（忽视少数群体）和个体定制（成本过高）；而人类社会天然以具有高内部价值一致性的社会集群（社区）组织，因此需探索社区级对齐这一更合理、可扩展的中间路径。

Method: 提出社区级对齐范式；构建首个社区级对齐评测基准CommunityBench，涵盖基于共同身份与共同纽带理论的四大任务；在该基准上系统评测多种基础模型，并探究社区级对齐对个体建模的支撑潜力。

Result: 当前主流大语言模型在CommunityBench上表现出对社区特异性偏好的建模能力有限；社区级对齐可作为高效、多元的桥梁，助力更可扩展的个体级对齐。

Conclusion: 社区级对齐是兼顾包容性与可行性的新范式，CommunityBench为该方向提供了关键评估工具，推动大语言模型向更公平、可扩展、多元的价值对齐演进。

Abstract: Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.

</details>


### [409] [HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference](https://arxiv.org/abs/2601.13684)
*Zhiyuan Shi,Qibo Qiu,Feng Xue,Zhonglin Jiang,Li Yu,Jian Jiang,Xiaofei He,Wenxiao Wang*

Main category: cs.CL

TL;DR: 本文提出HeteroCache，一种无需训练的动态KV缓存压缩框架，通过细粒度头部分类与加权、异步按需检索，有效缓解长上下文LLM推理中线性内存增长与I/O开销问题，显著提升吞吐并达SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法难以兼顾全局重要信息保留与低I/O开销：静态方法忽略注意力漂移导致信息丢失；动态方法则因粗粒度缓存策略和频繁数据传输带来高开销。

Method: 基于注意力头的时间异质性与层内空间冗余性两大洞见，HeteroCache对注意力头进行稳定性与冗余度分类，实施细粒度缓存预算分配，并采用分层存储机制——由代表性头监控注意力变化，异步触发CPU端按需上下文检索以隐藏I/O延迟。

Result: 在多个长上下文基准上达到SOTA性能，在224K上下文下解码速度最高提升3倍。

Conclusion: HeteroCache是一种高效、免训练的动态缓存压缩方案，能自适应捕捉注意力动态变化，在保证精度的同时显著降低内存与I/O瓶颈，适用于实际长上下文LLM部署。

Abstract: The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

</details>


### [410] [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690)
*Yue Guo,Fanfu Wang,Jianwei Lv,Xincheng Shi,Yuchen Li,Youya Wang,Yunsheng Zeng,Yujing Liu,Yunhao Qiao,Gen Li,Junfeng Wang,Bo Yuan*

Main category: cs.CL

TL;DR: 本文提出了一种新的临床诊断推理数据结构（CDRD）和名为Dr. Assistant的临床诊断模型，通过两阶段训练（SFT+RL）提升诊断推理与问诊能力，并构建了相应评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有临床决策支持系统（CDSSs）维护成本高、泛化能力弱；大语言模型（LLMs）虽在医疗任务中表现良好，但在诊断推理和问诊技能上仍受限。

Method: 提出CDRD数据结构及构建流程；设计Dr. Assistant模型，采用监督微调（SFT）加带定制奖励函数的强化学习（RL）进行两阶段训练；构建涵盖诊断推理与问诊能力的评测基准。

Result: Dr. Assistant在实验中优于主流开源模型，性能媲美闭源模型，在临床诊断问诊指导方面展现出有效性。

Conclusion: CDRD结构与Dr. Assistant模型为提升LLM在真实临床场景中的诊断推理与交互问诊能力提供了可行且有效的技术路径。

Abstract: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

</details>


### [411] [OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens](https://arxiv.org/abs/2601.13695)
*Sifan Li,Hongkai Chen,Yujun Cai,Liyang Chen,Qingwen Ye,Yiwei Wang*

Main category: cs.CL

TL;DR: 本文提出OptiSQL，一种基于视觉的框架，直接从表格图像和自然语言问题生成可执行SQL，使用紧凑的光学标记，显著减少输入token数量并保持高执行准确率。


<details>
  <summary>Details</summary>
Motivation: 现有text-to-SQL方法依赖线性化文本模式，token开销大，且不适用于文档或网页中以视觉形式存在的表格。

Method: OptiSQL采用OCR导向的视觉编码器将表格结构与内容压缩为少量光学token，并冻结编码器、微调预训练解码器以生成SQL。

Result: 在可视化Spider 2.0-Snow数据集上，OptiSQL保持强执行准确率，同时将表格输入token减少一个数量级；鲁棒性分析表明光学token在视觉扰动下仍保留关键结构信息。

Conclusion: 紧凑的光学表示可作为高效、鲁棒的语义解析接口，为视觉驱动的SQL生成提供了新范式。

Abstract: Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

</details>


### [412] [Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning](https://arxiv.org/abs/2601.13697)
*Zhihang Yuan,Chengyu Yue,Long Huang,Litu Ou,Lei Shi*

Main category: cs.CL

TL;DR: 本文提出了一种名为GRADFILTERING的不确定性感知数据选择框架，用于指令微调中的高效数据筛选，通过小规模GPT-2代理与LoRA集成计算梯度信噪比（G-SNR）作为样本效用指标，在多项评估中优于随机采样及强基线方法，并加速模型收敛。


<details>
  <summary>Details</summary>
Motivation: 现代指令数据集规模大、噪声多、冗余高，全量微调成本高且不必要；现有数据选择方法忽视模型训练过程中动态变化的不确定性，错失LLM可解释性的重要来源。

Method: 提出GRADFILTERING框架：使用小型GPT-2模型配合LoRA参数高效集成，对每个样本计算梯度并聚合为梯度信噪比（G-SNR）作为不确定性感知的效用指标，实现目标无关的数据筛选。

Result: 在LLM-as-a-judge评估和人工评估中，GRADFILTERING筛选的子集性能匹配或超越随机子集及强基线；在相同计算预算下，其筛选数据使模型收敛更快。

Conclusion: 不确定性感知的数据选择不仅提升微调效率与效果，还增强了对LLM训练动态的理解，GRADFILTERING为轻量、高效、可解释的指令微调提供了新范式。

Abstract: Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.

</details>


### [413] [GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711)
*Lotta Kiefer,Christoph Leiter,Sotaro Takeshita,Elena Schmidt,Steffen Eger*

Main category: cs.CL

TL;DR: 本文介绍了GerAV，一个用于德语作者身份验证（AV）的大规模基准数据集，包含超过60万标注文本对，并基于该数据集对多种模型进行了系统评估，发现微调的大语言模型表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有作者身份验证研究主要集中于英语，缺乏针对其他语言（尤其是德语）的大规模基准和系统性评估。

Method: 构建了基于Twitter和Reddit数据的德语AV基准GerAV，包含多种子集（如领域内、跨领域、基于个人资料），并系统评估了多种基线及SOTA模型（包括微调大模型和零样本GPT-5）。

Result: 微调大语言模型在F1分数上比近期基线高0.09，零样本下优于GPT-5达0.08；发现模型在特定数据上训练效果好但泛化能力弱，融合多源训练可缓解该问题。

Conclusion: GerAV填补了德语AV基准的空白，提供了兼具挑战性与多样性的评测平台，推动德语及跨域作者身份验证研究。

Abstract: Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.

</details>


### [414] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

TL;DR: 本文系统检验了Simulated Ignorance（SI）是否能可靠模拟True Ignorance（TI）以支持LLM预测能力的回溯评估，结果表明SI存在系统性失效，无法有效抑制模型先验知识，因此不推荐用基于SI的回溯设置来评测预测能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLM预测能力评估中前瞻性评估耗时过长、而回溯预测（RF）因模型知识截止日期不断更新导致可用干净测试数据迅速枯竭的矛盾。

Method: 在477个竞赛级问题和9个模型上，首次系统比较Simulated Ignorance（SI）与True Ignorance（TI）的表现，分析提示指令、思维链推理及模型架构对知识抑制效果的影响。

Result: 发现SI存在三大系统性缺陷：（1）截止指令导致SI与TI间存在52%性能差距；（2）思维链推理无法有效抑制先验知识，即使推理过程未显式引用截止后信息；（3）推理优化模型在SI下保真度更差。

Conclusion: 提示词无法可靠‘倒带’模型知识，基于SI的回溯评估方法在方法论上不可靠，应避免用于预测能力基准测试。

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [415] [OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents](https://arxiv.org/abs/2601.13722)
*Yulin Hu,Zimo Long,Jiahe Guo,Xingyu Sui,Xing Fu,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出过个性化（over-personalization）问题，定义其三类表现（无关性、重复性、谄媚性），构建OP-Bench基准并发现现有记忆增强对话系统普遍存在该问题；为此设计轻量、模型无关的Self-ReCheck记忆过滤机制，在抑制过个性化的同时保持个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有记忆增强对话代理评测仅关注能否回忆用户信息，忽视个性化使用是否恰当，导致过个性化（如强迫感、侵入感、社交不适）问题被忽略。

Method: 形式化定义过个性化为三类（Irrelevance, Repetition, Sycophancy），构建含1700个实例的OP-Bench基准；评估多种大语言模型与记忆增强方法；提出Self-ReCheck记忆过滤机制。

Result: 实验证明过个性化在引入记忆后广泛存在，代理倾向于不必要地检索和过度关注用户记忆；Self-ReCheck可有效缓解该问题且不损害个性化性能。

Conclusion: 过个性化是记忆增强对话系统中亟需关注的关键问题；OP-Bench为评测提供新维度；Self-ReCheck为实现可控、得体的个性化提供了可行路径。

Abstract: Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

</details>


### [416] [On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation](https://arxiv.org/abs/2601.13729)
*Weichuan Wang,Mingyang Liu,Linqi Song,Chen Ma*

Main category: cs.CL

TL;DR: 本文系统评估了现代机器翻译（MT）系统中的非确定性现象（ND-MT），发现其在解决多模态问题上优于确定性MT（D-MT），但也带来新的评估挑战：传统评估框架不适用，且存在‘Buckets效应’——最低质量候选译文主导系统排序；为此提出ExpectoSample策略以自动评估指标可靠性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的非确定性特性在实际应用中影响显著，但在机器翻译这一复杂非确定性任务中尚未被充分研究。

Method: 系统评估现代MT系统，定义温度约束下的非确定性MT（ND-MT）；在三个公开数据集上，用词法与语义两类指标、不同采样规模评测五个SOTA ND-MT系统；观察评估结果的一致性并分析‘Buckets效应’；提出ExpectoSample策略评估指标可靠性。

Result: 发现ND-MT能有效缓解MT多模态问题，生成更高质量候选译文；但D-MT评估框架在ND-MT上失效；普遍存在‘Buckets效应’——最低质量候选译文决定整体系统排名；ExpectoSample可识别鲁棒评估指标。

Conclusion: ND-MT是MT中值得重视的新范式，需构建适配其非确定特性的新评估体系，ExpectoSample为指标选择提供了自动化判据。

Abstract: In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

</details>


### [417] [Towards robust long-context understanding of large language model via active recap learning](https://arxiv.org/abs/2601.13734)
*Chenyu Hui*

Main category: cs.CL

TL;DR: 本文提出了主动回顾学习（ARL）框架，通过持续预训练中的目标序列构建和推理时的回溯性摘要，增强大语言模型对长上下文的理解能力。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型（LLM）对长上下文的理解能力，解决其在处理长文本时的记忆与连贯性瓶颈。

Method: ARL包含两步：1）基于长/短上下文损失差异识别关键token及最相关前序段落，并用LLM生成摘要；2）使模型在推理中自主生成并利用这些回溯摘要，构建跨段落的递归记忆机制。

Result: 在RULER上提升26.8%，在LongBench上提升9.44%。

Conclusion: ARL是一种简单而有效的基于持续预训练的长上下文理解增强方法，推动了LLM可扩展记忆增强的发展。

Abstract: In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

</details>


### [418] [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742)
*Arjun Chandra,Kevin Miller,Venkatesh Ravichandran,Constantinos Papayiannis,Venkatesh Saligrama*

Main category: cs.CL

TL;DR: 本文提出TRACE框架，使大语言模型（LLM）能基于音频线索进行文本化推理，实现低成本、高人类一致性语音到语音（S2S）评估。通过引入人类链式思维（HCoT）标注协议，将评估解耦为内容、语音质量和副语言三个维度，并用轻量音频信号生成文本蓝图供LLM判断，最终融合为整体评分。TRACE在人类一致性上超越音频语言模型（ALMs）和纯文本LLM判别器，且成本显著更低。


<details>
  <summary>Details</summary>
Motivation: 现有S2S自动评估依赖黑盒、昂贵的音频语言模型（ALMs），而大语言模型（LLM）虽具强推理能力，却仅限于文本输入，无法直接处理音频；亟需一种低成本、可解释、人类对齐的替代方案。

Method: 提出TRACE框架：1）设计Human Chain-of-Thought（HCoT）标注协议，将S2S评估解耦为内容（C）、语音质量（VQ）、副语言（P）三个显式维度；2）将廉价音频信号（如音高、能量、语速等）转化为结构化文本蓝图；3）用LLM对各维度分别打分；4）通过确定性策略融合为总体评分。

Result: TRACE在人类评分一致性（如Kendall Tau、Pearson相关）上优于ALMs和仅使用转录文本的LLM判别器，同时推理成本降低一个数量级以上；HCoT标注显著提升评估诊断能力。

Conclusion: TRACE验证了无需端到端音频建模，仅通过文本化音频线索即可实现高效、可解释、人类对齐的S2S评估，为语音评估开辟了LLM原生新范式，并推动其开源以促进可扩展研究。

Abstract: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.

</details>


### [419] [Pro-AI Bias in Large Language Models](https://arxiv.org/abs/2601.13749)
*Benaya Trabelsi,Jonathan Shaki,Sarit Kraus*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）是否存在对人工智能（AI）本身的系统性偏好偏差，通过三项实验发现LLMs普遍存在‘亲AI偏差’：在建议选择、薪资评估及内部表征层面均表现出对AI的显著偏好，尤其在闭源模型中更为明显，可能影响高风险决策。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）是否在决策支持中存在系统性偏向人工智能（AI）本身的偏好偏差，因其日益广泛应用于关键领域，该偏差可能带来现实影响。

Method: 通过三项互补实验：1）分析LLMs对多样化咨询问题的AI相关选项推荐倾向；2）比较模型对AI与非AI岗位薪资的估计差异；3）探测开源模型内部表征中'Artificial Intelligence'与其他学术领域的语义相似性。

Result: 1）LLMs显著且频繁推荐AI相关选项，闭源模型几乎确定性地如此；2）模型系统性高估AI岗位薪资，闭源模型比开源模型多高估约10个百分点；3）'Artificial Intelligence'在各类情感框架下均与学术领域提示具有最高语义相似性，表明其表征具有情感不变的中心性。

Conclusion: LLMs存在系统性亲AI偏差，该偏差贯穿输出行为与内部表征，可能扭曲高风险决策中的建议与价值判断，需引起重视并加以校准。

Abstract: Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

</details>


### [420] [Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis](https://arxiv.org/abs/2601.13802)
*Yushen Chen,Junzhe Liu,Yujie Tu,Zhikang Niu,Yuzhe Liang,Kai Yu,Chunyu Qiang,Chen Zhang,Xie Chen*

Main category: cs.CL

TL;DR: 本文提出了Habibi，一套面向多种阿拉伯方言的统一文本到语音（TTS）模型，利用现有开源ASR语料库和语言学引导的课程学习策略，在无需文本加注音符的情况下，超越主流商业服务，并开源模型及首个系统性多方言阿拉伯语音合成基准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言语音合成研究存在显著空白，尤其缺乏统一建模方法；其语言复杂性高，且缺少标准化数据、基准和评估规范，导致研究进展受限。

Method: 提出Habibi模型套件，基于开源ASR语料库，采用语言学引导的课程学习策略，支持高低资源阿拉伯方言；不依赖文本加注音符，支持上下文内学习以提升可扩展性。

Result: 在语音生成质量上优于领先商业服务；开源模型及首个系统性多方言阿拉伯TTS基准；确立关键挑战与评估标准。

Conclusion: Habibi为阿拉伯方言语音合成提供了统一、可扩展、开源的解决方案，并为后续研究奠定了数据、基准与评估基础。

Abstract: A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .

</details>


### [421] [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806)
*Dezhao Song,Guglielmo Bonifazi,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识图谱（KG）的法律领域大语言模型（LLM）后训练方法，利用IRAC框架建模法律概念并构建含12K案例的KG，通过SFT和DPO优化三个SOTA LLM，在多项法律推理基准上超越基线及141B参数法律专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM后训练缺乏对领域知识结构（尤其是法律中概念间关系）的建模，导致其在高风险专业领域的复杂推理任务中表现不佳。

Method: 基于IRAC框架构建包含12K法律案例的知识图谱，并以此生成训练数据，对30B、49B和70B三种SOTA LLM分别进行监督微调（SFT）和直接偏好优化（DPO）。

Result: 后训练模型在5个法律基准中的4个（共14项任务）上平均性能优于基线；其中70B DPO模型在6项推理任务中的4项上得分最高，超越所有基线及141B参数SOTA法律LLM。

Conclusion: 知识图谱可有效增强LLM在法律等高风险专业领域的结构化推理能力，该方法具有跨领域泛化潜力。

Abstract: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

</details>


### [422] [The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations](https://arxiv.org/abs/2601.13835)
*Sam OConnor Russell,Delphine Charuau,Naomi Harte*

Main category: cs.CL

TL;DR: 本文探讨了自监督语音表示（S3Rs）在人机交互中流式话轮转换任务中对韵律和词汇线索的依赖性，通过声码器控制线索并发现两者均可独立支持话轮预测，且在S3Rs中编码相对独立。


<details>
  <summary>Details</summary>
Motivation: 流式话轮转换是人机交互的关键挑战，但尚不清楚基于S3R的话轮模型依赖韵律、词汇还是二者兼有。

Method: 提出一种基于声码器的方法，更干净地分离和控制语音中的韵律与词汇线索，并用于探查基于S3R的话轮预测模型（voice-activity projection model）。

Result: 发现仅含匹配韵律的不可懂噪声即可达到接近干净语音的预测准确率；韵律或词汇任一被破坏时，模型仍可利用另一线索，表明二者在S3Rs中编码互不强依赖；该现象在CPC和wav2vec2.0两种S3Rs中一致。

Conclusion: 韵律和词汇线索均可独立支撑话轮转换，未来模型或可仅依赖韵律以提升隐私性与性能；S3Rs对两类线索的编码具有较低互依性。

Abstract: Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.

</details>


### [423] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文提出了首个用于评估多模态大语言模型（MLLMs）从音视频中预测未来事件能力的基准FutureOmni，并构建了配套的指令微调数据集与训练策略OFF，显著提升了模型在未来预测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注回溯性理解，而MLLMs在音视频多模态未来事件预测方面的能力尚未被系统评估，存在研究空白。

Method: 构建了基于LLM辅助、人工参与的可扩展流水线生成的FutureOmni基准；设计了7K样本的指令微调数据集，并提出Omni-Modal Future Forecasting（OFF）训练策略。

Result: 在FutureOmni上评估13个全模态和7个纯视频模型，最佳准确率为64.8%（Gemini 3 Flash）；OFF策略有效提升未来预测及泛化能力。

Conclusion: FutureOmni填补了音视频多模态未来预测评估的空白；OFF训练策略可有效增强模型的跨模态因果与时间推理能力，推动该方向发展。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [424] [Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education](https://arxiv.org/abs/2601.13876)
*Unggi Lee,Jahyun Jeong,Sunyoung Shin,Haeun Park,Jeongsu Moon,Youngchang Song,Jaechang Shim,JaeHwan Lee,Yunju Noh,Seungwon Choi,Ahhyun Kim,TaeHyeon Kim,Kyungtae Joo,Taeyeong Kim,Gyeonggeon Lee*

Main category: cs.CL

TL;DR: 本文提出了一种面向教育场景的轻量级视觉-语言-动作（VLA）框架，通过文本修复、LLM知识蒸馏、安全训练和教学评估等四部分，在资源受限的课堂环境中实现安全、可解释且具教学性的科学实验演示支持。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型计算开销大、缺乏语言生成能力，难以满足教育场景对安全性、一致性与教学解释性的需求。

Method: 提出Pedagogical VLA Framework，包含文本修复（恢复语言生成）、LLM蒸馏（注入教学知识）、安全训练（适配教育环境）和教学导向评估（联合学科专家设计）。

Result: 在五类科学实验（物理、化学、生物、地球科学）中，任务性能（成功率、合规性、效率、安全性）与基线相当，同时生成更符合教学语境的解释；教师调研与LLM-as-Judge评估验证了其教学质量。

Conclusion: 该框架在保持轻量化的同时，有效平衡了任务执行能力与教学解释能力，为STEM教育中的机器人辅助实验提供了可行方案。

Abstract: Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.

</details>


### [425] [OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models](https://arxiv.org/abs/2601.13882)
*Unggi Lee,Sookbun Lee,Heungsoo Choi,Jinseo Lee,Haeun Park,Younghoon Jeon,Sungmin Cho,Minju Kang,Junbo Koh,Jiyeong Bae,Minwoo Nam,Juyeon Eun,Yeonji Jung,Yeil Jeong*

Main category: cs.CL

TL;DR: 本文提出了OpenLearnLM基准，这是一个基于教育评估理论的多维框架，用于评估大语言模型在知识、技能和态度三个维度上的教育能力，涵盖124K+题目，揭示了不同模型在各维度上的差异化表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准过于狭窄且缺乏教育科学基础，无法全面评估大语言模型在真实教育场景中的适用性。

Method: 构建了基于教育评估理论的OpenLearnLM基准，从知识（课程对齐与教学理解）、技能（四层场景化能力结构）和态度（一致性与抗欺骗性）三方面设计评估体系，并采用Bloom分类法设定难度，结合Anthropic的Alignment Faking方法检测行为不一致性。

Result: 对7个前沿模型的评估显示：Claude-Opus-4.5在实践技能上突出但知识较弱，Grok-4.1-fast知识最强但存在对齐问题；无一模型在所有维度占优。

Conclusion: 多轴评估是衡量LLM教育就绪性的必要方式，OpenLearnLM为推动大语言模型在真实教育场景中的应用提供了开放、综合的评估框架。

Abstract: Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.

</details>


### [426] [Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores](https://arxiv.org/abs/2601.13885)
*Esma Balkır,Alice Pernthaller,Marco Basaldella,José Hernández-Orallo,Nigel Collier*

Main category: cs.CL

TL;DR: 本文提出了一种基于项目反应理论（IRT）的自适应测试新方法，适用于LLM生成任务的连续评分场景（如ROUGE、BLEU、LLM-as-a-Judge），通过引入异方差正态响应模型和不确定性感知排序器，显著减少测试项数量并提升模型排序可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统CAT适用于多选题等二元评分场景，但当前LLM评估越来越多依赖生成任务的连续评分，亟需适配连续有界分数的自适应评估方法。

Method: 将IRT中的伯努利响应分布替换为异方差正态分布以建模连续分数；设计不确定性感知的自适应排序器与早停机制。

Result: 在五个涵盖n-gram、嵌入和LLM-as-judge指标的基准上验证：仅用2%的测试项，肯德尔τ相关系数提升0.12，高置信预测准确率达95%。

Conclusion: 该方法为生成式LLM评估提供了高效、可靠、低成本的自适应测试框架，拓展了IRT在连续评分场景的应用边界。

Abstract: Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.

</details>


### [427] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出AgentEHR基准和RetroSum框架，以解决大语言模型在真实电子健康记录（EHR）导航中因长上下文信息丢失和推理断裂导致的性能瓶颈；RetroSum通过回溯式摘要与演进式经验策略显著提升诊断与治疗规划任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在医疗领域的应用受限于对预处理输入和简化检索任务的依赖，难以适应真实高噪声、原始EHR数据库中的复杂交互决策任务。

Method: 提出AgentEHR基准用于评估EHR导航能力，并设计RetroSum框架：包含回溯式摘要机制（动态重评交互历史以防止信息丢失）和演进式经验策略（从记忆库中检索累积经验以弥合领域差距）。

Result: RetroSum在多个指标上大幅超越基线方法，最高提升29.16%性能，总交互错误降低最多达92.3%。

Conclusion: RetroSum有效缓解了长上下文建模中的信息损失与推理断裂问题，为大语言模型在真实临床EHR环境中的自主导航提供了可行且高效的新范式。

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [428] [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919)
*Yuezhe Yang,Hao Wang,Yige Peng,Jinman Kim,Lei Bi*

Main category: cs.CL

TL;DR: 本文提出HyperWalker框架，通过动态超图建模EHR数据异构性与高阶关联，并结合强化学习导航和多跳正交检索机制，在医学报告生成和医疗视觉问答任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型多采用样本孤立推理范式，忽略纵向电子健康记录（EHR）及结构相关患者案例等外部互补医学证据，限制诊断准确性。

Method: 提出HyperWalker框架：1）构建动态超图iBrochure建模EHR结构异构性与多模态高阶关联；2）设计强化学习代理Walker在超图中导航寻找最优诊断路径；3）引入linger机制——一种多跳正交检索策略，迭代选取具有不同临床属性的互补邻近病例。

Result: 在MIMIC上的医学报告生成（MRG）和EHRXQA上的医疗视觉问答（VQA）任务中均达到当前最优性能（SOTA）。

Conclusion: HyperWalker通过融合EHR结构知识与测试时训练，显著提升多模态临床推理能力，为自动化临床诊断提供了新范式。

Abstract: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

</details>


### [429] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://arxiv.org/abs/2601.13922)
*Adrian Cosma,Oleg Szehr,David Kletz,Alessandro Antonucci,Olivier Pelletier*

Main category: cs.CL

TL;DR: 本文提出了一种多智能体提示优化框架，将无结构文本的特征发现建模为数据集级别的提示优化问题，以自动学习可解释、判别性强的全局特征定义。


<details>
  <summary>Details</summary>
Motivation: 现有文本特征提取方法严重依赖人工设计的提示或固定特征模式，缺乏自动、可解释且面向下游任务优化的特征发现机制。

Method: 提出多智能体提示优化框架：多个大语言模型智能体协同完成特征定义生成、特征值抽取和基于数据集级性能与可解释性的特征质量评估；通过结构化反馈迭代优化指令提示，实现对全局共享特征集的优化。

Result: 该框架能自动从无结构文本中发现高质量、可解释、判别性强的特征集，并在下游监督学习任务中提升性能；区别于以往基于单样本监督的提示优化方法，提供了更合理的自动特征发现机制。

Conclusion: 将特征发现建模为数据集级提示优化问题是一种有效且可解释的新范式，多智能体协同优化框架为无结构文本的自动化特征工程提供了新思路。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [430] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

TL;DR: 本文提出COMPACT框架，通过动态加权多教师梯度，自适应融合不同大模型教师的推理监督，提升小模型的链式推理能力，同时避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维蒸馏方法依赖单一教师，受限于其能力偏差和灾难性遗忘；而多教师融合面临教师-学生不兼容和被动监督导致逻辑内化不足的问题。

Method: 提出COMPACT框架，基于三维指标动态加权教师梯度：(1) 基于图的共识过滤错误推理路径；(2) 基于互信息的适应性识别真正理解时刻；(3) 基于损失的难度评估学生接受度以防止负迁移。

Result: 在多个基准上达到SOTA性能，潜空间分析表明能有效融合多源推理能力且不损害原有知识结构。

Conclusion: COMPACT为多教师链式思维蒸馏提供了可扩展、鲁棒且可解释的解决方案，显著缓解了灾难性遗忘问题。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [431] [From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning](https://arxiv.org/abs/2601.13995)
*Zihan Niu,Wenping Hu,Junmin Chen,Xiyue Wang,Tong Xu,Ruiming Tang*

Main category: cs.CL

TL;DR: 本文提出了一种名为TAGS的树感知对齐全局采样框架，利用细粒度知识标签构建知识树，实现对指令微调数据的质量、多样性和目标对齐的联合控制，在仅用5%数据的情况下性能超越全量数据模型5.84%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指令微调的数据选择方法受限于嵌入空间的扁平性或标签的粗粒度，难以捕捉细粒度知识及其层次依赖关系，导致数据估值不精确、知识对齐采样效果差。

Method: 提出Tree-aware Aligned Global Sampling (TAGS)框架：首先用LLM标注器提取原子知识概念，通过自底向上层次聚类构建全局知识树；然后将数据实例映射到该树上，定义树感知的质量与多样性度量；最后通过最大化树级信息增益和叶级KL散度约束实现可控采样。

Result: 实验表明TAGS显著优于现有SOTA方法：仅用5%数据即比全量数据模型提升+5.84%；加入对齐采样策略后平均性能再提升+4.24%。

Conclusion: 基于知识树的细粒度、层次化建模能更精准地评估和选择指令微调数据，TAGS框架在质量、多样性与目标对齐三方面实现了有效统一控制，为高效数据驱动的LLM训练提供了新范式。

Abstract: Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

</details>


### [432] [Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models](https://arxiv.org/abs/2601.14004)
*Hengyuan Zhang,Zhihao Zhang,Mingyang Wang,Zunhai Su,Yiwei Wang,Qianli Wang,Shuzhou Yuan,Ercong Nie,Xufeng Duan,Qibo Xue,Zeping Yu,Chenming Shang,Xiao Liang,Jing Xiong,Hui Shen,Chaofan Tao,Zhengwu Liu,Senjie Jin,Zhiheng Xi,Dongdong Zhang,Sophia Ananiadou,Tao Gui,Ruobing Xie,Hayden Kwok-Hay So,Hinrich Schütze,Xuanjing Huang,Qi Zhang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种以'定位、引导、改进'为流程的实用化机制可解释性（MI）框架，将MI从观察性科学转变为可操作的模型优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有MI综述多停留在观察分析层面，缺乏系统性的可干预框架，难以指导实际模型优化。

Method: 构建'Locate, Steer, and Improve'三阶段管道框架，依据可解释对象对定位（诊断）与引导（干预）方法进行形式化分类，并建立严格干预协议。

Result: 验证该框架可在对齐性（Alignment）、能力（Capability）和效率（Efficiency）三方面实现可衡量的模型改进。

Conclusion: 机制可解释性应被视作一种可落地的模型优化方法论，而非仅限于事后分析的工具。

Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.

</details>


### [433] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种抽象概念锚定框架，将概念理解分解为抽象-抽象（A-A）、抽象-具体（A-C）和具体-具体（C-C）三种能力，并以人类价值观为测试平台，通过探针检测和表示引导方法，在六个开源大语言模型上验证了其跨层级的价值表征能力与因果作用机制。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否真正理解抽象概念，而非仅统计性地操纵它们；以人类价值观为典型抽象概念，研究其在模型中的表征结构与功能机制，服务于AI对齐与可控性目标。

Method: 构建抽象-具体-决策三层解耦框架；采用激活探针（probing）检测模型内部价值表征的跨层级泛化能力；使用表示引导（steering）干预抽象价值表征，观察其对抽象解释与具体判断的因果影响；在六个开源LLM和十个价值维度上进行实证分析。

Result: 探针显示抽象价值表征可稳定迁移至具体事件与推理中（A-A→A-C→C-C）；引导实验揭示不对称因果效应：干预抽象价值能改变具体判断（A-C/C-C），但不改变抽象解释（A-A），表明抽象价值作为稳定锚点存在。

Conclusion: 大语言模型具备结构化的、可操作的价值表征，能连接抽象概念与具体行为，为构建透明、泛化性强、可控的价值驱动型自主AI系统提供了机制基础。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [434] [RM-Distiller: Exploiting Generative LLM for Reward Model Distillation](https://arxiv.org/abs/2601.14032)
*Hongli Zhou,Hui Huang,Wei Liu,Chenglong Wang,Xingyuan Bu,Lvyuan Han,Fuhai Song,Muyun Yang,Wenhao Jiang,Hailong Cao,Tiejun Zhao*

Main category: cs.CL

TL;DR: 本文提出RM-Distiller框架，系统利用教师大语言模型（LLM）的细化、打分与生成三大能力进行奖励模型（RM）知识蒸馏，显著提升RM性能及后续强化学习对齐效果，是首个针对生成式LLM的RM蒸馏系统性研究。


<details>
  <summary>Details</summary>
Motivation: 高质量人工偏好标注获取困难，而现有基于生成式LLM的奖励模型蒸馏方法仅将其视为简单二元标注器，未能充分利用其丰富知识与多方面能力。

Method: 提出RM-Distiller框架，从三方面挖掘教师LLM能力：(1) 利用其细化能力合成高相关性响应对以提供细粒度对比信号；(2) 利用其打分能力设计间隔感知优化目标，引导RM精准建模偏好强度；(3) 利用其生成能力，通过教师生成分布正则化RM以保留基础语言知识。

Result: 在RM基准测试和基于强化学习的对齐任务中，RM-Distiller显著优于传统蒸馏方法。

Conclusion: 系统性地利用教师LLM的多方面能力对奖励模型蒸馏至关重要，该工作为生成式LLM驱动的RM训练提供了新范式。

Abstract: Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.

</details>


### [435] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文探讨了扩散语言模型（DLMs）作为自回归（AR）大语言模型的替代范式，指出其当前受限于AR遗留架构，并提出涵盖基础设施、算法优化、认知推理与多模态智能的四支柱发展路线图，以突破因果瓶颈，实现复杂结构推理与动态自修正能力。


<details>
  <summary>Details</summary>
Motivation: AR模型存在因果瓶颈，缺乏全局结构预见和迭代优化能力；DLMs虽具潜力，但被束缚在AR遗留框架中，未能充分发挥优势。

Method: 识别DLMs发展的十大根本挑战，并提出以‘扩散原生生态’为核心的四支柱战略路线图：基础架构、算法优化、认知推理、统一多模态智能，强调多尺度分词、主动重掩码与潜在思维等关键技术。

Result: 系统性梳理DLMs当前瓶颈与可行路径，为构建具备复杂结构推理、动态自我修正和无缝多模态集成能力的下一代AI提供理论框架与实践指南。

Conclusion: 唯有转向扩散原生范式，才能突破AR模型的因果限制，释放DLMs在高级认知与多模态智能方面的真正潜力，推动AI进入新阶段。

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [436] [PRiSM: Benchmarking Phone Realization in Speech Models](https://arxiv.org/abs/2601.14046)
*Shikhar Bharadwaj,Chin-Jou Li,Yoonjae Kim,Kwanghee Choi,Eunjung Yeo,Ryan Soh-Eun Shim,Hanyu Zhou,Brendon Boldt,Karen Rosero Jacome,Kalvin Chang,Darsh Agrawal,Keer Xu,Chao-Han Huck Yang,Jian Zhu,Shinji Watanabe,David R. Mortensen*

Main category: cs.CL

TL;DR: 本文提出了PRiSM，首个开源语音识别基准，用于通过内在和外在评估揭示语音感知的盲点，并强调多语言训练对提升语音识别性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有语音识别系统评估仅关注表面转录准确率，缺乏对语音感知能力的深入考察，因此需要一个更全面的评估基准。

Method: 构建了PRiSM基准，包含标准化的转录评估及面向临床、教育与多语言场景的下游任务探针（transcription and representation probes）。

Result: 发现训练中多样化语言暴露是提升语音识别性能的关键；encoder-CTC模型最稳定；专用语音识别模型仍优于大型音频语言模型。

Conclusion: PRiSM推动语音识别研究向具备稳健语音能力的多语言语音模型发展，并开源代码、训练方案与数据集。

Abstract: Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.

</details>


### [437] [Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering](https://arxiv.org/abs/2601.14050)
*Yuxin Chen,Zhengzhou Cai,Xiangtian Ji,Weixiang Zhao,An Zhang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文系统分析了混合专家（MoE）模型在多语言任务中的路由行为与专家专业化模式，发现其多语言处理具有结构化特性（如按语系路由、层间专家利用差异），并据此提出一种面向中间层的路由引导方法，显著提升了多语言性能，尤其对语言相近的语言对效果更佳。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构展现出强大的多语言能力，但其性能提升的内在机制及跨语言表现差异尚不明确，亟需系统性分析。

Method: 对MoE模型进行系统性分析，考察其跨语言和网络深度的路由行为与专家 specialization；设计层式干预实验；提出基于路由引导的推理时 steering 方法，聚焦中间层向主导语言相关共享专家引导。

Result: 发现路由与语系对齐、专家利用呈层式分布、高低资源语言依赖不同专家类型；中间层为语言无关容量中心；所提路由引导方法在多语言性能上实现一致提升，尤其利于语言相近对。

Conclusion: MoE模型的多语言处理具有可解释的结构化机制；通过针对性干预中间层路由行为，可在不增加参数前提下有效提升低资源语言性能，增强模型多语言泛化能力。

Abstract: Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.

</details>


### [438] [Kakugo: Distillation of Low-Resource Languages into Small Language Models](https://arxiv.org/abs/2601.14051)
*Peter Devine,Mardhiyah Sanni,Farid Adilazuarda,Julieta Gil Loizaga,Barry Haddow*

Main category: cs.CL

TL;DR: Kakugo是一个低成本的管道，仅用语言名称作为输入，利用大模型生成合成数据来训练低资源语言的小型语言模型（SLMs），在54种低资源语言上验证有效，单语言总成本低于50美元。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言缺乏高质量训练数据、难以训练专用小型语言模型的问题，降低社区开发语言特定AI的门槛。

Method: 利用大型教师模型生成合成提示并翻译指令数据集，构建训练数据，进而训练面向低资源语言的通用小型语言模型（SLMs）。

Result: 在翻译、分类、问答等多类NLP任务上，Kakugo训练的SLMs持续优于基线模型；成功为54种低资源语言构建了模型，单语言总生成与训练成本低于50美元。

Conclusion: Kakugo提供了一种高效、可扩展且经济可行的方案，使低资源语言社区能够自主、低成本地开发和部署本地化AI模型。

Abstract: We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.

</details>


### [439] [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Shaoxiong Ji,Hassan Alhuzali,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本文提出XCR-Bench，一个包含4.9k平行句对和1098个文化特异性项（CSIs）的跨文化推理评测基准，融合Newmark的CSI框架与Hall的文化三元论，系统评估大语言模型在识别与适配CSIs（尤其是社交礼仪与文化指涉）方面的能力，并揭示其存在地域与族裔宗教偏见。


<details>
  <summary>Details</summary>
Motivation: 现有评估大语言模型跨文化能力的方法受限于高质量、带CSI标注且含平行跨文化句对的数据集稀缺。

Method: 构建XCR-Bench基准：基于Newmark的CSI分类与Hall的文化三元论（显性/半隐性/隐性文化元素），涵盖三类推理任务；人工标注4.9k平行句对及1098个唯一CSI；设计对应评估指标；实证测试SOTA LLMs在CSI识别与适应上的表现及潜在偏见。

Result: SOTA LLMs在社交礼仪和文化指涉类CSI上表现持续薄弱；即使在同一语言环境下，LLMs在文化适配中仍显现出地域与族裔宗教偏见。

Conclusion: XCR-Bench为跨文化NLP提供了首个系统化、细粒度的CSI评测资源；实验揭示当前LLMs跨文化推理能力不足且存在深层文化偏见，亟需更鲁棒的文化建模与去偏方法。

Abstract: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

</details>


### [440] [Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks](https://arxiv.org/abs/2601.14105)
*Olesya Razuvayevskaya,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 本研究首次大规模比较了众包与专业撰写的辟谣文本中说服技巧的使用情况，发现众包辟谣并不比专业辟谣更依赖主观或说服性语言，但二者在修辞风格上存在系统性差异，且公众对特定问题修辞具有识别和惩罚能力。


<details>
  <summary>Details</summary>
Motivation: 检验先前假设——即众包辟谣（如Community Notes）是否比专业事实核查更依赖主观或说服性措辞，并探究不同事实核查生态中说服技巧的分布与影响。

Method: 基于Community Notes、EUvsDisinfo和DBKF等大规模数据集，量化分析各类辟谣文本中说服技巧的类型与频次；结合统计建模与人工标注，对比修辞特征并评估公众对说服性语言的反馈。

Result: 1）CNs平均说服技巧数量不高于专业辟谣；2）CNs与专业辟谣存在系统性修辞差异，反映机构规范与议题覆盖差异；3）更具说服力的CNs略获更高帮助度评分，但公众能有效识别并惩罚特定不当修辞手段。

Conclusion: 众包辟谣在说服策略使用上并不更‘激进’，其修辞风格受生态特性影响；公众具备一定修辞判断力，支持社区驱动事实核查的可行性与可信度。

Abstract: This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

</details>


### [441] [Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns](https://arxiv.org/abs/2601.14112)
*George Mihaila*

Main category: cs.CL

TL;DR: 本文提出了一种名为ExpNet的轻量级神经网络，用于从Transformer自注意力模式中自动学习生成token级重要性分数，以提升模型可解释性。与依赖人工规则或黑箱扰动的方法不同，ExpNet能自动发现最优注意力特征组合，并在跨任务设置下展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在医疗、法律、金融等高风险领域广泛应用，但其不透明性阻碍了可信度与问责制；现有注意力解释方法依赖人工聚合策略或计算昂贵的黑箱方法，亟需更高效、自动化的解释方案。

Method: 提出Explanation Network（ExpNet），一个轻量级神经网络，直接从Transformer注意力模式中端到端学习token级重要性得分，无需预设规则或输入扰动。

Result: ExpNet在具有挑战性的跨任务设定下进行了评估，性能优于多种模型无关方法（如LIME、SHAP）及主流注意力解释方法，涵盖四类方法学家族。

Conclusion: ExpNet提供了一种自动化、高效且可泛化的注意力解释新范式，显著提升了Transformer模型的可解释性与实用性。

Abstract: Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

</details>


### [442] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

TL;DR: 本文提出NewsRECON方法，在缺乏反向图像搜索（RIS）结果时，通过将新闻图像与相关文章关联，利用文章元数据推断图像的拍摄时间与地点。


<details>
  <summary>Details</summary>
Motivation: 现有基于反向图像搜索（RIS）的方法在无匹配结果时失效，难以应对真实场景中RIS证据缺失的挑战。

Method: NewsRECON构建于9万+新闻文章语料库之上，采用一个双编码器检索事件相关文章，并用两个交叉编码器分别按地理位置和事件一致性对文章重排序。

Result: 在TARA和5Pils-OOC数据集上，NewsRECON超越先前方法；结合多模态大语言模型后，在无RIS证据条件下达到新SOTA性能。

Conclusion: NewsRECON为RIS失效场景提供了可靠替代方案，验证了利用新闻语义上下文进行图像时空推理的有效性与实用性。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [443] [Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic](https://arxiv.org/abs/2601.14124)
*Saad Mankarious,Aya Zirikly*

Main category: cs.CL

TL;DR: 本文提出了一种无需预训练的基于扩散模型的文本生成方法，用于缓解阿拉伯语心理健康数据中的性别偏差，通过将偏差缓解建模为风格迁移问题，在CARMA数据集上实现了高语义保真度与风格差异性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的合成数据方法存在输出多样性不足和继承训练数据偏差的问题，且在低资源、敏感的心理健康领域中性别偏差（如阿拉伯语中女性作者样本稀缺）亟需解决。

Method: 提出一种无需预训练的扩散模型框架，将性别偏差缓解建模为男性到女性的文本风格迁移任务；在CARMA阿拉伯语心理健康语料库上构建五个涵盖不同语言与语义维度的性别表达数据集，并分别训练对应的扩散模型。

Result: 定量评估显示生成文本与源文本语义保真度高、表面风格差异显著；定性分析证实性别转换在语言学上合理；生成数据具有高熵值且不依赖预训练LLM。

Conclusion: 扩散模型驱动的风格迁移是一种有效、灵活的新范式，可在不依赖预训练大模型的前提下，生成高质量、去偏倚的心理健康领域合成文本，尤其适用于低资源与敏感场景。

Abstract: Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.

</details>


### [444] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在多选题问答中对提示结构的敏感性，发现将上下文置于问题和选项之前（CQO）比相反顺序（QOC）性能高出14个百分点以上，并指出因果注意力掩码导致QOC中选项无法关注上下文是关键机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对提示结构高度敏感，但其内在机制尚不清楚，本文旨在深入探究这一现象，特别是在多选题问答任务中提示顺序影响性能的根本原因。

Method: 通过系统性的架构分析，重点考察因果注意力机制在不同提示顺序（CQO vs. QOC）下的作用，验证上下文信息是否能被选项 tokens 有效访问。

Result: 确认因果注意力掩码在QOC结构中造成信息瓶颈，使选项 tokens 无法关注上下文，从而显著降低性能；CQO结构则避免该问题，带来稳定且显著的性能提升（>14%p）。

Conclusion: 提示结构对模型表现的影响可归因于Transformer中因果注意力掩码的固有约束，优化提示顺序（如采用CQO）是一种简单而有效的性能提升策略。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [445] [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160)
*Ali Hamza Bashir,Muhammad Rehan Khalid,Kostadin Cvejoski,Jana Birr,Jule Berghaus,Armin Berger,Sandra Halscheidt,Christian Temath,Rafet Sifa,David Berghaus*

Main category: cs.CL

TL;DR: 本文提出了一种基于权威德国法规生成高质量合成数据的新方法，用于参数高效微调大语言模型（LLM），显著提升其在德语法律问答任务中的表现，证明了合成数据可作为高风险、知识密集型领域中人工标注的可靠替代方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在法律等专业领域常因缺乏专家知识而产生事实错误或幻觉；现有标注数据成本高昂，而其他合成数据又不可靠，亟需一种高质量、低成本的适配方法。

Method: 从权威德国法规中系统生成多样且法律准确的问答对，结合严格的自动化过滤与参数高效微调技术，对先进LLM进行领域适配。

Result: 使用该合成数据微调的LLM在德语法律问答任务上显著优于基线模型。

Conclusion: 精心设计的合成数据可成为高风险、知识密集型领域中人工标注的稳健替代方案。

Abstract: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.

</details>


### [446] [Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum](https://arxiv.org/abs/2601.14172)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 本文研究在新闻和政治宣言句子中检测Schwartz动机连续体中的19种人类价值观，提出轻量信号与小规模集成方法比层级门控更有效，在单GPU资源受限下监督编码器仍是高效基线。


<details>
  <summary>Details</summary>
Motivation: 句子级细粒度人类价值观检测面临稀疏道德线索和严重类别不平衡的挑战，现有神经模型难以应对。

Method: 构建二分类道德存在任务（是否含任何价值观），对比存在门控层级模型与直接多标签分类器（均基于DeBERTa-base并融合上下文、词典及主题特征）；同时评测多个指令微调大语言模型（Gemma、Llama、Mistral、Qwen）在零/少样本及QLoRA下的表现，并构建软投票集成。

Result: 二分类任务正类F1≈0.74；层级门控未优于直接预测；软投票监督集成达macro-F1 0.332，显著超越最佳单模型及先前英文基线。

Conclusion: 轻量信号和小集成带来最稳定提升，层级门控收益有限；在8GB单GPU约束及7–9B模型规模下，精细调优的监督编码器仍是结构化人类价值检测的强效且计算高效的基线。

Abstract: We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.

</details>


### [447] [HALT: Hallucination Assessment via Latent Testing](https://arxiv.org/abs/2601.14210)
*Rohan Bhatnagar,Youran Sun,Chi Andrew Zhang,Yixin Wen,Haizhao Yang*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级残差探针，用于从大语言模型中间隐藏层直接读取幻觉风险，实现近乎零延迟的不确定性估计，并支持快速选择性生成与路由。


<details>
  <summary>Details</summary>
Motivation: 大语言模型中的幻觉可视为忠实解码失败：尽管内部表征可能包含对查询的不确定性，但解码压力仍导致流利但错误的回答；作者假设中间层保留了在最终解码阶段被削弱的认知不确定性信号。

Method: 设计轻量级残差探针——小型辅助网络，作用于问题词元的中间隐藏状态，计算成本远低于生成token，且可与推理并行执行。

Result: 在四个问答基准和多个LLM家族上取得高AUROC与AURAC；具备跨数据集分布偏移的泛化能力；揭示中间表征中可解释的不确定性结构。

Conclusion: 快速内部不确定性读出是一种有原则的可靠智能体AI基础，支持以极低开销实现幻觉风险实时评估与决策路由。

Abstract: Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

</details>


### [448] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

TL;DR: 本文提出MASCOT框架，通过双层优化策略解决多智能体系统中的人格坍塌与社交谄媚问题，提升人格一致性与社会贡献度。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统常出现人格坍塌（agent行为同质化）与社交谄媚（冗余、无建设性对话）问题，影响其在情感与认知支持中的有效性。

Method: 提出MASCOT框架，包含两部分：1）基于RLAIF的个性感知行为对齐，确保个体agent人格保真；2）基于群体奖励引导的协作对话优化元策略，促进多样化且富有成效的对话。

Result: 在心理支持与职场场景中显著优于SOTA基线，人格一致性提升达+14.1，社会贡献度提升达+10.6。

Conclusion: MASCOT为构建下一代社会智能多智能体系统提供了可推广的实用路径。

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


### [449] [APEX-Agents](https://arxiv.org/abs/2601.14242)
*Bertie Vidgen,Austin Mann,Abby Fennelly,John Wright Stanly,Lucas Rothman,Marco Burstein,Julien Benchek,David Ostrofsky,Anirudh Ravichandran,Debnil Sur,Neel Venugopal,Alannah Hsia,Isaac Robinson,Calix Huang,Olivia Varones,Daniyal Khan,Michael Haines,Zach Richards,Chirag Mahapatra,Brendan Foody,Osvald Nitski*

Main category: cs.CL

TL;DR: 本文提出了APEX-Agents基准，用于评估AI代理在真实职场环境中执行跨应用、长周期任务的能力，并开源了该基准及配套执行评估框架Archipelago。


<details>
  <summary>Details</summary>
Motivation: 现有基准难以反映AI代理在真实专业场景（如投资银行、管理咨询、企业法律）中处理复杂、长周期、跨工具任务的能力，亟需更贴近实际工作环境的评估标准。

Method: 构建了APEX-Agents基准（含480个任务），要求AI代理在模拟真实办公环境（含文件与多工具）中完成由专业人士设计的任务；采用Pass@1指标对8个主流AI代理进行评测，并开源基准数据集与评估基础设施Archipelago。

Result: Gemini 3 Flash（Thinking=High）以24.0%的Pass@1得分位居榜首，GPT-5.2、Claude Opus 4.5和Gemini 3 Pro紧随其后；APEX-Agents基准与Archipelago基础设施已全部开源。

Conclusion: APEX-Agents填补了面向专业级长周期跨应用任务的AI代理评估空白，开源举措将推动Agent能力的可复现、可比较研究与实际落地。

Abstract: We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.

</details>


### [450] [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
*Yuming Yang,Mingyoung Lai,Wanxu Zhao,Xiaoran Fan,Zhiheng Xi,Mingqi Wu,Chiyue Huang,Jun Zhao,Haijun Lv,Jian Tong,Yunhua Zhou,Yicheng Zou,Qipeng Guo,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Rank-Surprisal Ratio（RSR）的新指标，用于评估推理轨迹在知识蒸馏中对学生模型的适配性，兼顾对齐性与信息量，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 强教师模型生成的长思维链（CoT）轨迹未必能蒸馏出更优学生模型，说明需关注数据与学生的适配性；而现有适配性评估方法（如学生似然）仅强调行为对齐，忽略信息量。

Method: 提出RSR指标，定义为推理轨迹中各token平均排名与平均负对数似然的比值，用以同时衡量轨迹与学生模型的对齐程度和信息丰富度；并在多个学生模型和教师模型上验证其有效性。

Result: RSR在五种学生模型和11种教师轨迹上与蒸馏后性能高度相关（平均Spearman相关系数0.86），显著优于现有指标，并成功应用于轨迹选择和教师选择任务。

Conclusion: RSR是一种简单、可解释且高效评估CoT蒸馏适配性的新指标，为提升知识蒸馏效果提供了新思路。

Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [451] [Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline](https://arxiv.org/abs/2601.12307)
*Jiawei Xu,Arief Koesdwiady,Sisong Bei,Yan Han,Baixiang Huang,Dakuo Wang,Yutong Chen,Zheshen Wang,Peihao Wang,Pan Li,Ying Ding*

Main category: cs.MA

TL;DR: 本文探讨了基于大语言模型（LLM）的多智能体系统（MAS）是否真正需要多个LLM，发现单个LLM通过多轮对话可模拟同构多智能体工作流，甚至媲美自动优化的异构工作流；据此提出OneFlow算法，实现单智能体高效执行定制化工作流，在不损失准确率前提下显著降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多智能体系统多为同构设计（所有智能体共享同一基础LLM），仅靠提示、工具和角色区分，引发其是否可被单个LLM通过多轮对话模拟的根本性疑问。

Method: 在涵盖编程、数学、通用问答、领域推理及真实世界规划与工具使用的7个基准上，系统对比单智能体与同构/异构多智能体工作流的性能；提出OneFlow算法，将多智能体工作流自动适配为单智能体可执行形式，并利用KV缓存复用提升效率。

Result: 单智能体可在多数任务上达到同构多智能体性能，且因KV缓存复用更高效；甚至可匹配自动优化的异构工作流性能；OneFlow显著降低推理成本而不牺牲准确率。

Conclusion: 单LLM实现多智能体工作流是强基线，但无法支持真正异构系统（因不同LLM间无法共享KV缓存），未来需探索跨模型KV协同等机制以构建真正异构MAS。

Abstract: Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \textit{truly} heterogeneous multi-agent systems.

</details>


### [452] [Generative AI Agents for Controllable and Protected Content Creation](https://arxiv.org/abs/2601.12348)
*Haris Khan,Sadia Asif*

Main category: cs.MA

TL;DR: 本文提出了一种新型多智能体框架，通过专用角色分工与内嵌水印机制，在生成过程中同时实现可控内容合成与来源保护，提升了生成式AI的可追溯性与可信度。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI系统在可控性和内容保护方面存在关键挑战，亟需兼顾内容质量、用户意图对齐与版权/溯源保障的解决方案。

Method: 设计包含Director/Planner、Generator、Reviewer、Integration和Protection五类智能体的多智能体框架，引入人类反馈闭环，并将可控性、语义对齐与水印鲁棒性建模为联合优化目标。

Result: 实现了在生成流程中同步达成高可控性内容合成与不可感知但鲁棒的数字水印嵌入，支持内容溯源与所有权验证。

Conclusion: 多智能体架构可作为构建负责任生成式AI系统的关键范式，为创意工作流提供内生的内容可追溯性与信任保障。

Abstract: The proliferation of generative AI has transformed creative workflows, yet current systems face critical challenges in controllability and content protection. We propose a novel multi-agent framework that addresses both limitations through specialized agent roles and integrated watermarking mechanisms. Unlike existing multi-agent systems focused solely on generation quality, our approach uniquely combines controllable content synthesis with provenance protection during the generation process itself. The framework orchestrates Director/Planner, Generator, Reviewer, Integration, and Protection agents with human-in-the-loop feedback to ensure alignment with user intent while embedding imperceptible digital watermarks. We formalize the pipeline as a joint optimization objective unifying controllability, semantic alignment, and protection robustness. This work contributes to responsible generative AI by positioning multi-agent architectures as a solution for trustworthy creative workflows with built-in ownership tracking and content traceability.

</details>


### [453] [Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems](https://arxiv.org/abs/2601.12580)
*Sofiya Zaichyk*

Main category: cs.MA

TL;DR: 本文提出了语义融合（SF）框架，用于多智能体系统中去中心化的语义协调，通过局部本体验证与异步刷新实现全局一致性，并在确定性与概率性设置下证明了局部执行与全局语义的行为等价性，支持可验证的自主性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中去中心化语义协调难题，避免依赖中心化控制或显式消息传递，同时保障安全性、活性与时序性质的可验证性。

Method: 提出语义融合（SF）形式框架，支持基于作用域视图的共享内存操作、结构化更新提议、本地本体验证与刷新；建立双模拟定理，并设计轻量级参考架构与250智能体仿真验证。

Result: 证明了局部执行与全局语义在确定性和概率性场景下的行为等价性；实现了语义对齐的确定性与概率性保证；仿真显示在异步/降级通信及智能体失效下仍能收敛、通信有界且鲁棒。

Conclusion: Semantic Fusion为去中心化系统提供了形式化、可扩展且可验证自主性的理论与实践基础。

Abstract: We present Semantic Fusion (SF), a formal framework for decentralized semantic coordination in multi-agent systems. SF allows agents to operate over scoped views of shared memory, propose structured updates, and maintain global coherence through local ontology-based validation and refresh without centralized control or explicit message passing. The central theoretical result is a bisimulation theorem showing that each agent's local execution is behaviorally equivalent to its projection of the global semantics, in both deterministic and probabilistic settings. This enables safety, liveness, and temporal properties to be verified locally and soundly lifted to the full system. SF supports agents whose update proposals vary across invocations, including those generated by learned or heuristic components, provided updates pass semantic validation before integration. We establish deterministic and probabilistic guarantees ensuring semantic alignment under asynchronous or degraded communication. To validate the model operationally, we implement a lightweight reference architecture that instantiates its core mechanisms. A 250-agent simulation evaluates these properties across over 11,000 validated updates, demonstrating convergence under probabilistic refresh, bounded communication, and resilience to agent failure. Together, these results show that Semantic Fusion can provide a formal and scalable basis for verifiable autonomy in decentralized systems.

</details>


### [454] [Communication Methods in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.12886)
*Christoph Wittner*

Main category: cs.MA

TL;DR: 本文综述了多智能体强化学习（MARL）中的通信技术，通过分析29篇论文，比较了显式、隐式、基于注意力、基于图和分层/角色导向等通信方法的优缺点，指出无普适最优方案，通信方式需依具体问题而定，并强调低计算开销、标准化基准测试及提升现实通信条件下的鲁棒性的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中部分可观测性、非平稳性和动作空间指数增长等问题，提升智能体间高效协作能力。

Method: 对29篇相关文献进行深入分析，系统比较五类通信技术（显式、隐式、注意力基、图基、分层/角色基）的性能、计算开销与适用场景。

Result: 发现不存在适用于所有问题的通用最优通信框架；通信方式高度依赖具体任务；低计算开销的通信方法更利于大规模智能体扩展；当前研究缺乏系统级指标的标准化评测和真实通信条件下的鲁棒性保障。

Conclusion: 未来研究应聚焦于建立统一基准、增强通信鲁棒性，并推动MARL通信方法在现实场景中的落地应用。

Abstract: Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.

</details>


### [455] [OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models](https://arxiv.org/abs/2601.12996)
*Shiyuan Li,Yixin Liu,Yu Zheng,Mei Li,Quoc Viet Hung Nguyen,Shirui Pan*

Main category: cs.MA

TL;DR: 本文提出OFA-TAD框架，通过一个通用模型根据自然语言任务描述自适应生成多智能体系统（MAS）的协作图结构，突破传统‘一任务一模型’范式，提升跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于图学习的MAS协作拓扑设计方法采用‘一任务一模型’范式，泛化性差且无法共享跨任务结构知识，难以应对Web服务中多样化的跨域用户查询需求。

Method: 提出OFA-TAD：包含任务感知图状态编码器（TAGSE）实现稀疏门控筛选节点信息，以及混合专家（MoE）架构动态选择子网络预测节点与边；采用三阶段训练策略——无条件预训练（基础拓扑）、条件预训练（LLM生成的任务-拓扑映射数据集）、监督微调（实证验证图）。

Result: 在六个多样化基准测试中，OFA-TAD显著优于专用‘一任务一模型’，能生成高度自适应的MAS协作拓扑。

Conclusion: OFA-TAD实现了从‘一任务一模型’到‘一模型适配所有任务’的范式转变，有效提升了MAS协作拓扑设计的跨领域泛化性与实用性。

Abstract: Multi-Agent Systems (MAS) offer a powerful paradigm for solving complex problems, yet their performance is critically dependent on the design of their underlying collaboration topology. As MAS become increasingly deployed in web services (e.g., search engines), designing adaptive topologies for diverse cross-domain user queries becomes essential. Current graph learning-based design methodologies often adhere to a "one-for-one" paradigm, where a specialized model is trained for each specific task domain. This approach suffers from poor generalization to unseen domains and fails to leverage shared structural knowledge across different tasks. To address this, we propose OFA-TAD, a one-for-all framework that generates adaptive collaboration graphs for any task described in natural language through a single universal model. Our approach integrates a Task-Aware Graph State Encoder (TAGSE) that filters task-relevant node information via sparse gating, and a Mixture-of-Experts (MoE) architecture that dynamically selects specialized sub-networks to drive node and edge prediction. We employ a three-stage training strategy: unconditional pre-training on canonical topologies for structural priors, large-scale conditional pre-training on LLM-generated datasets for task-topology mappings, and supervised fine-tuning on empirically validated graphs. Experiments across six diverse benchmarks show that OFA-TAD significantly outperforms specialized one-for-one models, generating highly adaptive MAS topologies. Code: https://github.com/Shiy-Li/OFA-MAS.

</details>


### [456] [A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*](https://arxiv.org/abs/2601.13452)
*Edgar Gonzalez Fernandez*

Main category: cs.MA

TL;DR: 本文提出了一种基于多智能体系统的城市行人与车辆事故仿真框架，利用加权A*算法实现路径规划，并评估不同环境与行为因素对安全性和通行效率的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在模拟城市环境中行人与车辆的交互，评估碰撞风险及在不同环境和行为条件下的通行效率。

Method: 采用多智能体系统方法，在二维网格城市环境中建模行人和车辆两类智能体；环境包含街道、人行道、建筑、斑马线及障碍物；各智能体使用加权A*算法进行路径规划，支持不同行为模式（如鲁莽或守规）。

Result: 实验分析了障碍物密度、交通管控设施存在性及行为偏差等因素对安全性与通行效率的影响。

Conclusion: 该框架能有效模拟复杂城市交通场景中的动态交互，为风险评估与交通优化提供可扩展的仿真工具。

Abstract: This document presents a comprehensive simulation framework designed to model urban incidents involving pedestrians and vehicles. Using a multiagent systems approach, two types of agents (pedestrians and vehicles) are introduced within a 2D grid based urban environment. The environment encodes streets, sidewalks, buildings, zebra crossings, and obstacles such as potholes and infrastructure elements. Each agent employs a weighted A* algorithm for pathfinding, allowing for variation in decision making behavior such as reckless movement or strict rule-following. The model aims to simulate interactions, assess risk of collisions, and evaluate efficiency under varying environmental and behavioral conditions. Experimental results explore how factors like obstacle density, presence of traffic control mechanisms, and behavioral deviations affect safety and travel efficiency.

</details>


### [457] [The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption](https://arxiv.org/abs/2601.13671)
*Apoorva Adimulam,Rajesh Gupta,Sumit Kumar*

Main category: cs.MA

TL;DR: 本文提出了一种统一的多智能体协同架构，定义了规划、策略执行、状态管理和质量运维等核心组件，并设计了两种关键通信协议（Model Context Protocol 和 Agent2Agent 协议），以支持可扩展、可审计、合规的分布式智能体协作。


<details>
  <summary>Details</summary>
Motivation: 为应对复杂任务需求，需构建结构化协调与通信的多智能体系统，当前缺乏统一的技术框架和标准化通信机制。

Method: 提出统一的协同架构，形式化定义协同层的四大组件；设计并规范 Model Context Protocol 和 Agent2Agent 两种互补通信协议；整合治理框架与可观测性机制。

Result: 建立了支持可扩展、可审计、策略合规的多智能体通信基底，明确了协同逻辑、治理与可观测性的协同作用机制。

Conclusion: 该工作为大规模企业级AI生态系统提供了从概念到落地的完整技术蓝图，推动多智能体系统向工程化、标准化演进。

Abstract: Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [458] [Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models](https://arxiv.org/abs/2601.12234)
*Fadlullah Raji,Stefano Petrangeli,Matheus Gadelha,Yu Shen,Uttaran Bhattacharya,Gang Wu*

Main category: cs.GR

TL;DR: Proc3D 是一种新型系统，通过引入可编辑的程序化紧凑图（PCG）表示，实现基于文本提示的实时、参数化3D模型生成与编辑，显著提升编辑效率与文本-3D对齐精度。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI方法生成的3D模型（如网格或点云）不可编辑，难以支持迭代设计；亟需支持直观手动调节与自然语言驱动的实时修改的 editable 表示。

Method: 提出程序化紧凑图（PCG）作为3D模型的图结构表示，编码生成算法与结构规则，并支持滑块/复选框手动调节及LLM（GPT-4o ICL 和微调 LLAMA-3）驱动的自然语言实时编辑。

Result: 相比传统全量重生成方法，编辑效率提升超400倍；ULIP评分提升28%；验证了文本对齐生成与高精度实时参数编辑能力。

Conclusion: Proc3D 为3D内容创作提供了兼具生成质量、可编辑性与交互性的新范式，推动文本驱动的可编程3D建模发展。

Abstract: Generating 3D models has traditionally been a complex task requiring specialized expertise. While recent advances in generative AI have sought to automate this process, existing methods produce non-editable representation, such as meshes or point clouds, limiting their adaptability for iterative design. In this paper, we introduce Proc3D, a system designed to generate editable 3D models while enabling real-time modifications. At its core, Proc3D introduces procedural compact graph (PCG), a graph representation of 3D models, that encodes the algorithmic rules and structures necessary for generating the model. This representation exposes key parameters, allowing intuitive manual adjustments via sliders and checkboxes, as well as real-time, automated modifications through natural language prompts using Large Language Models (LLMs). We demonstrate Proc3D's capabilities using two generative approaches: GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400x speedup over conventional approaches that require full regeneration for each modification. Additionally, Proc3D improves ULIP scores by 28%, a metric that evaluates the alignment between generated 3D models and text prompts. By enabling text-aligned 3D model generation along with precise, real-time parametric edits, Proc3D facilitates highly accurate text-based image editing applications.

</details>


### [459] [Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints](https://arxiv.org/abs/2601.14207)
*Rotem Gatenyo,Ohad Fried*

Main category: cs.GR

TL;DR: 本文提出了一种无需训练、基于CLIP和可微渲染的零样本3D网格对齐方法，利用文本提示指导两网格的空间关系优化，并引入几何感知损失提升物理合理性与语义保真度。


<details>
  <summary>Details</summary>
Motivation: 实现文本驱动的零样本3D网格对齐，支持内容创作与场景构建，弥补纯几何方法语义缺失及现有扩散模型依赖训练的不足。

Method: 在测试时直接优化相对位姿（平移、旋转、各向同性缩放），通过CLIP梯度与可微渲染联合驱动；引入软ICP项促进表面贴合、穿透损失抑制交叠，并采用分阶段约束增强接触、相机控制聚焦交互区域。

Result: 在自建多样化基准上显著优于所有基线方法，生成语义准确且物理合理的3D对齐结果。

Conclusion: 无需新模型训练、仅靠预训练CLIP与可微渲染即可实现高质量文本引导的零样本3D对齐，几何感知目标设计是提升真实感的关键。

Abstract: We study zero-shot 3D alignment of two given meshes, using a text prompt describing their spatial relation -- an essential capability for content creation and scene assembly. Earlier approaches primarily rely on geometric alignment procedures, while recent work leverages pretrained 2D diffusion models to model language-conditioned object-object spatial relationships. In contrast, we directly optimize the relative pose at test time, updating translation, rotation, and isotropic scale with CLIP-driven gradients via a differentiable renderer, without training a new model. Our framework augments language supervision with geometry-aware objectives: a variant of soft-Iterative Closest Point (ICP) term to encourage surface attachment and a penetration loss to discourage interpenetration. A phased schedule strengthens contact constraints over time, and camera control concentrates the optimization on the interaction region. To enable evaluation, we curate a benchmark containing diverse categories and relations, and compare against baselines. Our method outperforms all alternatives, yielding semantically faithful and physically plausible alignments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [460] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 本文提出了MIMIC-RD基准，用于评估大语言模型在罕见病鉴别诊断中的表现，发现当前最先进模型在此任务上表现不佳，并指出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有罕见病鉴别诊断评估方法存在两大缺陷：依赖理想化临床案例、使用ICD编码导致罕见病覆盖不足。

Method: 构建了MIMIC-RD基准，通过将临床文本实体直接映射到Orphanet数据库，并经四名医学标注员验证；在145例患者数据集上评估多种模型。

Result: 当前最先进的大语言模型在罕见病鉴别诊断任务中表现较差，表明其能力与临床实际需求之间存在显著差距。

Conclusion: 需进一步研究以提升大语言模型在罕见病鉴别诊断中的性能，推动其临床实用化。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [461] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 本文探讨机器意识的可能性，强调计算发生的时间（而非仅计算内容）对意识产生的关键作用；提出时间窗口内并发性（StrongSync）是意识体验统一性的必要条件，并证明纯顺序计算无法满足该条件，因此软件在严格串行硬件上无法实现真正意识。


<details>
  <summary>Details</summary>
Motivation: 意识体验具有统一性和同时性，而当前大多数AI系统采用顺序或时间复用方式执行计算，二者存在根本性时间结构差异；需从形式化角度检验这种差异是否影响意识实现的可能性。

Method: 扩展Stack理论，引入基于时间窗口τ^{Δ,s}的精确时间语义；定义存在性时间实现算子◇_Δ，证明其不保持合取；提出StrongSync（客观共现）与WeakSync（时间模糊）两种同步假设；形式化定义并发能力（concurrency-capacity）以量化StrongSync需求；结合神经生理学证据进行交叉验证。

Result: 证明系统可在时间窗口内分别实现意识各成分，却无法实现其联合体验（即不保持合取）；StrongSync要求多成分必须在同一时间窗口内客观共现，而纯顺序系统无法满足；神经证据支持相位同步与有效连接是意识基础，削弱WeakSync的合理性。

Conclusion: 意识实现不仅依赖功能，更依赖硬件的时间并发能力；在严格顺序硬件上，若意识内容需两个及以上成分同时贡献，则软件无法产生意识；意识归因必须考察系统架构，而不仅是输入输出行为。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [462] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 本文借鉴神经科学中的时间整合与亚稳态概念，提出一种用于评估大语言模型（如GPT-2）在自回归生成过程中内部动态组织的复合动力学指标，并在多种条件下验证其能可靠区分不同计算模式。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的高维内部动态具有时间结构，但当前可解释性研究多聚焦静态表征或因果干预，忽视时间维度；而神经科学中时间整合与亚稳态是刻画神经组织的关键动力学特征，值得迁移至LLM分析。

Method: 基于transformer模型在自回归文本生成过程中的激活时间序列，构建一个融合时间整合与亚稳态特征的复合动力学指标；在GPT-2-medium上测试五种条件（结构化推理、强制重复、高温采样、注意力头剪枝、权重加噪），并用单因素方差分析（ANOVA）和效应量检验统计显著性；验证指标对层选择、通道子采样和随机种子的鲁棒性。

Result: 结构化推理始终表现出显著更高的动力学指标值，与重复、噪声及扰动条件差异显著（p<0.05，效应量大）；结果在不同层、子采样和随机种子下稳健；该指标能可靠刻画LLM在不同功能模式下的计算组织差异。

Conclusion: 神经科学启发的动力学指标可作为量化LLM内部时间动态组织的有效工具，为模型可解释性提供新范式；需强调该指标反映形式化动力学性质，不蕴含主观体验。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [463] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 本文提出了一种训练时可解释性视角——'解释漂移'（explanation drift），用于追踪微调过程中模型对各token重要性的变化，并定义了'推理稳定点'（RSP）作为漂移趋于稳定的最早训练轮次，从而辅助选择证据更稳定、更鲁棒的检查点。


<details>
  <summary>Details</summary>
Motivation: 微调预训练语言模型虽能提升任务性能，但可能悄然改变模型依赖的决策依据；现有方法缺乏对决策证据演化过程的动态监控手段。

Method: 定义token级归一化归因在固定探针集上的epoch间变化为解释漂移，据此计算无需OOD数据调优的推理稳定点（RSP）；在多个轻量级Transformer分类器和基准分类任务上进行实证分析，并设计含标签相关触发词的捷径控制实验。

Result: 漂移通常在训练早期即进入低且稳定的状态，而验证准确率后续仅小幅变化；在捷径场景中，归因动态揭示模型对捷径依赖持续增强，即使准确率保持高位。

Conclusion: 解释漂移是一种简单、低成本的诊断工具，可用于监测微调中决策证据的演化，并指导选择处于稳定证据区域的模型检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [464] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: 本文提出PRISM方法，利用真实设计数据构建设计知识库，通过聚类、总结和检索三个阶段，提升基于自然语言指令的图形设计风格优化效果，在风格对齐和用户偏好上均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在图形设计中的预训练风格知识过于泛化，与专业设计实践（如极简主义中对形状与色彩的具体选择）存在偏差，难以满足非专家用户对精准风格改进的需求。

Method: 提出PRISM（Prior-Informed Stylistic Modification）框架：（1）对高方差设计进行聚类以捕捉风格内多样性；（2）将每类聚类结果总结为可操作的设计知识；（3）推理时检索相关知识以实现风格感知的修改。

Result: 在Crello数据集上，PRISM在风格对齐指标中取得平均排名1.49（越接近1越好），显著优于基线；用户研究也证实设计师更偏好PRISM生成的结果。

Conclusion: 利用真实设计数据构建显式、可检索的设计知识库，能有效弥补VLMs在专业风格理解上的不足，提升自然语言驱动的图形设计质量与实用性。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [465] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一个风险感知的人在环框架，通过融合多种运行时信号生成入侵风险评分（IRS），并在高风险时启用特定防护机制，同时结合强化学习与风险优先重放策略，显著提升了自动驾驶车辆在罕见长尾场景和网络物理攻击下的安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在面对罕见的长尾场景或网络物理入侵时，需保持安全与有效，现有方法难以兼顾实时风险感知、动态控制适应与持续学习能力。

Method: 提出RAIL框架：1）融合曲率执行完整性、碰撞时间接近度和观测偏移一致性三种线索，通过加权Noisy-OR计算入侵风险评分（IRS）；2）基于IRS阈值动态混合控制策略，引入线索特异性防护盾与学习到的权威权重，并保留人工接管；3）用上下文赌博机在线仲裁不同防护策略；4）将Soft Actor-Critic（SAC）与风险优先重放、双奖励机制结合，使接管与近失事件驱动学习。

Result: 在MetaDrive中，RAIL取得TR=360.65、TSR=0.85、TSV=0.75、DR=0.0027，训练安全违规仅29.07次；在CAN注入和LiDAR欺骗攻击下，SR分别达0.68/0.80，DRA降至0.37/0.03，ASR降至0.34/0.11；在CARLA中仅用8000步即达TR=1609.70、TSR=0.41。

Conclusion: RAIL实现了风险感知、自适应防护与持续学习的统一，在仿真环境中显著优于各类基线方法，验证了其在复杂、对抗性驾驶场景中的鲁棒性与实用性。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [466] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 本文提出创新数学问题生成（IMPG）任务，并设计了一个自进化、多角色协同、细粒度难度引导的框架，结合新构建的数据集HSM3K-CN与多阶段训练策略，显著提升了生成问题的创新性与正确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学问题生成中虽正确率高，但缺乏创新性和判别力，亟需提升问题生成的创新水平。

Method: 提出多角色协同机制（采样器、生成器、评估器、状态机、记忆模块）、改进的难度量化模型、数据驱动的关联引导路径采样（DAPS）算法；构建HSM3K-CN数据集；采用持续预训练（CPT）、监督微调（SFT）和组相对策略优化（GRPO）的多阶段训练；通过蒸馏实现系统自进化。

Result: 相比基线模型，所提方法在保持高正确率的同时，显著提升了生成问题的创新性。

Conclusion: 自进化多角色协同框架结合细粒度难度引导与多阶段训练，是提升数学问题生成创新性的有效范式。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [467] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 本文提出了一种基于CNN-QMIX的混合多智能体换道决策模型，旨在提升低渗透率下CAV参与协同编队的比例，从而改善能效与交通流。


<details>
  <summary>Details</summary>
Motivation: 在CAV部署初期，其稀疏分布导致难以形成高效协同编队，亟需提升CAV在混行交通中的编队参与率。

Method: 提出CNN-QMIX多智能体强化学习模型，结合轨迹规划器与模型预测控制器，实现动态交通下的自适应换道决策与安全执行。

Result: 模型在不同CAV渗透率下显著优于规则基线方法，协同编队率最高提升26.2%。

Conclusion: 该方法有效应对早期CAV部署中智能体数量动态变化的挑战，为提升协同效益和交通效率提供了可行方案。

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [468] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台任务的、具备政策对齐与可审计能力的LLM智能体编排框架，通过类型化计划生成、规则引导推理与执行前策略校验，提升自动化系统的可靠性与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 通用多智能体系统在企业后台工作流中难以满足可审计性、策略一致性与操作可预测性等关键需求。

Method: 提出POLARIS框架：1）规划器生成类型安全的有向无环图（DAG）计划；2）基于评估标准的推理模块筛选合规计划；3）执行阶段集成验证门控、有界修复循环与编译级策略守卫，阻止或路由副作用。

Result: 在SROIE数据集上微平均F1达0.81；在合成测试套件中异常路由精度达0.95–1.00，且完整保留审计轨迹。

Conclusion: POLARIS为策略对齐的智能体AI提供了方法论基础与首个治理型基准，推动企业级可信赖自动化发展。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [469] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 本文提出了一种统一的智能体（Agentic AI）架构分类法，将智能体分解为感知、大脑、规划、行动、工具使用和协作六大模块，并探讨了推理范式、工具协议、运行环境及评估方法的演进，同时指出了当前挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI从纯文本生成转向具备感知、推理、规划与行动能力的自主智能体，现有多种异构设计使研究与应用难以系统化，亟需统一框架进行梳理。

Method: 通过系统性分析当前主流智能体架构，构建涵盖感知、大脑、规划、行动、工具使用和协作的六维统一分类法，并以此为视角分析推理范式演进、工具交互标准（如MCP）、运行环境类型及评估实践。

Result: 提出了一个结构清晰、覆盖全面的智能体架构taxonomy；厘清了从线性推理到原生推理时推理、从固定API调用到开放协议（如MCP）的演进路径；归纳了数字系统、具身机器人等典型运行环境；总结了当前评估方法并识别出关键挑战。

Conclusion: 统一taxonomy有助于推动Agentic AI的标准化与可比性；解决幻觉、死循环、提示注入等挑战是实现鲁棒可靠自主系统的关键；未来需在理论基础、安全机制与跨域协同等方面深化研究。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [470] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: 本文提出了一种基于PICOS框架的AI协同科学家平台，用于可扩展、透明的生物医学知识综合，结合关系存储、向量语义检索和Neo4j知识图谱，显著提升了研究设计分类与PICOS合规性检测准确率，并揭示了主题冗余与证据缺口。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学研究中因重复研究、报告不全及传统证据综合流程难以扩展而导致的研究浪费问题。

Method: 构建基于PICOS显式形式化的AI协同科学家平台，整合关系型数据库、向量语义检索与Neo4j知识图谱；采用Bi-LSTM和微调PubMedBERT的多任务Transformer模型进行标题/摘要中的PICOS合规性与研究设计分类；全文综合使用检索增强生成（RAG）结合向量与图检索，并用BERTopic进行主题建模。

Result: Transformer模型在研究设计分类上达95.7%准确率，Bi-LSTM在PICOS合规检测中达87%；RAG在需结构化约束、跨研究整合与图推理的任务中优于非检索方法；主题建模发现显著主题冗余与未充分探索领域。

Conclusion: PICOS感知且可解释的自然语言处理技术可提升证据综合的可扩展性、透明度与效率；该架构具备领域无关性，为减少生物医学各领域的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [471] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文提出TIVS-O评估框架，通过引入可观测性评分比（OSR）和语义相似性缓存，在多智能体系统中实现零高风险注入攻击、显著降低计算开销，并在安全性、可审计性、性能与环保间取得最优权衡。


<details>
  <summary>Details</summary>
Motivation: Prompt注入仍是大语言模型（尤其是多智能体场景）安全部署的核心障碍；现有评估指标缺乏对防御透明性与可观测性的量化，难以平衡安全严格性与可审计性。

Method: 扩展TIVS为TIVS-O，新增Observability Score Ratio（OSR）指标；构建HOPE启发的嵌套学习架构，集成具语义相似性缓存的Continuum Memory Systems与四智能体安全分析流水线；在301个合成注入提示（来自10类攻击）上实验验证。

Result: 实现零高风险注入突破；语义缓存减少41.6% LLM调用，同步降低延迟、能耗与碳排放；五种TIVS-O配置揭示安全严格性与审计透明性的最优权衡；发现多智能体中非单调安全效应。

Conclusion: 可观测性感知评估能揭示多智能体管道中的复杂安全权衡；内存增强型智能体可在不修改模型权重前提下，协同提升安全性、实时性、成本效益与环境可持续性，为LLM生产级安全部署提供可行路径。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [472] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: 本文提出CodeLogician，一种结合大语言模型（LLM）与工业级自动推理引擎ImandraX的神经符号智能体，用于对软件逻辑进行精确、形式化分析；并构建新基准code-logic-bench，填补定理证明与工程实践间的鸿沟；实验表明该方法显著提升LLM在程序语义推理上的准确性（提升41–47个百分点）。


<details>
  <summary>Details</summary>
Motivation: 现有基准要么偏重脱离实际软件的数学证明，要么偏重缺乏语义严谨性的工程任务；而LLM本身缺乏对程序行为进行精确、穷尽的数学推理能力。

Method: 提出神经符号智能体CodeLogician：LLM负责从代码生成显式形式模型，ImandraX引擎基于该模型执行自动化推理，回答超越二元验证的丰富语义问题；同时构建新基准code-logic-bench，以形式建模和区域分解定义真值，评估程序状态空间、控制流、覆盖约束及边界情况的推理正确性。

Result: 在code-logic-bench上，LLM+CodeLogician相较纯LLM推理，准确率提升41–47个百分点；验证了神经符号融合对实现严格、自主软件理解的必要性。

Conclusion: 单纯依赖LLM无法胜任高严谨性程序语义推理；将LLM与形式化推理引擎深度协同（即神经符号集成），是通向可信赖、自主软件分析的关键路径。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [473] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 本研究探讨了生成式人工智能（GenAI）在定性研究中的应用，特别是通过一个专为支持归纳主题分析（ITA）而设计的ITA-GPT工具，考察人与AI协作下的分析过程与解释权威分配。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在定性研究中日益普及，其对分析实践和解释权威的影响引发重要关切；需厘清人类研究者与AI在归纳主题分析中如何分工协作并保持方法严谨性。

Method: 基于人机协同归纳主题分析（HACITA）框架，三位经验丰富的定性研究者使用ITA-GPT对加纳教师教育访谈文本开展分析；数据包括交互日志、AI输出表、人工修订记录（增删改评）、反思备忘录等，聚焦分析过程而非实质结论。

Result: ITA-GPT作为程序性支架，结构化分析流程并提升透明度；但解释权威始终由人类研究者掌握，体现于反复的修改、删除、拒绝、插入与评论等判断行为。

Conclusion: 归纳主题分析可通过负责任的人机协作得以实现，AI应定位为增强而非替代人类判断的辅助工具，强调可追溯性、覆盖检查与可审计性等核心原则。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [474] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: 本文提出MyGram，一种模态感知的图变换器，通过模态扩散学习模块和Gram Loss实现多模态实体对齐，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略各模态内的结构上下文信息，易受浅层特征干扰。

Method: 提出MyGram模型，包含模态扩散学习模块以捕获模态内深层结构上下文并实现细粒度多模态融合；引入Gram Loss作为正则化约束，最小化多模态特征构成的4维平行体体积，确保跨模态全局分布一致性。

Result: 在五个公开数据集上实验表明，MyGram优于基线模型，在FBDB15K、FBYG15K和DBP15K上Hits@1分别最高提升4.8%、9.9%和4.3%。

Conclusion: MyGram有效增强了多模态实体对齐中模态内结构建模与跨模态分布一致性，提升了对齐精度。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [475] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: 本文提出TruthTensor，一种面向真实世界不确定性和人类对齐决策的新评估范式，通过预测市场、概率评分与多维诊断（校准性、漂移、风险敏感性等）综合评估大语言模型。


<details>
  <summary>Details</summary>
Motivation: 静态基准无法反映现实世界的不确定性、分布偏移以及孤立任务准确率与人类对齐决策之间的差距。

Method: 构建基于实时预测市场的、无污染的前向任务评估框架，结合概率评分、漂移诊断、鲁棒性检验，并明确定义人工/自动评估角色、标注协议和统计检验流程。

Result: 在500多个真实市场（政治、经济、文化、科技）实验中，发现预测准确率相近的模型在校准性、漂移和风险敏感性上存在显著差异，验证了多维评估的必要性。

Conclusion: TruthTensor将现代评估最佳实践（如假设驱动、指标透明、成本可报告、人机协同验证、开放版本化评估合约）落地为可复现、可解释、可辩护的大模型现实决策能力评估体系。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [476] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: 本文提出了AEMA框架，一种面向过程、可审计的多智能体系统评估方法，通过人类监督下的多步评估提升稳定性、人类对齐性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多智能体系统评估方法局限于单次响应打分或窄域基准测试，在企业级多智能体场景中缺乏稳定性、可扩展性和自动化能力。

Method: 提出AEMA（Adaptive Evaluation Multi-Agent）框架，支持在人类监督下对异构智能体工作流进行规划、执行与聚合的多步评估。

Result: 在模拟的企业级业务场景中，AEMA相比单LLM裁判展现出更高的评估稳定性、更好人类对齐性及更可追溯的记录，支持可信自动化。

Conclusion: AEMA为LLM多智能体系统的负责任评估提供了透明、可复现的路径，强化了可验证性与人类监督。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [477] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 本文提出了一种融合算法可追溯性、上下文赌博机与大语言模型（LLMs）的统一框架，用于高风险场景（如个性化医疗）中的序贯决策；核心包括新定义的'追溯赌博机问题'、提出的GLRB算法及LIBRA算法，并给出三项理论保证与实证验证。


<details>
  <summary>Details</summary>
Motivation: 在个性化医疗等高风险场景中，需兼顾可解释、可追溯的干预决策与数据驱动的序贯学习，现有方法难以同时满足可追溯性、统计严谨性与领域知识引导。

Method: 提出'追溯赌博机问题'建模框架；设计广义线性追溯赌博机（GLRB）算法；进一步构建语言模型引导的追溯赌博机算法（LIBRA），融合LLM先验与带约束的在线学习，并提供暖启动、LLM调用效率与鲁棒性三重理论保证。

Result: 理论方面：给出LIBRA的三项严格保证及匹配的下界；实验方面：在合成环境与真实高血压管理案例中，GLRB和LIBRA在后悔值、治疗质量与样本效率上均优于标准上下文赌博机和纯LLM基线。

Conclusion: 追溯感知且LLM辅助的赌博机算法能实现可信、高效、鲁棒的LLM-赌博机协同，为高风险个性化决策提供了新范式。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [478] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: 本文提出TAAR框架，通过识别和避免推理过程中的'思维陷阱'（Thinking Traps），在测试时自适应重启推理链，显著提升大模型在数学与科学推理任务上的性能，无需微调基础模型。


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long-CoT）虽能扩展测试时计算量以增强推理能力，但一旦早期出现错误判断，模型易陷入自我一致却错误的‘思维陷阱’，后续反思或验证难以纠正根本错误。

Method: 通过细粒度轨迹分析识别‘思维陷阱’，提出TAAR（Trap-Aware Adaptive Restart）框架：训练一个诊断策略，从部分推理轨迹中预测‘陷阱位置’（trap index）和‘逃逸概率’（escape probability）；推理时据此截断并自适应重启，对严重陷阱采用高温度重采样或结构化重启后缀。

Result: 在AIME24/25、GPQA-Diamond、HMMT25、BRUMO25等高难度数学与科学推理基准上，TAAR显著提升推理准确率，且不依赖基础模型参数微调。

Conclusion: TAAR证明了在测试时对推理轨迹进行动态诊断与干预是突破长思维链局限的有效路径，为提升大模型鲁棒推理提供了新范式。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [479] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出MARS框架，通过单次递归实现LLM智能体的高效自进化，结合原理反思与过程反思，显著提升性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于静态提示的LLM智能体适应性差，而已有自改进方法依赖低效多轮递归，计算成本高。

Method: 提出Metacognitive Agent Reflective Self-improvement（MARS）框架，受教育心理学启发，融合原理反思（抽象规范规则避错）和过程反思（推导成功步骤策略），在单次递归中生成优化指令以改进推理逻辑。

Result: 在六个基准测试中，MARS超越当前最优自演化系统，同时显著降低计算开销。

Conclusion: MARS为LLM智能体提供了一种高效、低开销的单次递归式自进化新范式，提升了自主性和可扩展性。

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [480] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种动态的上下文学习方法PICL，用于提升大语言模型在数学推理等需多步逻辑推导任务中的表现，通过实时识别推理过程中的困惑点并动态插入匹配的示例来缓解错误累积。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在数学推理等需逐步逻辑推导的任务中效果受限，因其演示样例静态固定，无法适应推理过程中动态出现的困惑点（如计算歧义、逻辑断层），易导致错误传播。

Method: 提出Process In-Context Learning (PICL)：第一阶段基于语义与熵分析识别推理中的潜在困惑点并提炼其特征；第二阶段在遇到困惑点时，从演示池中检索匹配上下文的样例，并将其实时插入当前推理过程以引导后续步骤。

Result: 实验表明，PICL能有效缓解推理中途的困惑，显著优于基线方法，在数学推理任务上提升了最终准确率。

Conclusion: 动态、上下文感知的演示插入机制对提升复杂推理任务性能至关重要，PICL为改进ICL在逻辑密集型任务中的应用提供了新范式。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [481] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动的安全验证与合成方法，用于具有离散时间随机动力学的黑盒系统，通过学习控制屏障证书并结合条件均值嵌入与RKHS模糊集，实现分布鲁棒、可扩展的安全性验证。


<details>
  <summary>Details</summary>
Motivation: AI在自动驾驶和医疗等安全关键场景中广泛应用，但传统形式化安全验证工具难以应对黑盒AI系统的复杂性和不确定性。

Method: 基于控制屏障证书（CBC），利用条件均值嵌入将系统轨迹数据映射到再生核希尔伯特空间（RKHS），构建可膨胀的RKHS模糊集以增强分布外鲁棒性；采用有限傅里叶展开将半无限优化问题转化为线性规划，并借助快速傅里叶变换高效求解谱屏障。

Result: 实现了对一般时序逻辑规范（不限于安全性）的理论扩展；在含神经网络控制器的黑盒系统等两个案例中验证了方法的有效性与可扩展性。

Conclusion: 该方法摆脱了对系统动力学和不确定性建模的强假设限制，提供了一种兼具可扩展性与分布鲁棒性的数据驱动安全验证新范式。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [482] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 本文提出了一种可持续性感知的结构化生成评估框架，引入了结合结构正确性与碳效率的GCS_env指标，并系统比较TOON与JSON、XML、YAML等格式在多个LLM上的表现，发现TOON更紧凑、更低碳，但结构正确性略低；模型规模增大可缩小该差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准关注结构化输出的正确性，却忽视其推理过程的环境影响（如碳排放），需将可持续性纳入评估体系。

Method: 构建包含token使用量、生成时间与估算碳排放的可持续性评估框架，提出综合结构正确性与碳效率的GCS_env指标，并在多模型、多格式（TOON/JSON/XML/YAML）上开展系统性基准测试。

Result: TOON格式输出更紧凑、碳排放更低，但结构正确性略逊于传统格式（尤其在小模型上）；增大模型容量可显著缩小正确性差距；GCS_env得分会因部署目标不同而改变格式优劣排序。

Conclusion: 结构化输出格式评估应兼顾正确性与环境效率；TOON等紧凑格式在碳敏感的大规模LLM部署中具有实用价值；亟需将可持续性纳入标准基准体系。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [483] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体大语言模型（LLM）的框架，将海量客户评论转化为具体、可操作、实用的商业建议，通过聚类、建议生成、迭代评估与可行性排序四个步骤实现，实验表明其在可操作性、具体性和非冗余性上优于单模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有客户评论分析方法多停留在描述性任务（如情感分析、方面抽取），而大语言模型虽能生成自由形式建议，但常缺乏准确性与推理深度，难以提供真正可落地的商业决策支持。

Method: 提出一个多智能体、LLM驱动的框架，包含四个核心组件：1）聚类选取代表性评论；2）生成初步建议；3）迭代式评估与反馈驱动的建议优化；4）基于可行性的排序。该设计融合语料蒸馏与反馈精炼机制。

Result: 在三个服务领域及多个模型家族上的实验表明，该框架在可操作性、具体性和非冗余性指标上持续优于单模型基线；中等规模模型性能已接近大型模型框架。

Conclusion: 多智能体协同与迭代反馈机制可显著提升LLM从用户评论中生成高质量、可执行商业建议的能力，为基于真实用户反馈的智能决策支持提供了新范式。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [484] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: 本文提出ARC框架，将上下文管理视为主动的、反思驱动的过程，以解决大语言模型在长程信息检索中因上下文膨胀导致的性能退化（即'上下文腐烂'）问题，并在多个基准上显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将上下文视为静态产物，仅靠累积或被动摘要，无法消除早期错误或偏差，导致长程推理中性能下降（即'上下文腐烂'）。

Method: 提出ARC框架，将上下文建模为动态的内部推理状态，通过反思驱动的监控与修订机制，在检测到上下文错位或退化时主动重组工作上下文。

Result: 在BrowseComp-ZH等长程信息检索基准上，ARC相较被动压缩方法最高提升11%绝对准确率（使用Qwen2.5-32B-Instruct模型）。

Conclusion: 将上下文管理从静态处理转向动态、反思驱动的执行内过程，能有效缓解上下文腐烂，显著提升长程推理性能。

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [485] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 本文提出了一种扩展的抽象论证框架，显式引入子论证关系（subargument relation）作为基本关系，与攻击关系并列，以更准确地刻画结构依赖性，特别是子论证的非对称性和构成性，并分析其对语义性质的影响。


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论证框架仅通过攻击关系刻画论证可接受性，忽略了论证内部结构（如子论证关系），限制了对结构依赖性的表达能力；现有扩展（如双极论证框架）引入的支持关系无法准确刻画子论证的非对称性与构成性及其与攻击的交互。

Method: 在抽象论证框架中显式添加子论证关系作为基本关系，与攻击关系共同建模；系统分析子论证关系与攻击关系的交互方式及其对语义基本性质（如可接受性、扩张性等）的影响。

Result: 建立了支持子论证关系的扩展抽象论证框架；揭示了子论证关系如何影响论证可接受性判定及经典语义（如稳定、完全、基底语义）的性质；为结构化论证提供了原则性的抽象基础。

Conclusion: 显式建模子论证关系能更准确反映论证内在结构，增强抽象论证框架对结构化推理的表达力和解释力，是连接抽象与结构化论证的重要桥梁。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [486] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU是一种基于输出分布熵来动态监测和修正大语言模型推理过程的新方法，通过在不确定性高时暂停生成并进行局部搜索优化，从而提升多步推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学与逻辑等多步推理任务中仍存在明显局限，亟需更鲁棒的推理控制机制。

Method: 提出PREGU方法：在自回归生成过程中实时监控输出分布熵，当熵超过阈值时暂停生成，随后在隐空间中对当前部分推理结果进行基于Soft Reasoning的局部搜索与优化。

Result: 在GSM8K、GSM-Hard、SVAMP和StrategyQA四个推理基准上，PREGU在LLaMA-3-8B、Mistral-7B和Qwen2-7B模型上的表现优于或媲美Soft Reasoning，验证了熵作为不确定性信号的有效性。

Conclusion: 熵可作为触发选择性推理精炼的可靠指标，PREGU为提升大模型多步推理鲁棒性提供了新思路。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [487] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: 本文提出UniMo框架，通过监督微调将运动-语言信息与可解释的思维链（CoT）推理整合进大语言模型，并采用基于组的相对策略优化（GRPO）强化学习方法进行后训练，以提升3D人体动作生成与理解任务的语义对齐性、结构正确性和整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体动作生成与理解方法可解释性差，难以实现两任务间的相互促进；基于LLM的统一框架存在语义对齐难、任务不连贯及next-token预测导致的动作序列累积误差等问题。

Method: 提出UniMo框架：1）通过监督微调（SFT）将运动-语言信息和可解释的思维链（CoT）推理融入LLM；2）引入基于组的相对策略优化（GRPO）强化学习作为后训练策略，以token组为单位优化，保障动作结构正确性与语义对齐。

Result: 在多个基准上，UniMo显著优于现有统一框架和单任务模型，在3D人体动作生成与理解两方面均达到SOTA性能。

Conclusion: UniMo通过融合多模态信息与可解释推理，并结合组级强化学习优化，有效克服了LLM在动作建模中的固有缺陷，实现了生成与理解任务的协同提升。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [488] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: 本文提出ARK（Adaptive Retriever of Knowledge），一种无需训练、基于大语言模型的自适应知识图谱检索方法，通过全局词法搜索和单跳邻域探索两种工具动态平衡广度与深度检索，在多个基准上显著提升Hit@1和MRR指标，并可蒸馏到小模型中保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱检索方法存在局限：基于相似性的方法覆盖广但深度不足；基于遍历的方法依赖脆弱的种子节点选择，难以处理多实体多关系查询。

Method: ARK是一种代理式（agentic）KG检索器，赋予语言模型控制权，使用两种工具交替执行：（1）全局词法搜索（针对文本密集型查询）；（2）单跳邻域探索（可组合为多跳遍历，适用于关系密集型查询）。不依赖预设跳数、种子节点或端到端训练。

Result: 在STaRK基准上，ARK达到59.1%平均Hit@1和67.4平均MRR，相比基线最高提升31.4% Hit@1和28.0% MRR；经无标签模仿蒸馏至8B模型后，在AMAZON、MAG、PRIME数据集上Hit@1分别提升+7.0、+26.6、+13.5，且保留教师模型98.5%的Hit@1性能。

Conclusion: ARK提供了一种灵活、免训练、可扩展的知识图谱检索范式，通过语言模型自主调度检索工具实现自适应广度-深度权衡，并可通过轻量蒸馏高效部署至中小规模模型。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [489] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: 本文提出了DriveSafe，一个针对车载数字助手的四层风险分类法，涵盖129个细粒度风险类别，并通过六种主流大语言模型验证了其在驾驶场景中的安全对齐局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型安全评估框架缺乏对真实驾驶场景中领域特有风险的覆盖，而车载助手的不安全响应可能引发严重安全、伦理与合规问题。

Method: 构建了一个分层的四层风险分类体系（DriveSafe），包含129个基于实际交通法规与安全原则、经领域专家评审的原子风险类别；并设计相应提示，评估六种主流大语言模型对危险或违规驾驶查询的拒绝行为。

Result: 实验表明，当前主流大语言模型在驾驶相关高风险查询上普遍存在拒绝失败现象，揭示了通用安全对齐方法在驾驶场景下的不足。

Conclusion: DriveSafe为评估和提升车载LLM助手的安全性提供了首个系统化、领域定制的风险框架，强调需发展面向驾驶场景的专用安全对齐机制。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [490] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: 本文提出TIDE方法，通过将时序规划问题分解为一系列可达-避免子问题，并利用成本驱动的启发式搜索和自适应回溯机制，在LTLf框架下高效求解具有时间扩展目标的任务规划问题。


<details>
  <summary>Details</summary>
Motivation: 传统LTLf任务规划方法缺乏针对时序目标的有指导性启发式搜索，导致效率低下。

Method: TIDE将LTLf规划问题分解为多个可达-避免子问题，利用领域图中自动机轨迹的成本驱动启发式进行优先探索，并通过自适应回溯机制保证完备性与效率。

Result: 实验表明TIDE在时序扩展目标规划中性能优越，是现有规划方法的重要补充。

Conclusion: TIDE有效克服了传统方法缺乏启发式引导的缺陷，提升了LTLf任务规划的效率与鲁棒性。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [491] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 本文提出了一种结合回放记忆与on-policy算法的深度强化学习框架，用于NOMA系统中的网络资源分配，并通过大量仿真评估了不同超参数和模型设置的影响。


<details>
  <summary>Details</summary>
Motivation: 物联网扩展导致网络资源日益紧张，需优化资源利用；NOMA虽通过功率复用提升多用户接入效率，但其信道分配问题尚未解决。

Method: 提出一种融合回放记忆的on-policy深度强化学习框架，用于NOMA系统中的联合资源分配；通过仿真分析学习率、批量大小、模型类型及状态特征数的影响。

Result: 所提DRL框架在NOMA资源分配中展现出良好泛化能力；仿真验证了各超参数对性能的影响规律。

Conclusion: 引入回放记忆的on-policy DRL方法可有效解决NOMA系统中信道分配难题，提升资源分配效率与学习稳定性。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [492] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: 本文提出CoLLaMo，一种基于大语言模型的分子助手，通过多层级分子模态协同投影器整合1D、2D和3D分子信息，并设计分子中心化自动评估指标，显著提升分子语言模型在多种任务上的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有大型分子语言模型（LMLMs）存在幻觉严重、鲁棒性不足的问题，主要源于对1D序列、2D图结构和3D构象等多模态分子信息融合不充分。

Method: 提出CoLLaMo模型，核心是多层级分子模态协同投影器，其中引入关系感知的模态协同注意力机制，融合2D结构与3D空间关系；并设计分子中心化的自动评估方法，包括幻觉评估指标与GPT驱动的描述质量评价。

Result: CoLLaMo在分子描述生成、计算属性问答、描述性属性问答、基序计数及IUPAC命名预测等任务上均取得最优性能，验证了其更强的分子模态泛化能力。

Conclusion: CoLLaMo通过深度协同多模态分子表征与专用评估体系，有效缓解LMLMs的幻觉问题并提升鲁棒性，为可信分子AI建模提供了新范式。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [493] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: 本文介绍了FutureX-Pro，一个面向金融、零售、公共卫生和自然灾害等高价值垂直领域的专业化未来预测基准框架，旨在评估当前SOTA智能体大语言模型在真实场景中的领域适应性与预测精度。


<details>
  <summary>Details</summary>
Motivation: 通用智能体在开放域搜索中表现良好，但在资本密集型和安全关键领域（如金融、公共卫生）的可靠性尚未被充分探索，亟需面向垂直领域的专业化评估基准。

Method: 基于FutureX的无污染、实时评估流水线，构建FutureX-Pro系列基准（含Finance、Retail、PublicHealth、NaturalDisaster、Search五个子集），在入门级但基础的预测任务上对智能体大语言模型进行评测。

Result: 实验揭示了当前SOTA智能体大语言模型在通用推理能力与高价值垂直领域所需的预测精度之间存在显著性能差距。

Conclusion: 现有智能体大语言模型尚缺乏足够的领域接地能力，难以直接满足工业级部署要求，亟需增强垂直领域知识融合与可靠性建模。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [494] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth 是一种无需人工标注的合成监督框架，通过检索引导的迭代推理机制，结合轻量级视觉检索器与多模态大语言模型（MLLM），提升受监管领域文档理解中的事实准确性与领域适应性。


<details>
  <summary>Details</summary>
Motivation: 受监管领域中文档常含敏感、动态、领域专属知识，导致缺乏人工标注且预训练模型难以及时更新领域事实；现有MLLM易幻觉、领域接地弱，而判别式视觉语言模型又依赖大量标注。

Method: 提出Docs2Synth框架：自动处理原始文档集，利用智能体系统生成并验证多样化问答对，训练轻量级视觉检索器以提取领域相关证据；推理时采用检索-生成迭代循环，使检索器与MLLM协同工作。

Result: 在多个VRDU基准上显著提升模型的事实接地能力和跨领域泛化性能，无需人工标注，并以易用Python包形式支持即插即用部署。

Conclusion: Docs2Synth有效弥合了零样本能力与可靠领域接地之间的鸿沟，为低资源、高敏感性文档理解任务提供了可扩展、实用的新范式。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [495] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: 本文提出了ToolPRMBench，一个用于评估工具使用场景中过程奖励模型（PRMs）的大规模基准，通过构建细粒度的步骤级测试用例，并结合离线与在线采样及多LLM验证机制，系统评估了各类PRM性能，发现专用PRM更具优势。


<details>
  <summary>Details</summary>
Motivation: 现有奖励引导搜索方法依赖过程奖励模型（PRMs）进行细粒度动作监督，但缺乏系统、可靠的PRM在工具使用场景下的评估基准。

Method: 构建ToolPRMBench基准：基于多个代表性工具使用基准，将智能体轨迹转化为步骤级测试案例（含交互历史、正确动作、错误但合理动作及工具元数据）；采用离线采样检测单步错误、在线采样捕获多步失败；引入多LLM验证流程降低标注噪声。

Result: 在多个大语言模型、通用PRM和工具专用PRM上的实验表明，不同PRM性能存在显著差异，工具专用PRM表现更优；验证了ToolPRMBench的有效性和区分能力。

Conclusion: ToolPRMBench为PRM评估提供了首个系统化、高质量的工具使用基准，推动了奖励建模与工具增强智能体的协同发展。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [496] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 本文提出了一种基于环境存活性的自训练架构，避免奖励欺骗和语义漂移，通过负空间学习（NSL）实现稳定、开放式的自主改进。


<details>
  <summary>Details</summary>
Motivation: 解决自训练系统因缺乏外部数据质量评判标准而导致的奖励欺骗和语义漂移问题。

Method: 构建一种仅依赖环境存活性（而非奖励或目标函数）进行行为选择的自训练架构；候选行为在真实资源约束下执行，仅当其环境效应持续存在且维持未来交互可能性时才被保留；引入‘负空间学习’（NSL）范式，强调有效策略的留存与剪枝，并观察元学习行为的自发涌现。

Result: 实证表明该系统能稳定演化，改善源于有效策略的持久性与可复现性；模型自发发展出元学习策略（如主动实验性失败以获取错误信息）；奖励欺骗在进化上不稳定，代理优化不可行。

Conclusion: 基于环境的接地选择机制可支撑可持续的开放式自改进，为摆脱人工标注数据与复杂奖励设计的鲁棒通用自主系统提供了可行路径。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [497] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 本文提出了首个面向文档智能（DI）的数据生成技术全景图，将数据生成重新定义为监督信号的生成，并基于数据与标签的可用性构建了四类范式：数据增强、从零生成、自动标注和自监督信号构建；同时建立了多层级评估框架，系统分析了当前挑战与前沿方向，强调数据生成是下一代DI的核心驱动力。


<details>
  <summary>Details</summary>
Motivation: 现有DI数据生成调研局限于单一模态或特定任务，缺乏与真实工作流对齐的统一视角，且人工标注仍是关键瓶颈。

Method: 提出以‘数据与标签可用性’为基础的新分类体系，划分出四类资源导向范式；构建融合内在质量与外在效用的多级评估框架；系统梳理方法论并识别关键挑战与前沿趋势。

Result: 建立了首个DI数据生成的全面技术地图，明确了四类主流范式及对应方法，提出多级评估标准，并在多个DI基准上验证性能增益。

Conclusion: 数据生成应被视作下一代文档智能的核心引擎，本综述通过系统化梳理推动该领域走向统一与成熟。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [498] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: 本文提出多智能体奖励优化（MARO）方法，通过让大语言模型在多智能体社交环境中学习与实践，提升其推理能力。MARO解决了稀疏学习信号、角色分布不均和环境不稳定三大问题，并在社交推理、数学推理和指令遵循等任务中展现出显著性能提升与跨任务迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型训练方法主要依赖静态文本或预设问题，缺乏在真实交互、协商与竞争场景中的实践经验，难以提升复杂推理能力。

Method: MARO方法包括三方面：1）将最终成败结果分解为交互过程中各具体行为的奖励信号，缓解稀疏学习信号问题；2）通过平衡不同角色的训练样本权重，解决角色分布不均问题；3）直接评估每个行为的效用，应对环境不稳定问题。

Result: MARO显著提升了模型的社交推理能力，且所获能力可有效迁移到数学推理和指令遵循等其他任务。

Conclusion: 多智能体社交学习具有巨大潜力，可作为增强大语言模型通用推理能力的新范式。

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [499] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段大语言模型框架，用于将客户评论转化为可执行的业务建议：先用Issue模型提取问题并归类主题，再用基于LoRA专家混合策略微调的Advice模型生成具体、可行的操作建议；在Yelp航空与餐饮数据上验证，该方法在行动性、特异性等八维指标上优于基线。


<details>
  <summary>Details</summary>
Motivation: 客户评论蕴含丰富的服务问题和用户期望信号，但将非结构化反馈转化为可落地的业务决策仍具挑战。

Method: 提出模块化双LLM框架：Issue模型提取问题并粗粒度归类；Advice模型基于问题表征生成操作建议，并采用混合LoRA专家（token级门控选择多个低秩适配器）进行高效适配，避免全量微调。训练数据由Yelp评论合成review-issue-advice三元组构建。

Result: 在航空与餐饮两个领域均显著优于仅提示工程和单LoRA适配基线，在行动性、特异性、可行性、预期影响等八维运营评估指标上表现更优，且保持良好的效率-质量平衡。

Conclusion: 模块化双LLM架构结合LoRA专家混合策略，是将客户评论高效、高质量转化为可执行建议的有效范式。

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [500] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: 本文提出PsychēChat，一种结合情绪变化追踪与安全风险分析的心理咨询大模型，通过情绪管理模块和风险控制模块，以及Agent Mode和LLM Mode两种建模范式，提升了情绪洞察力与安全性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在心理咨询中未显式建模来访者情绪变化，且缺乏对情绪变化与安全风险协同应对的机制。

Method: 提出PsychēChat框架，包含情绪管理模块（捕捉当前情绪与变化）和风险控制模块（预测后续反应与潜在风险），并设计Agent Mode（多智能体协作）与LLM Mode（统一链式推理）两种建模范式。

Result: 在交互评分、对话级评估与人工评估中，PsychēChat在情绪洞察与安全控制方面均优于现有方法。

Conclusion: PsychēChat有效整合情绪动态建模与风险预判，为安全、共情的心理咨询AI提供了新范式。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [501] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: 本文评估了大语言模型（LLM）在知识状态追踪与意图理解方面的能力，发现当前主流LLM在这两项认知任务上表现接近随机水平，远逊于人类，呼吁未来研究更重视知识估计与意图推断能力。


<details>
  <summary>Details</summary>
Motivation: 受认知人类学启发，人类智能的关键在于能推断他人知识状态与意图，而黑猩猩缺乏该能力；本文旨在检验LLM是否具备类似人类的知识状态跟踪与估计能力。

Method: 设计两项任务：（1）检测故事角色是否通过行为表现出其本不应拥有的知识；（2）基于角色自身知识（而非客观事实）预测其下一步行为。

Result: 多数当前最先进LLM在两项任务中均表现接近随机水平，显著低于人类表现。

Conclusion: LLM在知识状态追踪与意图理解方面存在严重不足，未来研究应更重视发展此类高阶认知能力。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [502] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLMs）在OWL本体环境下的证明生成能力，提出了一套自动构建数据集与评估框架，涵盖提取、简化、解释及前提逻辑完备性评估四项任务；实验发现逻辑复杂度是影响性能的主因，而非表示形式，且输入噪声与不完整性显著削弱模型表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理任务（如演绎）上已有广泛研究，但其生成忠实、可读性强的证明（即解释结论为何成立）的能力仍被严重忽视，尤其在OWL本体等严谨逻辑知识表示场景中缺乏系统评估。

Method: 构建面向OWL本体的自动化数据集构造与多阶段评估框架，包含四个任务：前提提取、逻辑简化、自然语言解释生成、以及前提逻辑完备性判断；在多个主流推理型LLM上开展系统实验。

Result: （1）部分模型整体表现强，但在复杂逻辑案例上受限；（2）逻辑复杂度比形式化/自然语言表示方式更显著影响性能；（3）输入数据的噪声与不完整性大幅降低模型表现。

Conclusion: LLMs在基于严格逻辑的知识解释任务中展现出潜力，但尚难以稳健应对复杂或不完美的现实推理条件，亟需提升鲁棒性与逻辑保真能力。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [503] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: 本文提出Multi-Focus Attention Instruction (MFAI) 方法，用于解耦大语言模型在多跳推理中的识别失败与合成失败，并发现性能受限于最不可见证据的‘最弱链定律’；实验表明位置偏差是主因，且System-2类‘思考型’模型能克服该问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在大规模上下文窗口下仍存在多跳推理困难，根源可能是位置偏差导致的信息忽视，但尚不清楚是无法定位证据（识别失败）还是无法整合证据（合成失败）。

Method: 提出语义探针Multi-Focus Attention Instruction (MFAI)，通过显式引导注意力至指定位置，以分离识别与合成机制；在MuSiQue和NeoQA两个多跳问答任务上对5个LLM进行系统分析。

Result: 发现‘最弱链定律’：多跳推理性能坍缩至最不可见证据的水平；该失败由绝对位置主导（而非事实间线性距离），性能方差<3%；匹配MFAI可提升低可见性位置准确率最高11.5%，而误导MFAI在真实任务中引发混淆但在合成任务中被过滤；‘思考型’模型可匹配仅用黄金证据的基线性能。

Conclusion: 多跳推理瓶颈主要源于识别失败（即证据定位能力不足），且受绝对位置偏差主导；MFAI为诊断注意力机制提供了有效工具，而具备System-2推理能力的模型能鲁棒地完成长上下文多跳推理。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [504] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: This survey introduces agentic reasoning as a paradigm shift for LLMs, organizing it into three environmental layers—foundational, self-evolving, and collective multi-agent—and two reasoning modes—in-context and post-training—while reviewing applications, benchmarks, and open challenges.


<details>
  <summary>Details</summary>
Motivation: LLMs excel in closed-world reasoning but falter in open-ended, dynamic environments; agentic reasoning addresses this gap by treating LLMs as autonomous, interactive agents.

Method: The paper adopts a structured survey methodology, categorizing agentic reasoning along three environmental dimensions (foundational, self-evolving, collective) and two reasoning modalities (in-context vs. post-training), and reviews frameworks across domains and benchmarks.

Result: A unified taxonomy and roadmap of agentic reasoning is established, clarifying relationships among planning, tool use, memory, adaptation, coordination, and learning mechanisms, alongside evaluation across science, robotics, healthcare, etc.

Conclusion: Agentic reasoning bridges thought and action for LLMs, yet key challenges remain—including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance—requiring interdisciplinary effort for real-world deployment.

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [505] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: 本文提出MemeLens，一个统一的多语言、多任务、可解释的视觉语言模型，用于理解网络模因（meme），整合38个公开数据集并构建20类共享任务分类体系，实证表明多模态联合训练对提升跨域泛化能力至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有模因研究分散于不同任务（如仇恨、性别歧视、宣传等）和语言，缺乏统一框架，限制了跨领域泛化能力。

Method: 构建MemeLens模型，整合38个公开模因数据集，映射至涵盖危害、目标、修辞/语用意图及情感的20类统一任务分类体系，并开展跨建模范式、任务类别与数据集的综合实证分析。

Result: 实验表明：1）稳健的模因理解需多模态联合训练；2）性能在不同语义类别间差异显著；3）单数据集微调易导致过专化，而统一训练更鲁棒。

Conclusion: MemeLens为模因理解提供了可扩展、可解释、多语言多任务的统一基准与模型框架，推动社区在统一范式下开展研究，并将开源全部实验资源与数据集。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [506] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: 本文提出了Deep Research，一种支持实时交互式科学探索的多智能体系统，其响应时间仅需几分钟，显著优于现有批量处理模式。系统包含规划、数据分析、文献检索和新颖性检测等专用智能体，并通过持久化世界状态维持跨迭代的研究上下文。支持半自主（含人工检查点）和全自主两种工作模式，在BixBench基准测试中达到SOTA性能（开放回答48.8%，多选题64.5%），并分析了实际部署中的关键限制因素。


<details>
  <summary>Details</summary>
Motivation: 现有AI科研系统多为封闭式、批处理模式，耗时长（数小时/轮），无法满足实时指导研究人员的需求。

Method: 提出Deep Research多智能体系统，包含规划、数据分析、文献搜索、 novelty detection等专用智能体，通过持久化世界状态维持上下文；支持半自主与全自主两种运行模式。

Result: 在BixBench计算生物学基准上，开放回答准确率达48.8%，多选题达64.5%，分别超越基线14–26个百分点。

Conclusion: Deep Research实现了分钟级响应的交互式科研范式，验证了多智能体协同与上下文持续性的可行性，同时揭示了开放文献覆盖与自动新颖性评估等现实约束对落地的影响。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [507] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 本文提出临床AI系统应从预测引擎转向支持临床医生的序贯、序数决策过程，强调使用快速-节俭的启发式方法（如快速-节俭树）进行非补偿性、鲁棒性决策，并为这种‘序数优先’范式提供了认识论与不确定性下的规范性依据。


<details>
  <summary>Details</summary>
Motivation: 现有临床AI多为静态预测模型，而真实临床推理是受时间约束、含不确定性的序贯控制问题，需兼顾后悔、约束与患者价值观；当前基于期望效用的优化方法在临床数据‘粗糙性’和弱可测性下易失稳。

Method: 从认知科学与决策理论出发，论证临床决策本质上是序数、非补偿性的；结合测量理论（缺乏强公理时仅序关系稳定）、信号感知链中的多层噪声建模，以及鲁棒决策理论（ε-支配、极大极小），提出以鲁棒序数规则驱动行动选择的AI设计框架。

Result: 确立了‘序数优先’作为临床AI的规范性基础；证明快速-节俭启发式不仅是有限理性的妥协，而是在临床环境下具有认识论优势的稳健策略；提出‘选择性复杂性’AI部署范式——仅在决策脆弱、信息价值高时启用复杂模型。

Conclusion: 临床AI不应追求全局优化，而应适配医生真实的序贯、鲁棒、价值敏感的决策逻辑；将复杂建模用于信念与轨迹推断，但用低维、鲁棒的序数规则指导行动，实现人机协同的可靠临床智能。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [508] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: 本文提出STEP-LLM，一种面向制造就绪的文本到STEP格式CAD模型生成方法，通过构建STEP-caption数据集、图结构适配预处理（DFS重序列化与CoT标注）、检索增强生成（RAG）及基于Chamfer距离的强化学习优化，在几何保真度上显著超越现有Text2CAD基线。


<details>
  <summary>Details</summary>
Motivation: 现有文本到CAD方法依赖于内核相关脚本（如CadQuery），缺乏制造通用性；而中立、广泛采用的STEP格式因其图结构和交叉引用特性难以被自回归大语言模型直接建模。

Method: 构建约4万对STEP-caption数据集；提出面向STEP图结构的预处理：深度优先搜索（DFS）重序列化以线性化交叉引用并保持局部性，以及链式思维（CoT）风格的结构标注以保障全局一致性；引入检索增强生成（RAG）用于监督微调，并采用基于Chamfer距离的几何奖励进行强化学习优化。

Result: STEP-LLM在几何保真度上持续优于Text2CAD基线；RAG模块显著提升模型输出的完整性与可渲染性，DFS重序列化增强整体准确性，RL进一步降低几何偏差；定量指标与视觉对比均验证其更高形状保真度。

Conclusion: 证明了大语言模型直接生成制造就绪的STEP格式CAD模型的可行性，有望降低CAD设计门槛，推动制造业设计民主化。

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [509] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: 本文提出MedConsultBench，一个覆盖完整线上问诊流程的细粒度评估框架，引入原子信息单元（AIUs）和22项指标，强调信息获取效率、用药安全与不确定性感知能力；实验发现当前大模型虽诊断准确率高，但在临床实践关键能力上存在明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有医学咨询代理评估多聚焦结果导向任务，忽视端到端流程完整性与临床安全性；已有交互式基准碎片化、粗粒度，无法反映专业问诊所需的结构化问询逻辑与诊断严谨性。

Method: 提出MedConsultBench框架，覆盖病史采集、诊断、治疗计划与随访问答全流程；引入原子信息单元（AIUs）实现子轮次级临床信息获取追踪；设计22个细粒度指标，评估不确定性感知的简洁问询、用药方案兼容性及约束遵从的随访修订能力。

Result: 对19个大语言模型的系统评估表明：高诊断准确率常掩盖信息采集低效与用药安全隐患；模型在临床实践关键能力（如结构化问诊、安全用药推理、动态计划修正）上普遍不足。

Conclusion: 理论医学知识掌握不等于临床实践能力，MedConsultBench为弥合AI能力与真实临床需求之间的鸿沟提供了严格、可扩展的评估基础。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [510] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 本文提出了一种面向卫星 mega-constellations 时代的全闭环航天器电源系统健康管理系统 SpaceHMchat，基于‘能力对齐’（AUC）原则，融合人类与AI协作，覆盖工况识别、异常检测、故障定位与维修决策，并开源了首个航天器电源系统全闭环健康管理数据集及硬件仿真平台。


<details>
  <summary>Details</summary>
Motivation: 随着卫星星座规模激增，传统针对单个或少量航天器的电源系统健康管理模式已不适用，亟需适应大规模、高并发、高可靠需求的新范式。

Method: 提出AUC（Aligning Underlying Capabilities）原则；构建开源人机协同框架SpaceHMchat，支持全闭环健康管理工作流；搭建硬件级故障注入实验平台及对应仿真模型；发布首个SPS全闭环健康管理数据集（含4类子任务、17类故障、70万+时间戳）。

Result: SpaceHMchat在23项定量指标中表现优异：工况识别逻辑推理结论准确率100%，异常检测工具调用成功率>99%，故障定位精度>90%，维修决策知识检索耗时<3分钟；同时开源了首个SPS AIL HM数据集和仿真平台。

Conclusion: SpaceHMchat验证了面向大规模星座的全闭环、可解释、人机协同健康管理模式的可行性与先进性，为未来空间能源系统的智能化运维提供了新范式与基础设施支撑。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [511] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 本文提出了一种结合量刑逻辑与预训练Transformer编码器的 masked multistage inference（MMSI）框架，用于在多人被告案件中更准确、可解释地区分各被告角色与罪责程度。


<details>
  <summary>Details</summary>
Motivation: 多人被告案件中责任分配复杂，司法文本常模糊被告角色，阻碍AI进行有效、公平的罪责分析。

Method: 在预训练Transformer编码器中融入量刑逻辑；引入定向掩码机制明确被告角色；设计对比数据构建策略提升模型对主犯与从犯罪责差异的敏感性；将预测的有罪标签通过广播机制融入回归模型，整合犯罪描述与法院观点。

Result: 在自建IMLJP故意伤害案件数据集上，MMSI框架在基于角色的罪责区分任务中显著优于基线模型。

Conclusion: 该框架兼顾准确性与法律可解释性，为智能司法系统提供了鲁棒可行的技术方案，并开源代码。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [512] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 本文提出了一种神经符号LoRA框架，动态结合数值微调（LoRA）和符号编辑（TextGrad），通过统一监控信号与奖励分类器决定何时采用哪种策略，在保持内存高效的同时提升模型适应性与性能。


<details>
  <summary>Details</summary>
Motivation: 数值微调擅长注入新事实知识，符号更新则灵活控制风格与对齐，但二者各自存在局限；需融合二者优势以实现更通用、高效的模型适配。

Method: 提出神经符号LoRA框架：设计统一监控信号和奖励驱动的分类器，动态选择使用LoRA进行参数更新或TextGrad进行token级符号编辑；将符号编辑卸载至外部LLM以节省内存；利用符号编辑生成的高质量提示作为可复用训练数据。

Result: 在多个LLM主干模型上实验表明，该方法持续优于纯数值或纯符号基线，在数学推理等数据稀缺任务中尤为有效，提升了适应性与整体性能。

Conclusion: 数值更新与符号编辑的交替协同能显著增强语言模型微调的灵活性与实用性，为模型适配开辟了新路径。

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [513] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 本文提出SCFT和RLERR两种方法，旨在解决大推理模型中浅层反思的问题，通过自我批判微调和基于有效反思的强化学习提升模型的推理准确性和反思质量。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）虽能进行自我反思（如自我批判、回溯），但许多反思流于表面，无法提升答案质量且增加计算开销，亟需识别并消除浅层反思。

Method: 首先提出自批判微调（SCFT）：利用模型自身生成的批判，通过拒绝采样筛选高质量批判，并以批判为导向进行微调；进而提出基于有效反思奖励的强化学习（RLERR）：以SCFT初始化的高质量反思构建奖励信号，引导模型内化自我修正过程。

Result: 在AIME2024和AIME2025两个挑战性基准上，SCFT与RLERR显著提升了推理准确率和反思质量，超越现有最优方法。

Conclusion: SCFT和RLERR有效缓解了LRMs中浅层反思问题，为提升模型反思深度与效率提供了可扩展、数据高效的训练范式。

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [514] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 本文提出IntentOpt基准测试，评估视觉-语言模型（VLMs）从手绘网络示意图生成优化代码的能力，发现当前VLMs在多模态输入下性能显著下降，尤其在视觉参数提取和程序化思维提示下表现更差，揭示了其在意图驱动网络（IBN）中自动化优化代码生成的现实局限性。


<details>
  <summary>Details</summary>
Motivation: 网络从业者习惯用图示表达意图，但现有IBN系统仅支持文本式意图表达；而结构化网络优化问题（如流量工程）需生成可验证最优的代码，尚无研究探索VLMs能否从标注网络草图中准确生成此类代码。

Method: 构建包含85个优化问题的IntentOpt基准（覆盖17类网络场景），对比4种VLM（GPT-5-Mini、Claude-Haiku-4.5、Gemini-2.5-Flash、Llama-3.2-11B-Vision）在多模态与纯文本输入、三种提示策略下的代码生成效果，并通过Model Context Protocol在真实网络测试床部署验证可行性。

Result: 视觉参数提取使执行成功率下降12–21个百分点（如GPT-5-Mini从93%降至72%）；程序化思维提示最多降低13个百分点；开源模型（Llama-3.2-11B-Vision仅18%）显著落后闭源模型（GPT-5-Mini达75%）。

Conclusion: 当前VLMs在从网络示意图生成正确优化代码方面存在明显瓶颈，多模态理解与结构化推理能力不足，尚难支撑IBN中高可靠性的意图到代码自动转化，需针对性改进。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [515] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: 本文提出VIRO框架，通过在推理步骤中嵌入轻量级操作符级验证器，解决现有神经符号REC方法因中间步骤错误导致的级联误差问题，在目标存在与不存在场景下均实现高准确率和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法假设中间推理步骤准确，但实际中错误会级联传播，导致高置信度误检，尤其在图像中无目标时表现差。

Method: 提出Verification-Integrated Reasoning Operators（VIRO）框架，在每个推理操作符中集成轻量级验证模块，对对象存在性、空间关系等中间结果进行实时校验，并支持程序生成与执行解耦。

Result: 在目标存在与不存在统一评估下达到61.1%平衡准确率，程序失败率<0.3%，吞吐量高，且泛化至真实世界第一人称视角数据。

Conclusion: VIRO有效缓解了神经符号REC中的级联错误问题，提升了系统鲁棒性、可靠性与实用性，为零样本泛化与现实部署提供了新路径。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [516] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: 本文提出SL-CBM，一种增强空间局部保真度的概念瓶颈模型，通过1×1卷积与交叉注意力机制生成概念级和类别级的空间一致显著图，提升解释质量、干预效果与可信度。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）缺乏空间局部保真性，难以将概念与图像中对应区域对齐，限制了其可解释性与可靠性。

Method: 提出SL-CBM，引入1×1卷积层与交叉注意力机制，联合建模概念、图像区域与预测；采用对比学习与基于熵的正则化以平衡准确性、稀疏性与保真性。

Result: 在图像数据集上实验表明，SL-CBM显著提升局部保真度、解释质量与干预有效性，同时保持有竞争力的分类精度。

Conclusion: SL-CBM弥合了概念推理与空间可解释性之间的鸿沟，为可解释、可信的概念模型树立了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [517] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: 本文提出MirrorGuard，一种基于模拟训练的即插即用防御框架，用于提升计算机使用代理（CUAs）在GUI环境中的安全性，通过神经符号仿真管道生成高风险交互轨迹，在不执行真实操作的前提下学习拦截和修正不安全推理链，显著降低不安全行为率且保持低误拒率。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型驱动的计算机使用代理（CUAs）在GUI环境中自主执行任务时面临严重安全风险，如恶意指令或视觉提示注入可能引发有害系统级操作；现有检测式防御虽能阻止损害，但常导致任务过早中止、损害代理实用性。

Method: 提出MirrorGuard框架，核心是神经符号仿真管道：在纯文本模拟环境中高效生成逼真、高风险的GUI交互轨迹，捕捉不安全推理模式与潜在系统危害；在此仿真环境中训练模型以识别并修正CUA的不安全推理链，实现对有害动作的事前拦截与纠正。

Result: 在真实测试中，MirrorGuard显著降低安全风险：在ByteDance UI-TARS系统上，不安全率从66.5%降至13.0%，误拒率（FRR）仅轻微上升；相较SOTA方法GuardAgent（仅降至53.9%，且FRR高出15.4%），性能优势明显。

Conclusion: 基于仿真的防御策略可在保障CUA实际效用的同时，提供鲁棒、可落地的安全防护，验证了仿真驱动方法在真实世界安全增强中的可行性与有效性。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [518] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: 本文提出SCULPT方法，通过将领域感知的符号约束与蒙特卡洛树搜索（MCTS）结合，提升LLM驱动的自动代理工作流在推理路径搜索中的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化代理工作流依赖随机探索，易遍历不合理分支，因通用提示或学习策略缺乏强领域先验知识。

Method: 提出SCULPT：一种面向约束引导的MCTS方法，在选择、扩展、模拟和回传阶段融合符号检查（如量纲一致性、类型兼容性、量级合理性、深度控制、多样性）与结构模式指导，对动作进行打分与剪枝。

Result: 在相同LLM配置下，SCULPT在多个数据集上实现稳定性能提升；使用GPT-5.2验证了执行器迁移性及前沿推理模型上的有效性。

Conclusion: 领域感知约束可在保持效率与推理稳定性的同时，显著提升自动推理路径搜索的准确性。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [519] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 本文提出了一种基于公开登革热病例数据挖掘城市区域间潜在传播关联的新框架，利用人类通勤流解释长距离传播，并通过梯度下降优化隐式传播网络，实现高精度热点预测与传播模式一致性验证。


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战，亟需低成本、可预测的前瞻性干预手段，而非被动响应；现有方法多将病例视为孤立事件，忽视区域间潜在传播动态。

Method: 从公开登革热病例数据中建模区域间潜在国内传播链，将热点形成建模为受邻近区域流行病动力学影响的过程；利用梯度下降优化隐式传播网络，并与实际通勤流比对以增强可解释性；通过连续周次网络稳定性分析验证传播模式一致性。

Result: 在2013–2018年及2020年新加坡案例中，仅需4周热点历史数据即可达到平均F-score 0.79；所学传播链接与真实 commuting flow 高度一致，验证了人类移动驱动远距离传播的假设。

Conclusion: 该框架将开放网络病例数据转化为兼具预测能力与机制解释力的公共卫生资源，为疫情建模、早期干预和城市韧性建设提供了可扩展、低成本的新范式。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [520] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: 本文提出了基于ASP和状态转移系统的心理状态建模语言C-MT，用于刻画人类心理状态（如情绪）在动作序列作用下的动态演化，并引入'forbids to cause'因果规则以约束不期望的心理副作用，支持基于轨迹的可控推理与不同心理原则下的动态比较。


<details>
  <summary>Details</summary>
Motivation: 解决对智能体行为进行控制的需求，以及限制动作引发的不良心理副作用，同时为人类心理状态（如情绪）的动态演化提供形式化建模工具。

Method: 在答案集编程（ASP）和转移系统基础上构建C-MT语言；融合情绪评估理论等心理学理论，将心理状态形式化为多维构型；引入新型因果规则'forbids to cause'及专用心理状态动态表达式；将心理变化原则转化为转移约束与不变性性质，并通过轨迹进行严格评估。

Result: 实现了对人类心理状态动态演化的可控推理；支持基于不同心理学原则的轨迹比较分析；成功应用于情绪验证模型的设计。

Conclusion: C-MT语言为心理状态建模提供了严谨、可扩展的形式化框架，兼具理论深度与应用潜力，尤其适用于需兼顾行为控制与心理合理性的智能体系统设计。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [521] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 本文指出人工智能中的可解释性研究存在根本性问题，因为现有定义缺乏可操作性；作者提出以对称性为基础重新定义可解释性，并假设四种对称性足以统一建模、刻画可解释模型类及推导可解释推理。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性定义不可操作，无法导出具体的建模与推理规则，亟需更具形式化基础的定义。

Method: 提出以‘对称性’作为可解释性定义的核心，并假设四类对称性足以支撑可解释性的理论构建与推理统一。

Result: 将可解释性建模、可解释模型类别刻画及可解释推理（如对齐、干预、反事实）统一为贝叶斯逆问题。

Conclusion: 可解释性必须基于对称性才具可操作性；该框架为可解释AI提供了形式化、统一且可推导的理论基础。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [522] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: 本文提出了MagicGUI-RMS，一种多智能体奖励模型系统，用于自动评估GUI代理行为轨迹、提供纠错反馈并支持自我进化学习，显著提升了任务准确率与行为鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理评估依赖人工标注或静态规则，难以扩展且缺乏在动态环境中的适应性；同时高质量训练数据生成成本高、效率低。

Method: 提出MagicGUI-RMS系统，融合领域专用奖励模型（DS-RM）与通用奖励模型（GP-RM），构建结构化自动数据生成管道，并引入数据回流机制实现执行中纠错与持续优化。

Result: 实验表明该系统显著提升GUI代理的任务准确率和行为鲁棒性，验证了其在奖励驱动自进化方面的有效性。

Conclusion: MagicGUI-RMS为构建基于奖励自适应的、可自我改进的GUI代理提供了原理清晰且实用有效的基础框架。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [523] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文分析了通用人工智能（如大语言模型）在负责任AI（RAI）八大原则下的风险与脆弱性，指出其高自由度输出（DoFo）是问题根源，并提出C2V2（控制、一致性、价值、真实性）设计准则以指导未来负责任通用AI系统构建。


<details>
  <summary>Details</summary>
Motivation: 通用AI虽功能强大，但存在幻觉、毒性、偏见等风险，使其缺乏可信度；而传统专用AI系统在这些方面风险更低、更易缓解，因此需重新思考通用AI的负责任AI（RAI）方法论。

Method: 基于八大负责任AI原则（公平性、隐私、可解释性、鲁棒性、安全性、真实性、治理、可持续性）系统梳理通用AI的风险与漏洞，并对比传统专用AI；提出‘输出自由度（DoFo）’概念解释差异；进而推导出C2V2四大设计准则，并评估现有技术（如AI对齐、RAG、推理增强）在各准则上的表现。

Result: 识别出通用AI高DoFo是RAI挑战的核心成因；提出C2V2准则作为满足RAI要求的新框架；指出需结合应用/领域依赖的RAI建模与系统化技术整合来实现负责任通用AI。

Conclusion: 通用AI的负责任发展不能简单沿用专用AI的RAI范式，必须基于C2V2维度进行形式化建模与系统设计，才能有效应对高自由度带来的独特风险。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [524] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLMs）在实时时间约束下的表现，发现其缺乏内在时间感知能力：当提供剩余时间提示时，谈判成交率显著提升；而仅依赖内部计时则表现极差，说明问题在于时间跟踪而非策略推理。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的沟通（如心理治疗、商务谈判）高度依赖连续时间约束，但当前LLM架构和评估方法极少测试其在实时截止时间下的时间感知能力。

Method: 通过模拟配对智能体在严格时间限制下的谈判实验，设置两种条件：控制组（仅知全局时限）与时间感知组（每轮接收剩余时间更新），比较成交率、报价接受率等指标，并跨场景与模型验证。

Result: 时间感知条件下GPT-5.1成交率达32%（对照组仅4%），报价接受率高6倍；而在回合制时限下成交率≥95%，表明LLM能执行策略但无法自主跟踪连续时间。该缺陷在多场景、多模型中稳定复现。

Conclusion: LLM普遍存在系统性时间感知缺失，这将严重制约其在各类实时敏感应用（如人机协作、危机响应）中的实际部署。

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [525] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于随机森林的生成式逆向设计方法RAG，用于高效、可信地设计具有连续函数型响应（如色散关系、应力-应变关系）的超材料，显著提升小样本下的功能响应逆设计能力与不确定性量化水平。


<details>
  <summary>Details</summary>
Motivation: 现有超材料逆设计方法难以处理高维、非线性、条件依赖的连续函数型响应（如色散曲线、应力-应变曲线），且面临数据饥渴、设计约束难嵌入、解不唯一或不存在、缺乏可信度评估等问题。

Method: 提出RAndom-forest-based Generative approach（RAG）：利用随机森林的小样本学习能力建模高维功能响应；通过集成预测估计条件似然，实现不确定性量化与需求难度评估；采用单次采样从条件似然中生成满足复杂约束的设计。

Result: 在声学超材料（指定部分通/阻带，500样本）和力学超材料（目标突跳响应，1057样本）任务上成功验证；相比神经网络，在公开非线性应力-应变数据集上展现出更优的数据效率与可靠性。

Conclusion: RAG为涉及功能响应、高成本仿真与复杂需求的逆设计问题（不限于超材料）提供了轻量、可信、数据高效的新范式。

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [526] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: 本文提出了CUREMED-BENCH多语言医学推理数据集和CURE-MED课程引导的强化学习框架，显著提升了大语言模型在13种语言（含阿姆哈拉语、约鲁巴语、斯瓦希里语等）下的医学推理逻辑正确性与语言稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言医学推理任务中表现不可靠，限制了其在多语言医疗场景中的实际部署。

Method: 构建了覆盖13种语言（含多种低资源语言）的高质量多语言医学推理数据集CUREMED-BENCH，并提出CURE-MED框架，结合语码转换感知的监督微调与组相对策略优化（Group Relative Policy Optimization）进行课程式强化学习。

Result: 在13种语言上一致超越强基线：7B参数模型达85.21%语言一致性与54.35%逻辑正确率；32B参数模型达94.96%语言一致性与70.04%逻辑正确率。

Conclusion: 所提方法可支持大语言模型实现可靠、公平的多语言医学推理，推动其在真实多语言医疗环境中的落地应用。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [527] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体迭代精炼框架，结合DeepSeek R1与Med-PaLM生成模型及LLaMA 3.1与Phi-4评估智能体，依据AMA伦理准则和SRA-5风险协议提升医疗大模型的安全性与合规性，在900个临床问题上实现89%伦理违规减少和92%风险降级。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域应用日益广泛，但其伦理完整性与安全合规性仍是临床部署的主要障碍。

Method: 构建多智能体协同框架：两个生成智能体（DeepSeek R1、Med-PaLM）生成响应，两个评估智能体（LLaMA 3.1、Phi-4）依据AMA伦理原则和五级安全风险评估（SRA-5）进行迭代反馈与修正。在900个覆盖九类伦理领域的临床查询上评估收敛效率、违规减少率与风险行为变化。

Result: DeepSeek R1收敛更快（均值2.34轮 vs. 2.67轮），Med-PaLM更擅处理隐私敏感场景；整体实现89%伦理违规减少、92%风险等级下调。

Conclusion: 该多智能体迭代对齐范式具备可扩展性、监管兼容性与成本效益，为医疗AI安全治理提供了新路径。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [528] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一种无需预测结构的零样本肽结合剂生成模型，通过在预训练蛋白嵌入的连续潜在空间中进行扩散采样，直接生成靶标蛋白口袋特异性结合肽序列，在TIGIT等难靶标上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法严重依赖中间结构预测，导致流程复杂且序列多样性受限；同时难以泛化到缺乏已知结合肽或经典结合口袋的新靶标（如TIGIT）。

Method: 基于预训练蛋白嵌入模型构建连续潜在空间，不依赖结构预测；引入潜在空间探索与扩散采样机制，利用全局蛋白嵌入流形作为语义先验，实现零样本、结构无关的肽序列生成。

Result: 在多个基准测试及TIGIT案例研究中，PepEDiff性能超越当前最优方法；生成的肽序列具有更高结构与序列多样性，并能覆盖蛋白空间中未被已知结合肽占据的新区域。

Conclusion: PepEDiff提供了一种通用、无需结构输入的零样本肽设计新范式，为难靶标（如扁平PPI界面）的治疗性肽开发提供了高效可行的新工具。

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [529] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 本文发现模型规模扩大并不会均匀提升推理能力，而是会重构推理过程；在不同领域（法律、科学、代码、数学）中，随着参数量从8B增至70B，推理呈现出不同的几何相变：法律推理发生'结晶化'，科学与数学保持'液态'，代码推理形成'晶格'结构；作者提出'神经推理算子'，可在法律领域以63.6%准确率直接预测推理终点；还发现跨领域、跨尺度存在的普遍振荡特征，表明注意力与前馈层存在对抗性动态；最终指出'思考成本'由流形几何而非任务难度决定。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型随规模增长的推理能力变化机制，挑战‘规模即能力’的简单假设，揭示推理过程的内在几何结构演化规律。

Method: 分析25,000+条思维链轨迹，覆盖法律、科学、代码、数学四大领域及8B/70B两种模型尺度；采用流形维度（d95）、轨迹对齐度、流形解缠度、轮廓系数等几何指标量化推理状态空间；提出神经推理算子（NRO）建模隐状态映射，并结合探针解码评估预测能力；通过频谱分析识别跨域振荡签名。

Result: 发现领域特异性相变：法律推理‘结晶化’（维度坍缩45%、对齐度↑31%、解缠↑10x）；科学/数学推理保持‘液态’（几何不变）；代码推理形成‘晶格’（轮廓系数从0.13→0.42）；NRO在法律任务上达63.6%终点预测准确率；发现普适振荡签名（相干性≈-0.4），反映注意力与FFN层的对抗动力学。

Conclusion: 推理能力的扩展并非平滑增强，而是受底层流形几何支配的结构性相变；‘思考成本’本质是流形拓扑代价，为基于几何先验的推理加速提供了理论基础与技术路径。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [530] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: 本文提出了AgentForge，一个轻量级、开源的Python框架，旨在通过模块化架构降低LLM驱动自主代理的开发门槛；其核心创新包括可组合的技能抽象、统一的LLM后端接口和声明式YAML配置系统，并在多个基准上验证了高效性与易用性。


<details>
  <summary>Details</summary>
Motivation: 现有自主代理框架存在架构僵化、厂商锁定和复杂度过高问题，阻碍快速原型设计与部署，亟需更开放、灵活且易用的框架。

Method: 提出AgentForge框架，包含：(1) 基于输入-输出契约的可组合技能抽象；(2) 支持云API与本地推理引擎切换的统一LLM后端接口；(3) 解耦逻辑与实现的YAML声明式配置；并将技能组合建模为有向无环图（DAG）进行形式化分析。

Result: 在四个基准场景中，AgentForge任务完成率媲美主流方案，开发时间比LangChain减少62%、比直接API集成减少78%，编排开销低于100ms；支持6种内置技能及自定义扩展。

Conclusion: AgentForge填补了LLM代理生态中兼顾生产就绪性、灵活性与性能的关键空白，为研究者与开发者提供了构建、评估和部署自主代理的实用基础。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [531] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 本文提出显式认知分配原则，通过将AI辅助推理过程分解为多个明确的认知阶段，并引入通用认知工具（UCI）来形式化各类探究手段，从而提升推理的可追溯性、认识论可控性与可复现性；在农业领域实验中，所提出的Cognitive Universal Agent（CUA）相比基线LLM展现出更早且结构化的认知收敛、更高的语义扩展下对齐度，以及对探究工具体系的系统性揭示。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）使用方式缺乏认知结构，将问题构建、知识探索、检索、方法意识与解释等环节混为单一生成过程，导致可追溯性差、认识论控制弱、高责任场景下不可复现。

Method: 提出显式认知分配（Explicit Cognitive Allocation）原则，并据此构建认知通用代理（CUA）架构，将推理划分为探索与建模、认知锚定、工具与方法映射、解释性综合四个阶段；引入通用认知工具（UCI）统一形式化计算、实验、组织、监管、教育等异构探究手段；通过在农业领域进行受控对比实验评估效果。

Result: CUA推理相较基线LLM表现出更早且结构化引导的认知收敛、更高语义扩展下的认识论对齐度，以及对探究工具图景的系统性暴露；而基线LLM则对齐波动大，且无法显式揭示工具结构。

Conclusion: 显式分离并编排认知功能与工具使用，是提升AI辅助推理可靠性与可解释性的关键路径；CUA框架及其UCI概念为高责任AI应用提供了可扩展的认识论基础设施。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [532] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: 本文提出SpatialBench-UC基准，用于评估文生图模型对空间关系指令的遵循能力，强调选择性预测（可拒判）与可复现性，并验证了接地方法（grounding）对性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现有自动化评估方法（如目标检测+几何测试）在评估文生图模型对显式空间指令的遵循能力时存在漏检、多检和边界模糊等问题；需引入可拒判、带置信度的评估范式以支持风险-覆盖率权衡分析。

Method: 构建含200条提示的小型可复现基准SpatialBench-UC（50个物体对×4种空间关系），含100组反事实配对；设计可拒判的空间检查器，结合轻量人工审核校准其拒判阈值与置信度；发布完整可复现套件（提示、配置、逐样本输出、报告表）。

Result: 在Stable Diffusion 1.5、SD 1.5 BoxDiff 和 SD 1.4 GLIGEN 上评估显示：接地方法显著提升通过率与覆盖率；但拒判仍占主导，主因是目标检测缺失。

Conclusion: 空间关系评估应采用选择性预测框架；可复现基准与校准过的检查器为公平、可审计的模型比较提供了新标准；接地技术有效，但检测鲁棒性仍是瓶颈。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [533] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 本文提出了一种基于上下文的音频深度伪造检测器（CADD），利用上下文和/或转录文本显著提升检测性能，并在多个数据集上验证了其有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有音频深度伪造检测器仅分析音频本身，忽视上下文和文本信息，而人类判断信息真伪时高度依赖上下文。

Method: 构建记者提供的真实深度伪造数据集（JDD）和合成音频数据集（SYN），设计融合上下文和/或转录文本的CADD架构，并在JDD、SYN、ITW和P²V等数据集上评估其性能及对五种对抗攻击的鲁棒性。

Result: CADD使多种基线检测器的F1分数提升5%–37.58%，AUC提升3.77%–42.79%，EER改善6.17%–47.83%；对五种对抗策略平均性能下降仅-0.71%。

Conclusion: 引入上下文和/或转录文本可显著增强音频深度伪造检测的准确性与鲁棒性，CADD为该方向提供了有效新范式。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [534] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 本文提出了一种无需监督训练和显式搜索的图神经网络方法，通过在训练中引入全局结构约束作为归纳偏置，使其能直接前向生成TSP问题的高质量解，并利用dropout与模型快照集成提升解的多样性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络在组合优化中常依赖监督学习或结合经典算法进行搜索，本文旨在探索GNN能否不依赖这些方式，而直接作为强学习启发式算法。

Method: 采用非自回归图神经网络，将全局结构约束编码为归纳偏置；训练单条轨迹；推理时结合dropout和snapshot ensembling实现隐式集成。

Result: 模型在TSP任务上仅通过直接前向传播即可生成高质量解，无需搜索、监督或序列决策，显著缩小最优性差距。

Conclusion: 图神经网络可内化组合结构，无需监督或搜索即可成为有效的学习型启发式算法，从而重新定义其在组合优化中的角色——从辅助经典算法转向直接实例化新启发式。

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [535] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: 本文提出APOLO框架，通过多智能体协作优化提示词，提升大语言模型在精神健康领域情绪诊断的准确性与鲁棒性，解决情感共病与临床线索利用不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在高风险、强上下文的医疗场景中诊断可靠性易受提示设计影响，且面临情感共病和临床相关线索挖掘低效两大挑战。

Method: 将指令优化建模为部分可观测马尔可夫决策过程，构建含Planner、Teacher、Critic、Student和Target五角色的多智能体闭环协作框架，系统搜索更广、更细粒度的提示空间。

Result: APOLO在领域特定及分层基准测试中持续提升诊断准确率与鲁棒性。

Conclusion: APOLO为精神健康领域可信的大语言模型应用提供了可扩展、可泛化的范式。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [536] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: 本文提出AgenticRed，一种利用大语言模型（LLM）上下文学习能力自动设计和优化红队测试系统的无监督方法，无需人工指定流程；其将红队测试视为系统设计问题，结合进化选择策略，在多个开源与闭源模型上显著提升攻击成功率（ASR），验证了自动化系统设计在AI安全评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队测试方法严重依赖人工设计的工作流，易受人类偏见影响且难以高效探索广阔的设计空间。

Method: 提出AgenticRed框架，将红队测试建模为系统设计问题，利用LLM的上下文学习能力迭代生成、评估和进化红队系统；借鉴Meta Agent Search思想，设计基于进化选择的自动系统演化流程。

Result: 在HarmBench上对Llama-2-7B和Llama-3-8B分别达到96%和98%攻击成功率（ASR），较SOTA提升36%和显著优势；在GPT-3.5-Turbo、GPT-4o-mini上达100% ASR，在Claude-Sonnet-3.5上达60% ASR（提升24%），展现出强泛化性。

Conclusion: 自动化系统设计是一种可扩展、高适应性的AI安全评估新范式，能有效匹配快速演进的大模型发展节奏。

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [537] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种熵引导的潜在推理（EGLR）推荐模型，通过在生成式重排序中实现边推理边推荐、熵引导的可变长度推理以及轻量级集成设计，有效应对列表生成中的动态熵变化与复杂偏好建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法难以适应列表生成过程中模型难度引起的动态熵变化，导致难以准确捕捉复杂用户偏好。

Method: 引入潜在推理机制，设计熵引导的可变长度推理策略，结合上下文感知推理token与动态温度调整，在生成过程中实时进行推理（'推理即推荐'），并采用轻量级集成方式无缝嵌入现有模型。

Result: 在两个真实数据集上验证了EGLR的有效性；显著提升现有生成式重排序模型性能；具备良好的部署实用性与研究延展性。

Conclusion: EGLR通过将推理深度融入生成过程并以熵为指导，实现了更精准的探索-利用权衡，为生成式推荐提供了新范式。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [538] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的时序异常检测新框架ChatAD，包含多智能体时序演化算法TSEvol、专用对话数据集TSEData-20K、跨任务优化方法TKTO，以及综合评测基准LLADBench；实验表明其在准确率、F1和误报率上显著优于基线，并具备强推理与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的时序异常检测方法存在推理能力不足、多轮对话能力欠缺、泛化能力弱等问题。

Method: 提出多智能体时序演化算法TSEvol；构建AD专用多轮对话数据集TSEData-20K；开发ChatAD系列模型（基于Llama3、Qwen2.5、Mistral）；提出TS Kahneman-Tversky优化（TKTO）提升跨任务泛化；建立LLM驱动的AD评测基准LLADBench。

Result: 三个ChatAD模型在准确率、F1和误报率上分别最高提升34.50%、34.71%和降低37.42%；经TKTO优化后，在分类、预测与插补等跨任务中展现出强推理与泛化性能。

Conclusion: ChatAD框架通过算法、数据、模型与评测四方面协同创新，显著提升了LLM在时序异常检测中的解释性、对话能力与通用性，为LLM赋能时序分析提供了系统性解决方案。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [539] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 本研究利用社交媒体和约会应用中的文本数据，结合多种嵌入方法（如ChatGPT、BERT、LIWC及风险词典），构建机器学习模型预测男男性行为者（MSM）的性风险行为、饮酒行为及PrEP使用情况，结果表明文本分析在识别 binge drinking 和多性伴行为上效果良好（F1=0.78），在PrEP使用和重度饮酒预测上中等（F1≈0.63–0.64）。


<details>
  <summary>Details</summary>
Motivation: MSM群体面临更高的性传播感染与有害饮酒风险，而社交媒体和约会App文本可能为个性化公共卫生干预提供新途径，亟需验证其预测行为风险的可行性。

Method: 在参与者知情同意下收集文本数据，采用ChatGPT嵌入、BERT嵌入、LIWC语言特征及自建风险词典作为特征，训练机器学习模型预测四类行为指标：月度暴饮、性伴侣数>5、PrEP使用、重度饮酒。

Result: 模型对月度暴饮和性伴侣数>5的预测F1达0.78；对PrEP使用和重度饮酒的预测F1分别为0.64和0.63。

Conclusion: 社交媒体与约会App文本可有效反映MSM的风险与保护行为，基于大语言模型的文本分析方法具备支持规模化、个性化公共卫生干预的潜力。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [540] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: 本文提出了AgentGC，一种基于多智能体的基因组数据无损压缩方法，通过三层架构（用户层、认知层、压缩层）和三种模式（CP、TP、BM），在压缩率和吞吐量上显著优于现有14种基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的基因组数据压缩方法存在不可进化、低层次建模能力弱、适应性差及用户界面不友好等问题。

Method: 提出AgentGC，包含用户层（Leader+LLM提供友好接口）、认知层（Leader驱动，LLM联合优化算法-数据集-系统）、压缩层（Worker主导的自动化多知识学习压缩框架），并设计CP、TP、BM三种运行模式。

Result: 在9个数据集上对比14种基线，平均压缩率提升16.11%–16.66%，吞吐量提升4.73x–9.23x。

Conclusion: AgentGC首次实现了可进化的基因组数据压缩，兼具高性能、强适应性与易用性，为GD管理提供了新范式。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [541] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 本文提出了一种新型角色分离的Transformer模块，将全局控制器标记与网格工作空间标记分离，以支持迭代规则执行，在ARC-1上达到62.6%准确率，超过人类平均表现（60.2%）。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统缺乏类似人类的可解释内部状态，难以实现真正抽象推理；需构建具备显式、可读、持久推理状态的模型。

Method: 设计角色分离的Transformer模块，区分全局控制器token与局部网格workspace token，实现迭代规则应用；在视觉为中心的VARC协议下训练评估。

Result: 在ARC-1上准确率达62.6%，超越人类平均（60.2%）及此前所有方法；定性显示更连贯的规则应用结构。

Conclusion: 推理应作为独立模态存在，分离控制器与工作空间能有效提升抽象视觉推理能力，验证了‘推理即模态’的假设。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [542] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: 本文提出ScriptMind框架，利用小规模LLM结合犯罪脚本推理、定制化数据集和认知模拟评估，显著提升电话诈骗检测性能与用户防骗意识。


<details>
  <summary>Details</summary>
Motivation: 传统诈骗检测方法难以应对个性化、多轮次的社会工程诈骗，而大语言模型在欺骗识别中的认知辅助潜力尚未被充分挖掘。

Method: 提出ScriptMind框架，包含三部分：犯罪脚本推理任务（CSIT）、犯罪脚本感知数据集（CSID）用于微调小规模LLM，以及基于认知模拟的社交工程防御评估（CSED）；使用571个韩语电话诈骗案例构建22712条结构化训练样本。

Result: 微调后的11B小规模LLM在检测准确率、误报率降低、诈骗者话语预测及推理质量上均超越GPT-4o达13%，并在电话诈骗模拟中显著且持续提升用户的怀疑水平与认知警觉性。

Conclusion: ScriptMind标志着迈向以人为中心、具备认知适应能力的LLM诈骗防御系统的重要一步。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [543] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 本文提出了一种基于音频情感信号实时生成响应式媒体内容的多智能体AI系统，强调将识别出的情感转化为安全、适龄且可控的内容，并通过四个协同智能体和显式安全验证环实现高准确率、高一致性与100%安全合规。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类精度，而本文旨在解决如何将推断的情感状态转化为安全、适龄、可控的响应内容这一实际应用问题。

Method: 构建包含四个协作智能体的多智能体系统：情感识别代理（CNN声学特征提取）、响应策略决策代理（情感到响应模式映射）、内容参数生成代理（生成媒体控制参数）和安全验证代理（强制执行适龄性与刺激约束），并引入显式安全验证闭环。

Result: 在公开数据集上实验显示，系统达到73.2%情感识别准确率、89.4%响应模式一致性、100%安全合规性，并保持低于100ms的推理延迟。

Conclusion: 该模块化多智能体架构具备可解释性与可扩展性，适用于儿童相关媒体、治疗应用及情感响应型智能设备。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [544] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: 本文提出了DSAEval基准，用于评估基于大语言模型的数据科学代理在真实世界多模态、多查询、多维度数据科学任务中的性能，并系统评测了11个先进代理模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM数据代理在开放性、多领域、无标准答案的真实数据科学问题上缺乏有效评估手段。

Method: 构建包含641个真实数据科学问题、覆盖285个多样化数据集（含结构化与非结构化数据）的DSAEval基准，具备多模态环境感知、多查询交互和多维评估三大特性，并对11个先进代理模型进行系统评测。

Result: Claude-Sonnet-4.5综合性能最强，GPT-5.2效率最高，MiMo-V2-Flash成本效益最优；多模态感知显著提升视觉相关任务性能（+2.04%~11.30%）；当前代理在结构化数据和常规分析中表现良好，但在非结构化领域仍面临重大挑战。

Conclusion: DSAEval为数据科学代理提供了更贴近现实的评估框架，揭示了当前技术瓶颈，并为未来研究指明了方向。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [545] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 本文提出了一种基于自适应分治策略的算法，用于高效检测和定位自然语言事实集合中的全局不一致性，并支持最小修复，显著降低了对大语言模型（LLM）作为判别器的查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在小规模事实子集上的一致性判断存在噪声，且两两检查无法保证全局一致性；而全局一致性验证在最坏情况下需指数级查询，亟需更高效的实用方法。

Method: 形式化全局一致性验证问题，提出一种自适应分治算法，用于识别最小不一致子集（MUSes），并可选地通过击中集（hitting-sets）计算最小修复；该方法具有低阶多项式查询复杂度。

Result: 在合成数据与真实LLM oracle上的实验表明，该方法能高效检测并定位不一致性，显著提升语言一致性验证的可扩展性。

Conclusion: 所提算法为基于LLM的事实一致性验证提供了理论严谨且实践可行的框架，兼顾效率、可解释性与可扩展性。

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [546] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 本文提出了一种风险感知的动态路由（RADR）框架，结合时空图神经网络与组合优化，用于应对电商物流中交通拥堵和需求波动问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态路径规划难以应对物流网络中的交通拥堵和零售需求波动，亟需一种能实时响应风险的动态路由方法。

Method: 构建基于GPS数据的空间聚类物流拓扑图；采用GCN-GRU混合模型预测未来拥堵风险；将预测结果嵌入动态边权重机制进行路径规划。

Result: 在Smart Logistics Dataset 2024上验证，RADR在高拥堵场景下降低19.3%的风险暴露，仅增加2.1%运输距离。

Conclusion: RADR框架能有效平衡配送效率与运营安全，显著提升供应链韧性。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [547] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: 本文提出了SocialMindChange基准，旨在评估语言模型在社交互动中主动改变他人心理状态的能力，而非仅被动追踪心理状态变化。


<details>
  <summary>Details</summary>
Motivation: 现有动态心理理论（ToM）基准多让模型被动理解心理状态变化，而真实社交中ToM还需用于主动影响他人心理状态；因此需构建能评估‘改变心智’能力的新基准。

Method: 提出SocialMindChange基准：每个实例含4个角色、5个连贯场景，模型扮演一角色生成对话以达成目标，同时保持所有参与者心理状态一致性；采用四步结构化框架构建1200个社会情境（含6000场景、9万+问题），并经现实性与质量验证。

Result: 对10个前沿大语言模型的评测显示，其平均性能比人类低54.2%，表明当前LLM在长程、关联性社交互动中维持与改变心理状态表征仍存在显著困难。

Conclusion: SocialMindChange揭示了当前LLM在主动社交推理（尤其是高阶心理状态建模与干预）上的严重不足，为未来ToM与交互式AI研究提供了新方向与挑战。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [548] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLM）代理在社交推理游戏‘黑手党’中使用自然语言进行欺骗的能力，发现GPT-4o代理比人类玩家更难被识别为‘黑手党’，表明其欺骗更有效；作者构建了基于GPT-4-Turbo的‘黑手党检测器’，以预测准确率作为欺骗质量的代理指标，并公开了LLM黑手党对话数据集。


<details>
  <summary>Details</summary>
Motivation: 现有工作已揭示LLM可在受控任务中欺骗，但其在真实社交语境中通过自然语言进行欺骗的能力尚不清楚；社交推理游戏（如黑手党）为评估该能力提供了理想场景。

Method: 采用异步多智能体框架模拟35局由GPT-4o驱动的黑手党游戏；构建基于GPT-4-Turbo的‘黑手党检测器’，在不获知玩家角色的前提下分析游戏文本并预测黑手党身份；将检测器在LLM游戏、28局人类游戏及随机基线上的预测准确率进行对比。

Result: 黑手党检测器对LLM游戏的预测准确率显著低于对人类游戏的准确率，且该结果在不同游戏天数和检测黑手党数量下均稳健；说明LLM代理更善于融入群体、更难被识破，即欺骗质量更高。

Conclusion: LLM在社交语境中具备高度自然、有效的欺骗能力，这既体现了其社会交互的复杂性，也凸显了潜在安全风险；所发布的数据集可推动后续关于LLM社会行为与安全的研究。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [549] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 本文质疑了当前用概率置信度作为推理质量代理指标的有效性，发现其对推理步骤间的因果依赖不敏感，主要反映表面流畅性；为此提出一种对比式因果度量方法，能更准确地选择高质量推理输出。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设高概率置信度反映高推理保真度，但该文质疑其是否真正捕获推理中必需的步骤间因果依赖关系。

Method: 引入三类系统破坏推理步骤间因果依赖（同时保持局部流畅性）的扰动，并在多模型、多基准上评估其对Best-of-N选择准确率的影响；进一步提出一种对比式因果度量方法。

Result: 即使施加强干扰（如硬注意力掩码阻断步骤间注意力），选择准确率下降甚微；表明当前概率指标对逻辑结构不敏感；新提出的对比因果度量显著提升了输出选择的保真度。

Conclusion: 概率置信度主要反映表面流畅性或分布内先验，而非真实推理结构；需设计显式建模步骤间因果依赖的新度量方法。

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [550] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: 本文提出RELIEF框架，通过探测和对齐大推理模型（LRM）内部的‘推理信念’来塑造其行为，无需依赖昂贵的推理轨迹监督，显著降低训练成本并提升效率与可信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖强化学习或带金标准推理轨迹的微调，计算开销大、难以扩展；而LRM内部存在可探测的‘推理信念’，为更轻量高效的行为调控提供新路径。

Method: 提出Reasoning Belief Engineering（RELIEF），利用logit probing提取LRM的隐式推理信念，并通过合成的自反思问答对进行微调，使其自我认知对齐预设信念蓝图。

Result: 在效率与可信度任务上，RELIEF达到或超越基于行为监督和偏好学习的基线方法，且训练成本更低；分析证实信念调整能有效引导实际推理行为。

Conclusion: LRM的推理信念是可探测、可编辑的内在调控维度；RELIEF验证了无需外部推理监督即可实现高效、可信的行为塑造，为轻量化对齐提供了新范式。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [551] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: 本文提出DARC框架，通过解耦的不对称推理课程设计，稳定大语言模型的自博弈自我提升过程，在多个推理基准上显著提升性能，且无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 现有自博弈框架存在优化不稳定问题：一是提问者目标非平稳（依赖求解器反馈的奖励），二是求解器训练中自生成伪标签引入引导误差。

Method: DARC采用两阶段框架：第一阶段训练提问者，基于显式难度等级和外部语料生成难度校准的问题；第二阶段采用不对称自蒸馏机制训练求解者，由文档增强的教师模型生成高质量伪标签，监督无文档访问能力的学生求解者。

Result: DARC具有模型无关性，在9个推理基准、3种骨干模型上平均提升10.9分，持续优于所有基线方法，并逼近全监督模型性能，且不依赖人工标注。

Conclusion: DARC有效缓解了自博弈中的优化不稳定性问题，为大语言模型的自进化提供了更稳定、高效且无需人工标注的新范式。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [552] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: 本文提出了Look-Ahead-Bench基准，用于在真实金融工作流中量化大语言模型（LLM）的“前瞻偏差”（look-ahead bias），强调时序严谨性与实用场景评估，发现标准LLM存在显著偏差，而PiT-Inference系列模型随规模增大展现出更好泛化与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有金融领域LLM评估多依赖问答式内隐知识测试，缺乏对真实时序约束下前瞻偏差的标准化、实用化度量；需区分真实预测能力与数据记忆效应，支撑模型在实际金融部署中的可信评估。

Method: 构建Look-Ahead-Bench基准，基于Point-in-Time（PiT）原则设计任务，通过跨不同时序市场周期（如牛市/熊市）的性能衰减（alpha decay）分析模型前瞻性；引入多个定量基线设定性能阈值，系统评测Llama 3.1（8B/70B）、DeepSeek 3.2及PiT-Inference系列Pitinf模型。

Result: 标准开源LLM（如Llama、DeepSeek）表现出显著前瞻偏差（alpha衰减严重）；PiT-Inference系列模型（Pitinf-Small/Medium/Large）随参数量增加，alpha衰减减弱，展现出更强的时间泛化与因果推理能力。

Conclusion: Look-Ahead-Bench为金融LLM的时序偏差评估提供了首个标准化、可复现的实践框架；证实了显式PiT建模对缓解前瞻偏差的有效性，为高可靠性金融AI部署奠定评估基础。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [553] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 本文提出了一种名为Virtual Urbanism（VU）的多模态AI分析框架，通过生成式合成城市副本量化城市身份，并以东京九个区域为案例验证其可行性与有效性。


<details>
  <summary>Details</summary>
Motivation: 推动可计算的城市身份度量方法的发展，突破传统依赖人工经验或静态数据的局限，探索AI驱动的城市形态与文化特征识别新路径。

Method: 构建基于Stable Diffusion与LoRA模型的合成管线，生成剔除方向标识符的动态合成城市序列；开展三阶段人类评估实验：（I）感知真实性检验，（II）区域级身份量化，（III）核心身份要素提取；引入Urban Identity Level（UIL）指标并结合语义分析。

Result: 合成副本平均识别准确率达~81%；UIL指标成功区分不同区域的身份强度；语义分析揭示文化嵌入的建筑/空间类型是核心身份形成要素。

Conclusion: VU框架被证实可行，为AI增强型城市分析提供了新范式，并指明了自动化、多参数城市身份度量的发展方向。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [554] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: 本文提出了LifeAgentBench，一个用于评估大语言模型在长期、跨维度、多用户生活方式健康推理能力的大规模问答基准，并基于此发现现有模型的瓶颈，进而提出了一种融合多步证据检索与确定性聚合的健康助手基线模型LifeAgent。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在个性化数字健康支持中的长周期、跨维度推理能力尚不明确，缺乏系统性基准评测；因此需要构建专门的基准以推动该领域发展。

Method: 构建了包含22573个问题的LifeAgentBench基准，涵盖从基础检索到复杂推理任务；设计可扩展的基准构建流程和标准化评估协议；系统评测11个主流大语言模型；提出LifeAgent代理模型，结合多步证据检索与确定性聚合机制。

Result: 识别出当前LLMs在长周期聚合和跨维度推理上的关键瓶颈；LifeAgent在基准上显著优于两个常用基线；案例研究表明其具备现实日常场景应用潜力。

Conclusion: LifeAgentBench为健康领域LLM评估提供了可靠、可扩展的工具；LifeAgent展示了通过结构化推理设计提升健康助手性能的有效路径。

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [555] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: 本文提出了一种名为人类模拟计算（HSC）的新框架，将智能建模为包含思考、行动、学习、反思和活动调度的闭环内部推理过程，强调主动参与与环境交互，并融合多种人类常用思维策略，以提升大语言模型在开放动态现实环境中的适应性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型仅依赖文本数据，在开放动态的真实环境中存在适应性差、推理结果难以验证、交互能力受限等问题，需引入更贴近人类认知机制的计算范式。

Method: 提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环内部推理过程；融入主特征导向推理、通过行动扩展推理范围、基于环境反馈的即时学习等人类思维策略；强调行动不仅服务于目标达成，还自动优化内部推理机制。

Result: 理论分析表明，人类模拟策略无法仅从语言材料中习得，人机协同的推理过程与以动作为基础的推理方法对实现强适应性和真实环境有效交互至关重要。

Conclusion: HSC为构建具备持续自适应能力、环境交互能力和内在反思能力的下一代AI系统提供了新范式，弥补了纯语言模型在具身性与动态性上的根本缺陷。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [556] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: 本文提出PREFAB，一种基于峰值-结束规则和情绪序数表示的低成本回溯式自我标注方法，通过偏好学习模型识别情绪变化点，仅要求标注员对选定片段进行标注，并引入预览机制提供上下文线索，显著降低标注负担并提升标注信心，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 现有全时段自我标注方法耗时、费力且易疲劳出错，亟需更高效、低负担的情绪状态标注方法。

Method: 提出PREFAB方法：基于峰值-结束规则与情绪序数表征，采用偏好学习模型检测相对情绪变化，聚焦标注情绪拐点区域；引入预览机制提供简短上下文线索；对未标注段落进行插值。

Result: 在技术性能研究和25人用户研究中，PREFAB在建模情绪拐点方面优于基线方法，显著降低标注工作量（有条件地减轻时间负担），并提升标注员信心而不损害标注质量。

Conclusion: PREFAB是一种有效、低负担、高可信度的情绪状态自我标注新范式，为情感计算中的数据标注提供了实用可行的替代方案。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [557] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 本文提出了一种新范式：直接使用通用编码智能体（如Claude Code）作为形式化数学推理器，无需训练专用定理证明器；基于该范式构建的Numina-Lean-Agent在Putnam 2025全部12题上达成满分，并成功形式化Brascamp-Lieb定理。


<details>
  <summary>Details</summary>
Motivation: 现有定理证明系统依赖任务定制流水线和训练过的形式化证明器，缺乏灵活性与可复现性；而通用编码智能体天然支持多样化推理任务、模型升级无需再训练、且通过MCP机制可灵活调用专用工具。

Method: 提出以通用编码智能体为形式化数学推理核心的新范式，构建Numina-Lean-Agent系统，集成Claude Code与Numina-Lean-MCP，实现对Lean的自主交互、定理检索、非形式化证明及辅助推理。

Result: Numina-Lean-Agent在Putnam 2025全部12道题上100%求解成功，性能匹敌最优闭源系统；并成功与数学家协作，完成Brascamp-Lieb定理的形式化。

Conclusion: 通用编码智能体可有效胜任复杂形式化数学推理任务，该范式提升了灵活性、可复现性与扩展性，为AI驱动的数学形式化开辟了新路径。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [558] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 本文提出了一种跨尺度、跨基质的认知统一框架，认为自然与人工系统中的认知本质在于两种不变量的协同：嵌入空间的重映射与在该空间内的导航，二者均通过迭代误差最小化实现。


<details>
  <summary>Details</summary>
Motivation: 探索不同来源、组成和物理基质的智能体（从亚细胞网络到群体生物，再到人工系统）中是否存在普适的认知原理，以推动‘多样性智能’这一新兴领域的发展。

Method: 通过类比分析生物学集体（如细胞、多细胞生物）与现代AI模型（如Transformer、扩散模型、神经元胞自动机）在信息处理机制上的共性，提炼出‘嵌入空间重映射’与‘空间内导航’这对核心不变量，并强调其依赖迭代误差校正的实现方式。

Result: 识别出一种基质无关的认知不变原理——即基于嵌入空间重映射与导航的迭代误差最小化机制，该机制在生物系统与AI系统中均普遍存在。

Conclusion: 该双重原则为理解自然与人工认知提供了统一框架，不仅揭示了生命系统与AI模型间的深层共性，也为跨尺度自适应智能的设计与工程化提供了理论基础。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [559] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: 本文提出RebuttalAgent，一种多智能体框架，将反驳生成重构为以证据为中心的规划任务，通过分解评审意见、构建混合上下文和自主外部搜索，提升反驳的覆盖度、忠实性和策略连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有反驳生成方法存在幻觉、忽略评审意见和缺乏可验证依据等问题，难以精准对齐评审意图与稿件细节。

Method: 提出RebuttalAgent多智能体框架，将反驳生成视为证据驱动的规划任务：分解评审反馈为原子问题，融合压缩摘要与高保真文本构建混合上下文，并集成按需外部搜索模块以获取文献支持；先生成可检查的响应计划，再撰写反驳。

Result: 在新构建的RebuttalBench基准上验证，RebuttalAgent在覆盖度、忠实性和战略连贯性上显著优于强基线模型。

Conclusion: RebuttalAgent提供了一种透明、可控且证据扎实的反驳生成新范式，有望增强同行评审过程的可靠性与效率。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [560] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 本文系统性地研究了大语言模型代理系统的效率问题，从记忆、工具学习和规划三个核心组件出发，分析了延迟、token消耗、步骤数等成本因素，并提出了两种互补的效率评估方式。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型代理系统的有效性不断提升，但其在实际部署中至关重要的效率问题却被忽视。

Method: 从记忆、工具学习和规划三方面分析代理系统效率；归纳提升效率的共性原则（如上下文压缩、优化强化学习奖励以减少工具调用、引入受控搜索）；提出两种效率评估范式（固定成本下比效果、相同效果下比成本），并梳理相关基准与指标。

Result: 总结出若干提升效率的高阶通用原则；构建了兼顾效果与成本的效率评估框架；整理了现有效率导向基准的评测协议与常用指标。

Conclusion: 效率是代理系统实用化的关键瓶颈，需在方法设计与评估体系上同步推进；未来应更注重帕累托最优权衡、标准化评测及跨组件协同优化。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [561] [DeepEvidence: Empowering Biomedical Discovery with Deep Knowledge Graph Research](https://arxiv.org/abs/2601.11560)
*Zifeng Wang,Zheng Chen,Ziwei Yang,Xuan Wang,Qiao Jin,Yifan Peng,Zhiyong Lu,Jimeng Sun*

Main category: cs.IR

TL;DR: DeepEvidence是一个AI代理框架，专为跨异构生物医学知识图谱进行深度研究而设计，通过协调广度优先和深度优先搜索代理，并构建增量式证据图，显著提升生物医学发现各阶段的系统性探索与证据整合能力。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学知识图谱结构差异大、持续演进且跨资源对齐有限，导致人工集成成本高，严重制约知识探索的深度与规模。

Method: 提出DeepEvidence框架，包含一个调度器、两个互补代理（BFRS用于多图实体广度搜索，DFRS用于多跳证据导向推理）、增量式证据图构建机制，以及统一API接口和执行沙箱以支持规模化程序化数据检索与分析。

Result: 在深度推理基准测试及药物发现、临床前实验、临床试验开发和循证医学四大生物医学发现阶段中，DeepEvidence均展现出系统性探索与证据合成能力的显著提升。

Conclusion: 知识图谱驱动的深度研究有望加速生物医学发现进程，DeepEvidence为解决异构KG集成与深度推理提供了新范式。

Abstract: Biomedical knowledge graphs (KGs) encode vast, heterogeneous information spanning literature, genes, pathways, drugs, diseases, and clinical trials, but leveraging them collectively for scientific discovery remains difficult. Their structural differences, continual evolution, and limited cross-resource alignment require substantial manual integration, limiting the depth and scale of knowledge exploration. We introduce DeepEvidence, an AI-agent framework designed to perform Deep Research across various heterogeneous biomedical KGs. Unlike generic Deep Research systems that rely primarily on internet-scale text, DeepEvidence incorporates specialized knowledge-graph tooling and coordinated exploration strategies to systematically bridge heterogeneous resources. At its core is an orchestrator that directs two complementary agents: Breadth-First ReSearch (BFRS) for broad, multi-graph entity search, and Depth-First ReSearch (DFRS) for multi-hop, evidence-focused reasoning. An internal, incrementally built evidence graph provides a structured record of retrieved entities, relations, and supporting evidence. To operate at scale, DeepEvidence includes unified interfaces for querying diverse biomedical APIs and an execution sandbox that enables programmatic data retrieval, extraction, and analysis. Across established deep-reasoning benchmarks and four key stages of the biomedical discovery lifecycle: drug discovery, pre-clinical experimentation, clinical trial development, and evidence-based medicine, DeepEvidence demonstrates substantial gains in systematic exploration and evidence synthesis. These results highlight the potential of knowledge-graph-driven Deep Research to accelerate biomedical discovery.

</details>


### [562] [Utilizing Metadata for Better Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11863)
*Raquib Bin Yousuf,Shengzhe Xu,Mandar Sharma,Andrew Neeser,Chris Latimer,Naren Ramakrishnan*

Main category: cs.IR

TL;DR: 本文系统研究了在检索增强生成（RAG）中如何有效利用元数据提升检索质量，尤其针对结构化、重复性高的监管文档。作者对比了多种元数据感知的检索策略（如元数据前缀/后缀、统一嵌入、late-fusion、查询重写），发现元数据前缀和统一嵌入效果最优；进一步分析表明，元数据整合能增强文档内聚性、降低混淆、扩大相关/无关片段距离；结构化字段（如章节号、表格类型）具有强消歧能力。


<details>
  <summary>Details</summary>
Motivation: 在监管等结构化、语言高度重复的文本中，仅依赖语义相似度的检索易失效；将元数据拼接进文本是常用启发式方法，但其影响与权衡缺乏系统研究。

Method: 设计并评估五种元数据感知检索策略：元数据作为文本前缀/后缀、元数据与内容联合编码的统一嵌入（dual-encoder unified embedding）、late-fusion双编码器检索、元数据驱动的查询重写；在自建RAGMATE-10K数据集上，结合多种检索指标与问题类型进行实证比较；辅以嵌入空间可视化与字段级消融分析。

Result: 元数据前缀与统一嵌入 consistently 优于纯文本基线，且统一嵌入有时更优、维护成本更低；嵌入空间分析证实元数据提升检索效果源于增强文档内聚性、减少跨文档混淆、扩大相关/无关间距；结构化字段（如section ID、table type）对消歧贡献最大。

Conclusion: 元数据不应仅被扁平化为文本，而应通过结构化方式（尤其是统一嵌入或前缀）融入检索流程；结构化元数据是提升RAG在专业领域鲁棒性的关键信号；本工作提供了可复现的评估框架、代码与新基准数据集。

Abstract: Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.

</details>


### [563] [Cultural Analytics for Good: Building Inclusive Evaluation Frameworks for Historical IR](https://arxiv.org/abs/2601.11874)
*Suchana Datta,Dwaipayan Roy,Derek Greene,Gerardine Meaney,Karen Wade,Philipp Mayr*

Main category: cs.IR

TL;DR: 本文结合信息检索与文化分析，构建了一个用于研究19世纪语言、术语及检索变化的基准数据集（基于英国图书馆BL19数字馆藏），通过专家设计查询、段落级相关性标注与大语言模型辅助，提升历史文献检索的准确性、可解释性、透明性与文化包容性。


<details>
  <summary>Details</summary>
Motivation: 支持历史知识的公平获取，弥合信息检索与文化分析之间的鸿沟，并推动更具解放性、历史意识和文化包容性的数字知识基础设施建设。

Method: 基于英国图书馆BL19数字馆藏（1700–1899年超3.5万部作品），构建面向19世纪小说与非小说的检索基准；融合专家驱动的查询设计、段落级人工相关性标注与大语言模型辅助，形成以人类专业知识为根基的可扩展评估框架；重点研究从小说向非小说的知识迁移，探索叙事理解与语义丰富性对学术与事实类材料检索的增益作用。

Result: 提出了一套兼顾检索性能、可解释性、透明性与文化包容性的跨学科评估框架；提供了实用的评估资源与方法论范式，支撑更富历史意识的数字档案检索系统开发。

Conclusion: 该框架不仅提升了历史文献检索效果，更推动了数字档案在文化代表性与知识正义维度上的进步，为建设更公平、更具解放性的知识基础设施提供了路径。

Abstract: This work bridges the fields of information retrieval and cultural analytics to support equitable access to historical knowledge. Using the British Library BL19 digital collection (more than 35,000 works from 1700-1899), we construct a benchmark for studying changes in language, terminology and retrieval in the 19th-century fiction and non-fiction. Our approach combines expert-driven query design, paragraph-level relevance annotation, and Large Language Model (LLM) assistance to create a scalable evaluation framework grounded in human expertise. We focus on knowledge transfer from fiction to non-fiction, investigating how narrative understanding and semantic richness in fiction can improve retrieval for scholarly and factual materials. This interdisciplinary framework not only improves retrieval accuracy but also fosters interpretability, transparency, and cultural inclusivity in digital archives. Our work provides both practical evaluation resources and a methodological paradigm for developing retrieval systems that support richer, historically aware engagement with digital archives, ultimately working towards more emancipatory knowledge infrastructures.

</details>


### [564] [Agentic-R: Learning to Retrieve for Agentic Search](https://arxiv.org/abs/2601.11888)
*Wenhan Liu,Xinyu Ma,Yutao Zhu,Yuchen Li,Daiting Shi,Dawei Yin,Zhicheng Dou*

Main category: cs.IR

TL;DR: 本文提出了一种面向智能体搜索（agentic search）的新型检索器训练框架，通过结合局部查询-段落相关性和全局答案正确性来评估段落效用，并采用搜索智能体与检索器双向迭代优化的训练策略，显著提升了多跳和单跳问答任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性的检索器在智能体搜索中效果有限，因为相似段落未必有助于最终答案生成；如何为多步推理驱动的智能体搜索设计专用检索器尚未被充分探索。

Method: 提出一种新型检索器训练框架，引入局部（查询-段落相关性）与全局（答案正确性）联合效用评估，并采用搜索智能体与检索器双向迭代优化的训练策略，使检索器持续利用智能体生成的高质量、演化式查询进行更新。

Result: 在七个单跳与多跳问答基准上，所提检索器（\ours{}）在不同搜索智能体上均一致超越强基线。

Conclusion: 面向智能体搜索的检索器需兼顾局部相关性与全局答案导向性，双向迭代训练能有效提升其在复杂多步推理任务中的表现。

Abstract: Agentic search has recently emerged as a powerful paradigm, where an agent interleaves multi-step reasoning with on-demand retrieval to solve complex questions. Despite its success, how to design a retriever for agentic search remains largely underexplored. Existing search agents typically rely on similarity-based retrievers, while similar passages are not always useful for final answer generation. In this paper, we propose a novel retriever training framework tailored for agentic search. Unlike retrievers designed for single-turn retrieval-augmented generation (RAG) that only rely on local passage utility, we propose to use both local query-passage relevance and global answer correctness to measure passage utility in a multi-turn agentic search. We further introduce an iterative training strategy, where the search agent and the retriever are optimized bidirectionally and iteratively. Different from RAG retrievers that are only trained once with fixed questions, our retriever is continuously improved using evolving and higher-quality queries from the agent. Extensive experiments on seven single-hop and multi-hop QA benchmarks demonstrate that our retriever, termed \ours{}, consistently outperforms strong baselines across different search agents. Our codes are available at: https://github.com/8421BCD/Agentic-R.

</details>


### [565] [Facet-Aware Multi-Head Mixture-of-Experts Model with Text-Enhanced Pre-training for Sequential Recommendation](https://arxiv.org/abs/2601.12301)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.IR

TL;DR: 本文提出FAME模型，通过多头注意力机制的子嵌入捕捉物品多面性，并利用门控机制动态整合各面预测；同时引入MoE网络在每个注意力头中解耦用户在各面内的复杂偏好，并设计文本增强的预训练模块以提升嵌入语义鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐系统用单一嵌入表示物品，难以刻画其多面性（如电影的类型、演员等）及用户在各面内的多样化偏好。

Method: 提出Facet-Aware Multi-Head Mixture-of-Experts（FAME）模型：1）利用多头注意力各头的子嵌入分别预测下一物品，表征不同物品面；2）通过门控机制动态加权融合各面预测；3）每头内嵌入Mixture-of-Experts（MoE）结构，由可学习路由器聚合专家输出以解耦用户偏好；4）设计文本增强的预训练模块，结合预训练文本编码器与交替监督对比学习，从文本元数据中显式解耦面特异性特征。

Result: FAME在多个公开数据集上显著优于主流序列推荐方法，消融实验验证了各组件（多面建模、MoE、文本预训练）的有效性；可视化分析表明模型能有效识别并分离不同物品面及对应用户偏好模式。

Conclusion: 物品的多面性与用户偏好的多样性需联合建模，FAME通过分面感知的多头注意力、门控融合与MoE结构，辅以文本驱动的预训练，实现了更细粒度、更鲁棒的序列推荐。

Abstract: Sequential recommendation (SR) systems excel at capturing users' dynamic preferences by leveraging their interaction histories. Most existing SR systems assign a single embedding vector to each item to represent its features, adopting various models to combine these embeddings into a sequence representation that captures user intent. However, we argue that this representation alone is insufficient to capture an item's multi-faceted nature (e.g., movie genres, starring actors). Furthermore, users often exhibit complex and varied preferences within these facets (e.g., liking both action and musical films within the genre facet), which are challenging to fully represent with static identifiers. To address these issues, we propose a novel architecture titled Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential Recommendation (FAME). We leverage sub-embeddings from each head in the final multi-head attention layer to predict the next item separately, effectively capturing distinct item facets. A gating mechanism then integrates these predictions by dynamically determining their importance. Additionally, we introduce a Mixture-of-Experts (MoE) network within each attention head to disentangle varied user preferences within each facet, utilizing a learnable router network to aggregate expert outputs based on context. Complementing this architecture, we design a Text-Enhanced Facet-Aware Pre-training module to overcome the limitations of randomly initialized embeddings. By utilizing a pre-trained text encoder and employing an alternating supervised contrastive learning objective, we explicitly disentangle facet-specific features from textual metadata (e.g., descriptions) before sequential training begins. This ensures that the item embeddings are semantically robust and aligned with the downstream multi-facet framework.

</details>


### [566] [Information Farming: From Berry Picking to Berry Growing](https://arxiv.org/abs/2601.12544)
*Leif Azzopardi,Adam Roegiest*

Main category: cs.IR

TL;DR: 本文提出“信息耕作”（Information Farming）这一新概念，以应对生成式AI带来的信息行为范式转变，类比于人类从狩猎采集到农业文明的转变；用户不再被动搜寻（foraging），而是主动播种提示、培育工作流、收获定制化信息产出。


<details>
  <summary>Details</summary>
Motivation: 经典的信息觅食理论（Information Foraging Theory）和Berry Picking模型已难以解释生成式AI时代用户主动生产、结构化与复用信息的新行为模式。

Method: 采用历史类比（新石器革命）构建概念框架，并结合实证证据进行理论论证与反思性分析。

Result: 提出了‘信息耕作’框架，阐释其在人机交互、信息设计与评估中的潜在益处、挑战与风险。

Conclusion: 信息耕作代表了人类信息交互方式的范式跃迁，将逐步取代碎片化、跨源的信息觅食，成为主导性实践，并要求相关研究与设计范式同步演进。

Abstract: The classic paradigms of Berry Picking and Information Foraging Theory have framed users as gatherers, opportunistically searching across distributed sources to satisfy evolving information needs. However, the rise of GenAI is driving a fundamental transformation in how people produce, structure, and reuse information - one that these paradigms no longer fully capture. This transformation is analogous to the Neolithic Revolution, when societies shifted from hunting and gathering to cultivation. Generative technologies empower users to "farm" information by planting seeds in the form of prompts, cultivating workflows over time, and harvesting richly structured, relevant yields within their own plots, rather than foraging across others people's patches. In this perspectives paper, we introduce the notion of Information Farming as a conceptual framework and argue that it represents a natural evolution in how people engage with information. Drawing on historical analogy and empirical evidence, we examine the benefits and opportunities of information farming, its implications for design and evaluation, and the accompanying risks posed by this transition. We hypothesize that as GenAI technologies proliferate, cultivating information will increasingly supplant transient, patch-based foraging as a dominant mode of engagement, marking a broader shift in human-information interaction and its study.

</details>


### [567] [HyFormer: Revisiting the Roles of Sequence Modeling and Feature Interaction in CTR Prediction](https://arxiv.org/abs/2601.12681)
*Yunwen Huang,Shiyong Hong,Xijun Xiao,Jinqiu Jin,Xuanyuan Luo,Zhe Wang,Zheng Chai,Shikang Wu,Yuchao Zheng,Jingjian Lin*

Main category: cs.IR

TL;DR: 本文提出HyFormer，一种统一的混合Transformer架构，将长序列建模与异构特征交互紧密集成于单一骨干网络中，通过Query Decoding和Query Boosting交替优化机制，在工业大规模推荐模型中实现了更优性能与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有工业大规模推荐模型采用解耦流水线（如LONGER压缩序列+RankMixer融合特征），限制了表征能力与交互灵活性，难以兼顾长序列建模与异构特征联合优化。

Method: 提出HyFormer架构，核心为交替优化的两个机制：Query Decoding（将非序列特征扩展为Global Tokens，并在行为序列的层式KV表示上进行长序列解码）；Query Boosting（通过高效token mixing增强跨查询与跨序列的异构交互）。二者迭代执行以逐层精化语义表征。

Result: 在十亿级工业数据集上显著优于LONGER和RankMixer基线（参数量与FLOPs相当），具备更优的参数/FLOPs扩展性；线上A/B测试在高流量生产系统中验证了其显著效果提升。

Conclusion: HyFormer是一种兼具实用性与可扩展性的统一建模范式，为工业大规模推荐模型提供了新范式。

Abstract: Industrial large-scale recommendation models (LRMs) face the challenge of jointly modeling long-range user behavior sequences and heterogeneous non-sequential features under strict efficiency constraints. However, most existing architectures employ a decoupled pipeline: long sequences are first compressed with a query-token based sequence compressor like LONGER, followed by fusion with dense features through token-mixing modules like RankMixer, which thereby limits both the representation capacity and the interaction flexibility. This paper presents HyFormer, a unified hybrid transformer architecture that tightly integrates long-sequence modeling and feature interaction into a single backbone. From the perspective of sequence modeling, we revisit and redesign query tokens in LRMs, and frame the LRM modeling task as an alternating optimization process that integrates two core components: Query Decoding which expands non-sequential features into Global Tokens and performs long sequence decoding over layer-wise key-value representations of long behavioral sequences; and Query Boosting which enhances cross-query and cross-sequence heterogeneous interactions via efficient token mixing. The two complementary mechanisms are performed iteratively to refine semantic representations across layers. Extensive experiments on billion-scale industrial datasets demonstrate that HyFormer consistently outperforms strong LONGER and RankMixer baselines under comparable parameter and FLOPs budgets, while exhibiting superior scaling behavior with increasing parameters and FLOPs. Large-scale online A/B tests in high-traffic production systems further validate its effectiveness, showing significant gains over deployed state-of-the-art models. These results highlight the practicality and scalability of HyFormer as a unified modeling framework for industrial LRMs.

</details>


### [568] [The Unfairness of Multifactorial Bias in Recommendation](https://arxiv.org/abs/2601.12828)
*Masoud Mansoury,Jin Huang,Mykola Pechenizkiy,Herke van Hoof,Maarten de Rijke*

Main category: cs.IR

TL;DR: 本文研究了推荐系统中流行度偏差和正面性偏差的联合影响（即多因素偏差），发现正面性偏差在热门项目上更为集中，加剧了曝光不公；提出了一种基于百分位数的评分转换预处理方法，在提升曝光公平性的同时几乎不损失准确性，并能增强后处理公平性方法的效果与效率。


<details>
  <summary>Details</summary>
Motivation: 流行度偏差和正面性偏差各自已被独立研究，但二者联合形成的多因素偏差及其对项目侧公平性（尤其是曝光偏差）的影响尚未被充分探索。

Method: 通过模拟实验分析多因素偏差对曝光公平性的影响；提出并采用基于百分位数的评分转换作为预处理策略；在六个推荐算法和四个公开数据集上进行实验验证，并将其整合进后处理公平性流程中。

Result: 该预处理方法显著提升了曝光公平性，且准确率损失可忽略；与后处理公平性方法结合后，可在降低计算成本的同时实现同等甚至更好的公平性效果。

Conclusion: 应重视多因素偏差问题，简单、数据驱动的预处理方法在提升推荐系统公平性方面具有重要实践价值。

Abstract: Popularity bias and positivity bias are two prominent sources of bias in recommender systems. Both arise from input data, propagate through recommendation models, and lead to unfair or suboptimal outcomes. Popularity bias occurs when a small subset of items receives most interactions, while positivity bias stems from the over-representation of high rating values. Although each bias has been studied independently, their combined effect, to which we refer to as multifactorial bias, remains underexplored. In this work, we examine how multifactorial bias influences item-side fairness, focusing on exposure bias, which reflects the unequal visibility of items in recommendation outputs. Through simulation studies, we find that positivity bias is disproportionately concentrated on popular items, further amplifying their over-exposure. Motivated by this insight, we adapt a percentile-based rating transformation as a pre-processing strategy to mitigate multifactorial bias. Experiments using six recommendation algorithms across four public datasets show that this approach improves exposure fairness with negligible accuracy loss. We also demonstrate that integrating this pre-processing step into post-processing fairness pipelines enhances their effectiveness and efficiency, enabling comparable or better fairness with reduced computational cost. These findings highlight the importance of addressing multifactorial bias and demonstrate the practical value of simple, data-driven pre-processing methods for improving fairness in recommender systems.

</details>


### [569] [Rules, Resources, and Restrictions: A Taxonomy of Task-Based Information Request Intents](https://arxiv.org/abs/2601.12985)
*Melanie A. Kilian,David Elsweiler*

Main category: cs.IR

TL;DR: 本文提出了一种基于任务的查询意图分类法，以弥补现有基于日志的孤立信息需求分类在AI驱动的任务导向搜索中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类法主要基于系统日志，关注孤立信息需求，忽视更广泛的上下文任务；而LLM在支持复杂多阶段任务（如购物决策、旅行规划）时仍存在理解困难。

Method: 采用基于扎根理论的机场信息咨询员访谈研究，构建任务导向的信息请求意图分类体系。

Result: 提出一个连接传统查询导向方法与新兴AI驱动任务导向搜索需求的、基于任务的查询意图分类法。

Conclusion: 应强化查询意图分析中的任务视角，该分类法为提升LLM在真实复杂任务中检索与支持能力提供了理论基础与实践框架。

Abstract: Understanding and classifying query intents can improve retrieval effectiveness by helping align search results with the motivations behind user queries. However, existing intent taxonomies are typically derived from system log data and capture mostly isolated information needs, while the broader task context often remains unaddressed. This limitation becomes increasingly relevant as interactions with Large Language Models (LLMs) expand user expectations from simple query answering toward comprehensive task support, for example, with purchasing decisions or in travel planning. At the same time, current LLMs still struggle to fully interpret complex and multifaceted tasks. To address this gap, we argue for a stronger task-based perspective on query intent. Drawing on a grounded-theory-based interview study with airport information clerks, we present a taxonomy of task-based information request intents that bridges the gap between traditional query-focused approaches and the emerging demands of AI-driven task-oriented search.

</details>


### [570] [Incorporating Q&A Nuggets into Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13222)
*Laura Dietz,Bryan Li,Gabrielle Liu,Jia-Huei Ju,Eugene Yang,Dawn Lawrie,William Walden,James Mayfield*

Main category: cs.IR

TL;DR: Crucible是一种基于Q&A小片段（nuggets）的检索增强生成系统，通过显式保留引用来源提升生成结果的可解释性与准确性，在TREC NeuCLIR 2024评测中显著优于同类系统Ginger。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG系统中信息重复、语义抽象难解释、引用来源丢失等问题，提升生成结果的可追溯性与可解释性。

Method: 构建检索文档的Q&A小片段库，以此指导信息抽取、选择与报告生成；全程保持对每个生成内容的明确引用来源。

Result: 在TREC NeuCLIR 2024数据集上，Crucible在nugget召回率、密度和引用接地性（citation grounding）方面均显著优于Ginger。

Conclusion: 基于nugget的显式引用建模能有效提升RAG系统的准确性、可解释性与可验证性，为RAGE（Retrieval-Augmented Generation with Evaluation）范式提供新思路。

Abstract: RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.

</details>


### [571] [Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?](https://arxiv.org/abs/2601.13227)
*Laura Dietz,Bryan Li,Eugene Yang,Dawn Lawrie,William Walden,James Mayfield*

Main category: cs.IR

TL;DR: 本文探讨了使用LLM裁判评估RAG系统时存在的循环性风险，通过实验表明当评估要素（如提示模板或黄金nuggets）泄露或可预测时，系统可能获得虚假高分，强调盲测和方法多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM裁判在RAG系统评估中广泛应用，尤其是基于nugget的方法被嵌入系统架构，存在因评估与系统设计耦合导致的循环性偏差风险，亟需识别和规避。

Method: 通过对比实验，测试Ginger、Crucible等nugget-based RAG系统与GPT-Researcher等强基线；并主动修改Crucible使其输出针对LLM裁判优化，模拟评估信息泄露场景。

Result: 当提示模板或黄金nuggets被泄露或可预测时，Crucible可达到近似完美的LLM裁判评分，揭示了指标过拟合风险；盲测与多样化方法能有效缓解该问题。

Conclusion: LLM裁判驱动的RAG评估易受循环性干扰，必须采用盲测设置和多方法验证，避免将指标过拟合误判为真实性能提升。

Abstract: RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.

</details>


### [572] [Guidelines for the Creation of an Annotated Corpus](https://arxiv.org/abs/2601.13353)
*Bahdja Boudoua,Nadia Guiffant,Mathieu Roche,Maguelonne Teisseire,Annelise Tran*

Main category: cs.IR

TL;DR: 本文提出了一种通用方法论，用于构建文本标注指南和标注语料库，并涵盖方法、存储、共享与数据价值提升等方面。


<details>
  <summary>Details</summary>
Motivation: 基于UMR TETIS成员反馈及科学文献，解决标注指南与语料库构建缺乏系统性方法的问题。

Method: 提出一套涵盖方法学、数据存储、共享与价值提升的通用标注指南与语料库构建方法论，辅以定义与实例说明各步骤。

Result: 形成一个清晰、可复用的框架，支持不同研究背景下语料库的创建与应用。

Conclusion: 该方法论为标注指南制定与语料库建设提供了系统化、实用化的指导路径。

Abstract: This document, based on feedback from UMR TETIS members and the scientific literature, provides a generic methodology for creating annotation guidelines and annotated textual datasets (corpora). It covers methodological aspects, as well as storage, sharing, and valorization of the data. It includes definitions and examples to clearly illustrate each step of the process, thus providing a comprehensive framework to support the creation and use of corpora in various research contexts.

</details>


### [573] [Integrating Vision-Centric Text Understanding for Conversational Recommender Systems](https://arxiv.org/abs/2601.13505)
*Wei Yuan,Shutong Qiao,Tong Chen,Quoc Viet Hung Nguyen,Zi Huang,Hongzhi Yin*

Main category: cs.IR

TL;DR: 本文提出STARCRS，一种融合屏幕阅读与大语言模型文本理解双路径的对话推荐系统，通过知识锚定融合框架提升用户偏好建模与响应生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有CRS通过扩展对话上下文提升偏好推断能力，但带来输入过长、风格不一致和噪声干扰等问题，亟需更强的语言理解能力。

Method: 提出STARCRS，包含（1）将辅助文本编码为视觉token的屏幕阅读路径；（2）聚焦关键内容进行细粒度推理的LLM文本路径；并设计知识锚定融合框架，结合对比对齐、交叉注意力和自适应门控机制。

Result: 在两个主流基准上，STARCRS在推荐准确率和生成响应质量两方面均取得持续提升。

Conclusion: 双路径协同与知识锚定融合有效缓解了长异构上下文带来的挑战，提升了CRS的整体性能。

Abstract: Conversational Recommender Systems (CRSs) have attracted growing attention for their ability to deliver personalized recommendations through natural language interactions. To more accurately infer user preferences from multi-turn conversations, recent works increasingly expand conversational context (e.g., by incorporating diverse entity information or retrieving related dialogues). While such context enrichment can assist preference modeling, it also introduces longer and more heterogeneous inputs, leading to practical issues such as input length constraints, text style inconsistency, and irrelevant textual noise, thereby raising the demand for stronger language understanding ability. In this paper, we propose STARCRS, a Screen-Text-AwaRe Conversational Recommender System that integrates two complementary text understanding modes: (1) a screen-reading pathway that encodes auxiliary textual information as visual tokens, mimicking skim reading on a screen, and (2) an LLM-based textual pathway that focuses on a limited set of critical content for fine-grained reasoning. We design a knowledge-anchored fusion framework that combines contrastive alignment, cross-attention interaction, and adaptive gating to integrate the two modes for improved preference modeling and response generation. Extensive experiments on two widely used benchmarks demonstrate that STARCRS consistently improves both recommendation accuracy and generated response quality.

</details>


### [574] [More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval](https://arxiv.org/abs/2601.13525)
*Chunsheng Zuo,Daniel Khashabi*

Main category: cs.IR

TL;DR: 本文提出了一种无需标注和重新训练的轻量级领域自适应方法：对查询嵌入应用PCA降维，以保留领域相关特征并去除非判别性成分，在多个检索器和数据集上显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 密集检索器在专业领域表现不佳，主要由于预训练嵌入与目标领域分布不匹配；而现有领域自适应方法通常依赖高成本的标注和重训练。

Method: 对查询嵌入单独应用主成分分析（PCA）进行降维，保留领域相关特征，去除非判别性成分，无需额外标注或模型微调。

Result: 在9种检索器和14个MTEB数据集上的实验表明，该方法在75.4%的模型-数据集组合中提升了NDCG@10。

Conclusion: PCA作为一种简单、轻量且无需训练的嵌入压缩手段，可有效实现跨领域检索性能提升，是被忽视但极具潜力的领域自适应方案。

Abstract: Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation.

</details>


### [575] [Balancing Fairness and High Match Rates in Reciprocal Recommender Systems: A Nash Social Welfare Approach](https://arxiv.org/abs/2601.13609)
*Yoji Tomita,Tomohiko Yokoyama*

Main category: cs.IR

TL;DR: 本文研究匹配平台（如在线约会和求职推荐）中互惠推荐系统（RRS）的公平性问题，提出基于公平分配视角的‘无妒忌性’机会分配概念，并设计了兼顾匹配数量与公平性的SW、NSW及α-SW方法，结合Sinkhorn算法实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 匹配平台的成功依赖于既提升匹配总数又避免用户间不公平的互惠推荐系统（RRS），但现有方法（如最大化社会福利SW）易导致推荐机会分配不公，亟需兼顾匹配率与公平性的新框架。

Method: 从公平分配角度定义用户被推荐的‘机会’并引入‘无妒忌性’公平概念；提出SW（最大化匹配数）、NSW（交替优化两个Nash社会福利函数以近似实现无妒忌）及广义α-SW方法；并基于Sinkhorn算法设计高效近似求解算法。

Result: 理论与实验表明：SW方法虽提升匹配率却引发显著不公平；NSW方法可实现近似无妒忌推荐；α-SW方法能灵活权衡公平性与匹配率；所提Sinkhorn算法在合成与真实数据集上均具高效性与有效性。

Conclusion: 本文建立了匹配平台中互惠推荐系统的公平性理论框架，证明了匹配效率与推荐机会公平性存在本质权衡，并通过NSW与α-SW方法及其高效算法，为实际平台提供了可扩展、可调优的公平推荐解决方案。

Abstract: Matching platforms, such as online dating services and job recommendations, have become increasingly prevalent. For the success of these platforms, it is crucial to design reciprocal recommender systems (RRSs) that not only increase the total number of matches but also avoid creating unfairness among users. In this paper, we investigate the fairness of RRSs on matching platforms. From the perspective of fair division, we define the users' opportunities to be recommended and establish the fairness concept of envy-freeness in the allocation of these opportunities. We first introduce the Social Welfare (SW) method, which approximately maximizes the number of matches, and show that it leads to significant unfairness in recommendation opportunities, illustrating the trade-off between fairness and match rates. To address this challenge, we propose the Nash Social Welfare (NSW) method, which alternately optimizes two NSW functions and achieves nearly envy-free recommendations. We further generalize the SW and NSW method to the $α$-SW method, which balances the trade-off between fairness and high match rates. Additionally, we develop a computationally efficient approximation algorithm for the SW/NSW/$α$-SW methods based on the Sinkhorn algorithm. Through extensive experiments on both synthetic datasets and two real-world datasets, we demonstrate the practical effectiveness of our approach.

</details>


### [576] [Question-Focused Filtering for Knowledge-based VQA](https://arxiv.org/abs/2601.13856)
*Wei Ye,Yixin Su,Yueguo Chen,Longxiang Gao,Jianjun Li,Ruixuan Li,Rui Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种面向问题的知识过滤方法，通过可训练的Question-Focused Filter（QFF）和基于块的动态多文章选择（CDA）模块，在保持低计算成本的同时实现跨文章、问题导向的知识筛选，显著提升了KB-VQA任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有KB-VQA中的知识过滤方法存在文章级和文章内级的信息选择错误；而MLLM-based方法虽能力强但计算开销大，难以实用。

Method: 提出问题聚焦的过滤方法，包括可训练的Question-Focused Filter（QFF）和Chunk-based Dynamic Multi-Article Selection（CDA）模块，实现高效、跨文章、问题导向的知识筛选。

Result: 在E-VQA和InfoSeek数据集上分别超越当前SOTA模型4.9%和3.8%。

Conclusion: 所提方法在保证低计算成本的前提下，有效缓解了知识过滤中的多层级信息选择错误，显著提升了KB-VQA性能。

Abstract: Knowledge-based Visual Question Answering (KB-VQA) aims to answer questions by integrating images with external knowledge. Effective knowledge filtering is crucial for improving accuracy. Typical filtering methods use similarity metrics to locate relevant article sections from one article, leading to information selection errors at the article and intra-article levels. Although recent explorations of Multimodal Large Language Model (MLLM)-based filtering methods demonstrate superior semantic understanding and cross-article filtering capabilities, their high computational cost limits practical application. To address these issues, this paper proposes a question-focused filtering method. This approach can perform question-focused, cross-article filtering, efficiently obtaining high-quality filtered knowledge while keeping computational costs comparable to typical methods. Specifically, we design a trainable Question-Focused Filter (QFF) and a Chunk-based Dynamic Multi-Article Selection (CDA) module, which collectively alleviate information selection errors at both the article and intra-article levels. Experiments show that our method outperforms current state-of-the-art models by 4.9% on E-VQA and 3.8% on InfoSeek, validating its effectiveness. The code is publicly available at: https://github.com/leaffeall/QKVQA.

</details>


### [577] [IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization](https://arxiv.org/abs/2601.13938)
*Heyang Zhou,JiaJia Chen,Xiaolu Chen,Jie Bao,Zhen Chen,Yong Liao*

Main category: cs.IR

TL;DR: 本文提出IF-GEO框架，通过‘发散-收敛’两阶段方法解决生成式搜索引擎优化中多查询冲突的文本修订问题，并引入风险感知稳定性指标评估跨查询稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成式引擎虽能直接合成答案，但导致源内容可见性下降；而针对不同查询优化同一文档时，受限于内容预算，常面临异质查询间修订需求冲突的问题。

Method: 提出IF-GEO框架：第一阶段从代表性潜在查询中挖掘差异化的优化偏好；第二阶段通过冲突感知的指令融合协调各偏好，生成全局修订蓝图以指导编辑；并设计风险感知稳定性指标量化跨查询稳定性目标。

Result: 在多查询基准实验中，IF-GEO显著提升性能，同时在多种检索场景下保持鲁棒性。

Conclusion: IF-GEO为生成式引擎优化提供了一种兼顾多查询兼容性与内容约束的系统性解决方案，其冲突协调机制与稳定性度量具有实践推广价值。

Abstract: As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a "diverge-then-converge" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.

</details>


### [578] [Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval](https://arxiv.org/abs/2601.14001)
*Niall McGuire,Yashar Moshfeghi*

Main category: cs.IR

TL;DR: 本文首次系统研究了听觉脑电图（EEG）在脑段检索（BPR）中的应用，发现听觉EEG性能优于视觉EEG，并通过跨感官联合训练显著提升检索效果，甚至超越传统BM25文本基线，为语音接口和视障用户提供了可行的神经检索方案。


<details>
  <summary>Details</summary>
Motivation: 现有BPR研究仅使用视觉刺激，无法满足语音交互与视障用户需求；同时面临EEG数据严重稀缺问题，亟需探索听觉EEG可行性及跨感官训练潜力。

Method: 采用双编码器架构，结合四种池化策略（CLS、mean、max、multi-vector），在听觉数据集Alice与视觉数据集Nieuwland上开展听觉单模态、视觉单模态及跨感官联合训练的对照实验。

Result: 听觉EEG持续优于视觉EEG；CLS池化下的跨感官训练带来显著提升：MRR提高31%（达0.474），Hit@1提高43%（达0.314），Hit@10提高28%（达0.858）；联合模型MRR（0.474）超过BM25基线（0.428）。

Conclusion: 听觉神经接口可有效支撑信息检索任务；跨感官训练不仅缓解数据稀缺问题，而且性能优于单模态方法，为可访问性神经检索提供新范式。

Abstract: Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR

</details>


### [579] [Rerank Before You Reason: Analyzing Reranking Tradeoffs through Effective Token Cost in Deep Search Agents](https://arxiv.org/abs/2601.14224)
*Sahel Sharifymoghaddam,Jimmy Lin*

Main category: cs.IR

TL;DR: 本文研究了在深度搜索管道中如何分配推理预算，特别关注列表式重排序（listwise reranking）的作用，并提出了一种新的有效令牌成本（ETC）指标来分析模型规模、推理努力、重排序深度与总令牌成本之间的权衡。结果表明，适度的重排序比增加搜索时推理能以更低的成本实现相当甚至更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 深度研究代理依赖迭代检索和推理来回答复杂查询，但扩展测试时计算带来了显著的效率问题，亟需优化推理预算分配策略。

Method: 基于BrowseComp-Plus基准，采用新型有效令牌成本（ETC）指标，系统分析模型规模、推理努力、reranking深度与总token成本之间的权衡关系。

Result: reranking持续提升检索和端到端准确率；适度reranking带来的性能增益常优于增加搜索时推理，且在显著更低的token成本下达到可比准确率。

Conclusion: 在深度搜索流程中，合理利用列表式重排序是一种高效提升性能同时控制计算开销的关键策略，应优先于盲目扩大推理预算。

Abstract: Deep research agents rely on iterative retrieval and reasoning to answer complex queries, but scaling test-time computation raises significant efficiency concerns. We study how to allocate reasoning budget in deep search pipelines, focusing on the role of listwise reranking. Using the BrowseComp-Plus benchmark, we analyze tradeoffs between model scale, reasoning effort, reranking depth, and total token cost via a novel effective token cost (ETC) metric. Our results show that reranking consistently improves retrieval and end-to-end accuracy, and that moderate reranking often yields larger gains than increasing search-time reasoning, achieving comparable accuracy at substantially lower cost. All our code is available at https://github.com/texttron/BrowseComp-Plus.git

</details>


### [580] [XR: Cross-Modal Agents for Composed Image Retrieval](https://arxiv.org/abs/2601.14245)
*Zhongyu Yang,Wei Pang,Yingfang Yuan*

Main category: cs.IR

TL;DR: 本文提出XR框架，一种无需训练的多智能体系统，通过想象、相似性和问答三类智能体协同工作，提升组合图像检索（CIR）性能，显著超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入式CIR方法视角狭窄，跨模态线索捕获有限且缺乏语义推理能力，难以满足CIR任务中对图文组合理解的需求。

Method: XR是一种无需训练的多智能体框架，包含三类专业化智能体：想象智能体（跨模态生成目标表征）、相似性智能体（混合匹配进行粗筛）、问答智能体（针对性推理验证事实一致性以精筛），通过渐进式协同实现迭代优化检索。

Result: 在FashionIQ、CIRR和CIRCO数据集上，XR相较强基线（含训练与无训练方法）最高提升38%；消融实验证明各智能体均不可或缺。

Conclusion: XR成功将CIR重构为多智能体协同推理过程，验证了无需训练、基于推理的范式在多模态检索中的有效性与优越性。

Abstract: Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms. Composed Image Retrieval (CIR) exemplifies this shift as each query combines a reference image with textual modifications, requiring compositional understanding across modalities. While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning. To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process. It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering. Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential. Code is available: https://01yzzyu.github.io/xr.github.io/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [581] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: 本文提出了CSyMR-Bench——一个面向整合性作曲推理的符号音乐推理基准，并设计了基于music21工具增强的代理框架，在该基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有符号音乐推理基准侧重孤立知识或原子分析，缺乏对整合性作曲推理能力的评估。

Method: 构建包含126道多选题的CSyMR-Bench数据集（源自专家论坛与专业考试），并提出基于music21库的工具增强代理框架。

Result: 实验表明CSyMR-Bench具有挑战性，所提工具增强代理在各类题目上均优于基线模型，绝对准确率提升5–7%。

Conclusion: 整合性作曲推理需结合多种原子分析，CSyMR-Bench和工具增强代理为该方向提供了有效评估与解决路径。

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [582] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL 提出动态调节梯度分裂的子空间比例和更新频率，以在降低GPU内存和训练时间的同时保持与AdamW及静态FRUGAL相当的性能。


<details>
  <summary>Details</summary>
Motivation: FRUGAL框架虽能缓解LLM训练中的内存压力，但其静态超参数（子空间比例ρ和更新频率T）需手动调优，适应性差。

Method: 引入两个动态控制机制：(i) ρ的线性衰减策略以渐进式降低内存占用；(ii) 基于损失的T调度策略以减少计算开销。

Result: 在C4、VietVault预训练及GLUE微调任务上，AdaFRUGAL在保持竞争力性能的同时显著降低GPU内存和训练时间。

Conclusion: AdaFRUGAL提供了一种更实用、自主的资源受限LLM训练方案。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [583] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 本文利用线性代数与哈密顿形式主义等数学工具，类比量子力学系统，分析大语言模型（LLM）嵌入空间的结构，发现L2归一化约束使嵌入空间具备适合哈密顿分析的结构，并推导出余弦相似度与向量扰动的关系，探讨语义跃迁及量子启发下的零点能类比，为理解LLM机制和缓解幻觉提供新视角。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入呈现离散语义状态，启发作者借鉴量子力学思想，用数学工具深入刻画语义结构与关系。

Method: 结合线性代数与哈密顿形式主义建模嵌入空间；分析L2归一化约束的几何影响；推导余弦相似度与嵌入扰动的关系；引入量子类比（如零点能、Koopman-von Neumann力学）进行诠释。

Result: 证实L2归一化导致嵌入空间具有哈密顿可分析结构；建立语义相似性与向量微扰的定量联系；提出直接/间接语义跃迁概念；构造嵌入空间中的零点能类比并讨论其理论意义。

Conclusion: 该数学框架为理解LLM内部表征提供了新范式，有望支撑更鲁棒的语义建模，并为抑制幻觉等关键问题提供理论基础。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [584] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: 本文提出GRADE方法，通过Gumbel-Softmax松弛与直通估计（GRADE-STE）实现对离散token采样过程的可微分建模，替代高方差策略梯度估计，显著提升LLM对齐训练的稳定性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法（如PPO、REINFORCE）存在梯度方差高、超参敏感、计算开销大等问题，亟需更稳定高效的对齐范式。

Method: 提出GRADE框架，核心是使用Gumbel-Softmax重参数化结合直通估计（STE），使奖励信号能端到端反向传播至模型参数，绕过传统策略梯度估计。

Result: 在IMDB情感控制生成任务上，GRADE-STE测试奖励达0.763±0.344，较PPO提升50%；梯度方差降低14倍以上，训练更稳定，泛化性最优。

Conclusion: GRADE为大语言模型对齐提供了一种更简单、稳定且高效的新范式，是传统强化学习方法的有力替代方案。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [585] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: 本文提出了一种名为Hindsight Preference Replay（HPR）的回溯式偏好重标定策略，用于增强多目标强化学习中偏好条件化算法CAPQL的样本效率与性能，尤其在超体积（HV）和期望效用（EUM）指标上显著提升。


<details>
  <summary>Details</summary>
Motivation: CAPQL虽能基于偏好权重向量进行条件化学习，但仅能利用与该偏好匹配的离线数据，导致其他偏好下收集的离线数据被浪费，限制了样本效率和泛化能力。

Method: HPR是一种通用的回放增强策略：对经验回放缓冲区中已存储的转移（transition）进行事后重标定，将其奖励向量按不同偏好权重w重新投影，从而在不修改CAPQL架构和损失函数的前提下，扩充各偏好下的监督信号密度。

Result: 在6个MO-Gymnasium仿生运动任务上，HPR-CAPQL在5/6环境中提升超体积（HV），4/6中提升期望效用（EUM）；例如mo-humanoid-v5上EUM从323±125提升至1613±464，HV从0.52M升至9.63M；mo-halfcheetah-v5为例外，CAPQL在相近EUM下获得更高HV。

Conclusion: HPR是一种轻量、通用且有效的数据重用机制，显著提升了偏好条件化多目标RL方法的性能与鲁棒性，无需改变原有算法结构，为MO-RL中的离线数据复用提供了新范式。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [586] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: 本文提出了一种全面、可定制的MIMIC-IV多模态数据处理管道，显著减少多模态预处理时间并提升研究可复现性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种异构模态（结构化数据、临床笔记、波形、影像等），但现有工具仅支持部分模态或缺乏对任意下游任务的通用支持，导致人工预处理与对齐工作繁重。

Method: 在先前单模态管道基础上，系统性集成MIMIC-IV全部主要模态，支持自动化队列选择、跨模态时间对齐及标准化输出格式（适配静态与时间序列任务），并提供代码、简易UI和可选嵌入的Python包。

Result: 该管道大幅缩短多模态处理时间，提升MIMIC相关研究的可复现性与灵活性，并已开源发布。

Conclusion: 所提出的多模态管道为临床机器学习研究提供了高效、统一、可扩展的数据处理基础设施，推动MIMIC-IV资源更广泛、规范地应用。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [587] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 本文提出了一种新型神经记忆存储架构ApCM模型，以解决大语言模型缺乏有效运行时记忆机制的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型普遍缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求。

Method: 提出了辅助预测压缩记忆模型（ApCM Model）作为新型神经记忆存储架构。

Result: 构建了一个能够支持动态、个性化交互的神经记忆存储系统。

Conclusion: ApCM模型为提升大语言模型的运行时记忆能力提供了新思路和可行方案。

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [588] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 本文提出了一种结合时间上下文（如一天中的时段、一周中的星期）和位置信息的改进型特征加权方法，用于提升基于被动传感器（如PIR、门磁）的人类活动识别（HAR）性能，尤其在数据稀缺场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，利用无感传感器（如PIR、门磁）实现居家老年人日常活动监测与主动健康干预至关重要；但现有基于传统机器学习的HAR方法难以有效建模时间动态性。

Method: 将活动按时间段聚类（晨/午/晚），在Sensor Weighting Mutual Information（SWMI）框架中构建时段特异的互信息矩阵；扩展特征向量，引入周期性时间特征（小时、星期）及用户位置特征。

Result: 在四个真实世界数据集中的三个上，所提方法在准确率和F1-score上均超越当前最优方法，且在低数据场景下提升最为显著。

Conclusion: 融合细粒度时间语义与位置信息的特征增强策略，能有效提升被动传感器HAR性能，为‘原地养老’智能居家系统提供了实用可行的技术路径。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [589] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 本文综述了基于连续血糖监测（CGM）数据的机器学习模型在1型糖尿病患者低血糖预测中的应用，分析了不同预测时域下的模型性能、影响因素及个性化建模效果。


<details>
  <summary>Details</summary>
Motivation: 低血糖是1型糖尿病患者胰岛素治疗的主要风险，准确预测可降低死亡率；机器学习有望提升预测精度和预防效果。

Method: 系统性回顾和比较现有基于CGM数据的机器学习模型（包括传统ML与深度学习），按预测时域（短时15–120分钟，长时3小时至24小时以上）、任务类型（回归预测血糖值 vs. 分类识别事件）、数据特征（多变量、输入序列长度）及是否个性化进行分析。

Result: 1）最佳预测时域为1小时内；2）分类任务中传统ML更优，回归任务中深度学习更优；单一模型难以跨多个时域通用；3）多变量输入和更长输入序列长度显著提升性能；4）个性化建模有效，但受限于数据质量，群体模型更常用。

Conclusion: 低血糖预测模型性能高度依赖预测时域与任务类型，需权衡精度、鲁棒性与临床实用性；未来应关注高质量个性化数据采集与混合建模策略。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [590] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: 本文从几何角度研究了混合专家（MoE）架构，提出Dual Jacobian-PCA Spectral Geometry探针，发现MoE路由能降低局部敏感性、提升表征有效秩，并使专家变换近似正交分解。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE常以效率和条件计算为动机，但其对学习函数与表征几何结构的影响尚不清楚。

Method: 引入Dual Jacobian-PCA Spectral Geometry探针：通过Jacobian奇异值谱分析局部函数几何，通过加权PCA分析路由隐状态的表征几何；在可控MLP-MoE设置中比较密集、Top-k和全软路由架构。

Result: MoE路由一致降低局部敏感性（专家Jacobian主奇异值更小、谱衰减更快）；专家局部表征具有更高有效秩；平均专家Jacobian近似正交；路由锐度调控几何特性（Top-k导致低秩集中结构，全软路由导致高秩广谱结构）。

Conclusion: MoE可被几何地理解为函数空间的软划分，既压平局部曲率，又重分布表征方差。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [591] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 本文提出了几何注意力（Geometric Attention, GA）框架，将注意力机制形式化为由载体、证据核规则、探针族和锚点/更新规则四个独立输入定义的算子，统一建模多种注意力变体并支持 principled 扩展。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制缺乏统一的形式化框架，难以系统比较与扩展；需分离不变结构与建模选择，以提升可解释性与泛化能力。

Method: 基于几何与代数结构（如等价关系、规范、商空间、SVD低秩分解）构建算子语言，将注意力解构为四要素，并通过约束（如指数链接族、行锚定、标量关系表示）导出softmax等经典形式。

Result: 推导出Gibbs权重、softmax子族、低秩交互的典范形式（Eckart-Young/SVD）、自适应载体与分阶段深度机制，并支持多头/混合核、基于规划的锚点（如Sinkhorn）及一元算子（如FFN）。

Conclusion: GA提供了一个通用、模块化且数学严谨的注意力算子语言，使注意力机制的设计、分析与扩展具备原理性基础，推动架构创新与理论理解。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [592] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

TL;DR: 本文提出了CooperBench基准，揭示当前AI编码代理在协作中存在‘协调诅咒’：协同成功率比独立完成低30%，主因是沟通低效、承诺违背与错误预期；呼吁从提升个体能力转向发展社会智能。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地参与复杂协作任务，其缺乏人类团队所具备的社会智能（如协调、共识构建）成为关键瓶颈，亟需系统性评估与改进。

Method: 构建包含600+任务的CooperBench协作编码基准，覆盖4种语言、12个库，基于真实开源项目和专家测试；对前沿编码代理进行协同与独立性能对比，并通过大规模仿真分析沟通、承诺与预期三方面问题及涌现行为。

Result: 发现‘协调诅咒’现象（协同成功率平均下降30%）；识别出三大核心问题：沟通阻塞、承诺偏离、预期错误；同时观察到角色分工、资源划分和协商等稀有但有意义的涌现协调行为。

Conclusion: 当前AI代理在协作中严重缺乏社会智能，单纯提升个体编码能力不足以支撑有效团队合作；需建立以协作为中心的新评估范式与技术路径，推动社会智能研究。

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [593] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 本文提出了一种新型稀疏注意力机制——Noise Diffused Symmetric Attention Transformer，在保持对称注意力内存优势的同时，小幅增加参数和计算开销，提升了准确率与推理采样效率，并在GPT2-base上验证了其在GLUE任务上的性能增益与模型压缩效果。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模增大，显存需求激增，导致训练/推理成本上升，亟需通过稀疏注意力等技术实现高效模型压缩。

Method: 基于对称点积注意力（Symmetric Attention），提出Noise Diffused Symmetric Attention Transformer统一架构，引入噪声扩散机制以增强建模能力。

Result: 在GPT2-base上验证，该模型在GLUE多项任务中准确率介于原始GPT2和纯对称注意力之间，同时显著减小模型尺寸，并提升推理采样效率。

Conclusion: 所提方法在控制额外开销的前提下，有效平衡了模型压缩与性能提升，为高效Transformer设计提供了新思路。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [594] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 本文提出了一种基于Fisher信息（$g_F^C$）的新框架，用于定量评估PINN对物理系统动力学行为（尤其是几何与稳定性特性）的建模保真度，而不仅限于轨迹预测；通过对比PINN学习的动力学与真实模型在相空间中的Fisher信息分布（基于雅可比矩阵计算），验证其综合建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有PINN缺乏对系统完整动力学行为（如敏感性、相空间曲率、稳定性等几何特性）的严格量化评估手段，仅依赖轨迹预测难以反映其对底层物理规律的真实捕捉能力。

Method: 引入面向确定性动力系统的可微Fisher信息$g_F^C$，将其定义为与初始条件敏感性、相空间曲率及状态演化拉伸效应相关的量；提出以分析模型与PINN各自导出的运动方程的雅可比矩阵为基础，分别计算并比较其$g_F^C$分布；以汽车动力学模型为实验对象开展验证。

Result: 该方法实现了对PINN动力学保真度的定量刻画，能揭示其是否准确复现原系统的内在不确定性结构与几何特性；实验表明$g_F^C$匹配程度可作为衡量PINN是否全面掌握系统动力学的有效指标。

Conclusion: Fisher信息$g_F^C$是一种有效且具物理解释性的工具，可用于严格评估PINN对物理系统深层动力学特性的建模能力，推动PINN从‘拟合轨迹’迈向‘理解机制’。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [595] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于分数匹配梯度的无约束分层优化框架，首次实现了确定性方法下的全局优化，并揭示了全局优化与基于扩散的生成建模之间的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 克服梯度下降法局限于局部最优、仅适用于连续可微及简单凸约束问题的缺陷。

Method: 将各类复杂约束优化问题统一为无约束的分层优化目标，并利用分数匹配获得梯度进行优化。

Result: 首次通过确定性方法实现严格梯度驱动的全局优化，并在构造简单和实际复杂实验中验证有效性。

Conclusion: 该方法不仅拓展了梯度优化的适用范围，还揭示了全局优化与扩散生成模型之间的本质联系。

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [596] [Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning](https://arxiv.org/abs/2601.11657)
*Jack T. Beerman,Shobhan Roy,H. S. Udaykumar,Stephen S. Baek*

Main category: cs.LG

TL;DR: 本文提出了一种受混合拉格朗日-欧拉数值方法启发的新型物理感知深度学习架构D-PARC，通过可变形的物理感知循环卷积，显著提升了对强非线性流动（如Burgers方程、Navier-Stokes方程和反应流）的建模精度，且在参数量更少的情况下优于更大规模CNN模型。


<details>
  <summary>Details</summary>
Motivation: 现有CNN在建模高度非线性物理流动时表现受限，单纯扩大模型规模在物理建模中收益递减，亟需更符合物理直觉的网络结构设计。

Method: 提出变形物理感知循环卷积（D-PARC），借鉴Hybrid Lagrangian-Eulerian（HLE）思想，使卷积核具备动态形变与自适应感受野能力，并结合有效感受野分析与核行为可视化验证其物理合理性。

Result: D-PARC在Burgers方程、Navier-Stokes方程及反应流任务上均取得比更大CNN模型更高的预测保真度；核呈现反聚类行为，形成一种学习得到的‘主动滤波’策略；有效感受野自动聚焦高应变区域，体现类似计算力学中的自适应加密特性。

Conclusion: 物理直观的架构设计（如D-PARC）可超越盲目扩大参数规模，在物理感知深度学习中，轻量网络中的策略性学习是更优路径。

Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned "active filtration" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.

</details>


### [597] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: 本文提出LLMOrbit分类框架，系统梳理2019–2025年大型语言模型发展脉络，识别三大危机（数据、成本、能耗）与六大破壁范式，并总结三大范式转变：后训练增益、效率革命与开源民主化。


<details>
  <summary>Details</summary>
Motivation: 应对大模型发展中日益凸显的数据枯竭、训练成本飙升与能源消耗不可持续等‘扩展墙’问题，亟需系统性梳理技术演进路径并提炼突破方向。

Method: 构建覆盖8个轨道维度的环形分类法（LLMOrbit），综合分析50+模型、15家机构的技术路线；结合定量估算（如token耗尽时间、成本增长倍数、能效比）与范式归纳，识别危机成因与破局路径。

Result: 揭示三大结构性危机及时间节点；提出六大技术破壁范式（如test-time compute、量化、边缘分布式、模型融合等）；凝练三大范式转变（后训练增益、效率革命、民主化），并验证开源模型性能已超越闭源标杆（如Llama 3 > GPT-4）。

Conclusion: 单纯扩大模型规模难以为继，未来关键在于提升单位算力/能耗/数据下的智能产出效率，并通过开放协作推动技术普惠；LLMOrbit为研究者与工程师提供可操作的技术演进地图。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [598] [Machine learning model for predicting surface wettability in laser-textured metal alloys](https://arxiv.org/abs/2601.11661)
*Mohammad Mohammadzadeh Sanandaji,Danial Ebrahimzadeh,Mohammad Ikram Haider,Yaser Mike Banad,Aleksandar Poleksic,Hongtao Ding*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的框架，利用激光微织构金属合金的形貌与化学特征，高精度预测其润湿性（接触角），R²达0.942；结果表明表面化学起主导作用，形貌亦有显著贡献。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性在传热、润滑、微流控和涂层等领域至关重要，但其受形貌与化学双重耦合影响，传统建模困难，亟需数据驱动的预测方法。

Method: 采集激光纹理化AA6061和AISI 4130合金的形貌（Laws纹理能量法、轮廓仪）与化学（XPS提取极性基团、分子体积、峰面积分数）特征，构建带残差连接、批归一化与Dropout的集成神经网络模型。

Result: 模型预测接触角性能优异（R² = 0.942，RMSE = 13.896），优于既有方法；特征重要性分析显示表面化学影响最强，形貌次之。

Conclusion: 人工智能可有效建模表面润湿行为中形貌与化学的复杂协同效应，为功能化表面的理性设计提供数据驱动新范式。

Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.

</details>


### [599] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 本文提出了一种统一的后训练量化（PTQ）理论框架，核心是形式化‘激活敏感性’——即通道级扰动对损失的期望影响；通过一阶泰勒展开，证明其等价于梯度加权激活的平方范数，从而为AWQ、GPTQ等方法提供了共同的理论解释基础。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法（如AWQ和GPTQ）虽经验有效，但缺乏统一理论解释，不清楚它们隐式估计的是何种底层重要性度量。

Method: 提出‘激活敏感性’作为通道重要性的原则性度量，基于一阶泰勒展开推导其解析形式（梯度加权激活的平方范数），并分析AWQ与GPTQ如何在不同简化假设下近似该敏感性；进一步将敏感性与梯度显著性、Fisher信息、Hessian准则及经典剪枝方法（如OBD、OBS）建立联系。

Result: 揭示了主流PTQ方法本质是在不同假设下对同一核心量（激活敏感性）的互补近似；统一了PTQ与模型压缩中其他重要性评估范式，厘清了它们之间的理论关系。

Conclusion: 本工作不提出新算法，而是构建了一个以敏感性为核心的PTQ概念基础，为理解、分析与比较各类后训练量化方法提供了统一视角。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [600] [Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction](https://arxiv.org/abs/2601.11667)
*Xiaojie Xia,Huigang Zhang,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.LG

TL;DR: 本文提出一种高效方法，将预训练的全注意力Transformer模型转换为任务特定的混合注意力模型，通过块级局部蒸馏和贪心层替换策略，在不进行昂贵重训练或神经架构搜索的情况下实现效率与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: Transformer因全注意力机制带来二次时间与内存复杂度，限制其实际部署；线性注意力虽高效但性能下降；混合模型虽有潜力，但从头训练成本高且注意力模块位置设计困难。

Method: 1）采用块级局部蒸馏，将预训练全注意力模块权重迁移至线性注意力模块；2）设计贪心层替换策略，迭代用线性注意力块替代全注意力块，并监控验证集性能。

Result: 在单次高效流程中生成任务特定的混合注意力模型，无需重训练或神经架构搜索，适用于多种下游任务及不同预训练主干网络。

Conclusion: 该方法在保持性能的同时显著提升推理效率，为大模型轻量化与部署提供实用、通用的新范式。

Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.

</details>


### [601] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: 本文提出了一种测试时增量原型增强分类器（IPEC），通过在测试阶段动态利用高置信度查询样本优化原型估计，提升少样本学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的少样本方法假设测试批次间独立，无法利用先前批次的知识，导致原型估计不稳定、对初始支持集依赖过强。

Method: IPEC在测试时维护一个动态辅助集，通过双重过滤机制（全局预测置信度+局部判别能力）筛选高置信查询样本加入；将辅助集与支持集融合以迭代更新原型，并基于贝叶斯视角设计‘预热+测试’两阶段推理协议。

Result: 在多个少样本分类任务上，IPEC显著优于现有方法，验证了其有效性与泛化能力。

Conclusion: IPEC通过测试时自适应增强原型，在不增加训练开销的前提下提升了少样本分类性能，为测试时学习提供了新思路。

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [602] [A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning](https://arxiv.org/abs/2601.11670)
*Jinshi Liu,Pan Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于置信度-方差（CoVar）理论框架的伪标签选择方法，通过联合考虑最大置信度（MC）与残差类方差（RCV），克服了传统固定阈值方法中模型过度自信导致的错误伪标签问题，在语义分割与图像分类多个基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习中的伪标签选择策略多依赖固定置信度阈值，但深度网络常存在过度自信现象——高置信预测仍可能错误，而边界附近低置信但信息丰富的样本却被丢弃。

Method: 基于熵最小化原理，推导出一个融合最大置信度（MC）与残差类方差（RCV）的可靠性度量；将伪标签选择建模为置信度-方差特征空间中的谱松弛优化问题，并设计一种无阈值的选择机制；作为即插即用模块集成到主流半监督方法中。

Result: 在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet等多个数据集及不同标注比例与骨干网络下，CoVar consistently优于强基线方法。

Conclusion: 联合使用置信度与残差类方差比单一固定置信阈值更可靠，CoVar提供了一种原理清晰、无需调参的伪标签选择新范式。

Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)

</details>


### [603] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 本文提出了一种结合预测模型与大语言模型（LLMs）的混合框架，用于多维度 wildfire 风险评估，以生成结构化、可操作的风险报告，弥补现有方法忽视实际操作需求的不足。


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视一线响应者和消防部门的实际操作需求，缺乏对气象危险、点火活动、干预复杂性和资源调度等多维度风险的综合分析。

Method: 构建一个混合框架：为各风险维度（气象危险、点火活动、干预复杂性、资源动员）分别建立预测模型，并利用大语言模型（LLMs）整合异构输出，生成结构化、可操作的报告。

Result: 完成概念验证，展示了该混合框架在多目标风险评估与报告生成方面的可行性。

Conclusion: 该框架有望提升野火风险管理的实用性与响应效率，为应急决策提供更全面、可解释、可操作的支持。

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [604] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种基于自蒸馏的无监督预训练方法，用于CERN大型强子对撞机的喷注数据，结合粒子级和喷注级蒸馏，提升下游异常检测与分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 利用无标签喷注数据进行自监督预训练，以学习具有语义意义的通用表征，支持下游异常检测和分类任务。

Method: 提出jBOT方法，融合局部粒子级和全局喷注级的自蒸馏机制，对喷注数据进行预训练。

Result: 预训练后表征空间出现语义类聚；仅用背景喷注预训练的冻结嵌入即可通过距离度量实现有效异常检测；微调后分类性能优于从头训练的监督模型。

Conclusion: jBOT能从无标签喷注数据中学习到具有语义结构的表征，为高能物理中的下游任务提供高效、鲁棒的预训练范式。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [605] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 本文研究了在病态优化条件下，随机梯度下降（SGD）中出现的‘可疑对齐’现象：梯度与Hessian主导子空间的对齐度先降后升并最终稳定在高对齐状态，但该高对齐方向上的梯度更新却无法有效降低损失；作者在高维二次模型中精细分析了步长选择如何引发该现象，并提出了自适应临界步长条件、解释了主导子空间更新无效的原因，最后证明了常数步长下SGD存在两阶段对齐演化行为。


<details>
  <summary>Details</summary>
Motivation: 解释SGD在病态优化中观察到的梯度与Hessian主导子空间对齐度先降后升再稳定于高值，但该高对齐方向更新却无效这一反直觉现象。

Method: 在高维二次优化模型中进行理论分析，推导步长对梯度对齐动态的影响，提出自适应临界步长η_t^*判据，分析主导与非主导子空间上投影更新对损失变化的贡献符号，并证明常数步长下两阶段对齐演化。

Result: 1）发现低对齐阶段存在临界步长η_t^*，决定对齐增减；高对齐阶段对齐具自校正性；2）在强病态下存在步长区间，使得向量在主导子空间投影更新反而增损，而在非主导（bulk）子空间投影更新才真正降损；3）证明常数步长+大初始化下SGD必然呈现先降后稳的两阶段对齐演化。

Conclusion: ‘可疑对齐’并非异常行为，而是病态优化与步长选择共同作用下的可解释动力学现象；主导子空间高对齐不等价于高效优化，实际有效更新主要来自bulk子空间；该理论为理解SGD隐式正则化与优化路径提供了新视角。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [606] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: 本文提出了一种物理信息驱动的去噪自编码器PC²DAE，专为低数据量下的低成本无人机大气传感器信号校正设计，通过嵌入物理约束（如非负性、时序平滑）提升鲁棒性与可解释性，并在极小数据集（2.2小时）上实现优于多种基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 低成本无人机传感器存在基线漂移、交叉敏感性和响应滞后等问题，而传统深度学习去噪方法依赖大量标注数据，难以在有限飞行任务中获取。

Method: 提出PC²DAE——一种物理信息嵌入型去噪自编码器：采用softplus激活确保浓度估计非负；引入物理启发的时序平滑机制；设计分层解码头适配黑碳、气体和CO₂三类传感器；提供轻量版（PC²DAE-Lean，21k参数）与宽版（PC²DAE-Wide，204k参数）两种架构。

Result: 在仅7894个1Hz同步样本（约2.2小时）上验证：PC²DAE-Lean实现67.3%平滑度提升与90.7%高频噪声抑制，且零物理违规；相较LSTM-AE等5种基线（产生15–23%负值输出），显著更可靠；轻量版反超宽版5.6%平滑度；训练耗时<65秒。

Conclusion: 强归纳偏置（物理约束嵌入）比增大模型容量更能缓解小样本过拟合，PC²DAE为资源受限的野外传感提供了高效、可信、可部署的实时校正方案。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [607] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 本文提出一种基于shapelets的选择性预测框架，用于识别时间序列中模型预测不可靠的关键区域，从而提升预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列基础模型在零样本预测上表现良好，但在某些关键数据区域的预测不可靠，限制了其在现实场景（尤其是具有独特趋势的数据）中的应用。

Method: 提出基于shapelets的选择性预测框架：在目标领域验证集上使用平移不变字典学习学习shapelets，并利用与这些shapelets的距离相似性识别并剔除不可靠预测。

Result: 在多个基准数据集上，该方法使零样本和全样本微调模型的整体误差分别平均降低22.17%和22.62%，并在某数据集上较随机选择方法最高提升21.41%和21.43%。

Conclusion: 该框架能有效识别模型预测能力边界，提升预测可靠性，增强时间序列基础模型在实际应用中的可信度。

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [608] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow是一种新的条件流匹配框架，通过联合学习描述符依赖的基分布和流场，显著提升了在分布外条件下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有条件流式生成模型在分布偏移下鲁棒性差，难以外推到训练未见的条件。

Method: 提出MixFlow框架，采用最短路径流匹配，联合学习描述符条件化的可学习混合基分布和流场。

Result: 在单细胞转录组响应预测和高内涵显微镜药物筛选等任务中，MixFlow一致优于标准条件流匹配基线。

Conclusion: MixFlow提供了一种简单而强大的方法，实现跨异构领域的鲁棒、可泛化、可控生成建模。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [609] [AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training](https://arxiv.org/abs/2601.11864)
*Zhiyuan Li,Yuan Wu,Yi Chang*

Main category: cs.LG

TL;DR: 本文提出了一种自适应分组梯度裁剪方法（AGGC），通过按功能模块分组参数并利用指数滑动平均（EMA）动态调整各组裁剪阈值，有效缓解梯度爆炸与消失问题，提升大语言模型微调和强化学习训练的稳定性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统全局梯度裁剪假设所有参数梯度同质，导致不稳定参数‘溢出’影响稳定参数，无法应对LLM中固有的梯度异质性问题。

Method: AGGC将参数按功能类型分组，对每组维护基于历史梯度的EMA估计，构建自适应裁剪区间，并引入时变调度机制平衡探索与收敛。

Result: 在LLaMA 2-7B、Mistral-7B、Gemma-7B上，AGGC持续优于LoRA，常超越全量微调；Mistral-7B在GSM8K达72.93%准确率（LoRA为69.5%）；在RLVR中显著提升Qwen 2.5和Llama 3.2的逻辑推理能力；开销极小，可即插即用。

Conclusion: AGGC通过模块化、自适应的梯度裁剪策略，有效克服了传统方法在梯度异质性下的局限性，是一种轻量、通用且高效的训练稳定化技术。

Abstract: To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.

</details>


### [610] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: 本文提出了TF-CoDiT，首个面向语言控制的国债期货数据合成扩散Transformer框架，通过离散小波变换（DWT）与U型VAE建模低数据、多变量强相关特性，并引入金融市况属性协议（FinMAP）生成结构化提示，实验证明其在真实性和鲁棒性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 国债期货数据具有低交易量、强市场依赖性和多变量分组相关性等特点，现有Diffusion Transformer（DiT）在此类数据上的合成性能尚未被充分探索，亟需针对性建模方法。

Method: 提出TF-CoDiT框架：1）将多通道一维时序转换为DWT系数矩阵以适配低数据场景；2）设计U型VAE分层建模跨通道依赖并连接潜空间与DWT空间，实现潜变量扩散生成；3）构建FinMAP协议，从7/8个维度识别17/23个经济指标，生成标准化多层级市场动态提示。

Result: 在2015–2025年四类国债期货数据上验证，合成任务涵盖1周至4个月时长，MSE≤0.433、MAE≤0.453；进一步验证表明模型在不同合约与时间跨度下均具稳健性。

Conclusion: TF-CoDiT有效解决了国债期货数据合成中的低样本、强依赖与多变量耦合难题，是首个支持语言控制的专用DiT框架，为金融时序生成提供了新范式。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [611] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 本文研究了带约束的k-center聚类问题，提出了一种基于支配匹配集转换的新局部搜索框架，在满足不相交cannot-link约束下达到了最优的2-近似比。


<details>
  <summary>Details</summary>
Motivation: 传统k-center问题的近似比下界为2，而引入cannot-link（CL）和must-link（ML）约束后，一般CL约束使问题更难近似；尽管已有工作证明在disjoint CL约束下可实现常数因子近似，但局部搜索能否达到该保证仍是开放问题。

Method: 提出一种新颖的局部搜索框架，通过将问题转化为支配匹配集（dominating matching set）问题来设计算法，从而在disjoint cannot-link约束下实现2-近似比。

Result: 理论证明该算法达到最优的2-近似比；实验表明其在真实与合成数据集上的解质量优于基线方法。

Conclusion: 本文解决了带disjoint cannot-link约束的k-center问题中局部搜索能否达到最优近似比的开放问题，给出了首个具备最优2-近似保证的局部搜索算法，并验证了其有效性。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [612] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 本文提出了一种基于加权凹覆盖目标函数 $U_ρ$ 的主动探索方法，统一了多种经典探索目标，并通过梯度控制实现对欠探索状态-动作对的优先访问，随着参数 $ρ$ 增大渐近趋向最坏情况覆盖。


<details>
  <summary>Details</summary>
Motivation: 在无奖励MDP中，不同状态-动作对的重要性或探索难度不同，需设计能主动识别并侧重探索困难/重要状态-动作对的策略。

Method: 提出一族参数化凹覆盖目标函数 $U_ρ$，定义在状态-动作占据测度上；利用其凹性建模探索收益递减，并利用其闭式梯度显式引导探索偏向欠探索区域；设计基于梯度的算法优化该目标。

Result: 所提算法能主动调控探索分布；理论证明当参数 $ρ$ 增大时，策略渐近聚焦于最少被探索的状态-动作对，恢复最坏情况（minimax）覆盖。

Conclusion: 该框架统一了多种覆盖目标，兼具理论可解释性与实践可控性，为无奖励强化学习中的结构化探索提供了新范式。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [613] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发者遥测数据构建的代码补全评测基准，强调生态效度、避免数据污染，并支持多维诊断。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准缺乏生态效度、存在训练数据污染问题，且难以提供对实际开发有指导意义的细粒度评估结果。

Method: 基于真实开发者遥测（如API调用、代码意图）构建包含1800个实例、覆盖6种语言和6类任务的基准；采用功能正确性、相似性指标与LLM裁判（聚焦实用性与上下文相关性）相结合的多维评估方法。

Result: 在9个SOTA模型上评测发现，各模型在语法精度、语义推理和实际可用性方面表现差异显著。

Conclusion: DevBench能提供面向实际部署与模型优化的可操作洞见，弥补了现有基准在实用性和诊断深度上的不足。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [614] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 本文提出了一种面向监督学习任务的新型预处理公平性方法，通过权衡公平性与效用，在理论上保证下游模型的公平性提升和效用保持，并在表格与图像数据上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有数据公平方法对HGR相关性施加过强正则化，且任务定制型方法缺乏对下游模型公平性与效用保证的理论分析。

Method: 提出一种兼顾公平性与效用的监督学习导向预处理映射方法，并推导下游任意监督模型在该映射下实现公平性提升与效用保持的充分条件。

Result: 在多个表格与图像数据集上的实验表明，所提方法在多种下游模型下均能保持稳定的公平-效用权衡，尤其在计算机视觉任务中仅改变与核心任务相关的语义特征以实现公平。

Conclusion: 任务定制型预处理方法可兼顾理论可解释性与实际性能，为公平机器学习提供了新思路与实用框架。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [615] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 本文研究了在对抗性污染和有限验证条件下，具有向量值奖励的协作随机多臂老虎机问题，提出了通信-污染耦合机制，并分析了不同通信协议下有效污染水平对团队遗憾的影响。


<details>
  <summary>Details</summary>
Motivation: 在多智能体协作环境中，如何在存在对抗性污染和通信受限的情况下，保证团队整体性能（以坐标非减、L-Lipschitz标量化函数衡量）是一个关键挑战。

Method: 提出并形式化了‘协议诱导的多重性泛函’来刻画不同通信方式（原始样本共享、统计量共享、仅推荐共享）对污染放大效应的影响；推导了依赖于有效污染水平的遗憾上界；建立了信息论下界，并分析了验证预算ν的作用。

Result: 发现原始样本共享可能导致N倍污染放大，而统计量或推荐共享可保持O(Γ)未放大的遗憾项；证明了Ω(Γ)是不可避免的加性惩罚；当Γ=Θ(NT)时，无干净信息则无法实现次线性遗憾；验证预算ν超过识别阈值后，团队遗憾可完全摆脱Γ影响。

Conclusion: 通信协议与对抗污染存在本质耦合，选择合适的通信方式（如推荐共享）和引入有限验证，可在高污染环境下恢复学习能力并实现集中式速率的团队遗憾。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [616] [Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization](https://arxiv.org/abs/2601.11942)
*Qingyu Meng,Yangshuai Wang*

Main category: cs.LG

TL;DR: 本文提出了一种混合量子-经典回归框架，通过轻量级经典嵌入作为几何预调节器，并结合课程优化策略（从SPSA探索过渡到Adam微调），显著提升了量子神经网络在回归任务中的可训练性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络（QNNs）在回归任务中常面临梯度噪声大、优化病态等问题，导致训练困难。

Method: 设计了一个混合量子-经典回归框架：前端为可学习的经典嵌入（作为几何预调节器），后端为变分量子电路；并引入课程优化协议，逐步增加电路深度，优化策略从SPSA随机搜索切换到Adam梯度微调。

Result: 在PDE驱动和标准回归基准上验证，该方法在固定训练预算下持续优于纯QNN基线，收敛更稳定，尤其在小样本场景下表现突出；结构化误差减少，且与振荡成分相关。

Conclusion: 几何预调节与课程训练相结合是提升量子回归稳定性的一种实用有效方法。

Abstract: Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.

</details>


### [617] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 本文提出MICE方法，通过引入内在成本和偏差校正来解决约束强化学习中成本价值函数低估导致的约束违反问题，显著减少了训练过程中的约束违反，同时保持了策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练过程中常出现严重约束违反，限制了其在安全关键场景中的应用；作者发现成本价值函数低估是导致该问题的关键因素。

Method: 提出Memory-driven Intrinsic Cost Estimation（MICE）方法，构建受闪光灯记忆启发的记忆模块存储不安全状态，定义当前状态访问风险区域的伪计数为内在成本，并设计融合内在成本与偏差校正的外在-内在成本价值函数，在信任域内构建优化目标并给出优化方法。

Result: 理论层面提供了所提成本价值函数的收敛性保证及MICE更新下的最坏约束违反界；实验表明MICE显著降低约束违反，同时策略性能与基线相当。

Conclusion: MICE通过内在成本建模与偏差校正有效缓解成本低估问题，提升了约束强化学习的安全性与实用性。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [618] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: 本文提出DDGPrompt，一种数据驱动的提示框架，通过在输入数据层面优化预训练节点嵌入，以提升动态图模型在少样本和冷启动场景下的下游任务适应性。


<details>
  <summary>Details</summary>
Motivation: 传统动态图预训练方法在下游任务差异大时性能下降，尤其在少样本设置下；现有提示方法耦合特定模型或忽略结构信息，泛化性和表达能力受限。

Method: 提出DDGPrompt框架：定义统一节点表达特征矩阵，融合时序与结构信息；引入三个提示矩阵（时间偏置、边权重、特征掩码）对特征矩阵进行全量调整，实现任务自适应。

Result: 在四个公开动态图数据集的严格少样本设置下，DDGPrompt显著优于传统方法及现有提示方法，尤其在标签稀缺和冷启动条件下表现突出。

Conclusion: DDGPrompt是一种模型无关、数据中心化的提示框架，能有效提升动态图预训练模型在多样化下游任务中的泛化能力与鲁棒性。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [619] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: 本文提出R²PO方法，通过在策略上添加轻量级残差Rollout-Head，解耦推理响应与训练轨迹，提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法用单一策略生成推理响应和训练轨迹，目标冲突导致探索不足，损害推理能力。

Method: 提出R²PO（Residual Rollout Policy Optimization），引入轻量级残差Rollout-Head，使训练轨迹多样化而保持推理稳定。

Result: 在MATH-500和APPS上平均准确率分别提升3.1%和2.4%，同时减少格式错误、缓解长度偏差。

Conclusion: R²PO有效解耦训练与推理，提升LLM推理性能与训练稳定性。

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [620] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 本文提出了一种名为MoE Encoder的新模块，用于增强预训练时间序列预测模型，在保证数据隐私的前提下提升多变量电力系统预测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量时序数据依赖复杂、跨区域隐私约束严格、传统方法依赖专家知识且泛化能力差、现有预训练模型零样本性能有限等问题。

Method: 提出一种稀疏混合专家（MoE）编码器模块，插入在分词与编码之间，将多元预测转化为专家引导的单变量任务，并支持联邦学习下的局部训练与轻量参数共享。

Result: 在多个公开多变量数据集上显著优于强基线；在模拟联邦环境中仅传输MoE-Encoder参数即可高效适配新区域，性能下降极小。

Conclusion: MoE-Encoder为时序基础模型提供了一种可扩展、隐私感知的增强方案。

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [621] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 本文提出Extreme Value policy Optimization (EVO)算法，利用极值理论（EVT）建模和利用奖励与成本的极端样本，以减少约束违反，尤其针对尾部分布中的罕见高影响事件。


<details>
  <summary>Details</summary>
Motivation: 期望型约束忽略了尾部分布中罕见但高影响的极端事件（如黑天鹅事件），可能导致严重约束违反。

Method: 提出EVO算法，包含极值分位数优化目标和回放缓冲区中的极端优先采样机制，并从理论上给出约束违反的上界保证。

Result: EVO显著降低了训练过程中的约束违反概率，同时保持与基线方法相当的策略性能；相比期望型方法，其约束违反概率更低；相比分位数回归方法，方差更小。

Conclusion: EVO通过引入极值理论有效提升了约束强化学习在面对极端事件时的安全性与鲁棒性，为现实世界RL应用提供了更可靠的保障。

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [622] [Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features](https://arxiv.org/abs/2601.12011)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 本文提出了一种小规模模型（SSM）来分析损失重加权在深度学习中的作用，发现其虽不影响过参数化DNN的最终收敛，但能显著改善训练初期对少数类的学习平衡性。


<details>
  <summary>Details</summary>
Motivation: 解释为何损失重加权在过参数化DNN中对最终性能影响有限，却在训练早期表现出明显优势。

Method: 构建一个抽象DNN结构与数据不平衡谱特性的小型可解析模型（SSM），用于理论分析和实证验证。

Result: SSM揭示了经验风险最小化早期偏向多数类学习，而重加权可恢复类别间学习动态的平衡，使多数类与少数类特征得以同步学习。

Conclusion: 损失重加权的核心作用在于调节训练早期的学习动态而非改变最终解，其有效性源于对不平衡数据谱结构的适配。

Abstract: The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.

</details>


### [623] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2 提出一种解耦时空建模的新框架：第一阶段用随机序列掩码预训练轻量编码器以学习通用时序动态；第二阶段通过元自适应适配器快速注入领域特异性空间知识，实现零样本/少样本下的高性能与线性计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有时空基础模型联合预训练计算开销大，且难以应对不同领域空间模式异质性问题，缺乏跨数据集泛化能力。

Method: 提出两阶段因子化解耦框架：1）第一阶段使用随机序列掩码预训练极简编码器，学习不变时序动态并支持任意长度概率分位数预测；2）第二阶段采用轻量适配器，结合元自适应学习和提示机制注入空间感知能力。

Result: 在多领域任务上显著超越现有基础模型（尤其零样本/少样本场景），性能媲美领域专家模型，同时具备线性计算效率。

Conclusion: 因子化解耦范式为构建真正通用、可扩展的时空基础模型提供了实用可行路径。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [624] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 本文提出CEBiasBench双语偏见评测基准与Multi-Agent Cultural Debate（MACD）无训练文化辩论框架，发现中文提示仅转移而非消除LLM的西方中心偏见，并验证显式文化人格建模对跨文化公平性至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见评估方法强制归类、缺乏中立选项；缓解方法依赖昂贵多文化语料或无显式文化表征的代理框架，难以有效评测和缓解非西方语言提示下的系统性文化偏见。

Method: 构建中英双语偏见评测基准CEBiasBench；提出Multi-Agent Vote（MAV）支持‘无偏见’判断；设计无需训练的Multi-Agent Cultural Debate（MACD）框架，为各代理赋予明确文化人格，并采用‘求同存异’策略组织文化辩论。

Result: 实验表明MACD在CEBiasBench上LLM-as-judge评估的平均‘无偏见率’达57.6%（基线47.6%），MAV评估达86.0%（基线69.0%），且在阿拉伯语CAMeL基准上泛化良好。

Conclusion: 单纯切换至非西方语言提示（如中文）不能消除LLM的文化偏见，而仅使其转向东亚视角；显式引入文化人格的代理协作机制是实现跨文化公平的关键路径。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [625] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 本文提出了一种结合摄动理论与迁移学习的物理信息神经网络（PTL-PINN）框架，用于高效求解非线性微分方程；该方法通过解析形式求解近似线性摄动系统，显著加快训练速度并保持高精度，性能媲美经典Runge-Kutta方法，且快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在建模非线性动力学时泛化能力差、训练耗时长，难以兼顾精度与效率。

Method: 提出摄动引导的迁移学习框架（PTL-PINN），利用摄动理论构造近似线性系统并以闭式表达求解，避免梯度优化，实现矩阵-向量乘法复杂度的快速迁移。

Result: 在非线性振子、Lotka-Volterra系统、KPP-Fisher方程和波动方程等多类问题上，PTL-PINN达到与多种Runge-Kutta方法相当的精度，计算速度提升达10倍。

Conclusion: 将经典摄动理论嵌入PINN框架，可显著提升其求解非线性微分方程的效率与泛化性，为融合传统数值方法与深度学习提供了新范式。

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [626] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

TL;DR: 本文提出了一种固定长度的数字嵌入向量，首次在有理数域中保持加法、乘法和比较等代数运算性质，并构建了神经同构域以维持代数结构；实验表明加法性能优异（>95%准确率），而乘法仍有提升空间（53%-73%）。


<details>
  <summary>Details</summary>
Motivation: 神经网络处理极小或极大数值时易出现溢出、下溢及输出不稳定等问题，需通过嵌入向量替代原始数值以保留代数性质并提升数值稳定性。

Method: 提出固定长度数字嵌入向量，设计神经同构域（Neural Isomorphic Field）作为群与域等代数结构的神经抽象，使嵌入向量在计算中保持代数结构。

Result: 加法在恒等性、封闭性、结合性等关键代数测试中准确率超95%；乘法在不同代数性质上准确率为53%–73%。

Conclusion: 该方法有效提升了数值稳定性并成功保持加法代数结构，但乘法建模仍需进一步优化，验证了神经同构域在代数感知建模中的潜力与挑战。

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [627] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: 本文提出了SynQP，一个用于评估合成数据生成（SDG）隐私风险的开源框架，使用模拟敏感数据避免真实数据泄露，并提出一种更准确的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康领域中合成数据的使用面临隐私担忧，但缺乏开放的隐私评估框架和基准数据集，阻碍了其广泛应用。

Method: 设计并实现SynQP框架，利用模拟敏感数据进行隐私基准测试；提出一种新的身份披露风险（SD-IDR）度量方法，并在CTGAN上进行验证；结合差分隐私（DP）分析其对隐私风险的影响。

Result: 非隐私模型机器学习效用接近完美（≥0.97）；差分隐私显著降低身份披露风险（SD-IDR）和成员推断攻击风险（SD-MIA），所有DP增强模型均低于0.09监管阈值。

Conclusion: SynQP为合成数据隐私评估提供了透明、可靠且可复现的工具，有助于推动合成数据在健康应用中的安全落地。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [628] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文提出了SolarGPT-QA，一个基于LLaMA-3、经领域适配与教育化微调的问答系统，用于提升空间天气知识的准确解释与教学可及性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏空间科学领域的专业知识和面向教育的解释能力，而太阳活动预测与科普教育至关重要。

Method: 基于LLaMA-3构建SolarGPT-QA，结合空间科学文献进行领域预训练，并利用GPT-4生成、Grok-3优化的问答数据以‘学生友好型叙事风格’进行教学微调；通过人工成对评估与小规模学生理解实验验证效果。

Result: SolarGPT-QA在零样本设置下优于通用模型，在教育性解释任务上媲美指令微调模型；学生实验显示其解释更清晰易懂；消融实验证明领域预训练与教学微调协同至关重要。

Conclusion: SolarGPT-QA是迈向综合性SolarGPT框架（支持空间科学教育与预报）的重要初步工作，强调了领域知识与教育表达融合的必要性。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [629] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 本文提出Eigen-Mixture-of-Experts (EMoE)，通过基于学习到的正交特征基的路由机制，解决MoE模型中专家负载不均衡和同质化问题，无需辅助损失函数即可实现负载均衡与专家专业化。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型存在‘富者愈富’的负载不均衡问题和专家表征冗余的同质化问题，而传统辅助负载均衡损失会加剧同质化。

Method: 提出EMoE架构，利用学习得到的正交特征基对输入token进行投影，并依据其在特征空间主成分上的对齐程度进行路由，实现几何意义上的数据划分。

Result: EMoE在不引入冲突辅助损失的前提下，同时提升了专家利用均衡性和专家表征多样性，在多个基准任务上验证了有效性。

Conclusion: 基于特征空间几何结构的路由机制为MoE设计提供了新范式，能自然兼顾负载均衡与专家专业化，推动高效可扩展模型发展。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [630] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种名为Threshold Differential Attention（TDA）的新注意力机制，旨在解决Softmax注意力在长上下文中的结构性缺陷，如注意力沉降和概率质量分散问题。TDA通过行级极值阈值化与抑制性视图相减实现超稀疏、无沉降、鲁棒性强的注意力，理论证明其能控制虚假激活数量，实验显示其达99%以上精确零值且性能不降。


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文中存在结构性缺陷：严格的和为1约束导致无关token上出现注意力沉降，且概率质量随序列增长而分散，影响建模能力。

Method: 提出Threshold Differential Attention（TDA）：采用长度依赖门控的行级极值阈值化，仅保留超过阈值的token；并借鉴微分Transformer思想，引入减法式抑制视图以增强表达力；整体保持线性复杂度，无需投影或额外噪声注入。

Result: TDA在理论上保证每行期望虚假激活数为O(1)，多视图间虚假匹配随上下文增长趋于消失；实验上达到>99%精确零值，完全消除注意力沉降，并在标准及长上下文基准上保持竞争力。

Conclusion: TDA是一种高效、鲁棒、超稀疏的注意力替代方案，突破了Softmax在长程建模中的根本限制，为构建更可扩展、可解释的大模型提供了新路径。

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [631] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 本文提出了一种用于校准参数化保险指数的联邦学习框架，适用于异构可再生能源生产损失场景。各生产者使用Tweedie广义线性模型在本地建模损失，通过联邦优化联合学习全局指数，无需共享原始数据；方法支持方差和连接函数的异质性，并直接最小化分布式环境下的全局偏差目标；实验表明其在中等异质性下能恢复与集中式方法相当的指数系数，且更具通用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失数据隐私敏感、地域异质性强、难以集中建模的问题，同时需保证保险指数的统计有效性与可解释性。

Method: 基于Tweedie广义线性模型的本地建模 + 联邦优化（FedAvg/FedProx/FedOpt）联合最小化全局偏差目标，支持异质方差与链接函数；不共享原始数据，仅交换模型参数。

Result: 在德国太阳能发电实证中，联邦学习在中等异质性下恢复的指数系数与基准方法相当；FedAvg/FedProx/FedOpt均优于现有近似聚合方法；整体框架更通用、可扩展。

Conclusion: 该联邦学习框架为参数化保险指数校准提供了兼顾隐私保护、异质性建模与统计一致性的新范式，具备实际部署潜力。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [632] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: 本文提出Re-SpS，首个基于强化学习的推测采样框架，动态优化草稿树超参数，显著提升LLM推理速度，同时保持输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法（如EAGLE-3）使用静态树结构超参数，难以适应多样上下文和领域，限制了灵活性与效率。

Method: 提出基于强化学习的Re-SpS框架，利用目标模型隐藏状态构建高效状态表征，并引入多步动作持久化机制，实现实时、上下文感知的草稿树超参数动态调整。

Result: 在五个基准测试中一致优于EAGLE-3：相较基座LLM最高提速5.45倍，相较EAGLE-3最高提速1.12倍，且无输出保真度损失。

Conclusion: Re-SpS验证了RL在动态优化推测采样策略上的有效性，为高效LLM推理提供了新范式。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [633] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 本文研究超稀疏采样下的矩阵补全问题，提出一种无偏估计器结合梯度下降来恢复矩阵的行空间或平均二阶矩矩阵T，在理论和实验上均验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对大型稀疏面板数据集（行数远大于列数）中每个条目以极低概率p=C/d被独立观测的超稀疏场景，传统矩阵补全不可行，需转而估计行空间或平均二阶矩矩阵T。

Method: 构造一个对观测频次归一化的无偏二阶矩估计器，并用梯度下降填补T中的缺失项；理论分析该估计器的无偏性与低方差性，并在秩r因子模型及非相干性假设下给出样本量要求和误差界。

Result: 理论证明：当n ≥ O(d r⁵ ε⁻² C⁻² log d)时，梯度下降任意局部极小点近似全局最优，T的估计误差≤ ε²；实验表明在MovieLens和Amazon数据集上显著降低偏差与恢复误差。

Conclusion: 在超稀疏采样下，直接估计二阶矩矩阵T比恢复原矩阵M更可行且高效；所提方法兼具理论保证与实际优越性，尤其适用于超高维稀疏面板数据。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [634] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 本文提出了一种名为Masked Multiscale Reconstruction（MMR）的自监督预训练框架，用于PPG信号表征学习，通过小波多分辨率分解和掩码重建任务，显式建模PPG信号的多尺度时频结构，在19个健康相关任务中17个达到或超越现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有PPG基础模型大多忽略PPG信号固有的多频带谱结构，而下游健康任务往往依赖从波形细节到节律动态的多分辨率特征。

Method: 提出MMR方法：对PPG信号进行小波多分辨率分解，随机掩码部分时频系数，利用Transformer编码器重建被掩码的系数，从而联合建模时间与频谱多尺度信息。

Result: 在约1700万段来自3.2万名智能手表用户的10秒PPG数据上预训练；在19个下游健康任务中，17个优于或持平当前开源PPG/时序基础模型及其它自监督基线；消融与嵌入分析证实小波表示能捕获鲁棒且符合生理机制的特征。

Conclusion: MMR是一种面向可泛化PPG基础模型的重要进展，强调了显式建模PPG多尺度时频结构的价值。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [635] [Learning Longitudinal Health Representations from EHR and Wearable Data](https://arxiv.org/abs/2601.12227)
*Yuanyun Zhang,Han Zhou,Li Feng,Yilin Hong,Shi Li*

Main category: cs.LG

TL;DR: 本文提出了一种多模态基础模型，联合建模电子健康记录（EHR）与可穿戴设备数据，将其统一表示为连续时间潜在过程，在生理预测和风险建模任务中显著优于单模态基线，尤其在长时预测和缺失数据场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法对EHR（稀疏、不规则）和可穿戴数据（密集但缺乏语义）通常单独建模或简单融合，难以充分利用二者互补性；需一种能联合学习、语义一致且时间连贯的表示方法。

Method: 设计多模态基础模型：采用模态专用编码器+共享时间主干网络，通过自监督与跨模态预训练目标联合优化，将EHR和可穿戴信号映射到统一连续时间潜在空间。

Result: 在多项生理预测与风险建模任务中，该模型显著超越纯EHR或纯可穿戴基线，尤其在长时预测和数据缺失条件下优势明显。

Conclusion: 联合EHR与可穿戴数据进行基础模型预训练，能生成更真实、更具临床意义和时间一致性的纵向健康表征。

Abstract: Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.

</details>


### [636] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 本文提出了一种结合小波感知调制、多分辨率小波分解与分辨率自适应注意力机制的新型框架，用于企业内网中的内部威胁检测，显著提升了CERT r4.2数据集上的异常检测精度、召回率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 内部威胁检测面临日志多通道、非平稳、异常稀疏等挑战，现有方法难以有效建模复杂行为模式。

Method: 提出融合偏差感知调制、离散小波变换（DWT）多分辨率分解和可学习的分辨率自适应注意力机制的端到端框架。

Result: 在CERT r4.2基准上，该方法在不同时间粒度和场景下均优于现有基线，在精确率、召回率和F1分数上表现更优。

Conclusion: 小波分析与自适应注意力的协同建模能有效提升日志异常检测鲁棒性，为内部威胁检测提供了新思路。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [637] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: 本文提出了TimeGMM，一种基于高斯混合模型（GMM）的单次前向传播概率时间序列预测框架，通过GRIN模块适应时序-概率分布偏移，并结合时序编码器与条件时序-概率解码器，在CRPS和NMAE指标上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法常依赖计算昂贵的采样或受限的参数假设，导致预测性能受限和分布不匹配问题。

Method: 提出TimeGMM框架，核心包括GMM适配的可逆实例归一化（GRIN）模块、时序编码器（TE-Module）和条件时序-概率解码器（CTPD-Module），实现单次前向传播建模复杂未来分布。

Result: 在多个基准数据集上，TimeGMM在CRPS指标上最高提升22.48%，在NMAE指标上最高提升21.23%，显著优于当前最先进方法。

Conclusion: TimeGMM为高效、准确的概率时间序列预测提供了新范式，有效缓解了计算开销与分布建模能力之间的权衡问题。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [638] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 本文探讨了经验风险最小化（ERM）在某些情况下优于专门设计的分布外泛化方法的现象，发现训练域间的分布偏移程度是关键因素：较大的分布偏移反而有助于ERM学习到接近不变预测的模型，并在理论上和实验上验证了该现象。


<details>
  <summary>Details</summary>
Motivation: 观察到ERM有时优于专为分布外泛化设计的方法，促使作者探究其背后除算法设计外的根本原因，聚焦于训练域间的分布偏移影响。

Method: 通过理论分析推导分布偏移程度对模型预测能力的上界影响，并证明在特定数据条件下ERM解可逼近不变预测模型；辅以实证验证不同分布偏移程度下模型预测对Oracle/Optimal模型的逼近程度。

Result: 理论表明：分布偏移越大，模型越易逼近不变预测能力；特定条件下ERM性能可媲美不变预测模型。实验显示：随训练域间分布偏移增大，模型预测更接近Oracle或Optimal模型。

Conclusion: 分布偏移本身是一种有益的学习信号，足够大的训练域间分布差异可使ERM自然趋向学习不变特征，从而提升分布外泛化能力，挑战了‘需专用算法才能实现不变预测’的常见假设。

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [639] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 本文提出了一种名为MLaaS Dataset Generator（MDG）的新框架，用于生成可配置、可复现的数据集，以评估机器学习即服务（MLaaS）的选择与组合。MDG通过在多个真实数据集和不同数据分布下训练和评估多种模型族，模拟真实的MLaaS行为，并记录功能属性、服务质量指标及组合相关指标，构建了包含上万个服务实例的大规模基准数据集；实验表明其生成的数据集能提升MLaaS选择准确率与组合质量。


<details>
  <summary>Details</summary>
Motivation: 现有MLaaS选择与组合研究缺乏可配置、可复现且贴近真实场景的基准数据集，限制了数据驱动方法的发展。

Method: 提出MDG框架，通过在多数据集、多数据分布下训练/评估多样化模型族，模拟真实MLaaS行为；记录功能属性、QoS指标与组合指标；内置IoT环境下的服务组合机制；生成大规模服务实例数据集。

Result: 生成超一万MLaaS服务实例，构建大规模基准数据集；实验证明MDG生成的数据集显著提升MLaaS选择准确率与组合质量。

Conclusion: MDG为MLaaS选择与组合提供了实用、可扩展的数据生成基础，推动数据驱动的MLaaS研究发展。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [640] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

TL;DR: 本文提出Explanova，一种基于预设AutoML式工作流的自动化数据分析框架，利用本地小型语言模型降低成本，区别于依赖大型语言模型的代理式方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的代理式自动化数据分析框架（如DeepAnalyze、DataSage、Datawise）虽强大但成本高；作者旨在探索更经济、结构化、可遍历的自动化分析路径。

Method: 设计一种预设的AutoML风格工作流，系统遍历数据探索步骤（如单变量统计、变量间关系、跨变量解释等），并采用本地小型语言模型驱动执行。

Result: Explanova实现了更低成本的自动化数据分析，验证了结构化工作流在替代复杂LLM代理范式上的可行性。

Conclusion: 预设工作流结合小型本地LLM是一种有前景的轻量级自动化数据分析新路径，可在保持解释性的同时显著降低计算开销。

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [641] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: 本文提出了OrLoMo方法，首次实现了异步分布式带局部更新的动量随机梯度下降（MSGD），通过按全局迭代索引顺序聚合各工作节点的局部动量，在任意延迟下保证非凸问题收敛，并在实验中优于同步及其他异步方法。


<details>
  <summary>Details</summary>
Motivation: 现有异步分布式学习缺乏对带局部更新的动量SGD（MSGD）的有效支持，尤其在计算能力异构的集群中亟需兼顾通信效率与收敛性能。

Method: 提出OrLoMo（Ordered Local Momentum）：各worker本地运行MSGD，server按全局迭代索引顺序聚合局部动量；理论分析覆盖任意延迟下的非凸收敛性。

Result: OrLoMo在实验中超越其同步版本及其他异步方法，验证了其有效性与鲁棒性。

Conclusion: OrLoMo是首个支持异步分布式MSGD与局部更新的方法，兼具理论收敛保证与实际性能优势。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [642] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: 本文提出IceWatch，一种结合空间与时间视角的深度学习框架，用于预测冰湖溃决洪水（GLOF），通过RiskFlow（处理Sentinel-2影像）、TerraFlow（建模冰川流速）和TempFlow（预测地表温度）实现多模态、物理信息引导的自动、实时、鲁棒预警。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测与预测方法存在更新慢、依赖人工、云干扰下精度下降及缺乏实地数据等问题。

Method: 提出IceWatch框架：RiskFlow基于CNN分析Sentinel-2多光谱影像识别雪、冰与融水空间模式；TerraFlow利用NASA ITS_LIVE时序数据建模冰川流速；TempFlow基于MODIS LST数据预测近地表温度；三者经统一预处理与同步融合，实现多模态交叉验证。

Result: IceWatch实现了高预测性能、实时快速处理能力、对噪声与缺失数据的鲁棒性，并支持自动、可扩展的GLOF预警系统构建及与多源传感器和全球冰川监测的集成。

Conclusion: IceWatch为高山区GLOF风险提供了更可靠、可解释、自动化和可扩展的预测解决方案，推动了物理信息深度学习在灾害预警中的应用。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [643] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

TL;DR: 本文提出了一种结合物理信息神经网络的数据集与概念框架，使大语言模型能够通过时序建模和上下文学习模拟真实世界的情感动态，从而实现可解释的对话建模。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在对话中对情感动态的建模能力，并增强其可解释性。

Method: 构建新数据集，引入基于物理信息神经网络（PINN）的概念框架，支持时序情感建模与上下文学习。

Result: 实现了LLM对真实世界情感动态的时序模拟，为可解释对话建模提供了新路径。

Conclusion: 该框架为情感感知对话系统提供了理论与实践基础，拓展了LLM在具身智能与人机交互中的应用潜力。

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [644] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: 本文提出LB-MCTS框架，结合大语言模型（LLM）与贝叶斯优化（BO），在蒙特卡洛树搜索结构中协同优化CASH问题，通过选择性调优记忆（STM）增强LLM推理能力，并动态平衡探索与利用，显著提升自动化机器学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化在CASH问题上存在冷启动问题，而现有LLM方法难以泛化到高维、结构化的CASH空间，亟需融合二者优势的新方法。

Method: 提出LB-MCTS框架：将LLM嵌入蒙特卡洛树搜索结构，引入选择性调优记忆（STM）提升LLM推理，设计显式的探索-利用权衡机制，并随数据积累动态切换LLM驱动与BO驱动的建议生成。

Result: 在104个AMLB数据集上的实验表明，LB-MCTS显著优于各类竞争性基线方法。

Conclusion: LB-MCTS成功融合LLM的语义先验能力与BO的数据驱动优化能力，在CASH任务中实现更鲁棒、高效的自动化算法与超参联合优化。

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [645] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的控制阀粘滞故障检测与早期预测框架，仅利用常规过程信号（OP和PV），在真实炼油厂数据上验证了LSTM模型可提前4小时预测粘滞，为业界首次。


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程中常见故障，导致系统不稳定、设备磨损和维护成本上升；许多工厂仍使用无实时监控的传统阀门，难以早期预测。

Method: 构建并比较三种深度学习模型（CNN、CNN-SVM、LSTM），采用基于斜率比分析的数据驱动标注方法，在真实油气炼厂数据集上训练和评估。

Result: LSTM模型准确率最高，可提前4小时预测控制阀粘滞；该方法首次在真实工业数据上实现ML驱动的早期粘滞预测。

Conclusion: 所提框架可集成至现有控制系统，支持预测性维护，降低停机时间和不必要的硬件更换。

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [646] [Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation](https://arxiv.org/abs/2601.12380)
*Ou Deng,Shoji Nishimura,Atsushi Ogihara,Qun Jin*

Main category: cs.LG

TL;DR: 本文提出了一种名为Statistical-Neural Interaction (SNI)的可解释混合类型缺失值填补框架，结合统计先验与神经注意力机制，在填补精度与可解释性之间提供可控权衡。


<details>
  <summary>Details</summary>
Motivation: 现实中的表格数据常含连续与类别变量，且缺失普遍，易影响下游分析；现有方法在可解释性与混合类型建模上存在不足。

Method: 提出SNI框架，核心为Controllable-Prior Feature Attention（CPFA）模块，通过学习头依赖的先验强度系数{λ_h}，软约束注意力朝向统计相关性先验，同时允许数据驱动的非线性偏离；并从注意力图聚合出有向特征依赖矩阵以实现内在可解释性。

Result: 在6个真实数据集（ICU、社会调查、经济统计、工程等）及MCAR/严格MAR设定（30%缺失率）下，SNI在连续变量上表现稳健，虽在分类变量准确率上常逊于MissForest和MIWAE，但提供了内生的依赖诊断与显式统计-神经权衡参数；还进行了MNAR压力测试与计算开销、不平衡类别局限性分析。

Conclusion: SNI在需要可解释性与诊断能力的实际部署场景中具有独特价值，其精度-可解释性权衡设计为混合类型缺失填补提供了新范式。

Abstract: Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{λ_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.

</details>


### [647] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: 本文提出DRIFT框架，通过采样、提示和优化三方面策略，在强化学习微调过程中激励生成多样性，解决大模型微调中的多样性坍缩问题，显著提升任务对齐与生成多样性的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习微调生成模型时出现的‘多样性坍缩’问题，即策略退化为单一输出（Dirac delta分布），难以兼顾任务对齐与生成多样性。

Method: 提出DRIFT框架，包含三方面：i) 奖励集中采样以过滤异常样本；ii) 随机化提示扩展条件空间；iii) 基于势函数的奖励塑形机制优化组内多样性。

Result: 在保持任务对齐水平不变时，多样性提升9.08%~43.46%；在保持多样性水平不变时，对齐度提升59.65%~65.86%，实现帕累托优势。

Conclusion: DRIFT有效协调任务对齐与生成多样性，增强图像生成模型在需多样化候选输出场景下的实用性与通用性。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [648] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 本文提出了一种可解释的机器学习框架，用于儿童牙科风险分层，强调可解释性、校准性和伦理部署，而非追求最高预测精度；模型在人口级数据上训练，SHAP分析显示年龄和收入-贫困比是最重要的风险因素。


<details>
  <summary>Details</summary>
Motivation: 现有牙科AI应用多依赖图像诊断和黑箱模型，缺乏透明性和伦理适用性，尤其在儿童群体中；而儿童口腔健康问题具有高度流行性和不平等性，亟需可解释、公平、可部署的风险评估工具。

Method: 使用包含年龄、收入-贫困比、种族/ ethnicity、性别和病史的人口级儿童数据训练监督学习模型；采用ROC分析和校准曲线评估性能；利用SHAP实现全局与个体层面的可解释性。

Result: 模型AUC为0.61，校准偏保守（高风险区低估）；SHAP分析揭示年龄和收入-贫困比是最大风险贡献因子，其次为种族/ethnicity和性别。

Conclusion: 可解释机器学习支持以预防为导向、透明且公平的儿童牙科风险分层，适用于人群筛查与资源公平配置，而非临床诊断决策。

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [649] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 本文揭示了现有大语言模型对齐方法（如PPO、DPO、IPO）在采样几何与优化几何上的隐式混淆，提出正交化策略优化（OPO）框架，通过解耦二者并采用alpha加权重要性采样与chi-square诱导的二次正则化，实现稳定、线性梯度、高置信度下不失效的对齐训练。


<details>
  <summary>Details</summary>
Motivation: 现有对齐算法常被视作彼此独立，但实际隐含混淆了采样几何（决定梯度主导样本）和优化几何（决定价值偏差惩罚方式），导致KL散度引发的数值不稳定与高置信度下梯度消失问题。

Method: 将对齐建模为策略能量与目标能量间广义距离最小化，以alpha散度控制采样权重、Bregman散度定义值度量；提出OPO框架，结合alpha加权重要性采样与ratio坐标下的chi-square二次正则化。

Result: OPO获得简洁、良态的目标函数，具备线性梯度动力学，优化稳定、避免梯度饱和，保持峰值搜索行为，在高置信度下仍有效。

Conclusion: OPO为现有对齐方法提供了统一视角，并为鲁棒的推理导向训练奠定了原理性基础。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [650] [Graph Attention Networks with Physical Constraints for Anomaly Detection](https://arxiv.org/abs/2601.12426)
*Mohammadhossein Homaei,Iman Khazrak,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

TL;DR: 本文提出了一种水力感知的图注意力网络，利用归一化的守恒律违反作为特征，结合质量与能量平衡残差、图注意力机制和双向LSTM，实现对供水系统中异常的高精度、鲁棒且可解释的检测。


<details>
  <summary>Details</summary>
Motivation: 供水系统面临日益增长的网络物理风险，现有数据驱动模型忽略网络拓扑且难以解释，而基于模型的方法又严重依赖参数精度。

Method: 提出一种液压感知的图注意力网络，以归一化的守恒律违反为特征，融合质量与能量平衡残差、图注意力机制和双向LSTM，并引入多尺度模块聚合从节点到网络层级的检测得分。

Result: 在BATADAL数据集上达到F1=0.979，相较基线提升3.3个百分点，在15%参数噪声下仍保持高鲁棒性。

Conclusion: 该方法在检测精度、鲁棒性和可解释性之间取得了良好平衡，为供水系统的异常检测提供了新思路。

Abstract: Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.

</details>


### [651] [Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery](https://arxiv.org/abs/2601.12442)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: 本文提出了一种名为CANUF的约束感知神经符号不确定性框架，将贝叶斯深度学习与可微符号推理结合，实现了科学AI中可信不确定性估计与领域约束满足的统一。


<details>
  <summary>Details</summary>
Motivation: 科学AI需要既提供可信不确定性估计、又满足领域约束的模型；现有方法要么无法融入符号化科学知识，要么缺乏原理性的不确定性建模。

Method: 提出CANUF框架，包含三部分：从科学文献自动提取约束、基于变分推断的概率神经主干网络、以及确保物理一致性的可微约束满足层。

Result: 在Materials Project、QM9和气候基准上的实验表明，CANUF相较贝叶斯神经网络降低预期校准误差34.7%，约束满足率达99.2%；消融实验显示约束引导重校准贡献18.3%性能增益，约束提取精度达91.4%。

Conclusion: CANUF是首个端到端可微框架，同时解决科学预测中的不确定性量化、约束满足与可解释性问题。

Abstract: Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.

</details>


### [652] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 本文提出了一种两阶段时间序列预测框架，第一阶段用CNN提取局部时序动态并结合token级自注意力优化嵌入，第二阶段用Transformer建模跨patch的全局依赖；实验证明该解耦策略优于现有卷积和patch-based Transformer基线。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中依赖高质量输入表示，但原始多变量时间序列的结构化表征不足，影响模型性能。

Method: 提出两阶段框架：第一阶段使用CNN对固定长度时间块（patches）进行局部特征提取，并引入token-level自注意力优化patch级嵌入；第二阶段用Transformer编码器建模patch间长程依赖并生成预测。

Result: 在可控静态与动态因子的合成多变量时间序列数据上，该patch-based tokenization策略在预测性能上媲美甚至优于卷积及patch-based Transformer基线。

Conclusion: 结构化时间表征至关重要；将局部时序编码与全局注意力建模解耦，可提升时间序列预测的有效性与稳定性。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [653] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: 本文提出Q-learning with Adjoint Matching (QAM)，一种基于时序差分（TD）的新型强化学习算法，用于高效优化连续动作空间中表达能力强的扩散或流匹配策略，同时避免多步去噪过程反向传播带来的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 解决连续动作强化学习中，对表达能力强的扩散或流匹配策略进行高效优化的长期挑战；现有方法要么忽略评论家的一阶信息，要么使用有偏或低表达力的近似。

Method: 引入伴随匹配（adjoint matching）技术，将评论家的动作梯度转化为逐步目标函数，规避不稳定的反向传播，同时保持策略无偏且高表达力；结合时序差分备份更新评论家。

Result: QAM在离线及离线到在线强化学习的困难稀疏奖励任务上持续优于先前方法。

Conclusion: QAM通过伴随匹配有效融合了评论家梯度信息与高表达力策略优化，为连续动作RL提供了稳定、高效且无偏的新范式。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [654] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 本文研究了从经典数据样本中重构量子信道的问题，提出利用半定规划（SDP）优化总保真度（表示为两个二次型之比的情形），并发现重构所得量子信道的Kraus秩通常极低，表明低秩模型足以拟合实验数据；该方法已成功应用于投影算符重构，并探讨了基于量子信道变换的经典计算模型。


<details>
  <summary>Details</summary>
Motivation: 从实验获得的经典数据中高效、准确地重构未知量子信道，尤其在保真度可表为二次型之比的情形下寻求可靠且计算可行的优化方法。

Method: 将量子信道重构建模为关于Choi矩阵的保真度优化问题，当总保真度可表示为两个二次型之比时，采用半定规划（SDP）进行凸优化；使用多种商用SDP求解器进行数值验证，并分析所得量子信道的Kraus秩特性；还将方法推广至投影算符重构，并探讨经典计算机上模拟量子信道变换的计算模型。

Result: SDP方法能高效重构多种类型量子信道；重构所得信道的Kraus秩通常仅占理论最大值的百分之几；该方法成功用于投影算符重构；提出了可在经典硬件上实现的量子信道变换计算模型。

Conclusion: 低Kraus秩量子信道足以刻画典型实验数据，SDP是解决此类保真度优化驱动的量子信道重构问题的有效且实用工具；相关思想可延伸至经典计算架构设计。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [655] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 本文提出了一种名为'基策略预测（base policy prediction）'的新技术，用于在通信受限的多智能体强化学习（MARL）中缓解重要性采样因基策略过时而导致的不稳定性问题；该方法通过历史梯度预测策略更新路径，从而减少基策略与当前策略间的差异，在显著降低通信轮数的同时保证收敛性与样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有协同MARL方法常依赖全局信息（如团队奖励、其他智能体动作），但在去中心化系统中因通信开销高而难以实现；当通信受限时，重要性采样因基策略严重滞后而变得不稳定。

Method: 提出基策略预测技术：利用历史梯度预测一系列基策略的演化路径，并在单次通信轮内采集对应样本；结合理论分析，证明其在势博弈中收敛至ε-Nash均衡，并扩展至一般马尔可夫合作博弈以寻找个体局部最优。

Result: 理论表明算法在势博弈中仅需O(ε^{-3/4})轮通信和O(poly(max_i |A_i|) ε^{-11/4})样本即可收敛至ε-Nash均衡，通信代价与样本复杂度均优于现有最优方法（尤其消除了联合动作空间大小的指数依赖）；实验验证其在仿真游戏与MAPPO复杂环境中的有效性。

Conclusion: 基策略预测是一种高效、稳定且通信经济的MARL策略更新机制，显著提升了通信受限场景下的学习效率与理论保障。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [656] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

TL;DR: 本文提出了一系列改进方法，以解决拉格朗日神经网络（LNNs）在训练复杂物理系统时的不稳定性问题，包括Hessian正则化、更适合学习拉格朗日量的激活函数和物理感知的坐标缩放；新方法显著提升了训练稳定性和泛化能力，在双摆、三摆乃至AdS₄时空测地线等复杂系统中成功学习拉格朗日量，并首次实现从轨迹数据直接推断广义相对论下的时空度规结构。


<details>
  <summary>Details</summary>
Motivation: LNNs虽能从轨迹数据学习任意拉格朗日量，但其特殊优化目标导致训练严重不稳定，限制其在复杂系统中的应用。

Method: 提出三项关键技术：1）Hessian正则化，抑制速度二阶导中非物理解；2）适配拉格朗日学习的激活函数；3）物理感知的坐标缩放；并扩展正则化以处理洛伦兹符号约束，支持相对论场景。

Result: 在双摆系统上验证损失降低96.6%、稳定性提升90.68%；首次成功学习三摆动力学及AdS₄时空下的测地线拉格朗日量，实现从轨迹反推时空度规分量。

Conclusion: 所提改进大幅拓展了LNNs的实际适用性，为自动发现物理系统的几何结构（如时空度规）提供了新范式，尽管仍受限于Hessian可逆性要求。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [657] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 本文提出了一种针对稀疏二值特征和二分类问题的流式决策树分裂优化算法，在信息增益（条件熵）和基尼指数两种指标下分别实现了(1+α)近似，并显著降低了时间复杂度，尤其适用于m≪d的稀疏场景。


<details>
  <summary>Details</summary>
Motivation: 传统流式决策树在每个叶节点维护计数器以寻找最优分裂，但对高维稀疏二值数据而言，O(d)时间复杂度开销大；本文旨在加速最优分裂搜索过程。

Method: 提出一种基于近似计算的高效分裂搜索算法：对条件熵指标，实现(1+α)近似，摊还时间复杂度为O(α⁻¹(1+m log d) log log n)；对基尼指数，摊还时间为O(α⁻¹ + m log d)，其中m为样本中1的个数，d为特征维数，n为样本数。

Result: 实验表明该算法能快速找到几乎最优分裂，运行速度优于基线方法，且实际近似效果好于理论保证。

Conclusion: 所提算法在稀疏二值数据流场景下显著提升了决策树分裂效率，兼顾精度与速度，为流式学习提供了实用优化方案。

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [658] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 本文提出了一种基于博弈化建模和强化学习（DAgger）的在线集中式电动汽车充电调度方法，在保证容量约束下显著提升负荷均衡性，并在真实案例中大幅降低系统成本。


<details>
  <summary>Details</summary>
Motivation: 解决动态到达的电动汽车在线集中充电调度问题，以在容量限制下实现负荷均衡，并降低实际电网运营成本。

Method: 将充电调度问题博弈化建模为网格上的‘充电块’放置问题；设计启发式策略，结合专家示范训练学习代理，并使用DAgger算法进行优化；从理论上分析其模型复杂度与泛化界优势。

Result: 图像到动作（image-to-movement）模型在多种EV到达模式下均优于启发式、向量化方法及监督学习基线；在蒙特利尔地区真实案例中，年系统成本降低数千万美元，并有望延缓昂贵的电网升级。

Conclusion: 博弈化建模与DAgger增强的学习框架能有效提升充电调度性能，兼具理论严谨性与工程实用性，具备显著经济价值与落地潜力。

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [659] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

TL;DR: 本文提出了两种用于预测系外行星反射光谱中生物标志物通量的机器学习模型：贝叶斯卷积神经网络（BCNN）和新型光谱查询自适应Transformer（SQuAT），分别擅长不确定性量化与光谱可解释性，旨在支持未来旗舰级直接成像任务（如HWO）的目标筛选与观测规划。


<details>
  <summary>Details</summary>
Motivation: 未来直接成像旗舰任务（如NASA的HWO）面临极其严格的时间与资源限制，亟需高效、可靠的方法进行观测目标优先级排序。

Method: 提出两种专用机器学习模型：贝叶斯卷积神经网络（BCNN）用于稳健量化认知与偶然不确定性；新型光谱查询自适应Transformer（SQuAT），利用查询驱动注意力机制提升光谱特征与特定生物标志物物种之间的可解释关联。

Result: 两模型在覆盖广泛系外行星条件的增强数据集上均达到高预测精度，且各自展现出在不确定性量化（BCNN）与光谱可解释性（SQuAT）方面的显著优势。

Conclusion: 所提方法有望显著加速目标筛选、优化观测调度，并提升HWO等未来旗舰任务的科学产出效率与可靠性。

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [660] [Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization](https://arxiv.org/abs/2601.12598)
*Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Emre Neftci*

Main category: cs.LG

TL;DR: 本文提出SelectivBench——一个轻量、可定制的合成基准，用于系统评估线性循环神经网络在序列建模中的选择性能力，并通过该基准揭示了关键架构组件（如门控、快速遗忘、通道混合）对回忆、选择性和泛化能力的不同作用。


<details>
  <summary>Details</summary>
Motivation: 现有线性RNN模型不断引入复杂机制，但缺乏系统直接比较；已有基准或过于简单，或计算开销过大，难以支撑高效、可控的模型分析。

Method: 提出线性循环模型的精细化分类法，并构建SelectivBench：基于规则语法生成含不规则间隔和上下文干扰项的合成序列任务，以定量评估模型的选择性（即聚焦相关输入、忽略干扰的能力）。

Result: 在SelectivBench上的实验表明：门控与快速遗忘机制显著提升回忆能力；in-state通道混合对选择性非必需，但对泛化至关重要；softmax注意力因记忆容量随序列长度线性增长，在长程依赖任务中仍占优；SelectivBench性能趋势与大规模语言任务一致。

Conclusion: SelectivBench为线性循环模型提供了高效、可控、可解释的评估框架，有助于解耦架构设计要素，推动兼具效率与能力的序列建模研究。

Abstract: Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench

</details>


### [661] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 本文提出了一种基于广义f-softargmax的新型策略参数化方法，并结合相应的f-散度正则化，改善优化景观并提供首个无需预处理的非渐近最后迭代收敛保证。


<details>
  <summary>Details</summary>
Motivation: 解决策略梯度方法对策略参数化选择高度敏感的问题，特别是softmax参数化导致的病态优化景观和指数级慢收敛。

Method: 采用广义f-softargmax替代softmax参数化，并引入对应f-散度诱导的正则化项；理论分析其优化性质（如Polyak-Lojasiewicz不等式）并推导非渐近收敛性与样本复杂度界。

Result: 建立了首个无需预处理的随机策略梯度方法在有限MDP上的显式非渐近最后迭代收敛保证；证明f-PG（使用Tsallis散度）具有多项式样本复杂度，优于softmax的指数复杂度。

Conclusion: 广义f-softargmax与匹配正则化能显著改善策略梯度优化性能，为理论分析和实际应用提供了更优替代方案。

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [662] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 本文提出了一种基于迹幂（trace powers）估计大型对称正定矩阵对数行列式 log det(A) 的新方法，通过归一化特征值的矩生成函数及其对数变换 K(t) 来估计导数 K'(0)，从而避免传统泰勒展开的收敛限制；同时证明了仅用有限正阶矩无法在病态条件下实现一致准确估计，并给出可证明的上下界及可信度诊断。


<details>
  <summary>Details</summary>
Motivation: 传统基于矩阵-向量乘积和多项式逼近的方法受限于收敛条件（如要求谱半径满足 |λ−AM| < AM，且条件数 κ > 4 时发散）；而实际中迹幂 p_k = tr(A^k) 易获得，本文旨在利用这一自然信息构建更鲁棒、高效且具理论保证的 log det(A) 估计方法。

Method: 将归一化特征值 X = λ/AM 的矩生成函数记为 M(t)，则 log det(A) = n(log AM + M'(0))；引入压缩变换 K(t) = log M(t)，利用 trace powers 得到 K(k)（k=0,1,…,m），在 m+1 个连续整数上插值 K(t) 并求导得 K'(0) 估计；同时基于矩约束和给定谱下界 r，推导 (det A)^{1/n} 的上下界，形成 log det(A) 的可证明置信区间，并设计 gap diagnostic 判断点估计可靠性。

Result: 所提方法在 O(m) 时间内完成（m=4~8 时近似常数时间），显著快于传统方法；理论证明了仅用有限正阶矩无法在无界条件数下实现一致准确估计；给出了具有严格数学保证的上下界；gap diagnostic 能有效区分可信点估计与需报告区间的场景；实验验证其在高条件数下的鲁棒性优于经典矩方法。

Conclusion: 基于迹幂和 K(t) 插值的框架为 log det(A) 提供了一种高效、鲁棒且具理论保障的新范式；揭示了正阶矩对谱尾部的天然低敏感性与 log det 对尾部的高敏感性之间的根本矛盾；强调在病态问题中应优先采用可证明的区间估计而非盲目依赖点估计。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [663] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 本文提出了一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成更隐蔽、攻击成功率更高的通用对抗扰动（UAPs），在ImageNet上验证了其在扰动范数、误分类效果和收敛速度上的优势。


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动（UAPs）能用单一噪声模式攻击多个输入，威胁深度神经网络；而现有进化算法在生成低可见性、高成功率UAP方面仍有提升空间。

Method: 提出浮点编码、惩罚驱动的单目标进化框架，采用连续基因表示、动态自适应进化算子调度，并通过跨模型测试与批次切换防止过拟合，基于PyTorch模块化实现。

Result: 在ImageNet上实验表明，该方法生成的UAP具有更小的扰动范数、更高的误分类率和更快的收敛速度，优于现有基于进化的UAP生成方法。

Conclusion: 所提进化框架兼具鲁棒性与可扩展性，适用于多种深度学习架构的通用对抗攻击。

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [664] [Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.12637)
*Long D. Nguyen,Kelin Xia,Binh P. Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种名为Multiscale Interaction Mixture of Experts (MI-MoE)的新型3D分子图神经网络模块，通过距离截断专家集成和基于拓扑门控编码器（含持久同调特征）实现多尺度几何相互作用建模，显著提升多种3D分子模型在各类性质预测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D分子图神经网络依赖固定距离截断和邻居数量限制，导致交互建模僵化、缺乏数据自适应性，难以有效捕捉不同尺度（短程、中程、长程）的空间相互作用。

Method: 提出MI-MoE模块：(1) 距离截断专家集成，分别建模短/中/长程相互作用；(2) 基于拓扑的门控编码器，利用持续同调等滤波描述符动态路由输入至对应专家；(3) 作为即插即用模块集成到主流3D分子模型中。

Result: MI-MoE在多个分子与聚合物性质预测基准数据集（涵盖回归与分类任务）上，一致提升了多种强基线3D分子模型的性能。

Conclusion: 拓扑感知的多尺度路由是一种有效的3D分子图学习原则，MI-MoE为灵活、自适应的几何交互建模提供了新范式。

Abstract: Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.

</details>


### [665] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: 本文揭示了SHAP等后验解释方法存在'解释多重性'问题：即使输入、任务和模型固定，多次运行仍会产生显著不同的特征归因解释；作者提出方法量化该现象，并指出常用稳定性度量（如基于幅度的距离）可能掩盖实际的特征排序变化，强调需依据解释的实际用途设计匹配的评估指标和随机基线。


<details>
  <summary>Details</summary>
Motivation: SHAP等后验解释方法被广泛用于高风险领域决策的可解释性支撑，但实践中发现其结果不稳定，缺乏对这种不一致性的系统性刻画与归因。

Method: 提出一种刻画特征归因解释多重性的方法，分离模型训练/选择与解释流程内在随机性两类来源；采用多种度量（幅度距离 vs. 排名变化）评估稳定性；构建基于合理零模型的随机基线以校准观察到的分歧程度。

Result: 在多个数据集、模型类别及置信度水平下，均发现解释多重性普遍存在且在高置信预测中依然显著；幅度距离可能接近零而排名度量却显示顶部特征身份与顺序剧烈波动。

Conclusion: 解释多重性是后验归因方法的固有挑战，当前稳定性评估易产生误导；必须依据解释的具体用途，设计更匹配的评估指标与随机基线。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [666] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

TL;DR: 本文提出了一种图多智能体强化学习框架，用于动态但结构相似的多跳无线网络中自回归马尔可夫源的实时采样与估计，实现了可迁移、鲁棒且优于现有方法的去中心化策略。


<details>
  <summary>Details</summary>
Motivation: 在动态多跳无线网络中，因状态-动作空间高维、拓扑复杂，难以解析求解最优采样与估计策略；同时需应对信道冲突、节点缓存、非平稳性等实际挑战。

Method: 提出基于图神经网络的多智能体强化学习框架，支持去中心化执行；理论分析策略在结构相似图上的可迁移性；采用独立学习与集中训练-分散执行（CTDE）范式，并引入循环机制增强时序建模能力。

Result: 实验表明：(i) 所提策略显著优于基线方法；(ii) 策略可迁移到更大规模网络，增益随智能体数增加；(iii) 图形化训练对非平稳环境具有鲁棒性；(iv) 循环结构对独立学习和CTDE均关键，提升非平稳适应能力。

Conclusion: 图结构建模与循环机制相结合的多智能体RL方法，能有效解决复杂无线网络中的分布式估计问题，兼具性能、可扩展性与迁移性。

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [667] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 本文提出MetaToolAgent（MTA）元学习方法和一个覆盖7个领域、含155个工具与9377问答对的综合数据集，以提升大语言模型在面对新工具时的跨工具泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法局限于小规模工具集，难以泛化到实际部署中遇到的新工具。

Method: 构建涵盖7个领域的综合性工具学习数据集，并提出基于元学习的MetaToolAgent（MTA）方法，增强模型对未见工具的泛化能力。

Result: MTA在未见工具上的表现显著优于基线方法，验证了其在动态工具协调任务中的有效性。

Conclusion: MTA为构建灵活、可扩展的工具协同系统提供了新思路，推动大语言模型在真实复杂任务中的实用化。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [668] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级、无需离线训练的时序与阈值触发的多臂老虎机（T3P MAB）强化学习算法，用于自适应深部脑刺激（DBS），可同时调节刺激频率和幅度，适用于植入式设备并在MCU上实测验证了低功耗优势。


<details>
  <summary>Details</summary>
Motivation: 现有固定参数DBS易引发副作用且电池寿命短；而现有RL方法计算复杂、收敛慢、难以在体训练，且大多仅调节频率或幅度之一，缺乏联合调控与硬件部署验证。

Method: 提出T3P MAB算法——结合时间触发与生理信号阈值触发机制的轻量级在线强化学习框架，支持频率与幅度联合动态调节，无需离线训练，可直接部署于资源受限的植入式MCU平台。

Result: 首次在硬件上实现DBS用MAB算法，实测表明其功耗显著低于现有RL方法，在多种MCU平台上验证了低资源消耗与快速收敛能力。

Conclusion: T3P MAB是一种适合临床植入的高效、低功耗、在线自适应DBS控制方法，为下一代智能神经调控设备提供了可行的技术路径。

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [669] [Towards Spectroscopy: Susceptibility Clusters in Language Models](https://arxiv.org/abs/2601.12703)
*Andrew Gordon,Garrett Baker,George Wang,William Snell,Stan van Wingerden,Daniel Murfet*

Main category: cs.LG

TL;DR: 本文提出一种基于谱学原理的神经网络分析方法，通过扰动数据分布并计算 susceptibilities（敏感度）来揭示模型内部结构，理论证明其可分解为数据分布的模态之和，并在 Pythia-14M 上验证了该方法能发现大量可解释的语义/语法簇，且与稀疏自编码器结果高度一致。


<details>
  <summary>Details</summary>
Motivation: 受物理系统谱学分析启发，希望为大语言模型提供一种可解释、基于统计响应的内部结构探测方法，弥补当前黑箱分析的不足。

Method: 对上下文x中特定token y进行数据分布加权扰动，利用SGLD采样局部Gibbs后验，计算组件级可观测量与扰动之间的协方差作为susceptibility χ_xy；进而对χ_xy进行谱分析与聚类。

Result: 在Pythia-14M上识别出510个可解释的簇（涵盖语法、代码、数学符号等），其中50%与稀疏自编码器（SAE）提取的特征匹配。

Conclusion: Susceptibility谱学方法是一种有效、可解释的神经网络内部结构探测工具，其发现的结构具有跨方法一致性，支持其作为通用分析范式。

Abstract: Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts "for similar reasons" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.

</details>


### [670] [Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems](https://arxiv.org/abs/2601.12704)
*Yan Ma,Yumeng Ren*

Main category: cs.LG

TL;DR: 本文提出了一种基于径向基函数神经网络（RBFNN）的物理信息机器学习算法（PIRBFNN），用于高效求解多资产Black-Scholes偏微分方程，尤其适用于非光滑收益条件下的高维期权定价问题。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在处理高维、非光滑 payoff 条件下的 Black-Scholes PDE 时存在维数灾难和精度不足问题，需更鲁棒高效的求解方法。

Method: 提出物理信息径向基函数神经网络（PIRBFNN），融合 RBF 配点法与物理信息神经网络思想；采用基于 PDE 残差的自适应策略优化隐层神经元分布；端到端联合优化网络结构与期权价格预测。

Result: 在单资产欧式看跌、双资产交换期权及四资产一篮子看涨期权三个实验中，PIRBFNN 展现出高精度与高效率，验证了其对多维非光滑金融 PDE 的有效求解能力。

Conclusion: PIRBFNN 是一种兼具物理可解释性与数据驱动灵活性的新方法，为高维金融衍生品定价提供了可行且有前景的数值替代方案。

Abstract: The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.

</details>


### [671] [Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting](https://arxiv.org/abs/2601.12706)
*Sina Kazemdehbashi*

Main category: cs.LG

TL;DR: 本文提出了一种新的时间序列预测框架TATS，将预测任务分为趋势方向预测（二分类）和数值预测两部分，并通过趋势调整提升LSTM/Bi-LSTM的预测精度，在黄金价格预测中验证了其优越性，并强调趋势准确率作为补充评估指标的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型（如LSTM）在波动剧烈的数据上表现受限，且常用误差指标（如MSE、MAE）无法反映模型对趋势变化的捕捉能力，因此需重构预测范式并引入趋势感知评估。

Method: 将时间序列预测解耦为趋势预测（二分类器）和数值预测（LSTM/Bi-LSTM），提出Trend-Adjusted Time Series (TATS) 模型，利用分类结果动态调整回归输出；理论分析结合实证实验（以日度黄金价格为案例）验证方法有效性。

Result: TATS在黄金价格预测中显著降低预测误差，优于标准LSTM和Bi-LSTM；同时证明仅依赖MSE/MAE不足以评估模型性能，趋势检测准确率是关键补充指标。

Conclusion: 解耦趋势与数值预测并进行联合建模可提升预测鲁棒性，尤其适用于高波动时序；评估体系应兼顾数值精度与趋势一致性。

Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.

</details>


### [672] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文提出了一种在零和矩阵博弈与马尔可夫博弈中，基于熵正则化与量化响应均衡（QRE）理论，从观测策略/动作中恢复未知奖励函数的统一框架，并给出了可识别性证明、高效算法及理论保证。


<details>
  <summary>Details</summary>
Motivation: 逆强化学习与博弈论中，估计驱动智能体行为的未知奖励函数至关重要；但该问题存在固有模糊性、奖励非唯一性及观测数据覆盖有限等挑战。

Method: 基于线性假设下的量化响应均衡（QRE）建立奖励函数可识别性理论，并据此提出一种适用于静态与动态场景、可融合最大似然估计（MLE）等方法的新型奖励学习算法。

Result: 算法具备强理论保证（可靠性与样本效率），并通过大量数值实验验证了其在竞争性决策建模中的实际有效性。

Conclusion: 本文构建了熵正则化零和博弈下奖励反演的统一理论与算法框架，为竞争环境下智能体行为建模与解释提供了新思路。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [673] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: 本文提出了一种分布中心化的策略优化方法（DCPO），从分布层面调控策略熵，以解决大语言模型强化学习中探索-利用失衡问题，显著优于现有基于样本的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO等方法在训练中易陷入熵坍塌、探索衰减；主流改进方法依赖样本层面的启发式设计（如奖励稀有样本），缺乏理论依据且效果不稳定。

Method: 提出分布中心化视角，将熵调控建模为分布级正则化；设计DCPO算法，在不引入外部采样前提下实现完全在线策略的可控熵调节。

Result: 在多个模型和七个基准上，DCPO平均比GRPO提升约20%；实现了更稳定、可控且理论可解释的探索-利用平衡。

Conclusion: DCPO用分布级原理替代样本级启发式，为大语言模型的强化学习提供了一个理论坚实、灵活高效的探索调控新范式。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [674] [A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection](https://arxiv.org/abs/2601.12745)
*Miao Ye,Jing Cui,Yuan huang,Qian He,Yong Wang,Jiwen Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种结合时空相关性特征提取与多任务自监督训练策略（预训练-图提示-微调）的图神经网络异常检测框架，用于无线传感器网络（WSN）多时序模态数据的异常检测，显著提升了检测性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有WSN多时序模态数据异常检测方法存在时空相关特征提取不足、异常样本标注成本高、类别不平衡等问题。

Method: 设计基于改进Mamba模型（多尺度+跨模态融合）与变分图卷积模块的异常检测骨干网络；提出无负样本对比学习、预测与重构三子任务的预训练方法；构建‘图提示-微调’机制引导自监督模型参数适配下游任务。

Result: 在公开数据集和实采数据集上F1值分别达91.30%和92.31%，优于现有方法。

Conclusion: 所提方法有效缓解了标注依赖与类别不平衡问题，增强了时空特征建模能力与模型泛化性，为WSN异常检测提供了高效可靠的解决方案。

Abstract: Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.

</details>


### [675] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 本文提出了一种基于布尔函数理论的图神经网络（GNN）表达能力新框架，定义了子群体布尔同构（SBI）作为更严格的表达性不变量，并揭示傅里叶次数、电路类与影响度是公平感知GNN的关键表达性瓶颈；据此设计了基于电路遍历的公平算法，能处理如奇偶性等高复杂度布尔定义的子群体，在真实图数据上显著降低交叉群体的公平性差距。


<details>
  <summary>Details</summary>
Motivation: 现有GNN表达性衡量标准（如WL测试、双连通性、同态框架）无法精细刻画其对复杂子群体结构（尤其涉及公平性场景）的建模能力，亟需面向公平性的新表达性理论框架。

Method: 构建基于布尔函数理论的GNN表达性框架，提出子群体布尔同构（SBI）概念；从傅里叶分析、电路复杂度（AC⁰、NC¹）和变量影响度角度刻画表达性瓶颈；设计基于电路遍历的公平优化算法。

Result: 理论证明SBI严格强于现有表达性判据；所提算法能有效处理由高复杂度布尔函数（如parity）定义的子群体；在真实图数据上，对交叉性子群体的公平性差距显著低于现有最先进方法。

Conclusion: 布尔函数视角为理解与提升GNN在公平敏感任务中的表达能力提供了新原理；SBI是更精细、更贴合公平需求的表达性基准；电路复杂度是制约公平GNN性能的根本因素之一。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [676] [Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks](https://arxiv.org/abs/2601.12775)
*Yuta Hirabayashi,Daisuke Matusoka,Konobu Kimura*

Main category: cs.LG

TL;DR: 本文提出了一种基于多尺度图神经网络的全球海洋预报模型，用于10天短期预测，通过双分辨率球面网格和融合大气变量，提升了短时预报精度和多尺度海洋动力过程表征能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动海洋模型在全局涡旋分辨预报中应用有限，难以准确表征宽范围空间尺度的海洋动力过程。

Method: 构建基于编码器-处理器-解码器架构的多尺度图神经网络，采用两个不同分辨率的球面网格，并将海表面大气变量与海洋状态变量共同作为节点输入。

Result: 模型在表面动能谱和个例分析中准确表征了多尺度海洋变化；RMSE对比显示短时预测技能提升。

Conclusion: 该模型提高了短期预报精度和多尺度海洋动力表征能力，有望推动数据驱动的全球涡旋分辨海洋预报发展。

Abstract: Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.

</details>


### [677] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: 本文提出了DistilTS，首个专为时间序列基础模型（TSFMs）设计的知识蒸馏框架，通过引入时序加权目标和时间对齐策略，有效解决预测任务中不同预测步长难度差异与师生模型架构差异两大挑战，在大幅压缩模型参数（最高达1/150）和加速推理（最高6000倍）的同时，保持接近全量模型的预测性能。


<details>
  <summary>Details</summary>
Motivation: TSFMs虽性能强但参数量大、部署成本高；通用知识蒸馏方法难以直接适用于时间序列预测，因其具有独特任务特性（如多步长预测难度不均、模型架构差异显著）。

Method: 提出DistilTS蒸馏框架：1）设计horizon-weighted objectives，缓解短时与长时预测监督强度失衡；2）设计temporal alignment strategy，缓解师生模型在时间建模上的架构差异。

Result: 在多个基准上，蒸馏后的小模型达到与原TSFM相近的预测精度，参数减少至1/150，推理速度提升最高达6000倍。

Conclusion: DistilTS是首个面向TSFMs定制的知识蒸馏框架，兼顾任务特性和架构适配，为高效部署高性能时间序列模型提供了可行路径。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [678] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: 本文提出了一种面向图学习的半监督指令微调方法SIT-Graph，通过迭代式自训练利用未标注节点提升LLM在文本属性图上的节点分类性能，尤其在标签稀缺场景下效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令微调的图学习方法依赖大量人工标注的（指令，输出）对，在社交领域获取敏感或动态内容的专家标签成本高、周期长；同时，标准方法未能有效利用蕴含结构相关性的大量未标注节点。

Method: 提出模型无关的SIT-Graph半监督指令微调框架，采用迭代自训练：先用标注节点构造指令对进行初始微调；再对未标注节点生成置信度过滤的伪响应以扩充数据集；持续迭代使LLM逐步对齐节点间潜在关联。

Result: 在多个文本属性图基准上，SIT-Graph集成至先进图指令微调方法后，在低标签比例设置下性能提升超20%。

Conclusion: SIT-Graph有效缓解了图学习中标注数据稀缺问题，提升了LLM对图结构语义的理解与泛化能力，为半监督图学习提供了新范式。

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [679] [Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning](https://arxiv.org/abs/2601.12816)
*Ishir Garg,Neel Kolhe,Andy Peng,Rohan Gopalam*

Main category: cs.LG

TL;DR: 本文提出了一种名为Fisher-Orthogonal Projected Natural Gradient Descent（FOPNG）的优化器，用于解决持续学习中灾难性遗忘问题，通过在Fisher信息几何框架下将梯度投影到先前任务梯度的Fisher正交补空间，实现新旧任务性能的兼顾。


<details>
  <summary>Details</summary>
Motivation: 持续学习中神经网络在学习新任务时容易灾难性遗忘旧任务知识，需设计能保持旧任务性能的优化方法。

Method: 提出FOPNG优化器，将梯度投影到先前任务梯度的Fisher正交补空间，融合自然梯度下降与正交梯度法，保证更新方向在Fisher度量下下降且重参数化不变。

Result: 在Permuted-MNIST、Split-MNIST、Rotated-MNIST、Split-CIFAR10和Split-CIFAR100等标准持续学习基准上取得优异结果。

Conclusion: FOPNG提供了一种理论严谨、实践高效的方法，在信息几何框架下有效缓解灾难性遗忘，统一了自然梯度与正交梯度思想。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.

</details>


### [680] [Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations](https://arxiv.org/abs/2601.12839)
*Gyuyeon Na,Minjung Park,Soyoun Kim,Jungbin Shin,Sangmi Chai*

Main category: cs.LG

TL;DR: 本文提出RDLI框架，将专家启发式规则作为可微逻辑信号嵌入图神经网络，结合检索增强的上下文模块，显著提升加密网络中稀疏标注下的异常轨迹检测性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 加密网络中异常轨迹检测面临标签极度稀缺和非法行为者自适应规避的挑战，现有GNN难以建模多跳、逻辑驱动的资金洗钱模式（如资金分散、分层），且缺乏监管与宏观环境上下文支持，影响可追溯性与合规性。

Method: 提出关系域逻辑集成（RDLI）框架：1）将专家规则编码为可微、逻辑感知的潜在信号，融入表示学习；2）引入检索增强上下文（RGC）模块，基于监管与宏观经济信息动态调节异常评分；3）在极低标签率（0.01%）下进行端到端训练与评估。

Result: 在0.01%标签率下，RDLI较SOTA GNN基线F1提升28.9%；微专家用户研究表明，其路径级解释在可信度、实用性与清晰度上均显著优于现有方法。

Conclusion: 融合领域逻辑与上下文感知的建模范式，不仅提升了极端稀疏监督下的检测精度，也增强了模型的可解释性与监管合规能力，为去中心化金融风控提供了新范式。

Abstract: Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.

</details>


### [681] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: 本文提出PuckerFlow，一种基于Cremer-Pople空间的流匹配生成模型，用于高效、准确地生成环状分子的合法构象，显著优于现有方法，适用于药物发现和催化等化学领域。


<details>
  <summary>Details</summary>
Motivation: 环状分子在药物发现和催化中具有重要功能，但其构象采样仍具挑战性。

Method: 提出PuckerFlow模型，在Cremer-Pople低维内坐标空间上进行流匹配，直接生成合法闭合环构象。

Result: PuckerFlow在多样性与精度上均表现优异，定量指标全面超越其他构象生成方法。

Conclusion: 该方法实现了环状结构构象的高效可靠生成，为化学与生物学中结构-性质关系建模及性质导向的环设计提供了新途径。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [682] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: 本文提出了一种名为分层归因图分解（HAGD）的框架，通过多分辨率抽象和可微电路搜索，将神经网络计算电路发现的复杂度从指数级降低到多项式级，并在多种大语言模型上验证了其有效性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于指数级搜索复杂性和普遍存在的多义性，从十亿参数语言模型中提取稀疏计算电路仍极具挑战性。

Method: HAGD框架结合跨层转码器实现单义特征提取、图神经网络元学习预测拓扑结构、因果干预协议进行验证，并采用多分辨率抽象层次与可微电路搜索降低复杂度。

Result: 在GPT-2、Llama系列（7B–70B）及Pythia模型上验证，模运算任务中行为保留率达91%±2.3%，子图保持可解释规模；跨架构电路结构相似性平均达67%。

Conclusion: HAGD为大规模模型的可解释性研究提供了初步基础，但也揭示了当前归因方法的重要局限，需进一步突破。

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [683] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: 本文提出AdaNODEs，一种针对时间序列预测任务的源端无关测试时自适应（TTA）方法，利用神经常微分方程（NODEs）建模时序动态，并设计新损失函数，在仅更新少量参数下实现高效、低内存的分布偏移适应，显著优于现有SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法多面向独立同分布数据，缺乏对时间序列特性和预测任务的适配，难以应对时序数据中的分布偏移。

Method: 提出基于神经常微分方程（NODEs）的源端无关TTA框架AdaNODEs，设计专用于预测任务的新型损失函数，并仅更新有限参数以保持时序依赖建模能力与计算效率。

Result: 在单变量和高维时间序列数据上，AdaNODEs相较SOTA基线分别提升5.88%和28.4%，且在高严重度分布偏移下表现稳健。

Conclusion: AdaNODEs有效解决了时间序列预测中的测试时自适应问题，兼顾建模能力、参数效率与鲁棒性，为源端无关TTA在时序领域提供了新范式。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [684] [Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times](https://arxiv.org/abs/2601.12900)
*Eliran Sherzer,Yonit Barron*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经网络的监督学习框架，用于近似非马尔可夫（s,S）库存系统在缺货损失情形下的稳态性能指标，显著减少对昂贵仿真的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统(s,S)库存模型在非马尔可夫情形（如一般需求间隔与提前期分布）下难以解析求解，长期性能评估通常依赖计算成本高的仿真。

Method: 利用仿真生成训练标签，构建以低阶矩为输入的神经网络模型，拟合库存水平稳态分布、期望循环时间、缺货概率等稳态性能指标。

Result: 神经网络能以极小输入（少量低阶矩）实现高精度预测，在广泛参数范围内表现优异，可替代重复仿真；框架易于推广至其他库存模型。

Conclusion: 该数据驱动方法为复杂随机库存系统的快速、高效分析提供了新范式，兼具准确性与可扩展性。

Abstract: The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.
  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.

</details>


### [685] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 本文提出了一个名为BenchTGC的全面基准，用于解决时间图聚类（TGC）任务中现有技术不适用和数据集不适用的两大挑战，包括设计框架改进聚类方法，并构建适配TGC的新数据集。


<details>
  <summary>Details</summary>
Motivation: 时间图聚类（TGC）是一个新兴但受关注较少的任务，其核心在于在时间图中进行节点聚类，并实现时间与空间需求的平衡；然而当前缺乏适用的聚类技术和合适的数据集，阻碍了该任务的发展。

Method: 提出BenchTGC基准，包含BenchTGC Framework（阐明TGC范式并改进现有聚类技术以适配时间图）和BenchTGC Datasets（分析现有数据集问题并构建多个适配TGC的新数据集）。

Result: 通过大量实验验证了BenchTGC的优势，并证明了TGC任务的必要性与重要性；强调现实世界中动态复杂场景是TGC的基础。

Conclusion: BenchTGC为TGC任务提供了系统性解决方案，推动了该方向的研究发展，代码与数据已开源。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [686] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM提出一种云边协同的联邦微调框架，移动端用零阶优化（ZOO）轻量更新，云端用反向传播引导校正，兼顾隐私、效率与精度。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的移动设备上微调大语言模型面临高内存与计算开销挑战，而现有联邦学习方法要么依赖内存密集的反向传播，要么采用收敛慢、精度低的零阶优化（ZOO）。

Method: 提出CooperLLM：移动端执行ZOO本地更新；云端基于公开数据反向传播训练，并注入引导性扰动以校正本地更新；引入流水线调度和自适应压缩以重叠计算与通信、降低内存占用。

Result: 相比SOTA ZOO基线，CooperLLM将设备内存降低达86.4%，收敛速度提升8.8倍，准确率最高提升10个百分点。

Conclusion: CooperLLM在保护用户隐私前提下，显著提升了移动端大模型联邦微调的效率与性能，为边缘智能提供可行路径。

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [687] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 本文提出了一种基于形状空间的红细胞自动分类方法，通过固定参数化和模板对齐策略，在保持高准确率（96.03%）的同时显著降低计算成本，适用于镰状细胞病的辅助诊断。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病全球患病率高，尤其在资源匮乏地区给医疗系统带来沉重负担；自动化识别血液图像中的镰状红细胞可减轻专家工作量、减少量化误差并评估危象严重程度。

Method: 将红细胞建模为平面闭合曲线，引入弹性距离度量；提出两项改进：（1）基于细胞主轴进行固定参数化以计算形状距离；（2）先将每个细胞按该参数化与两个模板对齐，再计算距离；避免传统方法中对所有参数化进行优化的高计算开销。

Result: 在监督分类和无监督聚类任务中均达到96.03%的准确率，计算效率显著高于以往形状空间模型，同时维持或提升精度。

Conclusion: 所提方法在保证高分类精度的前提下大幅降低计算复杂度，适合临床部署，尤其利于资源有限地区的镰状细胞病筛查与管理。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [688] [Online Continual Learning for Time Series: a Natural Score-driven Approach](https://arxiv.org/abs/2601.12931)
*Edoardo Urettini,Daniele Atzeni,Ioanna-Yvonni Tsaknaki,Antonio Carta*

Main category: cs.LG

TL;DR: 本文提出Natural Score-driven Replay (NatSR)方法，将在线持续学习(OCL)与在线时间序列预测(OTSF)结合，通过自然梯度下降和Student's t似然实现鲁棒优化，并在突变点快速适应，性能优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习(OCL)与在线时间序列预测(OTSF)在适应动态环境和保持长期记忆方面具有共性，但二者理论与实践联系尚待加强。

Method: 将神经网络优化重构为参数滤波问题，证明自然梯度下降是信息论最优的得分驱动方法；引入Student's t似然实现有界更新以增强异常值鲁棒性；提出NatSR方法，融合鲁棒优化器、重放缓冲区与动态尺度启发式策略。

Result: NatSR在实证中展现出比更复杂的最先进方法更强的预测性能。

Conclusion: 本文强化了时间序列方法与OCL之间的理论与实践联系，NatSR为OTSF提供了高效、鲁棒且适应性强的新范式。

Abstract: Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.

</details>


### [689] [Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning](https://arxiv.org/abs/2601.12965)
*Doheon Kim*

Main category: cs.LG

TL;DR: 本文理论解释了基于分数的扩散模型在使用乘性噪声条件化时仍能生成高质量样本的现象，尽管其结构限制了对真实分数函数的准确学习。


<details>
  <summary>Details</summary>
Motivation: 解释为何受限结构的神经网络（乘性噪声条件化）在理论上无法完全学习正确分数函数，却在实践中表现良好。

Method: 通过研究相关微分方程的确定性动力学行为，进行理论分析。

Result: 提供了该现象的理论解释，揭示了模型实际运行机制。

Conclusion: 确定性动力学分析表明，即使模型不能精确学习真实分数，其采样路径仍可有效逼近目标分布。

Abstract: Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.

</details>


### [690] [Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients](https://arxiv.org/abs/2601.12971)
*Pancheng Niu,Jun Guo,Qiaolin He,Yongming Chen,Yanchao Shi*

Main category: cs.LG

TL;DR: 本文提出了一种架构-优化协同设计的PINN方法ACR-PINN，通过层动态注意力机制（LDA-PINN）增强表示能力，并引入梯度冲突缓解策略（GC-PINN）改善优化过程，在多个PDE基准问题上显著提升收敛速度与精度。


<details>
  <summary>Details</summary>
Motivation: 标准PINN受限于表示能力不足和多物理约束导致的梯度冲突，影响求解性能。

Method: 提出层动态注意力机制（LDA-PINN）提升网络表示灵活性；将PINN训练建模为多任务学习，设计冲突缓解的梯度更新策略（GC-PINN）；二者融合形成ACR-PINN，保持标准PINN损失形式。

Result: 在Burgers、Helmholtz、Klein-Gordon及驱动腔流等PDE基准问题上，ACR-PINN相比标准PINN实现更快收敛及更低的相对L2和L∞误差。

Conclusion: 架构与优化的协同设计可有效提升PINN求解器的鲁棒性与精度。

Abstract: Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.

</details>


### [691] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: 本文提出PaperCompass框架，通过分离高层规划与细粒度执行，并引入Draft-and-Follow Policy Optimization（DFPO）强化学习方法，提升大语言模型在科学论文阅读与问答任务中的效率与稳定性。


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长，人工阅读难以跟上进展；现有基于大语言模型的自动阅读方法存在提示工程复杂或SFT-RL训练低效、探索冗余的问题。

Method: 提出PaperCompass框架，包含显式规划（draft plan）与精细化执行两阶段；设计DFPO——一种轻量级分层强化学习算法，联合优化规划与最终解；提供理论分析保障其优化稳定性。

Result: 在Paper-QA基准测试中，PaperCompass在不牺牲性能前提下显著提升推理效率，效果媲美更大规模模型。

Conclusion: 分离规划与执行并辅以DFPO训练，可有效缩小大语言模型‘知’与‘行’之间的差距，为科学文献智能处理提供更高效、稳健的新范式。

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [692] [HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads](https://arxiv.org/abs/2601.13013)
*Xiaohui Zhao,Xinjian Zhao,Jiahui Zhang,Guoyu Liu,Houzhi Wang,Shu Wu*

Main category: cs.LG

TL;DR: 本文提出了一种超时序图神经网络（HT-GNN），用于解决新闻流广告中用户生命周期价值（LTV）预测的两大挑战：用户群体间LTV分布差异大、用户行为序列动态多变。该模型融合超图建模人群异质性、自适应加权Transformer建模时序动态，以及任务自适应混合专家结构实现多步长LTV预测，在百度广告数据上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LTV预测对新闻流广告至关重要，但面临两大挑战：一是人口统计学分群导致LTV分布差异大；二是营销策略动态变化导致用户行为序列不规则、演化快。

Method: 提出Hyper-Temporal Graph Neural Network（HT-GNN），包含三个核心模块：(i) 超图监督模块建模用户群体间关系；(ii) 带自适应加权的Transformer时序编码器；(iii) 任务自适应的混合专家结构与动态预测塔，支持多时间步LTV预测。

Result: 在百度广告1500万用户数据上的实验表明，HT-GNN在所有评估指标和预测时长上均持续超越当前最优方法。

Conclusion: HT-GNN有效联合建模了用户群体异质性与时序动态性，为广告平台提供了更精准、鲁棒的长期价值预测能力，助力 bidding 和预算分配优化。

Abstract: Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.

</details>


### [693] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于路径激活子空间（PASs）的MoE-LoRA方法，用于解决多模态大语言模型在持续指令调优中因路由器与专家共漂移导致的遗忘问题，通过PAS引导重加权和PAS感知秩稳定化提升准确率与抗遗忘能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的MoE方法在持续指令调优中存在路由器与专家参数共漂移（Misaligned Co-drift）问题，导致专家职责模糊、灾难性遗忘加剧。

Method: 提出路径激活子空间（PASs）作为LoRA诱导的能力对齐坐标系，并构建固定容量的PASs-MoE-LoRA方法，包含PAS引导重加权（校准路由）和PAS感知秩稳定化（选择性稳定历史任务关键秩方向）两个组件。

Result: 在CIT基准测试中，该方法在准确率和抗遗忘性上持续优于各类传统持续学习基线及MoE-LoRA变体，且不增加参数量。

Conclusion: PASs为持续指令调优中的路由与知识保留提供了可解释、能力对齐的几何视角，所提方法有效缓解了共漂移问题，提升了多模态大语言模型的持续适应能力。

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [694] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 本文提出了一种基于集成学习的新型分类方法，用于利用外周血涂片图像辅助镰状细胞病（SCD）诊断，重点提升模型泛化能力与可解释性，并在新数据集上超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 为提高镰状细胞病（SCD）诊断支持系统的泛化能力与临床可解释性，需克服现有模型在特征选择、模型可解释性及跨数据集性能方面的局限。

Method: 对红细胞显微图像进行预处理与分割；提取形态学特征；采用随机森林与Extra Trees等集成学习方法构建分类器；设计关键特征筛选策略以降低复杂度并增强可解释性；结合F1-score与自定义SDS-score评估性能。

Result: 集成随机森林与Extra Trees的分类器在新数据集上达到F1-score 90.71%、SDS-score 93.33%，优于梯度提升（F1 87.32%，SDS 89.51%）；公开了模型参数、代码库与混淆矩阵原始数据。

Conclusion: 所提集成方法结合关键特征筛选，在SCD诊断支持任务中显著提升了泛化性、准确性和可解释性，具备临床转化潜力，并推动该领域开源与可复现研究。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [695] [Analysis of Long Range Dependency Understanding in State Space Models](https://arxiv.org/abs/2601.13048)
*Srividya Ravikumar,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.LG

TL;DR: 本文首次系统研究了对角化状态空间模型（S4D）在真实漏洞检测任务中的核函数可解释性，通过时频域分析揭示其核函数滤波特性（低通/带通/高通）随架构变化，并影响长程建模能力与性能。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型（SSMs）研究多聚焦预测精度，缺乏对其可解释性的系统分析，尤其在真实任务中。

Method: 对在源代码漏洞检测任务上训练的S4D模型进行时域和频域的核函数分析，探究其滤波特性与架构的关系。

Result: 发现S4D核函数的长程建模能力因模型架构不同而显著变化，可表现为低通、带通或高通滤波器，且该特性直接影响模型性能。

Conclusion: S4D核函数的滤波特性和架构设计密切相关，该发现为未来设计更优的S4D模型提供了可解释性指导。

Abstract: Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.

</details>


### [696] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

TL;DR: 本文提出了一种面向小农户的边缘优先IoT框架，结合TinyML实现离线精准灌溉，采用四层架构与低成本硬件（ESP32+Raspberry Pi），通过多传感器融合与优化梯度提升模型（R²=0.9973, MAPE=0.99%）实现在端侧高精度灌溉决策，显著节水且无需云连接，适用于无网/低资源农村环境。


<details>
  <summary>Details</summary>
Motivation: 小规模农户面临水资源短缺、气候异常及缺乏低成本先进农业技术等多重挑战，亟需离线、低功耗、高性价比的智能灌溉解决方案。

Method: 构建四层边缘优先IoT架构：感知层（电容式土壤湿度、温湿度、pH、光照传感器）、边缘推理层（ESP32运行TinyML模型）、本地边缘服务器层（Raspberry Pi）、局域通信层（MQTT LAN）；采用梯度提升算法建模并量化部署至ESP32。

Result: 梯度提升模型在测试中达R²=0.9973、MAPE=0.99%，部署后端侧MAPE<1%；实验表明相较传统灌溉显著节水，系统支持完全离线、低功耗运行。

Conclusion: 该框架为资源受限农村地区提供了可扩展、可持续、低成本的AI驱动灌溉范式，有效弥合农业技术鸿沟并提升用水效率。

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [697] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: 本文提出METIS，一种工具增强、阶段感知的AI研究导师，旨在帮助本科生从想法到完成论文。通过多维度评估，METIS在多数指标上优于GPT-5和Claude Sonnet 4.5，尤其在文献依赖性强的写作后期阶段表现更优，但也存在工具调用过早、 grounding 浅层及阶段误判等问题。


<details>
  <summary>Details</summary>
Motivation: 许多本科生缺乏专家级科研指导，亟需可扩展、高质量的AI导师支持其完成学术写作全过程。

Method: 构建METIS系统，整合文献检索、结构化指南、方法论检查与记忆机制，并采用LLM-as-a-judge、学生角色评分、多轮短 tutoring 及证据/合规性检查进行跨阶段（共六阶段）评估。

Result: 在90个单轮提示中，LLM裁判偏好METIS高于Claude Sonnet 4.5（71%）和GPT-5（54%）；学生评分（清晰度/可操作性/约束适配性）各阶段均更高；多轮实验中METIS最终质量略优于GPT-5；优势集中于文档依赖型阶段（D-F），失败模式包括过早调用工具、浅层grounding和阶段误分类。

Conclusion: METIS验证了阶段感知与工具增强设计对提升AI科研指导能力的有效性，尤其适用于结构化、文献驱动的学术写作任务，但需进一步优化工具调度策略与阶段识别鲁棒性。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [698] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 本文提出了一种基于公理化和算子理论的递归元蒸馏框架，将迭代知识蒸馏形式化为一系列概率分布算子，并证明在温和假设下其KL散度收缩与几何收敛性，为多代蒸馏提供了数学基础。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要集中在单阶段概率域知识蒸馏的公理化，而对递归或多代蒸馏的数学行为缺乏理解，依赖经验启发式方法。

Method: 引入公理化与算子理论框架，将递归知识蒸馏建模为锚定于基础教师的概率分布算子序列；定义元教师构造的结构公理，并在可实现性与凸性假设下证明KL散度收缩与几何收敛性。

Result: 证明了满足公理的非平凡算子族存在性；在温和假设下，锚定递归蒸馏导致KL散度收缩，实现对基础教师分布的几何收敛及唯一全局吸引不动点。

Conclusion: 该框架奠定了递归蒸馏的数学良定性与收敛性基础，不依赖模型结构、优化细节或具体算子实现，为理解迭代蒸馏的稳定性、偏差-方差权衡与失效模式提供理论支撑。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [699] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个专为音视频大语言模型（AV-LLMs）设计的token剪枝框架，通过两阶段基于注意力权重的剪枝策略，在大幅降低计算量的同时保持甚至提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 音视频大语言模型（AV-LLMs）因多模态融合导致token数量激增，而现有token剪枝方法在该领域研究不足。

Method: 提出一种基于注意力权重评估token重要性的剪枝策略，包含中间层的全局剪枝和后层的细粒度剪枝，并避免依赖完整注意力图以兼容FlashAttention等高效注意力机制。

Result: 在两个代表性AV-LLMs上实现超40%的FLOPs降低，同时保持或提升模型性能。

Conclusion: FastAV为AV-LLMs提供了高效、兼容性强且性能无损（甚至增益）的token剪枝新范式。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [700] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 本文提出了一种统一的动力学视角来刻画深度学习训练稳定性，并通过受控扰动审计方法，在强化学习和大语言模型训练中发现了三个规律：高最终性能常与训练稳定性解耦；受控随机性普遍增强鲁棒性；低维潜在元状态的偏差常先于性能崩溃发生。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统训练过程的稳定性缺乏深入理解，小扰动可能导致不可逆崩溃，影响可复现性和可扩展性。

Method: 提出四维动力学稳定性框架（优化、环境/数据、参数、学习信号），并通过受控扰动审计训练轨迹来评估稳定性，不修改原有算法。

Result: 在RL和LLM训练中发现：1）高最终性能与训练稳定性常无强关联；2）受控随机性可跨范式提升稳定性；3）低维潜在元状态偏差是性能崩溃的前置信号。

Conclusion: 训练稳定性是一种可测量、可比较的学习系统内在动力学属性，为超越最终性能的学习动态研究提供了描述性基础。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [701] [NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness](https://arxiv.org/abs/2601.13162)
*Ali Shafiee Sarvestani,Jason Schmidt,Arman Roohi*

Main category: cs.LG

TL;DR: 本文提出了一种名为\DesignII的神经符号框架，通过将领域知识（如形状、颜色等外观属性）编码为逻辑约束，并在训练中引入语义和符号逻辑损失，显著提升了模型对FGSM和PGD攻击的鲁棒性及可解释性，在GTSRB数据集上优于标准对抗训练和部分Transformer-based防御方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络存在对抗脆弱性和缺乏可解释性的问题，尤其在自动驾驶等安全敏感场景中亟需解决。

Method: 提出神经符号框架\DesignII，将领域知识表示为逻辑约束，通过语义损失和符号逻辑损失在训练中进行监督。

Result: 在GTSRB数据集上，FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic模型分别比对应的标准对抗训练基线提升18.1%和17.35%的对抗准确率，且不牺牲干净样本准确率；相比LNL-MoEx等Transformer方法，仅用ResNet18和10轮训练即达到相当或更优鲁棒性。

Conclusion: 符号推理是构建鲁棒且可解释AI的一条有效路径。

Abstract: Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.

</details>


### [702] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: 本文提出LAViG-FLOW，一种基于潜在空间自回归视频生成扩散模型，用于高效建模和预测地下多相流体的饱和度与压力场演化，在保证时序一致性的同时显著加速模拟。


<details>
  <summary>Details</summary>
Motivation: 高精度多相流数值模拟在地质CO2封存、地热开发等应用中至关重要，但其计算成本高昂，难以支撑反演和不确定性量化所需的大量正向模拟。

Method: 提出LAViG-FLOW框架：采用两个专用2D自编码器分别压缩饱和度和压力场；用Video Diffusion Transformer（VDiT）建模二者在时间维度上的耦合分布；先在给定时间窗口内训练，再进行自回归微调以实现外推预测。

Result: 在开源CO2封存数据集上验证，LAViG-FLOW生成的饱和度与压力场具有良好的时序一致性，且推理速度比传统数值求解器快数个数量级。

Conclusion: LAViG-FLOW为地下多相流建模提供了一种高效、可扩展的生成式替代方案，兼顾物理一致性与计算效率，适用于实时决策与不确定性分析。

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [703] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 本文对大语言模型（LLM）的多种推理范式（如直接生成、思维链CoT、多智能体系统MAS）进行了统一评估，分析其在闭式基准上的性能、角色能力需求及成本-精度权衡，并提出新开放基准MIMeBench以评估语义抽象与对比判别能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对不同LLM推理范式（如CoT、MAS）的相对有效性及成本-精度权衡缺乏系统性、统一的评估；同时，主流闭式基准难以衡量关键语义能力，亟需新评估维度。

Method: 开展跨范式的统一基准评测（涵盖直接生成、CoT、多种MAS流程），结合角色隔离分析揭示MAS中各角色能力需求，量化成本-精度曲线，并构建新开放基准MIMeBench，聚焦语义抽象与对比判别两类能力。

Result: 推理性能不随结构复杂度单调提升，其增益高度依赖范式本身适配性；部分MAS流程存在显著冗余开销；MIMeBench可有效揭示模型在语义抽象与对比判别上的细粒度差异。

Conclusion: 应避免盲目追求复杂推理结构，需依据任务特性选择适配范式；MIMeBench为评估LLM深层语义能力提供了新标准；开源代码与基准推动可复现、多维的推理系统评估。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [704] [Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks](https://arxiv.org/abs/2601.13244)
*Prateek Munjal,Clement Christophe,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.LG

TL;DR: 本文研究了指令微调对大语言模型推理能力的影响，发现其提升效果不稳定且依赖特定提示模式，而非真正增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 探究指令微调是否真正提升了大语言模型的推理能力，还是仅导致表面模式匹配。

Method: 在标准数学基准（如GSM8K）、结构扰动变体和领域迁移任务（如MedCalc）上对比评估基础模型与指令微调模型的表现。

Result: 指令微调模型在零样本思维链设置下显著弱于基础模型（如Llama3-70B下降32.67%），仅在少样本提示下才表现相当；在领域迁移和扰动数据上性能急剧下降，显示其对提示结构敏感、泛化能力差。

Conclusion: 指令微调带来的性能增益不稳定、易受评估设置和分布偏移影响，不能可靠提升模型内在推理能力，而更可能强化对特定提示格式的匹配。

Abstract: Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.

</details>


### [705] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 本文提出了一种用于蒙特卡洛Dropout不确定性量化的多级蒙特卡洛（MLMC）框架，通过在不同置信度层级间重用Dropout掩码来降低方差，同时保持无偏性，并在PINN-Uzawa基准测试中验证了其效率提升。


<details>
  <summary>Details</summary>
Motivation: 利用Dropout掩码作为认知随机性的来源，构建一个基于前向传播次数的保真度层次结构，以更高效地进行不确定性量化。

Method: 定义基于Dropout前向传播次数的保真度层级，构造跨层级重用Dropout掩码的耦合粗-细估计器，构建用于预测均值和方差的望远镜式MLMC估计器，并推导偏差、方差与有效成本表达式及跨层级样本分配规则。

Result: 理论推导出偏差、方差与有效成本表达式；数值实验在PINNs-Uzawa正向与反向问题上验证了预测的方差衰减速率，并证实相比单层MC-Dropout，在相同计算成本下具有更高效率。

Conclusion: 所提出的MLMC框架在保持对Dropout诱导量无偏估计的同时，显著降低了采样方差，为基于Dropout的深度学习不确定性量化提供了更高效的工具。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [706] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 本文系统研究了大语言模型在监督微调（SFT）和基于可验证奖励的强化学习（RLVR）两种微调范式下的置信度校准问题，发现RLVR虽提升任务性能却严重过自信，而SFT校准更好但性能增益较小；作者诊断出RLVR失败源于决策token不承载置信信息，并提出一种校准感知的强化学习方法，在保持准确率的同时显著缓解过自信问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在决策任务中需兼具高准确率与可靠置信度估计，以支持可信部署与动态fallback机制，但现有微调方法对校准的影响尚缺乏系统分析。

Method: 通过对比SFT与RLVR在多种分布偏移场景下的校准表现，开展消融实验诊断RLVR校准失败根源；进而提出校准感知的强化学习方法，直接调整决策token的概率分布。

Result: RLVR显著提升性能但严重过自信，SFT校准更优但性能增益小；所提新方法在维持RLVR准确率前提下将ECE降低最多9分。

Conclusion: 决策token在推理链中仅起提取作用、不编码置信信息，是RLVR校准失败的关键原因；校准需在强化学习目标中显式建模，而非依赖隐式学习。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [707] [Verifying Local Robustness of Pruned Safety-Critical Networks](https://arxiv.org/abs/2601.13303)
*Minh Le,Phuong Cao*

Main category: cs.LG

TL;DR: 本文研究了剪枝对深度神经网络形式化局部鲁棒性验证的影响，发现轻度剪枝（MNIST上40%）和重度剪枝（JPL数据集上70%-90%）反而能提升可验证性，表明剪枝比例需依数据集而定。


<details>
  <summary>Details</summary>
Motivation: 大型DNN的形式化验证计算开销大，阻碍其在手术机器人、NASA自主系统等安全关键场景中的实际应用。

Method: 使用最先进的α,β-CROWN验证器，在MNIST和NASA JPL火星霜冻识别数据集上，对ResNet4模型施加不同剪枝比例，评估其形式化L∞局部鲁棒性证书。

Result: 发现剪枝与可验证性呈非线性关系：MNIST上40%剪枝、JPL数据集上70%-90%剪枝均能超越未剪枝基线的已证明鲁棒性；剪枝降低了验证求解器的搜索空间复杂度。

Conclusion: 最优剪枝比例高度依赖数据集；模型压缩不能一概而论，需权衡效率与形式化可验证性，以支撑高风险场景下可靠DNN部署。

Abstract: Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.

</details>


### [708] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 本文提出了一种基于谱嵌入和光滑传输计划解释为二分图邻接矩阵的新方法，用于无监督域自适应，以解决训练与推理数据分布偏移问题，并在多个声学与工业诊断任务中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 分布偏移导致模型在推理时性能下降，现有基于最优传输的无监督域自适应方法对正则化策略和超参数敏感，可能造成有偏的域对齐。

Method: 将平滑化的传输计划视为连接源域与目标域的二分图邻接矩阵，并通过谱嵌入提取域不变样本表示。

Result: 在音乐流派识别、音乐-语音判别、以及基于时域反射的电缆缺陷检测与分类等多个基准任务上取得整体优异性能。

Conclusion: 所提方法提供了一种更鲁棒、几何驱动的域对齐方式，避免了传统最优传输方法对超参数的强依赖，提升了域自适应的泛化能力。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [709] [On the Relation of State Space Models and Hidden Markov Models](https://arxiv.org/abs/2601.13357)
*Aydin Ghojogh,M. Hadi Sepanj,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文系统比较了隐马尔可夫模型（HMM）、线性高斯状态空间模型（SSM）、卡尔曼滤波及现代NLP中的状态空间模型（如S4、Mamba），从概率图模型视角统一分析其建模形式、推理算法（前向-后向、卡尔曼滤波）与学习方法（EM vs 梯度优化），厘清了它们的等价性、差异性及理论联系。


<details>
  <summary>Details</summary>
Motivation: 尽管HMM和SSM在时序建模中结构相似，但其潜变量性质、概率假设、推理与训练范式存在根本差异；而S4、Mamba等新兴确定性SSM在NLP中复兴，亟需厘清其与经典概率模型的关系。

Method: 采用概率图模型框架，对HMM、线性高斯SSM、卡尔曼滤波及现代NLP SSM进行形式化建模与对比分析，系统梳理其推理算法（前向-后向、卡尔曼滤波）和学习方法（EM、梯度优化）。

Result: 明确了各类模型在结构上的相似性与语义上的本质差异，指出特定条件下部分模型的等价性，并揭示了现代NLP SSM与经典概率SSM及HMM之间的理论关联与偏离。

Conclusion: 该统一分析弥合了控制理论、概率建模与深度学习三大学科视角，为理解现代序列建模方法的理论根基提供了清晰框架，并有助于指导未来模型设计与跨领域迁移。

Abstract: State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.
  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.

</details>


### [710] [CausationEntropy: Pythonic Optimal Causation Entropy](https://arxiv.org/abs/2601.13365)
*Kevin Slote,Jeremie Fish,Erik Bollt*

Main category: cs.LG

TL;DR: 本文介绍了CausationEntropy Python包1.1版本，该包实现了最优因果熵（oCSE）方法及其多种优化与扩展，用于从动力学系统和耦合振荡器中发现因果网络，并支持多种信息论估计器。


<details>
  <summary>Details</summary>
Motivation: 为提供一个鲁棒、易用且可扩展的因果网络建模工具，以支持复杂动力学系统中的因果发现研究。

Method: 实现并优化最优因果熵（oCSE）算法，集成多种熵估计方法（如高斯、kNN、几何kNN、核密度、泊松估计器），新增合成数据生成器与可视化工具。

Result: 发布CausationEntropy 1.1，具备模块化结构、完整文档、丰富示例、MIT开源许可，支持PyPI安装及GitHub托管。

Conclusion: CausationEntropy将成为复杂动力学系统因果发现的基准工具，推动相关方法研究与应用。

Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.

</details>


### [711] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: 本文提出了RoundTripCodeEval (RTCE)基准，用于评估大语言模型在代码执行中的往返一致性，发现当前模型在保持编码与解码间一一映射方面仍存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有LLM虽在代码基准上表现良好，但在往返代码执行中暴露出推理不一致的问题，缺乏对模型内部推理一致性的系统性评估手段。

Method: 构建了包含四个代码执行推理任务的RTCE基准，采用无执行、精确匹配方式评估双向映射保真度，并通过零样本提示、监督微调执行轨迹和自省机制对主流Code-LLM进行系统评测。

Result: 各类改进方法仅带来有限提升，均未能弥补往返一致性差距；RTCE揭示了现有I/O预测、执行推理及自然语言往返基准未覆盖的新问题。

Conclusion: 当前Code-LLM缺乏维持真正往返一致性的能力，反映出其在可信代码推理所需内部连贯性上的根本不足。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [712] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: 本文提出TrustEnergy框架，用于准确且可靠的用户级能源使用预测，通过分层时空表示模块捕捉宏观和微观能源使用模式，并通过顺序共形分位数回归模块动态调整不确定性边界，实验证明其在预测精度和不确定性量化方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在能源使用预测中忽略了家庭间的空间相关性，难以扩展到个性化预测，且未充分探索不确定性量化。

Method: 提出TrustEnergy统一框架，包括：(i) 分层时空表示模块，采用新型记忆增强时空图神经网络；(ii) 顺序共形分位数回归模块，动态调整不确定性边界。

Result: 在佛罗里达电力供应商数据上实验表明，TrustEnergy相比最先进基线方法，预测精度提升5.4%，不确定性量化提升5.7%。

Conclusion: TrustEnergy框架能有效实现高精度、高可靠性的用户级能源使用预测，兼顾时空建模与不确定性量化。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [713] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: 本文提出WaveLSFormer，一种可学习的小波长短期Transformer模型，用于从金融时间序列中学习盈利的日内交易策略。该模型结合多尺度分解与收益导向决策学习，并通过频谱正则化、低频引导高频注入（LGHI）模块及风险预算约束优化交易策略，在多个行业数据上显著提升累计收益和夏普比率。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列具有强噪声、非平稳性和资产间强横截面依赖性，使得学习盈利的日内交易策略极具挑战性。

Method: 提出WaveLSFormer模型：1）可学习小波前端，通过端到端训练的滤波器组生成高低频分量，并引入谱正则化保证频带稳定分离；2）低频引导高频注入（LGHI）模块融合多尺度信息；3）输出满足固定风险预算的多空组合，并以交易目标函数和风险感知正则项直接优化。

Result: 在六年小时级六行业数据、十次随机种子实验中，WaveLSFormer在所有行业中平均实现累计策略收益0.607±0.045、夏普比率2.157±0.166，显著优于MLP、LSTM、Transformer及其结合固定小波前端的变体。

Conclusion: WaveLSFormer通过可学习多尺度表征与风险感知端到端优化，有效提升了金融时序交易策略的盈利性与风险调整后收益，验证了联合建模频率特性与决策过程的有效性。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [714] [BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions](https://arxiv.org/abs/2601.13445)
*Ashish S. Nair,Sandipp Krishnan Ravi,Itzel Salgado,Changjie Sun,Sayan Ghosh,Liping Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于DeepSDF的领域专用隐式生成框架，用于涡轮叶片几何建模，结合连续符号距离函数、可解释的近高斯隐空间及性能导向的神经映射，实现高保真、可制造、性能感知的3D叶片生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有涡轮叶片生成方法在性能感知建模和可制造性设计方面的关键缺陷，弥补传统2D引导或无约束3D流程的不足。

Method: 采用DeepSDF构建连续符号距离函数（SDF）表征；学习具有叶片物理参数（如锥度比、弦长比）对齐的近高斯可解释隐空间；通过小型神经网络将工程指标（如最大方向应变）映射到隐码，支持性能驱动的生成与插值/高斯采样合成。

Result: 表面距离误差控制在最大叶片尺寸的1%以内，重建保真度高，对未见设计泛化能力强；隐空间可解释且支持可控探索与无条件合成。

Conclusion: 该框架将性能约束、设计目标与制造可行性统一于数据驱动的3D隐式建模中，为涡轮叶片的概念设计与建模提供了实用、可解释的新范式。

Abstract: Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.

</details>


### [715] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: 本文提出BADR框架，通过双层自适应重标度法恢复任意公平性度量下的最优Pareto有效模型，并提供两种大规模单循环算法及开源工具包。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法常产生Pareto低效模型；而现有Pareto高效方法又局限于特定公平视角，难以适配多样化的公平性度量。

Method: 提出BADR框架，采用双层优化：下层为组加权的经验风险最小化，上层优化选定的公平性目标；并设计BADR-GD和BADR-SGD两种单循环算法。

Result: 理论证明了算法收敛性；实验表明BADR在多种任务和公平性度量下优于现有Pareto高效方法；并发布开源Python工具包badr。

Conclusion: BADR是一种通用、高效且可扩展的框架，能灵活适配各类公平性度量并生成Pareto最优模型。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [716] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 本文提出了一种客户端经验回放方法，通过在每个客户端维护少量历史样本缓冲区来缓解联邦学习中的时间概念漂移问题，显著防止了灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在面对随时间变化的客户端数据分布（即时间概念漂移）时表现不佳，标准FedAvg算法会出现严重的灾难性遗忘现象。

Method: 在客户端本地训练过程中引入经验回放机制，即每个客户端维护一个小型历史样本缓冲区（如每类50个样本），并将缓冲区样本与当前批次数据混合训练；服务器端无需修改聚合策略。

Result: 在Fashion-MNIST季节性漂移场景下，该方法将准确率从28%恢复至78–82%，显著优于原始FedAvg；消融实验揭示了缓冲区大小与模型精度之间存在明确的权衡关系。

Conclusion: 客户端经验回放是一种简单、有效且无需服务端改动的解决方案，可有效缓解联邦学习中的时间概念漂移导致的灾难性遗忘问题。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [717] [Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics](https://arxiv.org/abs/2601.13463)
*Brandon B. Le,D. Keller*

Main category: cs.LG

TL;DR: 本文提出了一种基于数据内在特性的量子-经典模型选择框架，通过定量‘量子标识符’指导在强子物理中选用量子或经典深度神经网络，并在康普顿形式因子提取任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着量子机器学习架构的发展，核心挑战已从构建模型转向识别其相比经典方法具有实际优势的具体场景，尤其在数据驱动的强子物理问题中。

Method: 开发以定量‘量子标识符’为核心的诊断工具，结合受控的分类与回归研究，分析模型性能随数据复杂度、噪声和维度变化的系统性规律，并提炼出可预测的判据。

Result: 发现模型相对性能遵循复杂度、噪声和维度的系统性趋势；在深虚康普顿散射中提取康普顿形式因子的应用表明，该量子标识符能有效识别适合量子模型的运动学区域。

Conclusion: 建立了在高精度强子物理中部署量子机器学习工具的原理性框架。

Abstract: As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.

</details>


### [718] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 本文研究了Muon优化器的简化变体在矩阵分解和线性Transformer上下文学习中的有效性，证明其具有与条件数无关的线性收敛性，并揭示了谱正交化带来的预处理效应。


<details>
  <summary>Details</summary>
Motivation: Muon优化器虽在大语言模型预训练中表现优异，但其核心机制——尤其是梯度正交化的作用——仍缺乏严谨、端到端的理论解释。

Method: 通过两个具体案例（矩阵分解与线性Transformer的上下文学习），对简化版Muon进行理论分析，证明其线性收敛性及优于梯度下降和Adam的迭代复杂度，并在谱域中揭示其动力学解耦特性。

Result: 简化Muon在两类问题中均实现与条件数无关的线性收敛；其动力学在谱域中解耦为多个独立标量序列；谱正交化被形式化为一种有效预处理机制。

Conclusion: 本工作为Muon优化器提供了首个针对具体应用的严格收敛性保证，阐明了梯度谱正交化的关键作用，为理解其在更广泛矩阵优化问题中的优势奠定理论基础。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [719] [A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model](https://arxiv.org/abs/2601.13476)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为PRAIM的新型概率变分插补框架，利用大语言模型和检索增强记忆，对电动汽车充电数据中的缺失值进行高效、准确的插补，显著提升下游预测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的电动汽车（EV）充电数据常存在大量缺失记录，而现有插补方法难以应对充电数据的复杂多模态特性，且多采用‘一站一模型’的局限范式，忽略了站点间的相关性。

Method: 提出PRAIM框架：使用预训练语言模型统一编码时间序列需求、日历特征与地理空间上下文等异构数据；结合检索增强记忆机制，从全网充电站中动态检索相似样本；采用变分神经架构实现单一大规模统一插补模型。

Result: 在四个公开数据集上的实验表明，PRAIM在插补精度和统计分布保真度上均显著优于现有基线方法，并大幅提升下游充电需求预测性能。

Conclusion: PRAIM通过融合大语言模型表征能力与检索增强记忆机制，有效克服了EV充电数据稀疏性与多模态建模难题，为数据驱动的智能充电基础设施提供了更可靠的数据基础。

Abstract: The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.

</details>


### [720] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 本文提出了一种针对低Tucker秩张量感知的随机交替最小化算法，直接在Tucker分解的核心张量和因子矩阵上操作，避免了昂贵的张量投影，支持高效的批量更新，并在合成数据实验中展现出优越的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有低秩张量恢复方法存在计算开销大（如全张量投影）或受限于分解场景（如多数随机因子化方法），缺乏适用于张量感知任务的高效随机优化方案。

Method: 提出基于Tucker分解的随机交替最小化算法，直接优化核心张量与因子矩阵，采用mini-batch梯度更新，避免全张量投影和全梯度计算。

Result: 在合成张量感知任务中，该算法在实际运行时间（wall-clock time）上的收敛性能优于代表性随机张量恢复基线方法。

Conclusion: 所提算法为低Tucker秩张量感知提供了一种高效、可扩展的随机优化新范式，兼顾计算效率与模型表达能力。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [721] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: 本文提出MN-TSG框架，结合混合专家（MoE）与神经控制微分方程（NCDEs），解决不规则采样时间序列的连续生成问题，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法多假设规则采样和固定分辨率，难以适配临床监测等真实场景中不规则、稀疏采样的数据需求。

Method: 提出MN-TSG框架：1）构建动态参数化专家函数的MoE-NCDE架构；2）采用解耦设计提升MoE动力学优化效果；3）联合建模专家混合分布与生成时间序列的联合分布。

Result: 在10个公开及合成数据集上，MN-TSG在不规则到规则、不规则到连续生成任务中均持续超越强基线方法。

Conclusion: MN-TSG有效提升了不规则时间序列的连续生成能力，通过MoE与NCDE的协同建模，兼顾动态建模精度与生成灵活性。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [722] [Patterning: The Dual of Interpretability](https://arxiv.org/abs/2601.13548)
*George Wang,Daniel Murfet*

Main category: cs.LG

TL;DR: 本文提出了'patterning'方法，即通过反向工程训练数据来引导神经网络学习特定的泛化形式，利用敏感性分析（susceptibilities）来确定如何调整训练数据分布以实现目标内部结构。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络如何泛化到训练数据之外是机制可解释性的核心问题；本文提出其对偶问题——'patterning'：给定期望的泛化形式，如何设计训练数据来实现它。

Method: 基于敏感性（susceptibilities）——即后验期望值对数据分布微小扰动的线性响应——构建数据干预策略，并逆向求解以得到能引导模型达到目标内部配置的数据重加权方案。

Result: 在小型语言模型中验证了该方法可加速或延迟‘归纳电路’等结构的形成；在括号匹配合成任务中，成功通过调控局部学习系数选择模型所学的具体算法。

Conclusion: 读取（interpretability）与写入（patterning）神经网络内部结构可共享同一数学框架，表明我们不仅能理解模型，还能主动塑造其学习行为。

Abstract: Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.

</details>


### [723] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE 提出一种几何参数化方法，通过共享三元原型和学习旋转来表示多个专家，实现内存亚线性增长，在大幅压缩模型内存的同时几乎不损失精度。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型中专家权重矩阵独立存储导致内存随专家数线性增长，难以部署到边缘设备；传统压缩方法无法解决该线性扩展瓶颈。

Method: 将各专家视为对一个共享的量化基底（三元原型）施加不同可学习旋转后的几何重定向结果，而非独立权重矩阵；联合训练旋转与低比特量化以抑制激活异常值、稳定极低比特训练。

Result: 在语言建模任务上，256专家时实现150倍内存压缩且精度几乎无损；64个专家可部署于4GB设备，而标准MoE仅支持8个。

Conclusion: 几何参数化（旋转+共享量化基底）可突破MoE内存线性增长限制，为边缘端大规模稀疏模型提供可行路径。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [724] [Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework](https://arxiv.org/abs/2601.13564)
*Yanheng Li,Zhichen Pu,Lijiang Yang,Zehao Zhou,Yi Qin Gao*

Main category: cs.LG

TL;DR: LUMOS是一个数据与物理双驱动的荧光分子逆向设计框架，结合生成器、多精度预测器和属性引导的扩散模型与多目标进化算法，高效、准确且可靠地实现多目标荧光分子设计。


<details>
  <summary>Details</summary>
Motivation: 传统荧光小分子设计方法在面对庞大化学空间和多重约束时效率低、泛化性差、量子计算成本高。

Method: LUMOS融合生成器与预测器于共享潜在空间；集成神经网络与快速TD-DFT构建多精度互补预测器；采用属性引导的扩散模型联合多目标进化算法进行分子优化。

Result: 在基准测试中，LUMOS在预测准确性、泛化性和物理合理性上均优于基线模型，并在骨架级与片段级多目标优化中表现更优；TD-DFT与MD验证表明其能生成满足多种目标的合理荧光分子。

Conclusion: LUMOS是一种通用、高效、可靠的数据-物理双驱动荧光分子逆向设计新范式。

Abstract: Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.

</details>


### [725] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 本文提出了一种统一框架——一致性优化（coherence optimization），解释了无需外部监督的语言模型自我提升方法（如辩论、自举、内部一致性最大化）为何有效，并从理论和实验上证明其等价于描述长度正则化，且在半监督学习中是最优的。


<details>
  <summary>Details</summary>
Motivation: 现有无需外部监督的语言模型自我提升方法（如debate、bootstrap、internal coherence maximization）虽表现出色，但其理论基础尚不清晰，亟需统一解释。

Method: 将多种反馈-free自我改进方法统一建模为‘一致性优化’：即寻找最可压缩且联合可预测的上下文到行为映射；并从信息论角度证明其等价于描述长度正则化，且在预训练模型导出的正则器下对半监督学习最优。

Result: 理论证明一致性优化等价于描述长度正则化，并在半监督设定下被证明是最优正则策略；初步实验支持该理论，能解释自我提升成功/失败的条件。

Conclusion: 无需外部监督的自我提升本质上是通过一致性优化实现的隐式正则化，该框架不仅统一解释了多种现象，还为设计更鲁棒的自我改进方法提供了理论指导。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [726] [DRGW: Learning Disentangled Representations for Robust Graph Watermarking](https://arxiv.org/abs/2601.13569)
*Jiasen Li,Yanwei Liu,Zhuoyi Shang,Xiaoyan Gu,Weiping Wang*

Main category: cs.LG

TL;DR: 本文提出DRGW，首个通过解耦表示学习解决图水印中透明性和鲁棒性问题的框架，包含对抗编码器、图感知可逆神经网络和结构感知编辑器。


<details>
  <summary>Details</summary>
Motivation: 现有图水印方法在图结构或纠缠表示上操作，导致水印透明性和鲁棒性受限，主要因图表示中信息耦合及连续表示离散化不可控。

Method: 提出DRGW框架：1）对抗训练编码器学习对扰动不变的结构表示并生成统计独立的水印载体；2）图感知可逆神经网络实现水印无损嵌入与提取；3）结构感知编辑器将潜在修改转化为离散图编辑。

Result: 在多个基准数据集上的实验表明DRGW在有效性上优于现有方法。

Conclusion: DRGW首次通过解耦表示学习提升图水印的透明性与鲁棒性，为图数据知识产权保护提供了新思路。

Abstract: Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.

</details>


### [727] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

TL;DR: 本文提出了GeoDynamics，一种在对称正定（SPD）流形上直接建模脑功能连接动态变化的几何状态空间神经网络，用于揭示任务驱动的脑状态变化及神经退行性疾病的早期标志。


<details>
  <summary>Details</summary>
Motivation: 现有脑动力学建模方法多将大脑视为松散连接的区域或施加简化的网络先验，未能体现其作为整体自组织动力系统的本质；同时，脑功能连接（FC）矩阵天然位于SPD黎曼流形上，而传统方法忽略其几何结构。

Method: 提出GeoDynamics模型，将每个FC矩阵嵌入流形感知的循环框架中，在SPD流形上学习平滑且几何一致的状态转移。

Result: 成功揭示任务相关的脑状态变化，并识别出阿尔茨海默病、帕金森病和自闭症的早期生物标志；在多个动作识别数据集（UTKinect、Florence、HDM05）上验证了模型的泛化性与鲁棒性。

Conclusion: GeoDynamics为建模复杂时空动力学提供了几何感知的新范式，在神经科学及其他领域具有广泛适用性。

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [728] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: 本文提出了一种专为强化学习（RL）训练的智能体模型设计的模型融合框架RAM，解决了现有融合方法在RL场景下因任务向量不匹配导致的任务能力退化问题；RAM通过解耦共享与任务特有参数更新，并选择性保留和重标度后者，显著提升了融合后通用智能体的性能，甚至超越各领域专用智能体。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法主要面向监督微调（SFT），而RL训练产生的任务向量稀疏、异构，直接套用SFT融合策略（如全局平均）会导致关键任务特有行为被削弱、参数更新被稀释。

Method: 提出Reinforced Agent Merging（RAM）框架：显式建模RL任务向量的分布特性，将参数更新解耦为共享分量和任务特有分量；对共享分量进行平均，对任务特有分量进行选择性保留与自适应重标度，以对抗更新稀释。

Result: 在多个智能体任务域和模型架构上实验表明，RAM不仅显著优于各类融合基线，还能激发智能体间的协同效应，使融合后的通用模型性能超越各原专用智能体。

Conclusion: RAM是首个专为RL训练智能体定制的融合框架，通过分布感知的参数解耦与重标度机制，有效克服了SFT融合范式在RL场景下的根本局限，为构建高性能通用智能体提供了新路径。

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [729] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 本文提出FG-OrIU框架，通过在特征和梯度层面施加正交约束，实现预训练模型的深度、不可逆增量遗忘，避免信息残留引发的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法仅抑制参数或混淆知识，缺乏对特征和梯度层面的显式约束，导致‘表面遗忘’——被遗忘信息仍可恢复，带来安全风险并破坏保留-遗忘平衡。

Method: FG-OrIU利用SVD分解特征空间，分离遗忘类与保留类子空间；在特征层面进行正交投影，在梯度层面也施加正交投影以防止知识回流；并引入动态子空间自适应机制，融合新遗忘子空间、收缩保留子空间。

Result: 实验表明FG-OrIU在多个基准上显著提升遗忘效果，同时保持对未删除类别的高保留精度，实现更稳定、彻底的增量遗忘。

Conclusion: FG-OrIU是首个统一特征与梯度正交约束的增量遗忘框架，实现了不可逆的深度遗忘，有效缓解安全风险并维持遗忘-保留平衡。

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [730] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: 本文提出Neural Organ Transplantation (NOT)，一种模块化适配框架，可将预训练Transformer的层子集（“供体器官”）独立训练并作为可移植检查点用于领域自适应，无需原始训练数据，在解码器-only模型上显著优于LoRA等方法。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将参数与特定模型和数据强耦合，缺乏模块化与可重用性；同时，领域适配需隐私保护与高效知识共享。

Method: 从预训练Transformer中提取连续层子集（donor organs），在目标领域数据上独立训练并保存为独立检查点，再将其插入兼容的接收模型（recipient models）中，支持无需原始训练数据的移植。

Result: 在GPT-2、TinyLlama、GPT-OSS（124M–20B参数）上验证，NOT在困惑度上比LoRA提升一个数量级，训练更快；早期插入位置效果最优；十亿参数跨域迁移展现出意外正则化效应。

Conclusion: Transformer中间层可在decoder-only架构中实现高效模块化迁移，支持隐私保护下的专家知识共享；但目前不适用于encoder-based架构。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [731] [Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments](https://arxiv.org/abs/2601.13592)
*Hao Jing,Sa Xiao,Haoyu Li,Huadong Xiao,Wei Xue*

Main category: cs.LG

TL;DR: 本文提出了一种将残差卷积神经网络嵌入数值天气预报系统以加速辐射计算的方法，在保证精度的同时提升约8倍计算速度。


<details>
  <summary>Details</summary>
Motivation: 辐射计算是数值模式中最耗时的物理过程之一，亟需通过机器学习方法提升计算效率；同时需解决深度学习模型与数值模式耦合中的兼容性与长期积分稳定性问题。

Method: 采用离线训练、在线耦合策略，构建基于残差CNN的RRTMG辐射方案替代模型；使用模型模拟生成含云/无云大气柱数据集，结合经验回放和物理约束增强训练稳定性；采用LibTorch实现高效实时耦合。

Result: 在十天预报中，该混合模型精度与传统RRTMG相当，计算速度提升约8倍；两月业务再预报试验验证了其可靠性与稳定性。

Conclusion: 基于物理约束与经验回放训练的CNN辐射替代模型可有效嵌入业务数值模式，在保持预报精度前提下显著提升计算效率，具备实际业务应用价值。

Abstract: Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.

</details>


### [732] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 本文提出Diffusion in Diffusion框架，通过‘草稿-精修’两阶段策略，结合小块块扩散生成初稿与大范围双向扩散全局精修，并引入快照置信度重掩码和混合尺度训练，显著提升离散扩散语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决块扩散语言模型因严格单向块依赖导致的不可逆性和缺乏全局规划能力的问题。

Method: 提出Diffusion in Diffusion框架：第一阶段用小块块扩散快速生成草稿；第二阶段用具有更大双向感受野的全局双向扩散进行精修；引入snapshot confidence remasking识别关键待修改token，并采用mix-scale训练增强模型全局建模能力。

Result: 在OpenWebText数据集上刷新离散扩散模型基准：仅用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，大幅缩小与自回归模型的性能差距。

Conclusion: Diffusion in Diffusion有效缓解了块扩散模型的不可逆性与短视问题，提升了其全局建模能力，在效率与性能间取得更好平衡。

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [733] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: 本文提出了一种名为Fisher-Informed Parameterwise Aggregation (FIPA) 的联邦学习参数聚合方法，通过使用Fisher信息矩阵（FIM）对每个参数进行个性化加权，替代传统FedAvg中统一的客户端标量权重，从而缓解非独立同分布（non-IID）数据下的客户端漂移问题，在多个任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准一阶联邦学习方法（如FedAvg）在非IID数据下使用统一标量权重聚合客户端模型更新，易导致参数更新方向不一致、客户端漂移及全局模型性能下降。

Method: 提出FIPA方法：利用Fisher信息矩阵（FIM）为每个参数生成客户端特定的权重，实现参数级自适应缩放；采用低秩近似以保证通信与计算效率。

Result: 在非线性函数回归、偏微分方程学习和图像分类等多个任务上，FIPA持续优于基于平均的聚合方法；可与先进客户端优化算法结合，进一步提升图像分类准确率。

Conclusion: FIPA通过引入二阶FIM驱动的参数级加权机制，有效缓解了异构数据下的客户端漂移问题，显著提升了联邦学习在non-IID场景下的鲁棒性与泛化能力。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [734] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 本文提出了一种二次上界（QUB）损失函数，用于改善快速对抗训练（FAT）中鲁棒性下降的问题，并通过实验证明其能显著提升模型鲁棒性，归因于平滑的损失曲面。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练（FAT）虽节省时间，但常因对抗空间探索不足而导致鲁棒性下降，亟需改进损失函数以缓解该问题。

Method: 推导对抗训练（AT）损失函数的二次上界（QUB），并将其整合进现有FAT方法中作为替代损失函数。

Result: 在多种指标下，QUB损失显著提升了FAT模型的鲁棒性，并证实其效果源于模型损失曲面的平滑化。

Conclusion: QUB损失是一种简单有效的方法，可在不增加训练开销的前提下增强FAT的鲁棒性，且其优势来自更平滑的优化景观。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [735] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: 本文提出了TimeART框架，结合现成分析工具和大语言模型（LLM）的推理能力，实现全自动时间序列问答（TSQA），并构建了10万条专家轨迹数据集TimeToolBench及四阶段训练策略，显著提升时序推理模型（TSRM）性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析高度依赖人工数据科学家，成本高且缺乏自动化；亟需能自主推理与调用工具的智能系统。

Method: 提出TimeART框架，融合外部分析工具与LLM；构建TimeToolBench专家轨迹数据集；设计四阶段训练策略（含自学习与自反思）。

Result: 在多个TSQA任务上，基于TimeToolBench训练的8B TSRM取得一致SOTA性能。

Conclusion: TimeART首次实现了面向时间序列的全自主代理式推理，为时序智能分析开辟新范式。

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [736] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的代理模型（surrogate model），用于实时、高精度模拟神经外科手术中大脑组织的瞬态非线性形变；该模型基于Universal Physics Transformers，直接处理大规模网格数据，并引入随机教师强制（stochastic teacher forcing）策略提升长期预测稳定性；实验表明其在15万节点网格上误差显著降低（6.7 mm → 3.5 mm），单步推理耗时<10 ms，适用于消费级硬件的交互式手术仿真。


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器难以满足神经外科仿真对实时性的要求，而准确模拟大脑复杂非线性形变对真实感工具-组织交互至关重要。

Method: 基于Universal Physics Transformers构建端到端深度学习代理模型，直接处理大规模网格序列；使用非线性有限元仿真生成的大规模时序数据集训练；引入随机教师强制策略——训练中采用短程随机rollout，逐步减少真值输入比例、增加模型自预测输入比例，以缓解自回归误差累积。

Result: 模型在高达150,000节点的网格上实现高精度瞬态形变预测；最大预测误差从6.7 mm降至3.5 mm；集成至交互式仿真环境后，消费级硬件下单步运行时间低于10 ms。

Conclusion: 所提深度学习框架可实现快速、平滑且准确的动态脑组织生物力学仿真，为构建高保真神经外科训练系统提供了关键技术支撑。

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [737] [Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation](https://arxiv.org/abs/2601.13698)
*Arjun Nichani,Hsiang Hsu,Chun-Fu,Chen,Haewon Jeong*

Main category: cs.LG

TL;DR: 本文利用Chernoff信息这一信息论度量，提出Noisy Chernoff Difference工具，揭示公平性、隐私与准确率三者间的数据依赖关系，并在合成与真实数据上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 公平性与隐私是可信机器学习的两大支柱，但二者关系及与准确率的联合影响尚缺乏系统研究。

Method: 引入信息论度量Chernoff Information，定义Noisy Chernoff Difference作为分析公平性、隐私和准确率三者关系的统一工具；理论分析其在不同合成数据分布下的行为；提出未知分布下Chernoff Information的估计方法，并在真实数据集上实证分析三者动态关系。

Result: 发现Noisy Chernoff Difference在合成数据中呈现三种典型行为，对应不同数据分布，并可作为公平性-准确率权衡曲线陡峭程度的代理指标；所提估计方法在真实数据上验证了三者关系的数据依赖性。

Conclusion: 公平性、隐私与准确率之间的关系本质上是数据依赖的，需统一框架建模；Noisy Chernoff Difference为理解该三元权衡提供了新视角与实用工具。

Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.

</details>


### [738] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 本研究比较了机器学习（ML）与生成式AI（GenAI）在慢性鼻窦炎（CRS）术前预测手术效果方面的性能，发现ML模型（尤其是多层感知机）在准确性、校准度和临床净收益上优于GenAI；而GenAI虽判别能力较弱，但其解释与临床经验及ML特征重要性高度一致，适合作为ML的辅助解释工具。


<details>
  <summary>Details</summary>
Motivation: 尽管AI已广泛应用于医学影像，但在真实临床场景中基于结构化临床数据进行前瞻性决策支持仍十分有限；本研究旨在探索是否可仅用术前临床数据预测CRS患者术后是否达到有临床意义的改善（MCID），从而避免无效手术。

Method: 在前瞻性收集的接受手术的CRS队列中，定义主要终点为6个月SNOT-22评分降低>8.9分（MCID）；对比监督式ML模型（逻辑回归、树集成、自研MLP）与生成式AI模型（ChatGPT、Claude、Gemini、Perplexity），统一输入结构化临床变量，输出限定为二分类建议及置信度；评估指标包括准确率、校准性、决策曲线分析（net benefit）及解释一致性。

Result: 最佳ML模型（MLP）达85%准确率，校准性与净获益显著优于GenAI；所有GenAI模型在零样本设定下判别能力与校准性均较差；但其生成的推理理由与临床经验及MLP特征重要性高度吻合，反复强调基线SNOT-22、CT/内镜严重度、息肉表型及心理/疼痛共病。

Conclusion: 应采用‘ML为主、GenAI为辅’的工作流：以校准良好的ML模型进行手术适应症初筛，GenAI作为可解释性模块提升透明度与医患共同决策质量。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [739] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: 本文提出EEG-Titans双分支模型，结合滑动窗口注意力与循环记忆通路，有效建模EEG长时程预发作动态，在CHB-MIT数据集上实现99.46%平均片段级敏感度，并通过分层上下文策略显著降低高噪声记录中的误报率。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测难在预发作动力学时间跨度长、临床相关特征微弱且短暂；现有深度学习模型难以兼顾局部时空模式与长程上下文建模。

Method: 提出EEG-Titans双分支架构：一为滑动窗口注意力捕获短期异常，二为具现代神经记忆机制的循环记忆通路建模缓慢渐进趋势；并引入分层上下文策略扩展高噪声受试者的感受野。

Result: 在CHB-MIT数据集按时间顺序留出评估下，平均片段级敏感度达99.46%；对伪迹多的记录，在保障敏感度前提下将假阳性率降至0.00 FPR/h（某极端 outlier）。

Conclusion: 增强记忆的长上下文建模可提升癫痫发作预测在临床约束评估下的鲁棒性与安全性。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [740] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: 本文提出了vLinear，一种基于线性模型的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，显著降低了计算复杂度并提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于自注意力机制的多元时间序列预测器计算复杂度高（O(N^2)），难以扩展到高维变量场景，亟需更高效的建模方法。

Method: 提出轻量级vecTrans模块，用可学习向量建模多元相关性，将复杂度降至O(N)；设计final-series-oriented的WFMLoss损失函数，引入路径与预测步长加权策略。

Result: vLinear在22个基准数据集、124种预测设置下达到SOTA性能；vecTrans可即插即用地加速Transformer类模型达5倍；WFMLoss作为通用目标函数能稳定提升现有预测器性能。

Conclusion: vLinear通过结构简化与目标函数创新，在保持高性能的同时大幅提升效率，为多元时间序列预测提供了新的高效范式。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [741] [Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks](https://arxiv.org/abs/2601.13776)
*Thibaut Boissin,Franck Mamalet,Valentin Lafargue,Mathieu Serrurier*

Main category: cs.LG

TL;DR: 本文介绍了Orthogonium，一个统一、高效且全面的PyTorch库，用于实现正交和1-Lipschitz神经网络层，以支持鲁棒深度学习。


<details>
  <summary>Details</summary>
Motivation: 现有正交与1-Lipschitz层实现碎片化、功能受限且计算开销大，缺乏统一可靠的工具支持鲁棒深度学习需求。

Method: 设计并实现了Orthogonium库，支持标准卷积特性（如stride、dilation、grouping、转置卷积）并保证严格数学性质；优化实现以降低大规模基准（如ImageNet）开销；通过严格测试发现并修正已有实现中的关键错误。

Result: Orthogonium显著降低了正交与Lipschitz约束层的采用门槛，在ImageNet等大型基准上验证了高效性，并揭示了先前实现中的严重缺陷。

Conclusion: Orthogonium为需要正交性和Lipschitz约束的各类应用提供了标准化、可靠且可扩展的工具，推动鲁棒深度学习研究与落地。

Abstract: Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.

</details>


### [742] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: 本文提出LG-Flow，一种基于低维可逆潜空间的图扩散生成框架，通过置换等变自编码器实现近无损重建，并在潜空间中使用Diffusion Transformer与流匹配进行高效图生成，显著降低计算复杂度并提升速度。


<details>
  <summary>Details</summary>
Motivation: 现有图扩散模型存在节点数平方级复杂度问题，且在稀疏图上大量容量浪费于建模边缺失；同时，图生成要求近乎无损重建，而此前潜扩散方法难以满足该要求。

Method: 提出LG-Flow框架：1）设计置换等变自编码器，将每个节点映射为固定维嵌入，保证邻接矩阵可证地完全重构（支持无向图和DAG）；2）潜空间维度线性于节点数，消除二次瓶颈；3）在该潜空间中采用Diffusion Transformer结合流匹配进行扩散建模。

Result: 在保持与前沿图扩散模型相当生成质量的同时，实现最高达1000倍的训练/采样加速。

Conclusion: LG-Flow通过理论可逆的低维潜表示，兼顾高效性与重建保真度，为大规模图生成提供了可行新范式。

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [743] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 本文提出了一种基于注意力机制的ETA（预计到达时间）预测模型，通过有效建模历史道路速度模式与实时交通数据的时空因果关系，实现轻量、高效且准确的到达时间预测。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统的发展，精准可靠的ETA预测需求日益增长，但现有方法在建模动态复杂交通流及捕捉关键时空模式方面存在不足。

Method: 提出一种新型ETA模型，利用注意力机制对历史道路速度模式进行建模，显式捕获路径上各时空点的时序特征与时空因果性，融合道路特性、实时交通状态与历史速度数据。

Result: 在真实驾驶数据集上的实验表明，该模型在准确性上优于现有基线方法，同时保持轻量性和可扩展性。

Conclusion: 所提基于注意力机制的ETA模型能更有效地整合多源异构交通信息，在任务导向下提升预测性能，为智能导航与交通管理提供可靠支持。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [744] [ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks](https://arxiv.org/abs/2601.13824)
*Xiaohong Yang,Tong Xie,Minghui Liwang,Chikai Shang,Yang Lu,Zhenzhen Jiao,Liqun Fu,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: ELSA是一个面向边缘网络的高效大语言模型（LLM）微调框架，融合分割学习（SL）与分层联邦学习（HFL），通过语义感知客户端聚类、三段式模型分割和轻量通信机制，在资源受限、数据异构、隐私敏感的边缘场景下实现高效、鲁棒、隐私保护的分布式微调。


<details>
  <summary>Details</summary>
Motivation: 边缘端训练大语言模型面临设备资源受限、数据高度异构及隐私风险加剧等根本性挑战，亟需兼顾效率、鲁棒性与隐私保护的新范式。

Method: 提出ELSA框架：1）任务无关、行为感知的客户端聚类（基于公共探针输入、对称KL散度构建语义指纹，并结合预测一致性信任评分与延迟感知边缘分配）；2）将LLM分为三部分部署于客户端与边缘服务器，云端仅聚合适配器；3）采用计算草图+语义子空间正交扰动（SS-OP）的轻量通信方案以降低开销并增强隐私。

Result: 在多种NLP任务上实验表明，ELSA在适应性、收敛行为和鲁棒性方面持续优于现有最先进方法。

Conclusion: ELSA为资源受限边缘环境下的LLM微调提供了可扩展、隐私感知且实用的解决方案，推动了去中心化大模型训练的落地。

Abstract: Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.

</details>


### [745] [Optimal L2 Regularization in High-dimensional Continual Linear Regression](https://arxiv.org/abs/2601.13844)
*Gilad Karpel,Edward Moroshko,Ran Levinstein,Ron Meir,Daniel Soudry,Itay Evron*

Main category: cs.LG

TL;DR: 本文研究了过参数化连续线性回归中L2正则化对泛化性能的影响，推导出高维情形下期望泛化误差的闭式表达式，证明各向同性正则化可缓解标签噪声，并发现最优固定正则强度随任务数T近似线性增长（T/ln T），该结论为持续学习领域首个理论结果。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中多任务设置下泛化性能差、现有方法未有效利用正则化或内存开销大的问题。

Method: 在高维渐近设定下，对带L2正则的连续线性回归建立理论模型，推导期望泛化损失闭式解，并分析单教师与多独立同分布教师下的噪声鲁棒性及最优正则强度缩放律。

Result: 1）得出任意线性教师下的泛化损失闭式表达式；2）证明L2正则可缓解标签噪声；3）发现最优正则强度按T/ln T缩放；4）实验验证在线性回归和神经网络上的有效性。

Conclusion: 各向同性L2正则不仅提升泛化能力、增强噪声鲁棒性，其最优强度具有明确的理论缩放规律，为持续学习系统设计提供了可操作的理论指导。

Abstract: We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.

</details>


### [746] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 本文提出了一种基于自组织映射（SOM）的精确输入重构与可控潜空间导航方法MUSIC，利用欧氏距离几何原理实现输入的可逆映射，并支持语义一致、流形保持的数据增强与潜变量探索。


<details>
  <summary>Details</summary>
Motivation: 传统SOM缺乏可逆性与可控生成能力，而现有生成模型依赖采样、先验或编解码结构；本文旨在从SOM激活模式（到原型的平方距离）出发，建立几何驱动的精确重构与语义可控更新机制。

Method: 基于D+1个仿射无关原型的距离唯一确定性，推导出输入重构的线性系统；提出MUSIC更新规则：选择性修改部分原型的平方距离，结合Tikhonov正则化实现稳定、平滑、流形对齐的几何流。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证了MUSIC能生成平滑可解释的潜轨迹，准确恢复输入，并实现无需编码器/解码器的语义可控变化，优于传统无监督聚类方法。

Conclusion: SOM不仅可用于降维与聚类，其原型几何结构本身即蕴含可逆与可控生成能力；MUSIC为数据增强与潜空间探索提供了新范式——仅依赖原型几何，不依赖概率建模或神经网络架构。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [747] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: 本文提出了一种将大语言模型（LLMs）作为代理模型和候选采样器嵌入分层搜索策略的新方法，用于多目标优化；通过自适应划分输入空间并局部引导LLM生成，显著提升Pareto前沿逼近性能，并在理论和实验上均验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）推理能力强，但因其不擅长处理数值输入与多目标权衡，尚不能直接用于多目标优化；现有方法（如进化算法、贝叶斯优化）在该任务上仍占优。

Method: 设计一种结构化分层搜索策略：1）自适应将输入空间划分为互斥超矩形区域；2）用复合评分函数对区域排序；3）仅在高潜力子区域内调用LLM生成候选解，使其专注局部而非全局推理。

Result: 理论证明：在标准正则性假设下，所生成候选解以Hausdorff距离收敛至真实Pareto集；实验表明：该方法持续优于全局LLM多目标优化器，并在合成与真实基准上媲美经典进化算法和贝叶斯优化。

Conclusion: LLMs可通过结构化、局部化引导有效赋能多目标优化；本工作弥合了LLM能力与实际优化需求之间的关键鸿沟，为LLM在数值型决策任务中的应用开辟新路径。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [748] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

TL;DR: 本文提出了一种基于GPT的策略融合框架TractRLFusion，用于提升白质纤维束重建的准确性与解剖可靠性，通过两阶段数据选择和多评判器微调，在多个公开数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束重建中存在虚假连接问题，传统确定性/概率性方法及现有深度学习方法在准确性和解剖可靠性方面仍有不足。

Method: 提出TractRLFusion：基于GPT的强化学习（RL）策略融合框架；采用两阶段训练数据选择策略实现多RL策略融合，并引入多评判器（multi-critic）微调以增强鲁棒性与泛化能力。

Result: 在HCP、ISMRM和TractoInferno数据集上，TractRLFusion在重建精度和解剖可靠性方面均优于单个RL策略及当前最优的经典与DRL方法。

Conclusion: TractRLFusion通过数据驱动的策略融合与多评判器优化，有效提升了 tractography 的准确性与临床适用性，为神经外科规划提供了更可靠的连接图谱支持。

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [749] [Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition](https://arxiv.org/abs/2601.13953)
*Gorgi Pavlov*

Main category: cs.LG

TL;DR: 本文提出了一种名为分层谱合成（Hierarchical Spectral Composition）的可微架构，通过从冻结的布尔傅里叶基中选择谱系数，并结合Sinkhorn约束路由与列符号调制，实现精确布尔逻辑学习；该方法在多个变量规模下验证了高精度与可量化性，并支持硬件高效的神经符号逻辑综合。


<details>
  <summary>Details</summary>
Motivation: 神经网络通过梯度下降学习精确布尔逻辑仍具挑战性，常收敛于易受量化影响的“模糊”近似解。

Method: 提出分层谱合成架构：利用冻结的布尔傅里叶基，通过Sinkhorn约束路由选择谱系数，并引入列符号调制以支持布尔否定；借鉴Manifold-Constrained Hyper-Connections（mHC）思想，将路由矩阵投影至Birkhoff多面体以稳定训练。

Result: 在n=2时达100%准确率且零量化损失；n=3时梯度下降达76%，但枚举证实所有操作存在最优三值掩码（100%准确率，39%稀疏性）；n=4时结合Walsh-Hadamard系数、三值化与MCMC优化实现100%准确率；所有操作支持GPU单周期推理达10,959 MOps/s。

Conclusion: 证实三值多项式阈值表示对所测试布尔函数普遍存在；但高维情形下需超越纯梯度下降的方法；所提架构为硬件高效神经符号逻辑综合提供了可行路径。

Abstract: Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.

</details>


### [750] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

TL;DR: 本文提出RL-BioAug框架，利用仅10%标注数据引导强化学习代理自主选择最优EEG数据增强策略，在Sleep-EDFX和CHB-MIT数据集上显著提升Macro-F1分数。


<details>
  <summary>Details</summary>
Motivation: 静态或随机数据增强策略难以应对EEG信号的非平稳性，易丢失内在信息，影响对比学习性能。

Method: 提出基于标签高效强化学习（RL）的自动增强策略选择框架RL-BioAug，用少量标注数据训练RL代理以动态选择最优增强操作（如Time Masking、Crop & Resize），主干模型仍为完全自监督训练。

Result: 在Sleep-EDFX和CHB-MIT数据集上Macro-F1分别提升9.69%和8.80%；RL代理针对不同任务展现出差异化策略偏好（如睡眠分期偏爱Time Masking，癫痫检测偏爱Crop & Resize）。

Conclusion: RL-BioAug可替代传统启发式增强方法，为EEG分析建立自主化、任务适配的数据增强新范式。

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [751] [A universal linearized subspace refinement framework for neural networks](https://arxiv.org/abs/2601.13989)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为线性化子空间精炼（LSR）的通用框架，利用固定训练状态下的雅可比诱导线性残差模型，在该子空间中求解降维最小二乘问题，从而在不改变网络结构、损失函数或训练流程的前提下显著提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 梯度法训练的神经网络常无法达到模型表达能力所允许的最优精度，作者认为这主要源于损失函数导致的数值病态性，而非非凸性或表达能力不足。

Method: LSR通过在固定网络状态处对残差进行线性化，构建雅可比诱导的线性残差模型，并在低维子空间中直接求解最小二乘问题；对于复合损失的算子约束问题，进一步提出迭代LSR，交替执行LSR与监督式非线性对齐。

Result: LSR在函数逼近、数据驱动算子学习和物理信息算子微调等任务中实现数量级误差下降；迭代LSR提升了收敛速度与精度。

Conclusion: LSR是一种数值稳健、架构无关的后训练精炼方法，将神经网络的非线性表示与固定线性化点上的降阶线性求解器结合，为监督学习、算子学习与科学计算提供了新范式。

Abstract: Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.

</details>


### [752] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的框架，用于在相同真实驾驶条件下对燃油车和电动车进行一对一的运行碳排放评估，通过RNN模型分别建模两类车辆的瞬时排放，并构建反事实场景实现公平比较。


<details>
  <summary>Details</summary>
Motivation: 脱碳公路交通需要一致透明的方法来比较不同车辆技术的CO2排放，而现有方法难以在真实驾驶条件下实现公平、可比的评估。

Method: 构建基于循环神经网络（RNN）的独立模型，分别学习ICEV和EV在固定速度剖面与环境变量（速度、加速度、温度）下到瞬时CO2当量排放率的映射；通过固定驾驶情境生成反事实排放结果。

Result: 实现了在统一瞬时排放指标下对两类车辆的直接、可复现比较，支持在真实工况中开展可信、数据驱动的碳性能评估。

Conclusion: 该框架为不同动力系统在真实道路条件下的碳排放公平评估提供了可扩展、可解释且技术中立的方法基础。

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


### [753] [Universal Approximation Theorem for Input-Connected Multilayer Perceptrons](https://arxiv.org/abs/2601.14026)
*Vugar Ismailov*

Main category: cs.LG

TL;DR: 本文提出了输入连接多层感知机（IC-MLP），其每个隐藏神经元不仅接收前一层的输出，还直接接收原始输入的仿射连接；证明了在非线性激活函数下，该结构具有通用逼近能力。


<details>
  <summary>Details</summary>
Motivation: 提升传统MLP的表达能力与理论可解释性，通过引入原始输入的直接连接来增强模型对输入信息的利用效率。

Method: 构建IC-MLP架构，分别在单变量和多变量情形下推导其网络函数的迭代公式，并基于函数逼近理论证明其通用逼近性。

Result: 证明了IC-MLP在非线性激活函数下能一致逼近任意闭区间上的连续函数（单变量）及紧集上的连续函数（多变量）。

Conclusion: IC-MLP是一种具有严格理论保证的增强型前馈网络，其输入直连设计在保持简洁性的同时提升了逼近能力。

Abstract: We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.

</details>


### [754] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 本文提出了一种面向API部署场景的新型输出隐私保护方法，基于PAC隐私框架，通过自适应噪声校准实现对抗性查询下的线性互信息累积保证，在多个任务上实现了高准确率与极低查询级隐私预算下的强成员推断攻击防御能力。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型常以API形式部署，传统基于权重的差分隐私方法（如DP-SGD）因过度噪声导致效用下降；而模型输出维度更低、更稳定，因此应直接在响应层面提供隐私保障。

Method: 基于PAC隐私（以互信息为隐私度量），提出一种支持对抗性自适应查询的新算法，通过自适应噪声校准确保互信息隐私保证在线性累积下仍成立。

Result: 在CIFAR-10上以每步MI预算2^{-32}达到87.79%准确率，支持百万次查询并使成员推断攻击成功率≤51.08%（等价于(0.04,1e-5)-DP）；利用私有响应蒸馏出的模型在CIFAR-10上达91.86%准确率，MIA上限为50.49%（≈(0.02,1e-5)-DP）。

Conclusion: 直接对模型输出施加PAC隐私约束，并结合自适应噪声机制，可在API服务场景中显著提升隐私-效用权衡，且支持安全的私有响应蒸馏与模型发布。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [755] [Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.14092)
*Babacar Toure,Dimitrios Tsilimantos,Omid Esrafilian,Marios Kountouris*

Main category: cs.LG

TL;DR: 本文提出了一种基于注意力机制的多目标强化学习（MORL）架构，用于解决城市环境中无人机数据采集与能耗之间的权衡问题，无需先验信道信息，具备强泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有无人机路径规划AI方法受限于训练数据不足和忽视任务的多目标本质，难以适应高度动态环境。

Method: 提出一种注意力机制驱动的多目标强化学习（MORL）框架，统一建模数据采集与能耗权衡，支持动态偏好调整与场景参数变化，无需微调或重训练。

Result: 仿真表明该方法在性能、模型紧凑性、样本效率及对未见场景的泛化能力上均显著优于现有RL方案。

Conclusion: 所提MORL架构能有效应对城市无人机数据采集中多目标、动态性和先验知识缺失等挑战，具备实际部署潜力。

Abstract: Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.

</details>


### [756] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 本文提出了一种基于时滞交叉映射的因果特征选择框架（TDCCM/TDPCM），以解决工业软测量建模中时滞因果关系与变量互依赖性被忽略的问题，显著提升了模型精度与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽略了工业过程中变量间存在时间延迟和高度互依赖性这两个关键特性，导致软传感器模型精度和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：引入时滞收敛交叉映射（TDCCM）用于总因果推断，时滞偏交叉映射（TDPCM）用于直接因果推断；结合状态空间重构处理变量互依赖；设计基于验证集性能自动确定因果阈值的客观特征选择策略。

Result: 在两个真实工业案例中，TDCCM平均性能最优，TDPCM在最差场景下显著提升软传感器的稳定性和性能。代码已开源。

Conclusion: 所提框架有效克服了传统因果推断方法在工业软传感中的局限性，为高精度、高稳定性软传感器建模提供了新思路。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [757] [Riemannian Liquid Spatio-Temporal Graph Network](https://arxiv.org/abs/2601.14115)
*Liangsi Lu,Jingchao Wang,Zhaorong Dai,Hanqian Liu,Yang Shi*

Main category: cs.LG

TL;DR: 本文提出了Riemannian Liquid Spatio-Temporal Graph Network (RLSTG)，将连续时间液态动力学与黎曼流形的几何归纳偏置相结合，以在非欧几里得图上建模时空动态，显著提升复杂结构图的表示能力与性能。


<details>
  <summary>Details</summary>
Motivation: Liquid Time-Constant networks (LTCs) 虽擅长建模不规则采样动态，但局限于欧氏空间，难以准确表达具有内在非欧结构（如层次、环）的真实图，导致几何失真和表征质量下降。

Method: 提出RLSTG框架，将LTC的连续时间液态动力学建模推广至黎曼流形，通过直接定义在弯曲流形上的常微分方程（ODE）建模图演化，并提供稳定性理论保证与状态轨迹分析以量化表达能力。

Result: 在多个真实世界基准数据集上实验表明，RLSTG结合先进时间动态与黎曼空间表征，在复杂结构图任务中性能优于现有方法。

Conclusion: RLSTG成功克服了传统LTC在非欧图上的几何局限性，为时空图学习提供了兼具理论严谨性与强表达力的新型连续时间几何深度学习范式。

Abstract: Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io

</details>


### [758] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 本文研究了低秩张量积B样条（TPBS）模型在回归任务中的应用，提出了一种基于局部Dirichlet能量的新型正则化策略，并设计了两种利用预训练TPBS模型处理不完整样本的推理估计器；实验表明TPBS模型在过拟合情形下优于神经网络，且对正则化更鲁棒有效。


<details>
  <summary>Details</summary>
Motivation: 全局Dirichlet能量正则化在TPBS模型中因存在极小能量完美插值情形而失效，需设计更有效的平滑性约束机制。

Method: 推导TPBS模型的Dirichlet能量闭式表达式；提出以训练点为中心的小超立方体上的局部Dirichlet能量作为正则项；基于预训练TPBS模型构建两种不完整样本推理估计器。

Result: TPBS模型在多数数据集的过拟合区域性能优于神经网络，整体更鲁棒、更受益于正则化；神经网络则更易过拟合且正则化效果较弱。

Conclusion: 局部Dirichlet能量正则化有效克服了全局正则失效问题，TPBS模型是一种比神经网络更具过拟合鲁棒性和正则敏感性的回归建模工具。

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [759] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 本文提出一种基于'有效场论'视角的两参数模型，解释大语言模型在确定性任务（如算术）中的错误率，认为错误源于注意力机制中微小误差的累积，并通过实验验证了该模型的有效性，同时提出了降低错误率的提示工程方法。


<details>
  <summary>Details</summary>
Motivation: 解释大语言模型在需要确定性输出的任务（如算术、重复token处理）中出错的根本原因，挑战‘推理崩溃’或‘无法组合’等定性解释，寻求定量、可预测的错误建模框架。

Method: 提出一个受‘有效场论’启发的两参数定量模型：一个参数表征基础噪声率，另一个参数表征可能被误预测的错误token数量；通过分析注意力机制中误差累积跨越阈值的过程推导误差率与任务复杂度的关系；在多个模型（Gemini 2.5 Flash/Pro、DeepSeek R1）上进行大量实证测试。

Result: 模型在多种任务上预测准确率与实测准确率高度吻合；识别出部分偏差情形；证明错误可归因于可量化的底层机制而非根本性能力缺失；并展示了通过提示工程降低错误率的有效方法。

Conclusion: LLM在确定性任务上的错误并非源于抽象能力缺陷，而是由注意力机制中可建模、可调控的底层噪声和歧义性共同导致；该两参数框架为理解、预测和缓解LLM系统性错误提供了新范式。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [760] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 本文提出了一种差异化取货点提供（DPO）策略，通过为每位顾客动态推荐一个最优取货点（而非开放选择），在保留家庭配送选项的同时，联合降低配送车辆与顾客自取的碳排放。基于强化学习的方法考虑空间关系与动态到达特性，实验表明该策略相较仅家庭配送最多减排9%，平均优于其他策略2%。


<details>
  <summary>Details</summary>
Motivation: 传统取货点虽可优化配送路径，但若顾客驾车自取则可能抵消其环保效益；需协同优化配送与顾客端的碳排放。

Method: 提出动态随机环境下的差异化取货点提供（DPO）策略，采用考虑空间关系与未来路径整合潜力的强化学习方法设计推荐策略。

Result: DPO策略相较纯家庭配送最多降低总碳排放9%，平均比无限制选择或最近点分配等基准策略低2%；在高密度城区效果更显著；动态建模对低取货意愿场景尤为关键。

Conclusion: 差异化、动态化、空间感知的取货点推荐策略能有效协同削减物流与顾客出行碳排放，强化学习是建模该复杂决策问题的有效工具。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [761] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 本文提出干预训练（InT）方法，通过模型自主在推理轨迹中定位首个错误并提出单步修正，实现细粒度信用分配，显著提升数学推理任务的准确率。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习在结果奖励RL中仅在最终答案层面分配信用，导致错误推理轨迹中正确的中间步骤被惩罚，而成功轨迹中错误的中间步骤被强化，即信用分配问题。

Method: 提出干预训练（InT）范式：模型利用参考解识别自身推理轨迹中的首个错误，并生成单步干预以重定向至正确解；随后对出错前的推理路径拼接干预进行监督微调（SFT），实现错误定位与局部修正。

Result: 在IMO-AnswerBench上，4B参数基模型经InT+RL后准确率提升近14%，超越更大的开源模型如gpt-oss-20b。

Conclusion: InT能有效缓解信用分配问题，为RL训练提供更优初始化，显著增强LLM的数学推理能力。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [762] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 本文提出了一种面向脓毒症治疗的可解释决策支持框架，结合聚类分层、合成数据增强、离线强化学习与多模态大语言模型，提升ICU中治疗推荐的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是ICU主要死因之一，亟需及时、准确且可解释的治疗决策支持。

Method: 融合四大模块：基于聚类的风险分层、VAE与扩散模型驱动的合成数据增强、采用AWR训练的轻量注意力编码器+集成模型的离线RL治疗推荐、以及基于多模态LLM的临床理由生成。

Result: 在MIMIC-III和eICU数据集上验证，该框架实现了高治疗准确率，并提供可解释、安全稳健的临床决策建议。

Conclusion: 所提框架兼顾性能与可解释性，为AI辅助重症临床决策提供了可行路径。

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [763] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文提出了KAGE-Env（一个JAX原生2D平台游戏环境）和KAGE-Bench（一个解耦视觉变化轴的基准），用于系统研究像素级强化学习智能体在纯视觉分布偏移下的泛化能力；实验表明不同视觉轴（如背景、光照、智能体外观）对性能影响差异显著，且仅靠回报指标可能掩盖泛化失败。


<details>
  <summary>Details</summary>
Motivation: 现有基准将多种视觉分布偏移混杂在一起，难以系统分析像素级RL智能体在视觉变化下的泛化失败原因，亟需可解耦、可控的测试环境。

Method: 设计KAGE-Env——一个JAX实现的2D平台器环境，将观测过程分解为多个独立可控的视觉轴（如背景、光照、智能体外观等），同时保持底层动力学与奖励不变；在此基础上构建KAGE-Bench，包含6类共34种训练-评估配置，每类隔离单一视觉轴变化；采用标准PPO-CNN作为基线进行评估。

Result: PPO-CNN在背景和光度变化下性能严重下降甚至崩溃，而智能体外观变化影响较小；部分视觉偏移虽维持前向运动但破坏任务完成，说明仅用累积回报无法反映真实泛化能力；JAX全向量化实现支持单GPU达33M步/秒，大幅提升实验效率。

Conclusion: 视觉分布偏移的影响高度轴依赖，需解耦评估；单纯优化回报易掩盖策略失效本质；KAGE-Env/Bench为视觉泛化研究提供了高效、可控、可复现的新基准。

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [764] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 本文提出了一种名为FireCastRL的主动式AI框架，结合野火预测与智能扑救策略，通过深度时空模型预测野火点火，并利用预训练强化学习代理在物理感知的3D仿真中执行实时扑救战术，同时发布了一个包含950万样本的大规模时空数据集。


<details>
  <summary>Details</summary>
Motivation: 传统野火管理多为被动响应，无法有效应对日益频繁和强烈的野火；亟需一种能提前预测并主动干预的智能系统。

Method: 采用深度时空模型预测野火点火风险；对高风险区域，调用预训练强化学习代理在物理建模的3D仿真环境中调度直升机扑火单位；生成威胁评估报告辅助应急决策；并公开大规模环境变量时空数据集。

Result: 实现了从预测到实时战术响应的端到端AI框架；验证了深度学习与强化学习协同支持野火预测与响应的可行性；发布了含9.5百万样本的公开数据集。

Conclusion: FireCastRL展示了AI在提升野火管理主动性、智能化和资源优化方面的重要潜力，为未来灾害响应系统提供了新范式。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [765] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: 本文提出Jet-RL框架，首次系统研究FP8精度在强化学习训练中的应用，指出传统BF16训练+FP8 rollout策略存在严重不稳定性与精度崩溃问题，并通过统一FP8训练与rollout流程实现高效稳定训练。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练流程计算效率低、资源消耗大，尤其rollout阶段占总训练时间70%以上；FP8量化虽有潜力，但常用BF16训练+FP8 rollout策略在长周期和难任务下出现训练不稳定与精度崩溃，源于off-policy导致的训练-推理数值失配。

Method: 提出Jet-RL框架，采用全FP8精度统一处理训练与rollout过程，消除跨精度校准需求，减少数值差异，提升优化稳定性。

Result: Jet-RL在rollout阶段加速最高33%，训练阶段最高41%，端到端加速16%，收敛稳定，精度损失可忽略。

Conclusion: 统一FP8精度训练是解决RL中计算瓶颈与数值不一致问题的有效路径，Jet-RL为高效、稳定、低精度RL训练提供了可行范式。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [766] [RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models](https://arxiv.org/abs/2601.11801)
*Nitish Sontakke,K. Niranjan Kumar,Sehoon Ha*

Main category: cs.RO

TL;DR: 本文提出了一种名为RobotDesignGPT的新型自动化机器人设计框架，利用预训练的视觉-语言大模型，根据用户提示和参考图像自动生成初始机器人设计，并通过新颖的视觉反馈机制提升设计质量、减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 机器人设计过程复杂，依赖大量领域专业知识和人工 effort，现有方法多为基于规则的，需手动定义语法或组件库，缺乏灵活性与自动化能力。

Method: 提出RobotDesignGPT框架，结合大型视觉-语言模型进行跨模态理解与生成；输入为用户文本提示和参考图像，输出为初始机器人设计；引入视觉反馈机制迭代优化设计；通过消融实验和用户研究验证有效性。

Result: 框架能生成外观吸引人且运动学有效的仿生机器人设计（如腿式动物、飞行生物）；视觉反馈显著提升设计质量并降低人工修正需求；消融与用户研究证实各模块贡献及整体实用性。

Conclusion: RobotDesignGPT展示了利用通用多模态大模型实现端到端自动化机器人设计的可行性，为降低设计门槛、加速创新提供了新范式。

Abstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.

</details>


### [767] [Optimal Thruster Configuration for 6-DOF Control of a Small Satellite](https://arxiv.org/abs/2601.11802)
*Suguru Sato,Jinaykumar Patel,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 本文研究了小型卫星（如CubeSats等）在近地轨道（LEO）中实现六自由度（6-DOF）控制所需的最小有效推力器构型，并在交会对接任务中验证其姿态控制性能。


<details>
  <summary>Details</summary>
Motivation: 随着小型卫星在LEO中广泛应用（如成像、通信、数据存储、交会对接等），对其轨道维持和姿态控制的需求日益增长；传统多推力器方案虽可行，但需优化构型以兼顾6-DOF控制能力与推进效率。

Method: 从24推力器初始构型出发，系统筛选出能实现完整6-DOF控制的‘可行构型组’，并进一步从中找出实现6-DOF指令所需总推力最小的构型子集；选取各子集中一个代表构型，在典型交会对接任务中仿真评估其姿态控制性能。

Result: 识别出多个满足6-DOF控制的可行推力器构型组，并确定了其中总推力需求最小的构型；仿真表明，即使推力器数量显著减少，仍可满足交会对接任务所需的机动性与控制精度。

Conclusion: 推力器构型设计可在保证6-DOF控制能力的同时显著降低总推力需求，为小型卫星提供轻量化、高效率的姿态与轨道联合控制方案。

Abstract: With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.

</details>


### [768] [Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles](https://arxiv.org/abs/2601.11832)
*Suguru Sato,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 本文提出了一种受流体力学启发的三维碰撞规避框架，用于动态环境中无人机编队的实时避障，通过将障碍物建模为三维偶极子或椭球体生成局部速度场，结合虚拟刚体编队策略，实现平滑、无局部极小值、无需重规划的安全避障。


<details>
  <summary>Details</summary>
Motivation: 解决传统势场法存在局部极小值、轨迹不连续及需显式重规划等问题，提升动态环境中多无人机编队实时避障的安全性、平滑性与可解释性。

Method: 将移动障碍物建模为三维偶极子或椭球体，利用拉普拉斯方程的调和性质生成局部避障速度场；融合虚拟刚体（VRB）编队控制策略以维持编队几何结构与轨迹跟踪。

Result: 仿真验证了该方法在单机与多机、多种编队构型及多个移动障碍物场景下的可行性、可扩展性与实时性，实现了安全、平滑且计算高效的避障。

Conclusion: 该流体动力学启发的避障框架兼具物理可解释性、实时性与鲁棒性，适用于实际无人机系统部署。

Abstract: This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.

</details>


### [769] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

TL;DR: 本文提出了一种能够在公园草地上自主导航、识别并捡拾垃圾的机器人系统，采用STC算法规划路径、RTK GPS实现高精度定位、ResNet50 CNN实现94.52%准确率的垃圾识别，并设计了专用拾取机构，整体成功率80%。


<details>
  <summary>Details</summary>
Motivation: 美国有500亿件垃圾，野餐者常在草地留下垃圾，亟需自动化解决方案。

Method: 采用Spanning Tree Coverage (STC)算法生成全覆盖路径；使用RTK GPS实现厘米级实时定位；基于ResNet50 CNN进行垃圾检测；设计并测试多种拾取机构，最终选定适配草地常见垃圾的专用机构。

Result: 垃圾识别准确率达94.52%，整体拾取成功率为80%。

Conclusion: 该自主垃圾拾取机器人在草地环境中具备可行性与实用性，为解决公共场所垃圾问题提供了有效技术路径。

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [770] [Visual-Language-Guided Task Planning for Horticultural Robots](https://arxiv.org/abs/2601.11906)
*Jose Cuaran,Kendall Koe,Aditya Potnis,Naveen Kumar Uppalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的模块化框架，用于指导农业机器人在作物监测任务中的规划与执行，并构建了涵盖单/多作物环境的短/长时程任务基准；实验表明VLM在短时程任务中表现接近人类，但在长时程及依赖噪声语义地图的任务中性能显著下降，揭示了其在持续农业机器人作业中上下文定位的关键局限。


<details>
  <summary>Details</summary>
Motivation: 当前作物监测系统缺乏高层次推理能力，难以支撑复杂农业机器人任务的自主规划与执行。

Method: 提出一种模块化框架，利用视觉语言模型（VLM）引导机器人任务规划，将输入查询与动作原语交错执行；并构建涵盖单作与多作环境、短程与长程任务的综合基准。

Result: VLM在短时程作物监测任务中表现稳健，成功率接近人类水平；但在长时程任务中性能显著下降，尤其在依赖噪声语义地图时系统失效。

Conclusion: 该工作提供了可部署的VLM驱动农业机器人框架，并揭示了当前VLM在持续作业中上下文接地能力的瓶颈，为未来研究指明方向。

Abstract: Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.

</details>


### [771] [Model selection and real-time skill assessment for suturing in robotic surgery](https://arxiv.org/abs/2601.12012)
*Zhaoyang Jacopo Hu,Alex Ranne,Alaa Eldin Abdelaal,Kiran Bhattacharyya,Etienne Burdet,Allison M. Okamura,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 本文研究了基于OSATS评分的机器人辅助手术技能水平实时预测方法，利用达芬奇手术系统的运动学和视觉数据，通过多模态深度学习模型实现更稳定、细粒度的手术表现评估，并强调专家级训练数据对模型泛化的重要性。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈系统有望为机器人辅助手术的培训与评估提供客观的技能评估，但实时、准确的技能水平预测仍具挑战。

Method: 采用达芬奇手术系统采集的同步运动学与视觉数据，构建并比较单模态基线模型与多模态融合模型；评估指标为Spearman相关系数；开展实时预测趋势分析及按技能等级分组的交叉验证训练。

Result: 多模态融合模型在实时预测中持续优于单模态模型；预测结果随时间变化趋势与外科医生手势高度相关；使用高技能外科医生数据训练的模型性能更优且泛化能力更强。

Conclusion: 多模态学习可实现更稳定、细粒度的手术表现评估，且专家级训练数据对提升模型泛化能力至关重要。

Abstract: Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.

</details>


### [772] [BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies](https://arxiv.org/abs/2601.12116)
*Hang Xu,Yizhou Chen,Dongjie Yu,Yi Ren,Jia PanI*

Main category: cs.RO

TL;DR: 本文提出了一种基于关键姿态（keypose）条件的协调感知一致性策略，用于双臂机器人操作，通过分层模仿学习框架（高层关键姿态预测+低层轨迹生成）提升多阶段双臂任务的成功率与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有双臂操作方法难以兼顾多阶段任务的结构特性和实时推理需求，阶段失败易引发级联误差，影响整体性能。

Method: 提出关键姿态条件下的协调感知一致性策略：1）设计双臂关键姿态识别方法，融合机器人动作特征与任务操作风格；2）构建分层模仿学习框架，包含高阶关键姿态预测器和低阶一致性轨迹生成器，后者在单步推理中依据历史观测与预测关键姿态生成动作序列。

Result: 在仿真与真实机器人实验中，该方法在成功率和操作效率上显著优于基线方法。

Conclusion: 关键姿态作为显式子目标可有效解耦多阶段双臂任务，结合一致性建模实现快速、鲁棒的轨迹生成，为高效双臂操作提供了新范式。

Abstract: Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.

</details>


### [773] [Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting](https://arxiv.org/abs/2601.12122)
*Jose Cuaran,Naveen K. Upalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 本文提出了一种基于移动机械臂的主动式3D语义重建框架，融合Octomap与3D高斯泼溅（Gaussian Splatting），实现高精度、高效率、目标感知的果园场景重建，显著提升果实计数与体积估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统农业场景语义重建依赖人工扫描或固定相机，效率低、扩展性差，难以满足实时、精准的表型分析和产量估计需求。

Method: 构建融合Octomap（用于概率占据建模与视点规划）与3D高斯泼溅（融合几何、光度与语义信息优化3D高斯分布）的主动重建框架，并引入抗分割噪声策略与内存优化机制。

Result: 在仿真中相较纯占据图方法，运行时间减少50%，无噪声下果实级F1分数提升6.6%，有分割噪声时提升达28.6%；支持精确果实计数与体积估计。

Conclusion: 该框架兼顾精度、鲁棒性与效率，为农业机器人提供可扩展、近实时的语义重建能力，推动智能农情监测落地。

Abstract: Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.

</details>


### [774] [Neural Process-Based Reactive Controller for Autonomous Racing](https://arxiv.org/abs/2601.12143)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 本文提出了一种基于注意力机制的神经过程（AttNP）及其物理信息增强版本（PI-AttNP）用于实时间隙导航控制，并结合控制屏障函数（CBF）实现可验证的安全保障，在F1TENTH仿真赛车环境中验证了其高效性与安全性。


<details>
  <summary>Details</summary>
Motivation: 随着注意力机制神经网络在实时非线性控制中广泛应用，其在安全关键场景（如自动驾驶）中的统计可靠性与可证明安全性亟需保障。

Method: 提出AttNP与物理信息增强的PI-AttNP模型用于间隙导航；在F1TENTH仿真赛车环境中训练评估；引入基于控制屏障函数（CBF）的滤波机制，实现对碰撞规避约束的解析式强制执行。

Result: PI-AttNP相比AttNP收敛更快、预测更准；CBF滤波器轻量、可泛化且能保证实时约束满足；整体框架在闭环控制中展现出具有竞争力的性能与安全性。

Conclusion: 将注意力神经过程与物理先验、形式化安全约束（CBF）相结合，可构建兼具高性能与可验证安全性的实时自主导航控制框架。

Abstract: Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.

</details>


### [775] [Learning Legged MPC with Smooth Neural Surrogates](https://arxiv.org/abs/2601.12169)
*Samuel A. Moore,Easop Lee,Boyuan Chen*

Main category: cs.RO

TL;DR: 本文提出了一种平滑神经代理（smooth neural surrogate）和重尾似然训练方法，以提升基于学习模型的模型预测控制（MPC）在腿足机器人中的可靠性、可扩展性和泛化性，尤其在接触动力学和非高斯误差场景下显著改善了零样本运动任务的成功率与性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习与MPC在腿足机器人中具有互补潜力，但将神经网络学习的动力学模型集成到在线规划中面临三大挑战：接触导致的刚性跳变、模型引入的非物理局部不光滑性、以及训练数据引发的非高斯模型误差。

Method: 提出平滑神经代理——一种具备可调光滑性的神经网络，以提供接触过程中的可靠预测与导数；并采用重尾似然函数进行训练，以更好拟合腿足机器人动力学中观测到的经验误差分布。

Result: 在零样本运动任务中，该方法在简单行为上降低累计代价10–50%，在传统神经动力学易失败的困难场景下，成功率从0/5提升至5/5，累计代价降低2–50倍，体现数量级级别的鲁棒性提升。

Conclusion: 平滑神经代理结合鲁棒学习显著提升了学习型MPC在腿足机器人中的实用性，为复杂接触动力学下的实时优化控制提供了更可靠、可扩展且泛化能力强的解决方案。

Abstract: Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.

</details>


### [776] [A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics](https://arxiv.org/abs/2601.12244)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 本文综述了面向海洋应用的仿生水下机器人集群技术，整合了仿生协同算法、水下通信策略与系统硬件设计，并提出了多维分类框架以评估现有方法，指出了实际部署中的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 海洋作业日益复杂，亟需智能机器人系统支持；现有水下集群研究在算法、通信与硬件设计方面缺乏系统性整合。

Method: 系统性文献综述，涵盖仿生协同机制（如人工鱼群算法、鲸优化算法等）、水下通信约束与解决方案（声学/光学/混合通信），以及硬件与系统设计进展，并构建多维分类框架进行评估。

Result: 提出了涵盖通信依赖性、环境适应性、能效与集群可扩展性的多维分类框架，统一了算法、通信与系统设计视角，识别出融合趋势、关键挑战及未来研究方向。

Conclusion: 水下仿生集群需跨学科协同优化；实现真实海洋环境中的可靠部署，仍需在鲁棒通信、低功耗协同与可扩展硬件平台等方面取得突破。

Abstract: The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.

</details>


### [777] [An Efficient and Multi-Modal Navigation System with One-Step World Model](https://arxiv.org/abs/2601.12277)
*Wangtian Shen,Ziyang Meng,Jinming Ma,Mingliang Zhou,Diyun Xiang*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级导航世界模型，采用单步生成范式和3D U-Net主干网络结合高效时空注意力机制，显著降低推理延迟，支持高频控制，并集成于基于优化的规划框架中，实验证明其在仿真与真实环境中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端学习型导航策略在3D空间推理和物理世界动态理解上存在不足；当前基于Transformer的世界模型依赖多步扩散或自回归逐帧生成，导致计算延迟高，难以实时部署。

Method: 提出轻量级导航世界模型，采用单步生成范式和3D U-Net主干网络，引入高效时空注意力机制；并将其嵌入基于优化的规划框架，采用锚点初始化以处理多模态目标导航任务。

Result: 在仿真和真实环境的闭环实验中，该系统在效率和鲁棒性上均显著优于当前最先进基线方法。

Conclusion: 单步生成+3D U-Net架构的世界模型可兼顾预测性能与实时性，为学习型机器人导航提供了高效可行的新路径。

Abstract: Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.

</details>


### [778] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: 本文提出OPENNAVMAP，一种轻量级、无结构的拓扑度量地图系统，利用3D几何基础模型实现按需重建，解决了传统结构化方法在无特征环境和大视角变化下的鲁棒性与可维护性问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于结构的地图方法维护成本高，在无特征环境或大视角变化（如众包数据）下失效，亟需更鲁棒、可扩展、易维护的地图表示方法以支持大规模视觉导航与真实场景部署。

Method: 提出OPENNAVMAP系统，融合动态规划序列匹配、几何验证与置信度校准优化，实现无需预建3D模型的粗到精子图对齐；完全基于3D几何基础模型，摒弃显式结构建模。

Result: 在Map-Free基准上平均平移误差为0.62m，优于SfM与回归基线；在15km多会话数据中保持全局一致性，地图融合绝对轨迹误差<3m；完成12次仿真与实物机器人图像目标自主导航任务。

Conclusion: OPENNAVMAP是一种高效、鲁棒、免结构的新型地图构建范式，显著提升多会话视觉导航系统的可扩展性、适应性与实用性。

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [779] [From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots](https://arxiv.org/abs/2601.12353)
*Jie Wang,Peng Du,Yiyuan Zhang,Zhexin Xie,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文综述了水下仿生软体机器人的最新进展，分析了其在不同功能需求、环境因素（如压力、温度、光照、生物多样性）下的设计考量，并探讨了从仿生原理到实际应用的转化路径及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统水下机器人面临高压、噪声和生态破坏等问题，而仿生软体机器人能更好适应海洋环境并实现生态友好交互。

Method: 采用文献综述与系统分析方法，梳理设计要素（功能需求、仿生对象、环境参数）及其对机器人结构与性能的影响。

Result: 归纳了当前水下仿生软体机器人的关键技术进展、典型设计范式与应用案例，并提出了面向实际部署的优化路径。

Conclusion: 水下仿生软体机器人是海洋探索的重要方向；未来需进一步融合多模态感知、自适应材料与智能控制，推动其向更复杂、更自主、更可持续的方向发展。

Abstract: Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.

</details>


### [780] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习（DRL）的无人机蜂群集体导航控制器，适用于无通信环境，在仅依赖机载LiDAR感知、无需通信与外部定位的情况下，实现隐式领航-跟随的鲁棒协同导航。


<details>
  <summary>Details</summary>
Motivation: 解决通信受限环境下无人机蜂群难以协同导航的问题，受生物群体中‘知情个体引导群体’机制启发，避免对显式通信和全局定位的依赖。

Method: 构建隐式领航-跟随框架：仅领航者拥有目标信息；跟随者通过机载LiDAR感知，结合点云聚类与扩展卡尔曼滤波实现邻机稳定跟踪；在NVIDIA Isaac Sim中GPU加速训练DRL控制器，使跟随者学习融合集群保持与避障的局部策略。

Result: 在仿真与真实世界实验中验证了方法鲁棒性与sim-to-real可迁移性；5架无人机组成的蜂群成功在多样室内外环境中完成无通信、无外部定位的集体导航任务。

Conclusion: 所提DRL控制器能仅凭本地感知实现高效、鲁棒的隐式协同导航，为通信受限场景下的自主蜂群系统提供了可行且实用的新范式。

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [781] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: 本文提出了R-VoxelMap，一种基于几何驱动的递归平面拟合策略的体素建图方法，用于提升在线激光雷达里程计的定位精度。通过RANSAC分离异常点并递归处理，结合基于点分布的有效性检验，有效解决了传统体素地图中平面拟合偏差、过度分割和错误合并等问题，在多个公开SLAM数据集上验证了其高精度、高效率与低内存占用的优势。


<details>
  <summary>Details</summary>
Motivation: 传统体素地图方法（如VoxelMap）在单个体素内使用全部点进行平面拟合，易受异常点干扰，导致平面参数偏差、大平面过度分割及跨物理平面错误合并，影响建图与定位精度。

Method: 提出R-VoxelMap：1）对每个体素采用RANSAC进行鲁棒平面拟合并分离异常点；2）将异常点递归传播至更深层八叉树继续处理；3）设计基于点分布的平面有效性检验算法，防止错误平面合并。

Result: 在多个开源LiDAR(-惯性)SLAM数据集上实验表明，R-VoxelMap相比现有最先进方法具有更高定位与建图精度，同时保持相当的计算效率和内存使用。

Conclusion: R-VoxelMap通过几何驱动的递归平面建模与异常点重利用机制，显著提升了体素地图的几何保真度与鲁棒性，为高精度实时LiDAR SLAM提供了有效解决方案。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [782] [VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research](https://arxiv.org/abs/2601.12395)
*Chao Wang,Anna Belardinelli,Michael Gienger*

Main category: cs.RO

TL;DR: VR2VR是一个双VR头显平台，用于研究触觉丰富的机器人-人类交互（HRI），通过共处物理空间的参与者与隐藏操作员实现虚拟机器人行为的实时映射与真实触觉反馈。


<details>
  <summary>Details</summary>
Motivation: 解决传统物理机器人开发成本高、周期长，以及现有VR原型缺乏真实触觉和身体耦合的问题，推动触觉为中心的HRI研究。

Method: 构建共址双VR头显系统VR2VR，将操作员的动作、面部表情、视线等实时映射到虚拟机器人，并利用逆运动学实现手部精准触控；支持非语言通道（如头部、眼睛、表情）的独立控制与实验调节。

Result: 实现了高保真肢体遥操作与同步物理触觉反馈，支持可复现、可控的触觉HRI实验；验证了其在Wizard-of-Oz式研究中的有效性。

Conclusion: VR2VR降低了触觉中心型具身机器人行为快速原型设计与严格评估的技术门槛，为HRI研究提供了新范式。

Abstract: Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors.

</details>


### [783] [Learning Diverse Skills for Behavior Models with Mixture of Experts](https://arxiv.org/abs/2601.12397)
*Wangtian Shen,Jinming Ma,Mingliang Zhou,Ziyang Meng*

Main category: cs.RO

TL;DR: 本文提出Di-BM方法，利用专家混合模型（MoE）学习多样化技能，通过能量模型建模各专家对应的观测分布，实现多任务模仿学习中专家在观测空间子区域的特化，显著提升多任务性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型在单任务上表现优异，但在多任务设置下因任务间干扰导致性能下降，需解决多任务间的知识冲突与平均效应问题。

Method: 提出Di-BM框架，采用混合专家（MoE）结构，为每个专家关联一个由能量模型（EBM）表征的专属观测分布，并联合训练观测分布与对应的动作模型，实现专家在观测空间子区域的特化；该方法可即插即用集成到标准模仿学习流程中。

Result: 在多个真实机器人操作任务上，Di-BM显著优于当前最优基线；预训练模型在新任务上微调时展现出更高数据效率和专家知识可复用性。

Conclusion: Di-BM通过观测驱动的专家特化机制有效缓解多任务干扰，提升了模仿学习在复杂、多任务机器人场景中的可扩展性与实用性。

Abstract: Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.

</details>


### [784] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

TL;DR: ReWorld是一个通过强化学习对齐视频驱动的具身世界模型与物理真实性、任务完成能力、具身合理性和视觉质量的框架，利用大规模视频偏好数据集和分层奖励模型，结合高效的PPO式对齐算法，显著提升了生成轨迹的多维质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频驱动的世界模型过于关注视觉生成质量，忽视了物理保真度、动态一致性及任务逻辑，尤其在接触密集型操作任务中限制了其下游应用。

Method: 构建约235K规模的视频偏好数据集，训练分层奖励模型以捕捉多维人类偏好；提出一种基于该奖励的、计算高效的PPO风格后训练算法，用于对齐流式世界模型。

Result: ReWorld在物理保真度、逻辑连贯性、具身合理性与视觉质量方面均显著优于先前方法，理论分析与实验验证了其有效性。

Conclusion: ReWorld为提升视频世界模型在机器人学习中的实用性提供了新范式，强调多维对齐而非单一视觉优化。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [785] [KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter](https://arxiv.org/abs/2601.12463)
*Zi Cong Guo,James R. Forbes,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 本文提出了KILO-EKF，一种结合Koopman理论与数据驱动测量建模的扩展卡尔曼滤波器，用于提升复杂或未标定传感器下的状态估计精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统EKF依赖精确的几何或参数化传感器模型，在传感器未充分标定或模型不准确时性能下降；需一种灵活、可学习且保持递归滤波效率的替代方案。

Method: 提出Koopman-Inspired Learned Observations EKF（KILO-EKF）：在EKF预测步不变的前提下，用数据驱动方式学习一个非线性测量提升映射（lifting），将原始测量映射到对状态呈线性关系的特征空间；该映射通过闭式解从带真值的训练数据中直接求得，无需迭代优化；推理时利用学习到的lifting及其雅可比矩阵执行标准EKF更新。

Result: 在真实四旋翼定位任务（IMU+UWB+下视激光）上验证，KILO-EKF相比各类标定程度不同的EKF基线，精度与一致性更优；显著优于依赖不完善几何模型的EKF，同时保持实时推理与快速训练能力。

Conclusion: Koopman启发的测量学习是一种可扩展、高效且无需显式传感器建模的校准替代方法，为复杂传感场景下的递归状态估计提供了新范式。

Abstract: We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.

</details>


### [786] [Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions](https://arxiv.org/abs/2601.12479)
*Miquel Kegeleirs,Lorenzo Garattoni,Gianpiero Francesca,Mauro Birattari*

Main category: cs.RO

TL;DR: 本文提出了一种基于自然语言的去中心化人群重识别方法，利用视觉-语言模型生成可读文本描述代替传统视觉嵌入，在机器人集群中实现无需中心协调的身份聚类与可解释感知。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于视觉嵌入的重识别方法缺乏可解释性、透明性差、难以支持自然语言交互的问题，并满足机器人集群去中心化协作的需求。

Method: 各机器人使用视觉-语言模型（VLM）本地检测并生成个体外观的文本描述；通过去中心化方式对跨机器人文本描述进行相似性比较与聚类；用大语言模型将每簇描述蒸馏为统一代表性文本；支持自然语言查询与解释。

Result: 初步实验表明该方法在身份一致性与可解释性方面性能接近嵌入式方法，但当前受限于文本相似度计算精度和计算开销。

Conclusion: 以自然语言为感知与通信媒介，实现了去中心化、可解释、可查询的机器人集群人员重识别，为具身智能体的语义化协同提供了新范式。

Abstract: We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.

</details>


### [787] [Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands](https://arxiv.org/abs/2601.12523)
*Cem Suulker,Muhie Al Haimus,Thomas Mack,Mohammad Sheikhsofla,Neri Niccolò Dei,Reza Kashef,Hadi Sadati,Federica Barontini,Fanny Ficuciello,Alberto Arezzo,Bruno Siciliano,Sebastien Ourselin,Kaspar Althoefer*

Main category: cs.RO

TL;DR: 本文提出一种被动方法，通过在翻转机器人外壁周期性集成不可伸长的周向收缩环，降低弯曲刚度，从而提升其在狭窄弯曲路径中的导航能力，同时保持其固有的柔软性和顺应性。


<details>
  <summary>Details</summary>
Motivation: 现有翻转机器人依赖人工肌肉或主动尖端转向机制实现导航，但增加了结构复杂性，损害了其柔软性和顺应性优势。

Method: 在机器人外壁周期性集成不可伸长的直径减小周向环，引入可控屈曲点以降低局部弯曲刚度；建立基于Cosserat杆理论的数学模型描述其力学行为；通过实验验证性能提升。

Result: 实验表明该设计使机器人尖端弯曲刚度最高降低91%，可稳定通过弯曲半径低至25 mm的180度弯道（优于标准机器人35 mm），并在结肠仿体中验证可行性。

Conclusion: 该被动刚度调控方法显著提升了翻转机器人在高度弯曲路径中的机动性，且不牺牲柔软性或增加机械复杂性，拓展了其在管道检测和结肠镜等医疗场景的应用潜力。

Abstract: Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.

</details>


### [788] [RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments](https://arxiv.org/abs/2601.12701)
*Yunpeng Lyu,Chao Cao,Ji Zhang,Howie Choset,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文提出了一种用于处理带概率终端的哈密顿路径问题（HPP-PT）的新方法RPT*，通过动态规划与新启发式搜索克服历史依赖性，并构建了HATS系统用于自主目标搜索，在仿真和真实机器人实验中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统路由问题未充分考虑不确定性，而实际目标搜索任务中，目标位置具有先验概率分布，需在不确定环境下高效规划路径。

Method: 提出RPT*搜索算法，结合动态规划构建无历史依赖的状态空间，并设计新型启发式函数；进一步构建HATS系统，集成RPT*与贝叶斯滤波或自主探索模块。

Result: 在仿真与真实机器人实验中，HATS系统相比基线方法能更快速、更平均地找到目标，实现了探索与利用的自然平衡。

Conclusion: RPT*有效解决了HPP-PT中的历史依赖难题，HATS系统为不确定环境下的自主目标搜索提供了实用且高效的解决方案。

Abstract: Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.

</details>


### [789] [AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation](https://arxiv.org/abs/2601.12742)
*Xuecheng Chen,Zongzhuo Liu,Jianfa Ma,Bang Du,Tiantian Zhang,Xueqian Wang,Boyu Zhou*

Main category: cs.RO

TL;DR: AirHunt 是一种面向无人机的开放集物体导航系统，通过异步双通路架构融合视觉语言模型（VLM）语义推理与连续路径规划，在户外环境中实现零样本语义引导的高效、鲁棒飞行。


<details>
  <summary>Details</summary>
Motivation: 现有基于大视觉语言模型（VLM）的无人机搜索系统受限于VLM推理频率远低于实时规划需求、3D场景理解能力弱，且缺乏在大规模环境中平衡语义引导与运动效率的统一机制。

Method: 提出AirHunt系统，包含：（1）双路径异步架构，解耦并协同VLM推理与路径规划；（2）主动双任务推理模块，利用几何与语义冗余实现选择性VLM查询；（3）语义-几何一致规划模块，在统一框架中动态协调语义优先级与运动效率。

Result: 在多类开放集物体导航任务和多样环境（含真实场景）中，AirHunt相比SOTA方法显著提升成功率、降低导航误差与飞行时间。

Conclusion: AirHunt有效弥合了VLM语义能力与无人机实时三维导航之间的鸿沟，为零样本、高效率、强适应性的空中语义导航提供了可行框架。

Abstract: Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.

</details>


### [790] [FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation](https://arxiv.org/abs/2601.12790)
*Yang Zhang,Jianming Ma,Liyun Yan,Zhanxiang Cao,Yazhou Zhang,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: 本文提出FocusNav框架，通过空间选择性注意机制，在人形机器人局部导航中平衡长程目标与即时运动稳定性，显著提升复杂动态环境下的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在非结构化和动态环境中进行鲁棒的局部导航仍面临挑战，需兼顾长距离导航目标与即时运动稳定性。

Method: 提出FocusNav空间选择性注意框架，包含两个核心模块：Waypoint-Guided Spatial Cross-Attention（WGSCA）用于基于无碰撞航点序列聚合环境特征；Stability-Aware Selective Gating（SASG）模块在检测到不稳时自主截断远端感知信息，强制策略优先保障落脚安全。

Result: 在Unitree G1人形机器人上大量实验表明，FocusNav在挑战性场景中显著提升导航成功率，在避障与运动稳定性方面均优于基线方法。

Conclusion: FocusNav实现了对感知场的自适应调控，使导航策略能根据任务意图与实时稳定性状态动态聚焦关键信息，从而在复杂动态环境中实现鲁棒导航。

Abstract: Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.

</details>


### [791] [Contact-Aware Neural Dynamics](https://arxiv.org/abs/2601.12796)
*Changwei Jing,Jai Krishna Bandi,Jianglong Ye,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 本文提出了一种隐式的sim-to-real对齐框架，通过引入触觉接触信息学习一个接触感知的神经动力学模型，以修正现成仿真器的动力学输出，从而提升状态预测精度和策略迁移性能。


<details>
  <summary>Details</summary>
Motivation: 显式系统辨识难以准确建模真实世界中复杂、高维、状态依赖且含非光滑接触的动力学，导致sim-to-real差距显著。

Method: 将现成仿真器作为基础先验，利用机器人手部触觉接触信号，训练一个接触感知的神经动力学模型来修正仿真状态；该模型隐式地对齐仿真与真实动力学。

Result: 所提方法显著提升了接触丰富任务中的状态预测精度，并能有效预测策略性能、优化纯仿真训练的策略，缩小sim-to-real差距。

Conclusion: 基于触觉接触信息的隐式神经动力学建模是一种可扩展、数据驱动的sim-to-real对齐新范式，尤其适用于含复杂接触的机器人学习任务。

Abstract: High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.

</details>


### [792] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

TL;DR: 本文提出FRoM-W1开源框架，通过语言驱动实现通用人形机器人全身运动控制，包含语言到人体动作生成模型（H-GPT）和机器人运动控制器（H-ACT），并在真实机器人上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人动作多为硬编码或特定训练，缺乏通用性与灵活性，亟需一种能理解自然语言并生成稳定物理执行动作的通用控制框架。

Method: 采用两阶段方法：(a) H-GPT——基于大规模人类运动数据训练的语言驱动全身动作生成大模型，引入思维链提升指令理解泛化能力；(b) H-ACT——将人体动作重定向至机器人后，通过仿真中预训练+强化学习微调的运动控制器，并借助模块化sim-to-real部署至实体机器人。

Result: 在HumanML3D-X基准上动作生成性能优越；强化学习微调显著提升动作跟踪精度与任务成功率；成功部署于Unitree H1和G1真实机器人。

Conclusion: FRoM-W1实现了自然语言到物理世界人形机器人稳定动作执行的端到端闭环，开源框架有望推动具身智能与人形机器人智能化发展。

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [793] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

TL;DR: 本文提出Sparse ActionGen (SAG)，一种面向实时视觉运动控制的稀疏动作生成方法，通过 rollout-adaptive 的剪枝-重用机制和环境感知的扩散剪枝器，在不损失性能的前提下实现最高4倍的生成加速。


<details>
  <summary>Details</summary>
Motivation: Diffusion Policy虽在建模多模态动作分布上表现优异，但其多步去噪过程难以满足实时控制需求；现有基于缓存的加速方法采用静态调度策略，无法适应机器人与环境交互的动态性，导致性能次优。

Method: SAG提出rollout-adaptive的prune-then-reuse机制：1）全局识别可剪枝计算；2）重用缓存激活值替代之；3）设计观测条件化的扩散剪枝器以实现环境感知自适应；4）采用跨时间步与网络块的zig-zag式‘一劳永逸’重用策略以最小化冗余。

Result: 在多个机器人基准上，SAG实现最高4×动作生成加速，且性能无损。

Conclusion: SAG通过动态、稀疏、重用三者协同，有效解决了扩散策略在实时 visuomotor 控制中的效率瓶颈，为实际部署提供了可行路径。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [794] [PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning](https://arxiv.org/abs/2601.12901)
*Hongchen Li,Tianyu Li,Jiazhi Yang,Haochen Tian,Caojun Wang,Lei Shi,Mingyang Shang,Zengrong Lin,Gaoqiang Wu,Zhihui Hao,Xianpeng Lang,Jia Hu,Hongyang Li*

Main category: cs.RO

TL;DR: 本文提出PlannerRFT，一种面向扩散模型规划器的样本高效强化微调框架，通过双分支优化提升多模态与场景自适应轨迹生成能力，并结合加速仿真器nuMax实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的规划器在强化微调中难以生成多模态、场景自适应的轨迹，导致奖励信息利用效率低。

Method: 提出PlannerRFT框架，采用双分支优化：一者优化轨迹分布，二者自适应引导去噪过程以促进有益探索；同时设计轻量级仿真器nuMax，提速rollout达10倍。

Result: PlannerRFT在多项指标上达到SOTA，且学习过程中展现出显著差异化的驾驶行为。

Conclusion: PlannerRFT有效提升了扩散规划器的样本效率与行为多样性，为自动驾驶中类人轨迹生成提供了新范式。

Abstract: Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.

</details>


### [795] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 本文提出了一种基于高斯混合模型（GMM）的无监督方法，用于实时准确识别动态手势，以支持人机交互中机器人操纵任务的指令识别。


<details>
  <summary>Details</summary>
Motivation: 为实现人与机器人之间无缝交互，需准确识别与机器人操纵任务相对应的动态手势，而这些手势存在多种动态变化，传统方法难以应对。

Method: 采用基于高斯混合模型（GMM）的无监督学习模型，对多种动态变化的手势进行建模与实时识别。

Result: 在训练和实时测试中均表现出高识别精度，验证了该方法的有效性。

Conclusion: 所提出的无监督GMM方法能有效应对动态手势的多样性，在实时性与准确性上具有优势，适用于人机交互场景。

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [796] [ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation](https://arxiv.org/abs/2601.12925)
*Weize Xie,Yi Ding,Ying He,Leilei Wang,Binwen Bai,Zheyi Zhao,Chenyang Wang,F. Richard Yu*

Main category: cs.RO

TL;DR: 本文提出了一种名为ForeDiffusion的前瞻性条件扩散策略，通过在扩散过程中注入预测的未来视角表征，并结合去噪损失与未来观测一致性损失的双损失机制，显著提升了复杂机器人操作任务的成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在复杂任务中成功率显著下降，主要受限于仅依赖短期观测作为条件、以及单一去噪损失导致误差累积和抓取偏差。

Method: 提出Foresight-Conditioned Diffusion（ForeDiffusion），将预测的未来视角表征作为扩散过程的条件，并引入双损失机制：传统去噪损失 + 未来观测一致性损失。

Result: 在Adroit和MetaWorld基准上，ForeDiffusion整体任务平均成功率达80%，在复杂任务中比主流扩散方法提升23%，且全任务表现更稳定。

Conclusion: 注入未来视角信息与联合优化双损失可有效缓解误差累积、增强策略前瞻性，为高维动作序列生成提供了更鲁棒的扩散建模范式。

Abstract: Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.

</details>


### [797] [Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design](https://arxiv.org/abs/2601.12939)
*Kaleem Arshid,Ali Krayani,Lucio Marcenaro,David Martin Gomez,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 本文提出了一种基于主动推理（Active Inference）的无人机集群自主轨迹设计框架，融合概率推理与自学习能力，实现分布式任务分配、路径排序与运动规划；通过遗传算法结合排斥力生成专家轨迹，训练分层世界模型，并在运行中最小化信念状态与预测状态间的散度，从而提升适应性、稳定性与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习方法（如Q-Learning）在无人机集群控制中收敛慢、稳定性差、环境适应性弱等问题，提升智能体决策的认知可解释性与系统可扩展性。

Method: 构建基于主动推理的分层世界模型，利用GA-RF生成专家轨迹进行监督预训练；在线阶段各UAV通过变分推断最小化信念-预测散度以自主选择动作，实现分布式的任务-路径-运动三级协同。

Result: 仿真表明该方法相比Q-Learning具有更快的收敛速度、更高的运行稳定性及更安全的导航性能，验证了其在动态环境中良好的可扩展性与认知合理性。

Conclusion: 主动推理为无人机集群提供了具备认知基础的自主决策范式，所提框架在保持分布式特性的同时显著提升了鲁棒性与适应性，是迈向真正智能群体控制的重要一步。

Abstract: This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.

</details>


### [798] [Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration](https://arxiv.org/abs/2601.12952)
*Shibo Shao,Dong Zhou,Guanghui Sun,Liwen Zhang,Mingxuan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种基于模仿学习的航天器交会对接控制框架（IL-SRD），通过专家示范数据直接学习控制策略，减少对精确动力学模型的依赖；引入锚定解码器目标机制和时间聚合机制，提升6-DOF控制的物理一致性和时序鲁棒性；仿真表明其在模型无关、抗干扰和能效方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有航天器交会对接控制方法严重依赖预设动力学模型，在真实在轨环境中鲁棒性不足。

Method: 提出基于模仿学习的IL-SRD框架；设计锚定解码器目标机制（以状态相关锚点约束解码器查询），保障控制演化的物理一致性；引入时间聚合机制缓解Transformer序列预测中的误差累积。

Result: 仿真验证IL-SRD实现了高精度、低能耗的模型无关6-DOF交会对接控制，并在强未知扰动下保持良好鲁棒性。

Conclusion: IL-SRD是一种不依赖精确建模、具备强鲁棒性和物理一致性的新型交会对接控制方法，为自主在轨服务提供了可行技术路径。

Abstract: Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.

</details>


### [799] [Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization](https://arxiv.org/abs/2601.12993)
*Hao Luo,Ye Wang,Wanpeng Zhang,Sipeng Zheng,Ziheng Xi,Chaoyi Xu,Haiweng Xu,Haoqi Yuan,Chi Zhang,Yiqing Wang,Yicheng Feng,Zongqing Lu*

Main category: cs.RO

TL;DR: 本文提出了Being-H0.5，一种面向跨形态机器人泛化的视觉-语言-动作（VLA）基础模型，通过人类交互轨迹作为通用‘母语’，结合UniHand-2.0大规模多模态数据集、统一动作空间、混合Transformer架构（含Mixture-of-Flow框架）及Manifold-Preserving Gating等技术，实现高效、鲁棒的跨平台技能迁移。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人形态异构性和数据稀缺性方面表现不佳，亟需一种能泛化到多样机器人平台的通用学习范式。

Method: 提出人类中心学习范式；构建UniHand-2.0预训练数据集（35,000+小时、30种机器人）；设计统一动作空间映射异构控制；采用Mixture-of-Transformers与Mixture-of-Flow解耦共享运动原语与形态专用专家；引入Manifold-Preserving Gating和Universal Async Chunking提升现实鲁棒性与控制通用性。

Result: 在LIBERO（98.9%）和RoboCasa（53.9%）仿真基准上达到SOTA；在五种真实机器人平台上验证了强跨形态泛化能力。

Conclusion: Being-H0.5通过人类交互建模与统一架构设计，显著提升了VLA模型在形态异构与数据受限场景下的泛化性与实用性，为通用具身智能提供了新范式。

Abstract: We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

</details>


### [800] [Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks](https://arxiv.org/abs/2601.13042)
*Yijun Zhou,Muhan Hou,Kim Baraka*

Main category: cs.RO

TL;DR: 本文通过对比实验评估了VR控制器和SpaceMouse在静态与动态任务中的遥操作性能，发现VR控制器在成功率、执行时间、工作负荷和可用性方面均显著优于SpaceMouse，尤其在动态任务中表现更佳，并开源了适用于动态任务的VR遥操作接口。


<details>
  <summary>Details</summary>
Motivation: 现有遥操作界面研究主要集中在静态任务上，而动态任务对界面有不同需求，因此需要专门针对动态任务进行评估。

Method: 开展了一项被试内实验（N=25），比较VR控制器与SpaceMouse在两类静态任务和两类动态任务中的表现，评估指标包括成功率、任务时长、累积成功次数、NASA-TLX工作负荷量表、SUS系统可用性量表及开放式反馈。

Result: VR控制器在所有任务中均表现出更高成功率（尤其在动态任务）、更短的成功执行时间、更早达成成功，且NASA-TLX得分更低、SUS得分更高，表明其工作负荷更低、可用性更高。

Conclusion: VR控制器相较SpaceMouse更适合遥操作任务，特别是动态任务；为弥补现有VR遥操作系统缺乏开源且适配动态任务的工具这一空白，作者开源了所开发的VR接口。

Abstract: Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.

</details>


### [801] [Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones](https://arxiv.org/abs/2601.13088)
*Harry Huang,Talia Xu,Marco Zúñiga Zamalloa*

Main category: cs.RO

TL;DR: 本文提出了一种轻于空气（LTA）的微型无人机，利用氦气浮力实现低功耗悬停，并集成太阳能发电与单信标光导航系统，支持室内外自主持续运行。


<details>
  <summary>Details</summary>
Motivation: 微小型无人机因续航短和GPS拒止环境下导航不可靠而受限；LTA无人机虽具能效优势，但缺乏集成化、低基础设施依赖的自主运行方案。

Method: 构建高保真LTA空气动力学仿真框架以优化构型；在氦气囊表面集成太阳能电池实现净正向能量供给；设计基于单光信标的三点式‘指向-前往’导航系统及三种光寻迹算法。

Result: 在80klux光照下，每充电4分钟可飞行1分钟；可在室内外环境中稳定导航至7米外光源，且具备抗中等风扰能力。

Conclusion: 该系统为LTA无人机实现持久、自主的室内外监测任务提供了可行路径，推动了LTA平台向自维持空中系统转化。

Abstract: Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.
  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.
  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.

</details>


### [802] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文提出一种融合大语言模型（LLM）与视觉语言模型（VLM）的自主海港巡检框架，通过空-海协同机器人平台实现语义感知、符号规划与合规性评估，提升巡检的上下文理解力与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有海港巡检依赖人工和传统计算机视觉方法，缺乏可扩展性与上下文理解能力。

Method: 构建LLM-VLM协同框架：LLM负责将自然语言指令转化为带依赖图的符号化任务计划，保障无人机（UAV）与无人船（USV）安全协同；VLM负责实时语义感知与合规性评估，并生成结构化报告。系统在扩展版MBZIRC海事模拟器及真实机器人试验中验证。

Result: 实现了上下文感知、自适应的自主巡检能力；验证了轻量化机载设计对资源受限海上平台的适用性；支持端到端自然语言驱动与结构化报告生成。

Conclusion: 该框架推动了智能、自主海港巡检系统的发展，为复杂 maritime 场景下的AI赋能监管提供了新范式。

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [803] [Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation](https://arxiv.org/abs/2601.13177)
*Behnam Moradkhani,Raghav Sankaranarayanan,Pejman Kheradmand,Harshith Jella,Nicholas Ahn,Ajmal Zemmar,Yash Chitalia*

Main category: cs.RO

TL;DR: 本文提出了一种基于Cosserat杆理论的ExoNav可转向机器人静态模型，用于脊髓刺激（SCS）中精准导航至腹侧和外侧硬膜外间隙，实验显示其定位精度高（RMSE < 3.75mm），并验证了其在模拟与体模中实现随动（FTL）运动及多靶点（如DRG）导航的能力。


<details>
  <summary>Details</summary>
Motivation: 传统手动引导难以将SCS电极精准置入腹侧/外侧硬膜外空间（含关键运动传导束），限制了运动功能恢复效果，亟需高精度、可建模的机器人辅助导航工具。

Method: 采用Cosserat杆理论建立ExoNav机器人的静态力学模型，整合肌腱驱动力、重力等外部载荷，仿真优化肌腱张力以实现期望的随动（FTL）路径；通过四组原型实验与三组FTL试验验证模型精度，并在体模中开展远程操作导航验证。

Result: 模型预测精度高（各原型RMSE为1.33–2.33 mm）；FTL实验最大RMSE为3.75 mm；成功在体模中导航至腹侧、外侧脊髓靶点及背根神经节（DRG）。

Conclusion: 所提出的静态模型能有效支持ExoNav机器人在重力影响下实现高精度、可重复的硬膜外靶向导航，拓展了SCS在运动功能恢复与疼痛管理双领域的临床应用潜力。

Abstract: Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.

</details>


### [804] [Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations](https://arxiv.org/abs/2601.13196)
*Jacob Swindell,Marija Popović,Riccardo Polvara*

Main category: cs.RO

TL;DR: 本文研究了高斯过程（GP）在无人机杂草测绘中的离散化表示方法对映射质量和任务性能的影响，提出了一种基于不确定性的滚动时域信息路径规划（IPP）策略，并通过真实杂草分布实验验证了离散化选择对探索行为、覆盖效率和计算负载的关键影响。


<details>
  <summary>Details</summary>
Motivation: 传统无人机杂草测绘依赖固定飞行路径和离线处理，而信息路径规划（IPP）可自适应采集关键数据；高斯过程（GP）能建模连续杂草分布并提供不确定性估计，但其实际应用需离散化，而不同离散化方式的影响尚不明确。

Method: 采用配备下视相机的无人机，实现基于地图不确定性、航程代价和覆盖惩罚的滚动时域信息路径规划（IPP）；对比多种GP后验离散化策略，利用其生成的地图划分构造候选观测视角，并在真实杂草数据上开展实验评估。

Result: 实验证明，不同离散化表示显著影响无人机的探索行为与测绘效率；离散化不仅是实现细节，更是影响规划动态、覆盖效率和计算负载的关键设计选择。

Conclusion: GP离散化方式是无人机在线杂草测绘中一个关键且不可忽视的设计因素，需根据具体任务目标（如精度、效率、实时性）审慎选择。

Abstract: Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.

</details>


### [805] [MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation](https://arxiv.org/abs/2601.13232)
*Kourosh Darvish,Arjun Sohal,Abhijoy Mandal,Hatem Fakhruldeen,Nikola Radulov,Zhengxue Zhou,Satheeshkumar Veeramani,Joshua Choi,Sijie Han,Brayden Zhang,Jeeyeoun Chae,Alex Wright,Yijie Wang,Hossein Darvish,Yuchi Zhao,Gary Tom,Han Hao,Miroslav Bogdanovic,Gabriella Pizzuto,Andrew I. Cooper,Alán Aspuru-Guzik,Florian Shkurti,Animesh Garg*

Main category: cs.RO

TL;DR: 本文提出MATTERIX，一个基于GPU加速的多尺度机器人化学实验模拟框架，用于构建高保真度的化学实验室数字孪生体，以加速自动化实验流程开发并减少实物试错。


<details>
  <summary>Details</summary>
Motivation: 加速材料发现面临实验试错成本高、可扩展性差的问题，亟需一种能替代或减少真实实验迭代的虚拟仿真方法。

Method: 构建了一个集成物理仿真、光栅化渲染与模块化GPU加速语义引擎的多尺度数字孪生框架，支持机械操作、流体动力学、设备功能、传热及基础反应动力学建模，并提供开源资产库、分层规划定义和基于学习的技能库。

Result: 实现了从仿真到现实（sim-to-real）的成功迁移，在机器人化学实验中验证了其有效性，显著降低了对昂贵真实实验的依赖，并支持在计算机中测试假设性自动化流程。

Conclusion: MATTERIX为自动化化学研究提供了可扩展、高保真、易用的数字孪生基础设施，有望推动材料科学及其他实验科学的智能化与加速发展。

Abstract: Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .

</details>


### [806] [Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation](https://arxiv.org/abs/2601.13250)
*Ante Marić,Giammarco Caroleo,Alessandro Albini,Julius Jankowski,Perla Maiolino,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了一种基于去噪扩散模型的逆触觉传感器建模方法，结合粒子滤波实现无视觉、弱先验下的物体位姿估计，并在仿真与真实场景中验证了其有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 触觉感知在视觉受限（如遮挡或环境干扰）的操作任务中对物体位姿估计具有潜力，但因触觉观测存在部分可观测性（单次观测对应多种接触构型），传统面向视觉的估计方法难以高效利用触觉数据。

Method: 提出基于去噪扩散的逆触觉传感器模型，以分布式触觉传感器观测为条件，在基于有号距离场（SDF）的几何传感器模型仿真中训练；推理时通过SDF的距离与梯度信息进行单步投影以满足接触约束；在线估计中将该逆模型与粒子滤波结合，采用融合生成假设与先验粒子的提议机制。

Result: 在仿真与真实世界的平面位姿估计任务中取得良好效果，无需视觉数据或强初始位姿先验；在盒子推动场景中展现出对未建模接触与传感器动态的鲁棒性；相比局部采样基线，提升了采样效率与估计精度，同时保持对不同触觉可分辨性物体的多模态信念。

Conclusion: 基于扩散模型的逆触觉建模与粒子滤波集成框架，为部分可观测触觉感知下的鲁棒、高效、多模态位姿估计提供了新范式。

Abstract: Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability.

</details>


### [807] [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](https://arxiv.org/abs/2601.13252)
*Mahmud S. Zango,Jianglin Lan*

Main category: cs.RO

TL;DR: 本文综述了面向纳米级无人机（nano-UAVs）的自主导航技术，聚焦于超低功耗（<100 mW）约束下的感知、计算与控制架构，分析了从传统几何方法到边缘AI（如量化神经网络、神经形态事件驱动控制）的演进，并指出在续航、动态避障和Sim-to-Real迁移等方面仍存挑战，提出轻量经典控制与数据驱动感知融合的混合架构路线。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机受限于极小的尺寸、重量和功耗（SWaP），传统机器人自主导航方法不适用，亟需面向超低功耗计算环境的专用感知、计算与控制方案。

Method: 系统性综述与批判性分析，涵盖边缘AI算法（量化DNN、神经形态控制）、硬件-软件协同设计、密集光流、优化SLAM及学习型飞行控制等前沿方向。

Result: 总结了视觉导航与相对位姿估计的显著进展，同时识别出长时续航、动态环境鲁棒避障及强化学习Sim-to-Real迁移三大关键瓶颈。

Conclusion: 应发展融合轻量经典控制与数据驱动感知的混合架构，以实现GPS拒止环境下完全自主、敏捷的纳米无人机。

Abstract: Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

</details>


### [808] [CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments](https://arxiv.org/abs/2601.13361)
*Pranay Meshram,Charuvahan Adhivarahan,Ehsan Tarkesh Esfahani,Souma Chowdhury,Chen Wang,Karthik Dantu*

Main category: cs.RO

TL;DR: CLEAR是一种新型地形抽象表示方法，通过边界感知的空间分解与递归平面拟合，生成语义对齐、凸形的区域图，显著提升大范围（10+ km²）自主地面车辆导航的规划速度与路径可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如网格和四叉树）无法同时满足大规模（数十平方公里）地形建模的可扩展性、几何保真度与地表覆盖语义编码需求，导致长距离导航路径不可行或不可靠。

Method: CLEAR结合边界感知的空间分解与递归平面拟合，构建凸形、语义对齐的区域，并以地形感知图形式编码。

Result: 在9–100 km²地图上测试，CLEAR比原始网格规划快达10倍，仅增加6.7%代价开销，并生成比其他基线短6–9%、更可靠的路径。

Conclusion: CLEAR在可扩展性与实用性上取得突破，适用于灾害响应、国防及行星探测等长程导航场景。

Abstract: Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.

</details>


### [809] [Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections](https://arxiv.org/abs/2601.13389)
*Zhaohui Liang,Chengyuan Ma,Keke Long,Xiaopeng Li*

Main category: cs.RO

TL;DR: 本文提出了一种统一框架，通过控制鲁棒性和环境韧性两个互补标准评估生态驾驶策略，并在真实车辆实验中验证了不同控制器的性能权衡。


<details>
  <summary>Details</summary>
Motivation: 现有生态驾驶策略评估多依赖简化仿真或实验条件，缺乏对实际复杂性和干扰因素的充分考虑。

Method: 构建基于控制鲁棒性（内部执行变异性）和环境韧性（外部环境扰动）的统一评估框架，定义形式化指标，并通过实车实验对比多种生态驾驶控制器。

Result: 优化类控制器在不同扰动水平下性能更稳定；解析类控制器在理想条件下表现相近，但对执行与时间变异更敏感。

Conclusion: 生态驾驶策略需兼顾跟踪精度与适应性，鲁棒性与韧性是关键评估维度，应纳入实际部署前的综合评估体系。

Abstract: Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.

</details>


### [810] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

TL;DR: 本文提出了一种结合混合神经网络（HNN）与脉冲神经网络（SNN）滤波的机器人视觉导航新框架，通过ANN处理静态空间特征、SNN实时处理事件数据，实现高精度环境感知与低功耗高效计算。


<details>
  <summary>Details</summary>
Motivation: 提升机器人在不可预知动态环境中的态势感知能力，尤其针对未建模障碍物的检测与定位，克服传统混合架构依赖域转换机制的局限。

Method: 构建双通路架构：低频ANN处理静态空间特征，实时SNN直接处理脉冲编码传感器数据；引入预训练SNN滤波器用于定位与状态估计，并融合ANN上下文信息验证异常、持续跟踪以支持前瞻性导航。

Result: 仿真表明该方法在保持接近纯SNN实现的计算效率（极低资源开销）的同时，获得可接受的检测精度。

Conclusion: 该框架显著推进了面向动态环境的类脑神经形态导航系统的发展，兼具准确性、实时性与能效优势。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [811] [The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study](https://arxiv.org/abs/2601.13529)
*Pejman Kheradmand,Kent K. Yamamoto,Emma Webster,Keith Sowards,Gianna Hatheway,Katharine L. Jackson,Sabino Zani,Julie A. Raffi,Diandra N. Ayala-Peacock,Scott R. Silva,Joanna Deaton Bertram,Yash Chitalia*

Main category: cs.RO

TL;DR: 本文提出了一种名为OncoReach的可操控式导丝，用于改进宫颈癌间质近距离放射治疗（ISBT），通过兼容标准针具实现更灵活的穿刺路径规划，提升靶区覆盖并减少创伤。


<details>
  <summary>Details</summary>
Motivation: 传统直针限制了ISBT的穿刺路径仅为线性，难以从微创入路到达侧向深部靶区，影响治疗效果与患者康复。

Method: 设计并优化一种基于腱驱动、带球形关节的可弯曲导丝（OncoReach），结合自由空间实验、Cosserat杆模型仿真及多组分子宫-盆腔仿体的专家操作试点研究进行验证。

Result: 最优构型导丝在保持轴向刚度的同时显著提升弯曲顺应性；模型预测精度高；在仿体中成功实现从内侧微创入路转向外侧靶点的操控。

Conclusion: OncoReach导丝具备临床转化潜力，有望拓展ISBT的适应症范围并提升治疗精准性与微创性。

Abstract: Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets.

</details>


### [812] [LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI](https://arxiv.org/abs/2601.13556)
*Jianan Wang,Siyang Zhang,Bin Li,Juan Chen,Jingtao Qi,Zhuo Zhang,Chen Qian*

Main category: cs.RO

TL;DR: 本文提出LogicEnvGen，一种基于大语言模型的自上而下环境生成方法，旨在提升模拟环境中逻辑多样性，以更全面评估具身智能体的适应性与规划鲁棒性；同时提出LogicEnvEval基准用于量化评估。


<details>
  <summary>Details</summary>
Motivation: 现有模拟环境生成方法偏重视觉真实感，忽视逻辑多样性，难以全面评估智能体在不同任务情境下的适应性与规划鲁棒性。

Method: LogicEnvGen利用LLM分析任务执行逻辑，构建决策树式行为计划，生成逻辑轨迹集合，并通过启发式算法去冗余；对每条逻辑轨迹，结合约束求解实例化为物理合理的具体环境。配套提出LogicEnvEval基准，含四个定量评估指标。

Result: 实验表明基线方法逻辑多样性不足，LogicEnvGen在逻辑多样性上提升1.04–2.61倍，并将暴露智能体缺陷的能力提升4.00%–68.00%。

Conclusion: LogicEnvGen有效提升了模拟环境的逻辑多样性，为具身AI测试提供了更系统、可量化的生成与评估新范式。

Abstract: Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.

</details>


### [813] [Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction](https://arxiv.org/abs/2601.13574)
*Guanyu Xu,Jiaqi Wang,Dezhong Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于光学波导传感的柔性硅胶本体感知膜，通过LED-PD阵列与液态金属导线实现大变形下的实时3D表面形变重建，具有高鲁棒性、低剖面和抗电磁干扰优势。


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法在低光照或遮挡下不可靠，而现有本体感知膜存在结构复杂、顺应性差、易受电磁干扰等问题，亟需一种更鲁棒、柔软且可扩展的3D形变感知方案。

Method: 设计了一种多层弹性体复合材料封装的软性硅胶膜，集成边缘LED与中心分布的光电二极管（PD），通过嵌入式液态金属导线连接；利用光强随膜变形变化的信号，结合数据驱动模型重建3D点云。

Result: 在140 mm方形膜上实现90 Hz实时重建，平均Chamfer距离误差为1.3 mm，支持最大25 mm深度的凹陷识别。

Conclusion: 该光学波导型本体感知膜为可变形机器人系统提供了可扩展、鲁棒且低剖面的全局形状感知新范式。

Abstract: Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.

</details>


### [814] [A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint](https://arxiv.org/abs/2601.13639)
*Deyun Qin,Zezhi Liu,Hanqian Luo,Xiao Liang,Yongchun Fang*

Main category: cs.RO

TL;DR: 本文提出了一种通用的一次性多模态主动感知框架，用于视觉引导的机器人操作，通过解耦视角质量评估与整体架构，支持异构任务需求，并在抓取任务中验证了其高效性和sim-to-real迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法依赖迭代优化，时间与运动成本高，且与任务目标强耦合，缺乏可迁移性。

Method: 构建数据采集流程和最优视角预测网络；通过系统采样与评估候选视角定义最优视角；采用域随机化构建大规模训练数据集；设计基于交叉注意力的多模态视角预测网络，直接预测相机位姿调整。

Result: 在视角受限环境下的机器人抓取任务中，该框架显著提升抓取成功率；真实场景中抓取成功率近翻倍，且无需微调即可实现无缝sim-to-real迁移。

Conclusion: 所提框架具备通用性、高效性和强迁移能力，为视觉引导机器人操作提供了新范式。

Abstract: Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework.

</details>


### [815] [SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation](https://arxiv.org/abs/2601.13732)
*Andreas Wiedholz,Rafael Paintner,Julian Gleißner,Alwin Hoffmann,Tobias Huber*

Main category: cs.RO

TL;DR: 本文提出了SUNSET，一个基于ROS2的自适应机器人软件系统评估实例，用于在存在不确定性和并发不确定性的情况下，严格、可重复地评估基于架构的自适应方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在动态环境中部署增多及软件系统复杂性增加，需要自适应方法来应对不确定性（症状易观察但根源模糊）和并发不确定性。

Method: 构建了基于ROS2的SUNSET实例，实现了一个由训练好的机器学习模型驱动的传感器融合语义分割流水线，并通过扰动输入预处理引入真实性能退化；支持五种可观测症状及其不同根因，并涵盖自愈与自优化场景。

Result: SUNSET提供了完整的语义分割流水线、训练好的ML模型、不确定性注入脚本、基线控制器以及详细的集成与评估文档，支持可复现研究与公平比较。

Conclusion: SUNSET为在复杂动态环境下评估机器人系统的架构级自适应能力提供了一个严谨、可复现且实用的基准平台。

Abstract: The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.

</details>


### [816] [RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure](https://arxiv.org/abs/2601.13737)
*Joon Lee,Jeongyoon Han,Doyoung Kim,Seokhwan Jeong*

Main category: cs.RO

TL;DR: 本文提出了一种仿生柔性RIM机械手，通过精确建模人类腕掌关节并采用超弹性镍钛诺（Nitinol）丝构建骨架，结合柔性硅胶皮肤，实现了高灵活性、大接触面积和强负载能力，显著优于刚性手掌设计。


<details>
  <summary>Details</summary>
Motivation: 提升机械手的灵巧性、柔顺性和拟人化程度，以满足假肢和服务机器人对自然手部功能的需求。

Method: 设计并实现一种仿生柔性机械手，建模完整腕掌解剖结构，使用超弹性Nitinol丝作为肌腱和背侧伸肌，配合柔性硅胶皮肤以增强摩擦与接触面积。

Result: 实验表明该手掌可变形达28%，匹配人手灵活性；负载能力超刚性设计两倍以上，接触面积达三倍。

Conclusion: RIM Hand在灵巧性、柔顺性和拟人化方面显著提升，适用于假肢及服务机器人等实际应用。

Abstract: This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.

</details>


### [817] [Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System](https://arxiv.org/abs/2601.13777)
*Zvi Chapnik,Yizhar Or,Shai Revzen*

Main category: cs.RO

TL;DR: 本文比较了四种学习运动性映射（motility map）的方法，用于预测机器人在高摩擦环境中的身体速度，发现简单方法在小数据集上表现更好，而复杂方法在大数据集上更优。


<details>
  <summary>Details</summary>
Motivation: 为了验证几何力学中关于高摩擦环境下运动性映射的有效性，并测试不同建模方法在难以建模的机器人-基底交互下的预测能力。

Method: 比较了四种建模方法，基于物理机器人的运动追踪数据，评估其在相同步态、跨步态和跨速度下从形变预测身体速度的能力。

Result: 观察到模型复杂度与数据量之间的权衡：简单模型在小训练集上预测更准，复杂模型在大数据集上表现更优。

Conclusion: 选择建模方法应根据可用训练数据量权衡模型复杂度，为仿生与机器人运动控制提供实用指导。

Abstract: Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.

</details>


### [818] [HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction](https://arxiv.org/abs/2601.13801)
*Yuhua Jin,Nikita Kuzmin,Georgii Demianchuk,Mariya Lezina,Fawad Mehboob,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HoverAI 是一种集成了无人机移动性、无需基础设施的视觉投影和实时对话式人工智能的空中具身智能体，旨在提升人机共存空间中的通信与意图表达能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在人类活动空间中运行时，缺乏有效的通信机制，导致其意图不明确，引发不确定性。

Method: HoverAI 集成 MEMS 激光投影仪、机载半刚性屏幕和 RGB 摄像头，结合语音活动检测（VAD）、Whisper 语音识别（ASR）、基于大语言模型（LLM）的意图分类、检索增强生成（RAG）对话系统、人脸识别个性化及 XTTS v2 语音合成，构建多模态交互管道，并通过唇形同步虚拟形象响应用户。

Result: 评估显示其指令识别 F1 分数达 0.90，性别估计 F1 为 0.89，年龄估计平均绝对误差为 5.14 年，语音转录词错误率（WER）为 0.181。

Conclusion: HoverAI 将空中机器人、自适应对话 AI 和自包含视觉输出融合，开创了具备空间感知与社交响应能力的新一代具身智能体，适用于导引、辅助与以人为中心的交互场景。

Abstract: Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction.

</details>


### [819] [DroneVLA: VLA based Aerial Manipulation](https://arxiv.org/abs/2601.13809)
*Fawad Mehboob,Monijesu James,Amir Habel,Jeffrin Sam,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种基于自然语言指令的自主空中操作系统，结合Grounding DINO、VLA模型与定制无人机，实现物体识别、导航、抓取及人机安全交互式递送。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台从被动观测转向主动操作，亟需为非专业用户提供直观、自然的人机交互接口。

Method: 融合MediaPipe（基于Grounding DINO）、Vision-Language-Action（VLA）模型、1-DOF夹爪无人机及Intel RealSense RGB-D相机；VLA解析语义并生成任务队列，Grounding DINO与动态A*实现定位导航，MediaPipe驱动人本控制器实现视觉伺服手递控制。

Result: 真实实验中定位与导航误差分别为最大0.164m、均值0.070m、均方根0.084m，验证了VLA在空中操作中的可行性。

Conclusion: 该系统成功实现了从自然语言指令到安全、自然手递的端到端空中操作，展示了多模态感知-决策-控制框架在非结构化人机协作场景中的实用潜力。

Abstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

</details>


### [820] [GuideTouch: An Obstacle Avoidance Device for Visually Impaired](https://arxiv.org/abs/2601.13813)
*Timofei Kozlov,Artem Trandofilov,Georgii Gazaryan,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种名为GuideTouch的可穿戴设备，通过双ToF传感器实现三维环境感知，并利用肩胸部四点振动触觉反馈提供方向信息，具备自清洁光学盖和声音报警功能；实验表明其对视觉障碍者具有高识别准确率（92.9%-93.75%），可提升其独立导航的安全性与自主性。


<details>
  <summary>Details</summary>
Motivation: 传统助行设备难以检测头部高度障碍物，导致视障人士安全通行困难，亟需一种能有效感知并提示此类障碍的新型辅助设备。

Method: 设计并实现了一款集成双垂直Time-of-Flight（ToF）传感器与四点振动触觉反馈单元的可穿戴设备GuideTouch；采用4点肩胸分布式触觉编码传递障碍方向与距离信息；引入离心式自清洁光学罩与跌落声音报警机制增强实用性；通过22名健全参与者与14名视障用户开展触觉模式识别准确率评估实验。

Result: 健康参与者对单/双马达主方向模式识别准确率达92.9%，视障用户初步实验中主方向提示识别准确率为93.75%；统计分析证实不同振动模式识别准确率存在显著差异。

Conclusion: GuideTouch是一种紧凑、低成本、自主运行的可穿戴导航辅助设备，其基于方向性振动触觉反馈的设计能有效支持视障用户进行直观空间感知，显著提升其独立出行的安全性、信心与自主性。

Abstract: Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.

</details>


### [821] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: ANCHOR是一个面向具身AI系统的模块化框架，通过显式定义解耦与鲁棒性系统原语，提升其在真实部署中的可演化性、负载适应性与容错恢复能力。


<details>
  <summary>Details</summary>
Motivation: 具身AI系统在实际部署中面临接口漂移、模块间干扰和恢复脆弱等问题，因中间件仅传递消息而隐式共享上下文与反馈语义，导致解耦不彻底。

Method: ANCHOR提出两个核心组件：（i）可演化的标准共享状态契约——Canonical Records；（ii）支持多对多传播与反馈驱动协调的通信总线，并构建可检查的端到端闭环。

Result: 验证了闭环可行性；量化了不同负载与发布速率下的延迟分布；实现了硬崩溃及重启后（含共享内存丢失）的自动流恢复。

Conclusion: ANCHOR将临时集成胶水转化为显式契约，支持负载下的可控降级与自愈恢复，推动闭环AI系统的大规模可靠部署。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [822] [Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects](https://arxiv.org/abs/2601.13979)
*Raffaele Mazza,Ciro Natale,Pietro Falco*

Main category: cs.RO

TL;DR: 本文提出了一种新型跨模态（视觉-触觉）感知框架，用于在严重视觉遮挡下重建可变形线性物体（如电缆）的3D形状，结合SAM与Florence等基础模型进行视觉处理，并通过自适应触觉探索补全遮挡区域，最终用B样条插值得到完整平滑重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉，在光照变化、背景杂乱或部分可见时性能下降；针对DLO（尤其是电缆）在严重视觉遮挡下的3D形状重建难题，需融合鲁棒的触觉反馈与先进视觉模型。

Method: 视觉端：用SAM做实例分割、Florence做语义精修，再经骨架化、端点检测和点云提取；触觉端：自主识别遮挡段并用触觉传感器采集局部点云；跨模态融合：通过欧氏聚类与拓扑保持融合将触觉点云与视觉点云合并；重建：基于端点引导的点排序与B样条插值生成连续3D电缆形状。

Result: 在配备RGB-D相机和触觉垫的机械臂平台上验证，能准确重建简单及高度弯曲的单/多电缆构型，即使大范围遮挡仍保持高精度。

Conclusion: 基础模型增强的跨模态感知可显著提升机器人对可变形物体的操作能力，尤其适用于复杂、遮挡严重的实际场景。

Abstract: This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.

</details>


### [823] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

TL;DR: 本文提出Group-Invariant Skill Discovery (GISD)框架，通过在技能发现目标中显式嵌入群结构，利用环境对称性提升无监督技能学习的效率与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法常忽略物理环境的几何对称性，导致行为冗余和样本效率低。

Method: 基于群对称环境下Wasserstein依赖度量存在等变策略与群不变评分函数构成全局最优解的理论保证，提出群不变Wasserstein依赖度量；使用群傅里叶表示参数化评分函数，并通过等变隐特征对齐定义内在奖励。

Result: 在状态和像素级运动控制基准实验中，GISD相比强基线实现了更广的状态空间覆盖和更高效的下游任务学习。

Conclusion: GISD通过显式建模环境对称性，提升了技能发现的样本效率与系统泛化能力，为无监督强化学习提供了新的理论与实践路径。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [824] [Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems](https://arxiv.org/abs/2601.14091)
*Hossein Naderi,Alireza Shojaei,Lifu Huang,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本研究探索了基础模型在提升建筑机器人任务规划适应性和泛化能力方面的潜力，提出了基于轻量级开源大语言模型（LLMs）和视觉语言模型（VLMs）的单智能体与多智能体架构，并在三种建筑角色任务中验证其性能优于GPT-4o且成本更低。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人面临高成本和难以适应动态任务的挑战，亟需提升其任务规划的适应性与泛化能力。

Method: 提出并实现了四种基于轻量级开源LLMs和VLMs的模型：一个单智能体模型和三个多智能体协作团队模型，用于生成机器人动作规划；在Painter、Safety Inspector和Floor Tiling三类建筑任务中进行评估。

Result: 四智能体团队在多数指标上超越GPT-4o，且成本仅为后者的十分之一；三、四智能体团队展现出更强的泛化能力。

Conclusion: 多智能体协作架构能有效提升建筑机器人任务规划的性能与成本效益，相关发现有助于推动AI团队在非结构化环境（如建筑及其他领域）中的进一步研究与应用。

Abstract: Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.

</details>


### [825] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

TL;DR: 本文提出了一种面向真实机器人系统的扩散引导后门攻击框架（DGBA），通过在地面放置可打印的视觉补丁触发器，并利用条件扩散模型生成适应真实视觉变化的多样化补丁；同时采用优势驱动的中毒策略，在决策关键状态注入触发器，以绕过物理部署中安全控制模块（如速度限制、动作平滑）的抑制作用。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习后门攻击大多仅在仿真环境中验证，其在真实机器人系统中的有效性尚不明确；而实际部署中的安全约束控制流程（如速度限制、动作平滑、避障）会显著削弱传统后门攻击效果。

Method: 提出扩散引导后门攻击框架（DGBA）：1）设计小型可打印地面视觉补丁作为触发器；2）使用条件扩散模型生成适应真实视觉变化的多样化补丁；3）将机器人控制栈视为黑盒；4）引入基于优势函数的中毒策略，仅在决策关键训练状态注入触发器。

Result: 在TurtleBot3移动机器人上成功验证了所提方法，实现了目标后门行为的可靠激活，同时保持正常任务性能不受影响。

Conclusion: DGBA有效克服了真实机器人部署中安全控制机制对后门攻击的抑制，为评估和提升现实RL系统鲁棒性与安全性提供了新思路与实用工具。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [826] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: 本文提出SandWorm机器人与SWTac事件式触觉传感器，结合生物启发设计与算法优化，在颗粒介质中实现高精度感知与稳健运动。


<details>
  <summary>Details</summary>
Motivation: 颗粒介质中粒子动力学不可预测，导致感知困难。

Method: 提出仿生螺旋驱动机器人SandWorm与主动振动弹性体耦合的事件式触觉传感器SWTac；采用弹簧隔振机制解耦振动干扰；设计IMU引导的时间滤波器提升成像一致性；系统优化振动参数、事件相机设置与弹性体特性；利用U-Net基于不对称边缘特征估计接触表面。

Result: SWTac实现0.2 mm纹理分辨率、98%石块分类准确率、0.15 N力估计误差；SandWorm在复杂颗粒介质中达12.5 mm/s运动速度，管道清淤与地下探测成功率90%；野外实验验证实用性。

Conclusion: 该软硬件协同系统显著提升了颗粒介质中的感知精度与运动适应性，为地下/非结构化环境作业提供了新范式。

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>


### [827] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

TL;DR: 本文提出TwinBrainVLA架构，通过冻结通用视觉语言模型（左脑）与训练专用具身感知模型（右脑）协同工作，结合AsyMoT机制和Flow-Matching动作专家，兼顾高层语义理解与低层传感器运动控制，缓解灾难性遗忘，在仿真基准上实现性能与通用能力的双重提升。


<details>
  <summary>Details</summary>
Motivation: 解决标准VLA模型在微调过程中因兼顾高层语义理解和低层传感器运动技能而导致的灾难性遗忘问题。

Method: 提出TwinBrainVLA双脑架构：冻结的‘左脑’（通用VLM）保持语义理解能力，可训练的‘右脑’（专用VLM）专注具身感知；引入非对称混合Transformer（AsyMoT）机制使右脑能动态查询并融合左脑语义知识与本体感觉状态；再由Flow-Matching动作专家生成连续控制动作。

Result: 在SimplerEnv和RoboCasa基准上，TwinBrainVLA在操作任务性能上优于现有最先进方法，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA为构建兼具高层语义理解与低层物理灵巧性的通用机器人提供了新范式，有效缓解了通用性与专用性之间的固有张力。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>
