<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.CL](#cs.CL) [Total: 72]
- [cs.IR](#cs.IR) [Total: 10]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 38]
- [cs.LG](#cs.LG) [Total: 134]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey](https://arxiv.org/abs/2602.03878)
*Longjie Zhao,Ziming Hong,Jiaxin Huang,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: 本文首次系统综述了3D高斯点绘（3DGS）的知识产权（IP）保护问题，提出一个自底向上的分析框架，涵盖高斯扰动机制、主被动保护范式及生成式AI时代下的鲁棒性威胁，并指出了六大未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3DGS在商业应用中价值日益提升，但其IP保护研究仍零散、缺乏统一视角和系统分析。

Method: 提出首个系统性综述，并构建自底向上的三层次框架：（i）基于高斯的扰动机制；（ii）被动与主动保护范式；（iii）生成式AI背景下的鲁棒性威胁分析。

Result: 揭示了当前技术基础薄弱与鲁棒性表征不足等关键缺口，并归纳出六个具有潜力的研究方向。

Conclusion: 该工作为3DGS资产的可靠、可信IP保护提供了理论基础与系统性路线图。

Abstract: 3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.

</details>


### [2] [SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization](https://arxiv.org/abs/2602.04271)
*Lifan Wu,Ruijie Zhu,Yubo Ai,Tianzhu Zhang*

Main category: cs.CV

TL;DR: 本文提出SkeletonGaussian框架，通过骨架驱动的层次化运动分解（刚性+非刚性）实现从单目视频生成可编辑的动态3D高斯，提升可控性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有4D生成方法多采用隐式形变场表示运动，导致直接控制和编辑困难。

Method: 提出SkeletonGaussian：先用线性混合蒙皮（LBS）驱动稀疏骨架实现刚性运动，再用hexplane细化非刚性形变，构建层次化可编辑运动表征。

Result: 在生成质量上超越现有方法，并支持直观的运动编辑（如重定向、插值等）。

Conclusion: SkeletonGaussian为可编辑4D生成提供了新范式，兼顾高质量合成与用户可控性。

Abstract: 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input. Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning, followed by a hexplane-based refinement for non-rigid deformations, enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing, establishing a new paradigm for editable 4D generation. Project page: https://wusar.github.io/projects/skeletongaussian/

</details>


### [3] [TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions](https://arxiv.org/abs/2602.03879)
*Ali Bayeh,Samira Sadaoui,Malek Mouhoub*

Main category: cs.CV

TL;DR: 本文提出TruKAN，一种基于截断幂函数的新型Kolmogorov-Arnold网络架构，在保持表达力的同时提升精度、训练速度与可解释性，并在视觉任务中优于现有KAN变体。


<details>
  <summary>Details</summary>
Motivation: 解决Kolmogorov-Arnold网络（KAN）在计算效率与理论遵循之间的权衡问题，同时提升模型的可解释性与实际性能。

Method: 用源自k阶样条理论的截断幂函数替代KAN中的B样条基函数；每层结合截断幂项与多项式项，支持共享或独立节点；集成至EfficientNet-V2框架，采用混合优化与层归一化策略，并对比多种基线模型。

Result: TruKAN在多个计算机视觉基准数据集上相较MLP、KAN、SineKAN等模型，在精度、计算效率和内存占用方面均取得更优表现，且具备更强可解释性。

Conclusion: TruKAN通过简化且理论一致的基函数设计，在复杂视觉任务中实现了逼近能力与透明性的更好平衡，拓展了KAN在实际深度学习场景中的适用性。

Abstract: To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power functions derived from k-order spline theory. This change maintains the KAN's expressiveness while enhancing accuracy and training time. Each TruKAN layer combines a truncated power term with a polynomial term and employs either shared or individual knots. TruKAN exhibits greater interpretability than other KAN variants due to its simplified basis functions and knot configurations. By prioritizing interpretable basis functions, TruKAN aims to balance approximation efficacy with transparency. We develop the TruKAN model and integrate it into an advanced EfficientNet-V2-based framework, which is then evaluated on computer vision benchmark datasets. To ensure a fair comparison, we develop various models: MLP-, KAN-, SineKAN and TruKAN-based EfficientNet frameworks and assess their training time and accuracy across small and deep architectures. The training phase uses hybrid optimization to improve convergence stability. Additionally, we investigate layer normalization techniques for all the models and assess the impact of shared versus individual knots in TruKAN. Overall, TruKAN outperforms other KAN models in terms of accuracy, computational efficiency and memory usage on the complex vision task, demonstrating advantages beyond the limited settings explored in prior KAN studies.

</details>


### [4] [AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation](https://arxiv.org/abs/2602.04672)
*Jin-Chuan Shi,Binhong Ye,Tao Liu,Junzhe He,Yangjinhui Xu,Xiaoyang Liu,Zeju Li,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出AGILE框架，通过视觉语言模型引导生成完整、水密的物体网格，并采用锚定与跟踪策略替代脆弱的运动恢复结构（SfM），结合接触感知优化，实现单目视频中手-物交互的鲁棒重建，生成仿真就绪的数字资产。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖神经渲染导致几何碎片化、依赖脆弱的SfM初始化在野外视频中频繁失败，难以满足机器人和VR对仿真就绪数字孪生体的需求。

Method: 提出AGILE框架：1）利用VLM引导生成式模型合成完整水密物体网格；2）用基础模型在交互起始帧初始化物体姿态，再通过生成资产与视频观测的视觉相似性进行时序传播；3）引入接触感知优化，融合语义、几何与交互稳定性约束。

Result: 在HO3D、DexYCB及野外视频上实验表明，AGILE在全局几何精度上超越基线，且在挑战性序列中展现出极强鲁棒性；生成资产经真实到仿真的重定向验证，适用于机器人应用。

Conclusion: AGILE通过从重建范式转向智能体生成范式，兼顾高保真纹理、水密几何与物理合理性，为动态手-物交互建模提供了鲁棒、仿真就绪的新路径。

Abstract: Reconstructing dynamic hand-object interactions from monocular videos is critical for dexterous manipulation data collection and creating realistic digital twins for robotics and VR. However, current methods face two prohibitive barriers: (1) reliance on neural rendering often yields fragmented, non-simulation-ready geometries under heavy occlusion, and (2) dependence on brittle Structure-from-Motion (SfM) initialization leads to frequent failures on in-the-wild footage. To overcome these limitations, we introduce AGILE, a robust framework that shifts the paradigm from reconstruction to agentic generation for interaction learning. First, we employ an agentic pipeline where a Vision-Language Model (VLM) guides a generative model to synthesize a complete, watertight object mesh with high-fidelity texture, independent of video occlusions. Second, bypassing fragile SfM entirely, we propose a robust anchor-and-track strategy. We initialize the object pose at a single interaction onset frame using a foundation model and propagate it temporally by leveraging the strong visual similarity between our generated asset and video observations. Finally, a contact-aware optimization integrates semantic, geometric, and interaction stability constraints to enforce physical plausibility. Extensive experiments on HO3D, DexYCB, and in-the-wild videos reveal that AGILE outperforms baselines in global geometric accuracy while demonstrating exceptional robustness on challenging sequences where prior art frequently collapses. By prioritizing physical validity, our method produces simulation-ready assets validated via real-to-sim retargeting for robotic applications.

</details>


### [5] [DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection](https://arxiv.org/abs/2602.03881)
*Maxx Richard Rahman,Mostafa Hammouda,Wolfgang Maass*

Main category: cs.CV

TL;DR: 本文提出Diffusion-Guided Attention Network (DiGAN)，结合潜在扩散模型与注意力引导卷积网络，解决阿尔茨海默病早期诊断中纵向数据稀缺、时序不规则等问题，在合成与ADNI数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 早期阿尔茨海默病诊断困难，因脑结构变化微弱且时间进程不规则；现有深度学习方法依赖大量纵向数据，难以建模真实临床数据中的时序连续性与多模态不规则性。

Method: 提出DiGAN：利用扩散模型从有限数据合成逼真的纵向影像轨迹以增强时序上下文并提升对访视间隔不均的鲁棒性；引入注意力-卷积层捕获区分正常、轻度认知障碍及主观认知下降的结构-时序判别模式。

Result: 在合成数据集和ADNI数据集上的实验表明，DiGAN性能优于现有最先进基线方法。

Conclusion: DiGAN为阿尔茨海默病早期检测提供了新思路，尤其适用于小样本、不规则纵向临床数据场景。

Abstract: Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network (DiGAN), which integrates latent diffusion modelling with an attention-guided convolutional network. The diffusion model synthesizes realistic longitudinal neuroimaging trajectories from limited training data, enriching temporal context and improving robustness to unevenly spaced visits. The attention-convolutional layer then captures discriminative structural--temporal patterns that distinguish cognitively normal subjects from those with mild cognitive impairment and subjective cognitive decline. Experiments on synthetic and ADNI datasets demonstrate that DiGAN outperforms existing state-of-the-art baselines, showing its potential for early-stage AD detection.

</details>


### [6] [X2HDR: HDR Image Generation in a Perceptually Uniform Space](https://arxiv.org/abs/2602.04814)
*Ronghuan Wu,Wanchao Su,Kede Ma,Jing Liao,Rafał K. Mantiuk*

Main category: cs.CV

TL;DR: 本文提出一种无需从头训练即可将现有LDR预训练扩散模型适配至HDR图像生成的方法，核心是将HDR数据转换为感知均匀编码（如PU21/PQ）空间中进行VAE冻结+去噪器LoRA微调，从而统一支持文本到HDR生成与RAW到HDR重建。


<details>
  <summary>Details</summary>
Motivation: 现有主流图像生成模型（如Stable Diffusion、FLUX）受限于缺乏大规模HDR训练数据，仅能输出LDR图像；而HDR图像原生采用线性RGB表示，其强度与色彩统计特性与sRGB LDR图像差异显著，直接使用会导致重建质量严重下降。

Method: 利用感知均匀编码（PU21或PQ）将HDR图像映射到与LDR更兼容的表示空间；实证发现LDR预训练VAE在PU21编码下可高保真重建HDR输入；据此提出冻结VAE、仅对去噪器在感知均匀空间中进行低秩适应（LoRA）微调的轻量适配策略。

Result: 该方法在文本到HDR合成与单图RAW-to-HDR重建任务上均取得提升：显著增强感知保真度、图文对齐能力及有效动态范围，优于先前方法。

Conclusion: HDR生成无需从头训练大模型；通过感知一致的编码空间与模块化微调策略，可高效复用现有LDR扩散模型能力，为HDR内容生成提供实用、可扩展的新范式。

Abstract: High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing pretrained diffusion models can be easily adapted to HDR generation without retraining from scratch. A key challenge is that HDR images are natively represented in linear RGB, whose intensity and color statistics differ substantially from those of sRGB-encoded LDR images. This gap, however, can be effectively bridged by converting HDR inputs into perceptually uniform encodings (e.g., using PU21 or PQ). Empirically, we find that LDR-pretrained variational autoencoders (VAEs) reconstruct PU21-encoded HDR inputs with fidelity comparable to LDR data, whereas linear RGB inputs cause severe degradations. Motivated by this finding, we describe an efficient adaptation strategy that freezes the VAE and finetunes only the denoiser via low-rank adaptation in a perceptually uniform space. This results in a unified computational method that supports both text-to-HDR synthesis and single-image RAW-to-HDR reconstruction. Experiments demonstrate that our perceptually encoded adaptation consistently improves perceptual fidelity, text-image alignment, and effective dynamic range, relative to previous techniques.

</details>


### [7] [PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition](https://arxiv.org/abs/2602.03882)
*Haijiang Yan,Nick Chater,Adam Sanborn*

Main category: cs.CV

TL;DR: 本文提出PriorProbe方法，利用人机协同的马尔可夫链蒙特卡洛技术，精准提取个体认知先验，并成功提升神经网络在模糊面部表情识别任务中的个性化预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以准确、无偏地提取个体层面的认知先验，限制了神经网络的个性化能力。

Method: 提出PriorProbe方法，基于‘与人协同的马尔可夫链蒙特卡洛（MCMC with People）’，在面部表情识别任务中对个体参与者进行先验 elicitation，并将恢复的先验整合进先进神经网络中进行验证。

Result: PriorProbe提取的个体先验显著提升了模型对模糊刺激的个体分类预测性能，优于基线模型及其它先验来源，且不损害模型对真实标签的推理能力。

Conclusion: PriorProbe是一种通用、可解释的框架，为深度神经网络的个性化提供了新路径。

Abstract: Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitation approach grounded in Markov Chain Monte Carlo with People that recovers fine-grained, individual-specific priors. Focusing on a facial expression recognition task, we apply PriorProbe to individual participants and test whether integrating the recovered priors with a state-of-the-art neural network improves its ability to predict an individual's classification on ambiguous stimuli. The PriorProbe-derived priors yield substantial performance gains, outperforming both the neural network alone and alternative sources of priors, while preserving the network's inference on ground-truth labels. Together, these results demonstrate that PriorProbe provides a general and interpretable framework for personalizing deep neural networks.

</details>


### [8] [Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing](https://arxiv.org/abs/2602.03883)
*Akshansh Mishra,Rakesh Morisetty*

Main category: cs.CV

TL;DR: 本文提出了一种可解释的计算机视觉框架，用于三维CT体数据中的孔隙检测与关键性评估，通过几何特征描述和SHAP分析揭示表面距离是影响孔隙关键性的主导因素。


<details>
  <summary>Details</summary>
Motivation: 内部孔隙是增材制造部件的关键缺陷模式，现有自动缺陷检测方法缺乏可解释性，难以帮助工程师理解关键性预测的物理基础。

Method: 基于灰度切片重建三维体数据，采用阈值分割与连通域分析识别孔隙；提取尺寸、长宽比、范围及距边界的距离等几何特征；构建基于百分位欧氏距离的孔隙交互网络；使用机器学习模型预测关键性得分，并通过SHAP分析量化各特征贡献。

Result: 归一化表面距离对模型预测的贡献远超其他所有特征（高一个数量级以上），孔隙尺寸影响微弱，其余几何参数影响可忽略；表面邻近性与关键性呈强负相关，揭示了边界驱动的失效机制。

Conclusion: 该可解释框架实现了透明化缺陷评估，为增材制造的工艺优化与质量控制提供了可操作的洞见。

Abstract: Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality predictions. This study presents an explainable computer vision framework for pore detection and criticality assessment in three-dimensional tomographic volumes. Sequential grayscale slices were reconstructed into volumetric datasets, and intensity-based thresholding with connected component analysis identified 500 individual pores. Each pore was characterized using geometric descriptors including size, aspect ratio, extent, and spatial position relative to the specimen boundary. A pore interaction network was constructed using percentile-based Euclidean distance criteria, yielding 24,950 inter-pore connections. Machine learning models predicted pore criticality scores from extracted features, and SHAP analysis quantified individual feature contributions. Results demonstrate that normalized surface distance dominates model predictions, contributing more than an order of magnitude greater importance than all other descriptors. Pore size provides minimal influence, while geometric parameters show negligible impact. The strong inverse relationship between surface proximity and criticality reveals boundary-driven failure mechanisms. This interpretable framework enables transparent defect assessment and provides actionable insights for process optimization and quality control in additive manufacturing.

</details>


### [9] [4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping](https://arxiv.org/abs/2602.03890)
*Xindan Zhang,Weilong Yan,Yufei Shi,Xuerui Qiu,Tao He,Ying Li,Ming Li,Hehe Fan*

Main category: cs.CV

TL;DR: 本文提出了首个面向动态点云理解的多模态大语言模型4DPC²hat，构建了大规模跨模态数据集4DPC²hat-200K，并引入Mamba增强的时间推理架构与失败感知自举学习策略，显著提升了动作理解和时序推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态点云，而动态点云序列的理解因缺乏大规模跨模态数据集及难以建模时空运动模式而未被充分探索。

Method: 构建了包含44K动态物体序列、700K点云帧和200K问答对的大规模数据集4DPC²hat-200K；提出Mamba增强的时序推理MLLM；设计失败感知的自举学习策略以迭代提升模型推理能力。

Result: 在动作理解和时序推理任务上显著优于现有模型，为4D动态点云理解奠定了坚实基础。

Conclusion: 4DPC²hat是首个专为动态点云理解设计的MLLM，通过新数据集、新架构与新训练策略，有效推动了4D点云跨模态理解的发展。

Abstract: Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.

</details>


### [10] [Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation](https://arxiv.org/abs/2602.03892)
*Jinxing Zhou,Yanghao Zhou,Yaoting Wang,Zongyan Han,Jiaqi Ma,Henghui Ding,Rao Muhammad Anwer,Hisham Cholakkal*

Main category: cs.CV

TL;DR: 本文提出了MQA-RefAVS任务，即在无真值标注情况下评估语言引导的音视频分割（Ref-AVS）结果的质量，并构建了MQ-RAVSBench基准与MQ-Auditor模型来实现定量与定性评估。


<details>
  <summary>Details</summary>
Motivation: 现有Ref-AVS研究聚焦于生成分割掩码，而缺乏对掩码质量进行无需真值参考的可解释诊断机制。

Method: 提出MQA-RefAVS新任务，构建含几何与语义错误模式的MQ-RAVSBench基准，并设计基于多模态大语言模型（MLLM）的MQ-Auditor评估器，联合分析音视频文本输入及掩码本身以估计IoU、识别错误类型并给出质量控制建议。

Result: MQ-Auditor在MQ-RAVSBench上显著优于主流开源与商用MLLM；可有效检测Ref-AVS系统分割失败案例，并支持下游分割性能提升。

Conclusion: MQA-RefAVS填补了Ref-AVS中无监督掩码质量评估的空白，MQ-Auditor为多模态分割系统提供了可解释、可操作的质量审计能力。

Abstract: Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.

</details>


### [11] [GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction](https://arxiv.org/abs/2602.03893)
*Yibing Wang,Shuang Li,Tingting Huang,Yu Zhang,Chulhong Kim,Seongwook Choi,Changhui Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为GPAIR的超快速3D光声迭代重建方法，通过高斯核变换和GPU加速的可微Triton算子，实现了亚秒级重建速度，显著提升了3D光声断层成像的临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统迭代重建（IR）算法在三维光声断层成像（PACT）中存在计算耗时长的问题，严重限制其实际应用。

Method: 提出基于高斯核的超快速3D光声迭代重建方法（GPAIR），将传统空间网格变换为连续各向同性高斯核，并推导压力波的解析闭式表达式，结合GPU加速的可微Triton算子实现高效计算。

Result: GPAIR在动物实验中实现了对含840万体素的3D目标的亚秒级重建，比传统IR快数个数量级。

Conclusion: GPAIR大幅提升了3D PACT的重建速度，推动其向近实时、大规模临床应用迈进。

Abstract: Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.

</details>


### [12] [Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study](https://arxiv.org/abs/2602.03894)
*Hugo Markoff,Stefan Hein Bengtson,Michael Ørsted*

Main category: cs.CV

TL;DR: 本研究评估了视觉Transformer（ViT）基础模型在无需人工标注的情况下，直接对野生动物图像进行物种级聚类的能力，发现DINOv3结合t-SNE与监督层次聚类可实现近完美物种识别（V-measure 0.958），且无监督方法也表现优异（0.943），并能揭示年龄、性别等生态内变异性。


<details>
  <summary>Details</summary>
Motivation: 手动标注动物图像严重制约生态学研究规模与效率，亟需自动化、无监督或弱监督的图像分类方法以支持大规模生物多样性监测。

Method: 构建涵盖5种ViT模型、5种降维技术与4种聚类算法（2种监督、2种无监督）的综合基准框架，在60个物种（各200张验证图像）上系统评测；分析聚类成败条件及对种内变异（如性别、年龄、表型）的解析能力；引入长尾分布鲁棒性测试与过聚类策略。

Result: DINOv3 + t-SNE + 监督层次聚类达V-measure 0.958；无监督方法最高达0.943，仅1.14%图像被判定为离群需专家复核；方法对长尾分布鲁棒，过聚类可稳定提取年龄类、性二型、毛色差异等种内模式。

Conclusion: ViT基础模型（尤其是DINOv3）结合适当降维与聚类策略，可在极少甚至零标签前提下高效实现物种级图像组织，并挖掘生态相关种内变异，为生态图像分析提供实用、开源、可推广的技术路径。

Abstract: Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.

</details>


### [13] [Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs](https://arxiv.org/abs/2602.03895)
*Xuwei Tan,Ziyu Hu,Xueru Zhang*

Main category: cs.CV

TL;DR: 本文提出了NH-Fair统一公平性基准，涵盖视觉与多模态大模型，在标准化数据、指标和训练协议下评估公平性；发现精心调优的ERM基线常优于多数去偏方法，而一种组合数据增强策略在不损效用前提下稳定提升公平性；LVLM虽精度更高但仍存在子群偏差，架构与训练选择的影响常大于模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究因数据集异构、评估指标不一致、视觉与多模态模型孤立评估、超参调优不足等问题，难以进行公平有效的比较。

Method: 构建NH-Fair统一基准，覆盖监督与零样本设定下的视觉模型和大视觉语言模型（LVLM）；开展系统性ERM调优研究，识别显著影响效用与差异的关键训练选择；对比多种去偏方法，并提出并验证一种复合数据增强策略；分析LVLM的子群表现与缩放效应。

Result: 1) ERM超参调优对公平性与准确率均有显著影响，可提供实用调优指南；2) 多数去偏方法未稳定优于调优后的ERM基线，而复合数据增强方法在保持效用的同时持续改善公平性；3) LVLM平均准确率更高但仍有子群偏差，性能增益更多来自架构/训练设计而非单纯扩大模型规模。

Conclusion: NH-Fair为公平性评估提供了可复现、调优感知、危害意识强的统一框架；强调扎实基础训练（如ERM调优）与简单有效策略（如复合数据增强）的重要性，挑战了过度依赖复杂去偏算法或单纯扩大模型规模的惯性思维。

Abstract: Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.

</details>


### [14] [HY3D-Bench: Generation of 3D Assets](https://arxiv.org/abs/2602.03907)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Dongyuan Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jiaao Yu,Jiachen Xu,Jingwei Huang,Kunhong Li,Lifu Wang,Linus,Penghao Wang,Qingxiang Lin,Ruining Tang,Xianghui Yang,Yang Li,Yirui Guan,Yunfei Zhao,Yunhan Yang,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: 本文提出了HY3D-Bench，一个开源的3D生成数据集生态系统，包含25万高质量真实3D模型和12.5万合成资产，并引入结构化部件级分解，旨在解决3D内容生成中的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前神经表征与生成模型虽推动了3D内容创作发展，但受限于数据处理瓶颈，缺乏统一、高质量、易用的3D训练数据基础。

Method: 构建HY3D-Bench：（1）从大规模仓库中筛选并清洗25万高保真3D对象，生成水密网格与多视角渲染；（2）提供结构化的部件级分解标注；（3）设计可扩展AIGC合成流程，生成12.5万合成资产以覆盖长尾类别。

Result: HY3D-Bench已成功支撑Hunyuan3D-2.1-Small模型训练，验证其有效性；数据集开源，显著提升3D感知、机器人及数字内容生成领域的数据可及性与多样性。

Conclusion: HY3D-Bench为3D生成提供了高质量、结构化、规模化的数据基础，有望推动相关领域方法创新与实际应用落地。

Abstract: While recent advances in neural representations and generative models have revolutionized 3D content creation, the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation. Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings; (2) We introduce structured part-level decomposition, providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline, contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception, robotics, and digital content creation.

</details>


### [15] [Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition](https://arxiv.org/abs/2602.03913)
*Qiuming Luo,Tao Zeng,Feng Li,Heming Liu,Rui Mao,Chang Kong*

Main category: cs.CV

TL;DR: 本文提出了一种熵感知结构对齐网络，用于零样本手写中文字符识别，通过信息熵先验、双视角部首树和Top-K语义特征融合机制，提升了识别性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将汉字视为扁平的部首序列，忽略了其层次化拓扑结构及不同组件间信息密度的不均衡性。

Method: 提出熵感知结构对齐网络：1）引入信息熵先验动态调制位置嵌入，作为显著性检测器；2）构建双视角部首树提取多粒度结构特征，并用Sigmoid门控网络自适应融合；3）设计Top-K语义特征融合机制，利用语义邻域中心校正视觉歧义。

Result: 在零样本设定下显著超越现有CLIP基线，达到新SOTA；同时具备优异的数据效率，仅需少量支持样本即可快速适配。

Conclusion: 该方法通过信息论建模有效弥合了视觉与语义鸿沟，为零样本汉字识别提供了更鲁棒、高效的结构化建模范式。

Abstract: Zero-shot Handwritten Chinese Character Recognition (HCCR) aims to recognize unseen characters by leveraging radical-based semantic compositions. However, existing approaches often treat characters as flat radical sequences, neglecting the hierarchical topology and the uneven information density of different components. To address these limitations, we propose an Entropy-Aware Structural Alignment Network that bridges the visual-semantic gap through information-theoretic modeling. First, we introduce an Information Entropy Prior to dynamically modulate positional embeddings via multiplicative interaction, acting as a saliency detector that prioritizes discriminative roots over ubiquitous components. Second, we construct a Dual-View Radical Tree to extract multi-granularity structural features, which are integrated via an adaptive Sigmoid-based gating network to encode both global layout and local spatial roles. Finally, a Top-K Semantic Feature Fusion mechanism is devised to augment the decoding process by utilizing the centroid of semantic neighbors, effectively rectifying visual ambiguities through feature-level consensus. Extensive experiments demonstrate that our method establishes new state-of-the-art performance, significantly outperforming existing CLIP-based baselines in the challenging zero-shot setting. Furthermore, the framework exhibits exceptional data efficiency, demonstrating rapid adaptability with minimal support samples.

</details>


### [16] [Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science](https://arxiv.org/abs/2602.03915)
*Levi Lingsch,Georgios Kissas,Johannes Jakubik,Siddhartha Mishra*

Main category: cs.CV

TL;DR: 本文提出Phaedra tokenizer，专为科学图像（如PDE模拟数据）设计，兼顾物理与频谱保真度，在重建精度和分布外泛化能力上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像tokenizer面向视觉感知优化，难以满足科学图像对动态范围、物理属性和频谱特性的高保真要求。

Method: 基于经典shape-gain量化与本征正交分解（POD）思想，提出Phaedra tokenizer，并在多维指标（物理/频谱空间PDE性质保真度）下系统评估多种tokenizer。

Result: Phaedra在多个PDE数据集上显著提升重建精度，并在三类递进复杂任务（不同条件的已知PDE、未知PDE、真实地球观测与气象数据）中展现强分布外泛化能力。

Conclusion: 面向科学计算的tokenization需重新设计；Phaedra验证了融合物理先验与降维思想的tokenizer可兼顾精度与泛化性，为科学AI提供新范式。

Abstract: Tokens are discrete representations that allow modern deep learning to scale by transforming high-dimensional data into sequences that can be efficiently learned, generated, and generalized to new tasks. These have become foundational for image and video generation and, more recently, physical simulation. As existing tokenizers are designed for the explicit requirements of realistic visual perception of images, it is necessary to ask whether these approaches are optimal for scientific images, which exhibit a large dynamic range and require token embeddings to retain physical and spectral properties. In this work, we investigate the accuracy of a suite of image tokenizers across a range of metrics designed to measure the fidelity of PDE properties in both physical and spectral space. Based on the observation that these struggle to capture both fine details and precise magnitudes, we propose Phaedra, inspired by classical shape-gain quantization and proper orthogonal decomposition. We demonstrate that Phaedra consistently improves reconstruction across a range of PDE datasets. Additionally, our results show strong out-of-distribution generalization capabilities to three tasks of increasing complexity, namely known PDEs with different conditions, unknown PDEs, and real-world Earth observation and weather data.

</details>


### [17] [SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?](https://arxiv.org/abs/2602.03916)
*Azmine Toushik Wasi,Wahid Faisal,Abdur Rahman,Mahfuz Ahmed Anik,Munem Shahriar,Mohsin Mahmud Topu,Sadia Tasnim Meem,Rahatun Nesa Priti,Sabrina Afroz Mitu,Md. Iqramul Hoque,Shahriyar Zaman Ridoy,Mohammed Eunus Ali,Majd Hawasly,Mohammad Raza,Md Rizwan Parvez*

Main category: cs.CV

TL;DR: 本文提出了SpatiaLab，一个面向真实场景的视觉语言模型空间推理综合评测基准，包含1400个问题、六大类30种子任务，揭示了当前VLM在空间推理（如深度感知、导航、3D几何）上与人类存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有VLM空间推理评测多依赖合成或LLM生成环境，缺乏真实世界复杂性、视觉噪声和多样空间关系，难以反映实际能力瓶颈。

Method: 构建SpatiaLab基准：涵盖6大空间推理类别（相对位置、深度与遮挡、朝向、尺度、空间导航、3D几何），每类5个子类共30种任务；含1400个QA对，支持多选与开放作答两种评估方式；在多种SOTA VLM上开展系统评测。

Result: 所有测试VLM性能远低于人类：多选设置下最高模型InternVL3.5-72B为54.93%（人类87.57%）；开放作答下最高GPT-5-mini为40.93%（人类64.93%），且普遍下降10–25%；模型在深度感知、导航、3D几何等任务上表现最弱。

Conclusion: SpatiaLab揭示了当前VLM在真实空间推理中的关键局限，为推动具备鲁棒、类人空间理解能力的VLM发展提供了标准化评测框架与明确改进方向。

Abstract: Spatial reasoning is a fundamental aspect of human cognition, yet it remains a major challenge for contemporary vision-language models (VLMs). Prior work largely relied on synthetic or LLM-generated environments with limited task designs and puzzle-like setups, failing to capture the real-world complexity, visual noise, and diverse spatial relationships that VLMs encounter. To address this, we introduce SpatiaLab, a comprehensive benchmark for evaluating VLMs' spatial reasoning in realistic, unconstrained contexts. SpatiaLab comprises 1,400 visual question-answer pairs across six major categories: Relative Positioning, Depth & Occlusion, Orientation, Size & Scale, Spatial Navigation, and 3D Geometry, each with five subcategories, yielding 30 distinct task types. Each subcategory contains at least 25 questions, and each main category includes at least 200 questions, supporting both multiple-choice and open-ended evaluation. Experiments across diverse state-of-the-art VLMs, including open- and closed-source models, reasoning-focused, and specialized spatial reasoning models, reveal a substantial gap in spatial reasoning capabilities compared with humans. In the multiple-choice setup, InternVL3.5-72B achieves 54.93% accuracy versus 87.57% for humans. In the open-ended setting, all models show a performance drop of around 10-25%, with GPT-5-mini scoring highest at 40.93% versus 64.93% for humans. These results highlight key limitations in handling complex spatial relationships, depth perception, navigation, and 3D geometry. By providing a diverse, real-world evaluation framework, SpatiaLab exposes critical challenges and opportunities for advancing VLMs' spatial reasoning, offering a benchmark to guide future research toward robust, human-aligned spatial understanding. SpatiaLab is available at: https://spatialab-reasoning.github.io/.

</details>


### [18] [Entropy Reveals Block Importance in Masked Self-Supervised Vision Transformers](https://arxiv.org/abs/2602.03918)
*Peihao Xiang,Kaida Wu,Ou Bai*

Main category: cs.CV

TL;DR: 本文提出Gardener方法，利用预训练权重的信息熵无数据、一次性地评估视觉Transformer中各模块的重要性，实现高效剪枝，在视频识别任务中显著减少模型大小的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 掩码自监督视觉Transformer虽效果好，但模型大、部署难；亟需探究各Transformer模块对下游任务的相对重要性，并在无数据条件下高效剪枝。

Method: 基于预训练权重的信息熵估计模块重要性，提出无需数据、单次计算的块级剪枝方法Gardener，通过信息论指标识别冗余模块。

Result: 在VideoMAE-B上验证，Gardener在零数据、极低开销下，剪枝91.7%模块后仍保持竞争力，性能媲美或超越现有无数据剪枝方法，接近敏感度分析剪枝效果。

Conclusion: 掩码自监督视觉Transformer存在显著的模块级冗余；信息熵可作为模块重要性的可靠代理，为模型压缩与高效迁移学习提供新范式。

Abstract: Masked self-supervised vision transformers have become a dominant pretraining paradigm, yet their substantial model size poses significant challenges for resource-constrained deployment and efficient transfer learning. A fundamental question remains: are all transformer blocks equally important for downstream performance? In this paper, we show that block importance in masked self-supervised vision transformers can be accurately estimated without access to any data. Our key finding is that the information entropy of pretrained block weights strongly correlates with oracle sensitivity obtained via iterative block removal and finetuning. This observation enables Gardener, a data-free, one-shot, block-level pruning principle that identifies redundant blocks through simple information-theoretic measurements. We evaluate Gardener on VideoMAE-B across multiple pruning ratios and downstream video recognition benchmarks. Despite its negligible computational overhead, Gardener consistently matches or outperforms existing data-free pruning baselines and closely approaches sensitivity-based pruning. Remarkably, even after pruning up to 91.7\% of blocks, the pruned model retains competitive transfer performance. Our results reveal substantial block-level redundancy in masked self-supervised vision transformers and demonstrate that information-theoretic analysis offers a principled and efficient pathway for model compression and resource-efficient transfer learning.

</details>


### [19] [TiCLS : Tightly Coupled Language Text Spotter](https://arxiv.org/abs/2602.04030)
*Leeje Jang,Yijun Lin,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: TiCLS is an end-to-end text spotter that explicitly integrates external linguistic knowledge from a character-level pretrained language model to improve detection and recognition of ambiguous or fragmented scene text, achieving SOTA on ICDAR 2015 and Total-Text.


<details>
  <summary>Details</summary>
Motivation: Existing scene text spotting methods rely mainly on visual cues and ignore external linguistic knowledge; prior language model integrations suffer from misalignment with word-level granularity or lack of true external knowledge.

Method: TiCLS introduces a linguistic decoder that fuses visual and linguistic features, initialized by a character-level pretrained language model, enabling explicit incorporation of external linguistic knowledge in an end-to-end framework.

Result: TiCLS achieves state-of-the-art performance on ICDAR 2015 and Total-Text benchmarks.

Conclusion: Explicit integration of character-level pretrained language model guidance significantly improves robustness in recognizing ambiguous or fragmented scene text, validating PLM-guided linguistic integration as effective for scene text spotting.

Abstract: Scene text spotting aims to detect and recognize text in real-world images, where instances are often short, fragmented, or visually ambiguous. Existing methods primarily rely on visual cues and implicitly capture local character dependencies, but they overlook the benefits of external linguistic knowledge. Prior attempts to integrate language models either adapt language modeling objectives without external knowledge or apply pretrained models that are misaligned with the word-level granularity of scene text. We propose TiCLS, an end-to-end text spotter that explicitly incorporates external linguistic knowledge from a character-level pretrained language model. TiCLS introduces a linguistic decoder that fuses visual and linguistic features, yet can be initialized by a pretrained language model, enabling robust recognition of ambiguous or fragmented text. Experiments on ICDAR 2015 and Total-Text demonstrate that TiCLS achieves state-of-the-art performance, validating the effectiveness of PLM-guided linguistic integration for scene text spotting.

</details>


### [20] [AnyStyle: Single-Pass Multimodal Stylization for 3D Gaussian Splatting](https://arxiv.org/abs/2602.04043)
*Joanna Kaleta,Bartosz Świrta,Kacper Kania,Przemysław Spurek,Marek Kowalski*

Main category: cs.CV

TL;DR: 本文提出了AnyStyle，一种支持文本和图像多模态条件输入的前馈式3D重建与风格化框架，可在无姿态图像集合上实现零样本、无姿态的3D风格化，兼顾几何质量与风格可控性。


<details>
  <summary>Details</summary>
Motivation: 现有无姿态3D重建方法缺乏灵活可控的外观/风格控制能力，而基于图像的条件方式限制了可控性与灵活性。

Method: 提出模块化风格化架构AnyStyle，支持文本和参考图像两种风格输入，仅需对现有前馈3D重建主干网络做最小修改即可集成。

Result: 实验表明AnyStyle在风格可控性上优于先前前馈式风格化方法，同时保持高质量几何重建；用户研究证实其风格化质量优于当前SOTA方法。

Conclusion: AnyStyle为无姿态图像集合提供了高效、灵活、可控的零样本3D风格化新范式，拓展了3D高斯泼溅在创意内容生成中的应用边界。

Abstract: The growing demand for rapid and scalable 3D asset creation has driven interest in feed-forward 3D reconstruction methods, with 3D Gaussian Splatting (3DGS) emerging as an effective scene representation. While recent approaches have demonstrated pose-free reconstruction from unposed image collections, integrating stylization or appearance control into such pipelines remains underexplored. Existing attempts largely rely on image-based conditioning, which limits both controllability and flexibility. In this work, we introduce AnyStyle, a feed-forward 3D reconstruction and stylization framework that enables pose-free, zero-shot stylization through multimodal conditioning. Our method supports both textual and visual style inputs, allowing users to control the scene appearance using natural language descriptions or reference images. We propose a modular stylization architecture that requires only minimal architectural modifications and can be integrated into existing feed-forward 3D reconstruction backbones. Experiments demonstrate that AnyStyle improves style controllability over prior feed-forward stylization methods while preserving high-quality geometric reconstruction. A user study further confirms that AnyStyle achieves superior stylization quality compared to an existing state-of-the-art approach. Repository: https://github.com/joaxkal/AnyStyle.

</details>


### [21] [A Parameterizable Convolution Accelerator for Embedded Deep Learning Applications](https://arxiv.org/abs/2602.04044)
*Panagiotis Mousouliotis,Georgios Keramidas*

Main category: cs.CV

TL;DR: 本文提出了一种面向FPGA的CNN加速器硬件-软件协同设计方法，利用高层次综合（HLS）实现参数化设计，以同时优化延迟、功耗、面积和成本等多维约束。


<details>
  <summary>Details</summary>
Motivation: 现有FPGA上的CNN加速器多只关注性能（如GOPS），而实际嵌入式深度学习应用需兼顾延迟、功耗、面积和成本等多重约束。

Method: 采用基于高层次综合（HLS）的硬件-软件协同设计方法，对CNN加速器进行参数化建模与优化。

Result: 实验表明该参数化设计方法优于非参数化方法，并具备向其他深度学习应用扩展的能力。

Conclusion: 参数化HLS协同设计能更有效地满足嵌入式DL应用的多目标约束，提升设计灵活性与适用性。

Abstract: Convolutional neural network (CNN) accelerators implemented on Field-Programmable Gate Arrays (FPGAs) are typically designed with a primary focus on maximizing performance, often measured in giga-operations per second (GOPS). However, real-life embedded deep learning (DL) applications impose multiple constraints related to latency, power consumption, area, and cost. This work presents a hardware-software (HW/SW) co-design methodology in which a CNN accelerator is described using high-level synthesis (HLS) tools that ease the parameterization of the design, facilitating more effective optimizations across multiple design constraints. Our experimental results demonstrate that the proposed design methodology is able to outperform non-parameterized design approaches, and it can be easily extended to other types of DL applications.

</details>


### [22] [Fast, Unsupervised Framework for Registration Quality Assessment of Multi-stain Histological Whole Slide Pairs](https://arxiv.org/abs/2602.04046)
*Shikha Dubey,Patricia Raciti,Kristopher Standish,Albert Juan Ramon,Erik Ames Burlingame*

Main category: cs.CV

TL;DR: 本文提出了一种无需真值标注、快速且无监督的全切片图像（WSI）配准质量评估（RQA）框架，结合组织掩码和形变特征指标，兼顾全局结构一致性和局部形变合理性，在多标记和多专家验证中表现出与人工评估高度相关。


<details>
  <summary>Details</summary>
Motivation: 现有WSI配准质量评估方法依赖人工标注或强度相似性度量，存在耗时、不可靠、计算开销大等问题，难以用于大规模数字病理质控。

Method: 提出一种联合使用下采样组织掩码和形变场特征的无监督RQA框架：掩码指标评估全局结构对应性，形变指标评估局部平滑性、连续性与变换真实性。

Result: 在多种IHC标记及多位专家评估下，自动化指标与人工评分呈现强相关性；无需真值即可实现高保真、实时、低计算资源消耗的质量评估。

Conclusion: 该框架为无真值场景下的WSI配准提供了可靠、高效、可扩展的质量评估方案，适用于大规模数字病理质控。

Abstract: High-fidelity registration of histopathological whole slide images (WSIs), such as hematoxylin & eosin (H&E) and immunohistochemistry (IHC), is vital for integrated molecular analysis but challenging to evaluate without ground-truth (GT) annotations. Existing WSI-level assessments -- using annotated landmarks or intensity-based similarity metrics -- are often time-consuming, unreliable, and computationally intensive, limiting large-scale applicability. This study proposes a fast, unsupervised framework that jointly employs down-sampled tissue masks- and deformations-based metrics for registration quality assessment (RQA) of registered H&E and IHC WSI pairs. The masks-based metrics measure global structural correspondence, while the deformations-based metrics evaluate local smoothness, continuity, and transformation realism. Validation across multiple IHC markers and multi-expert assessments demonstrate a strong correlation between automated metrics and human evaluations. In the absence of GT, this framework offers reliable, real-time RQA with high fidelity and minimal computational resources, making it suitable for large-scale quality control in digital pathology.

</details>


### [23] [Artifact Removal and Image Restoration in AFM:A Structured Mask-Guided Directional Inpainting Approach](https://arxiv.org/abs/2602.04051)
*Juntao Zhang,Angona Biswas,Jaydeep Rade,Charchit Shukla,Juan Ren,Anwesha Sarkar,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、全自动的AFM图像伪影检测与修复框架，结合分类、语义分割、方向性插值与局部高斯平滑，实现几何感知的高质量恢复。


<details>
  <summary>Details</summary>
Motivation: AFM图像常受环境噪声、扫描缺陷和针尖-样品相互作用引入的伪影影响，导致分辨率下降，亟需自动化、高保真的修复方法。

Method: 采用两阶段流程：首先用分类模型判断图像是否含伪影；若存在，则用定制轻量语义分割网络生成伪影掩码，再基于结构方向自适应扩展掩码，并采用方向性邻域插值与局部高斯平滑进行修复；整个系统集成于支持实时调参和批量处理的GUI中。

Result: 实验表明该方法能有效去除伪影，同时保持纳米级结构细节，具备良好的鲁棒性与几何感知能力。

Conclusion: 所提框架为AFM数据分析提供了一种高效、全自动、高保真的伪影校正解决方案，适用于实际科研与工业场景。

Abstract: Atomic Force Microscopy (AFM) enables high-resolution surface imaging at the nanoscale, yet the output is often degraded by artifacts introduced by environmental noise, scanning imperfections, and tip-sample interactions. To address this challenge, a lightweight and fully automated framework for artifact detection and restoration in AFM image analysis is presented. The pipeline begins with a classification model that determines whether an AFM image contains artifacts. If necessary, a lightweight semantic segmentation network, custom-designed and trained on AFM data, is applied to generate precise artifact masks. These masks are adaptively expanded based on their structural orientation and then inpainted using a directional neighbor-based interpolation strategy to preserve 3D surface continuity. A localized Gaussian smoothing operation is then applied for seamless restoration. The system is integrated into a user-friendly GUI that supports real-time parameter adjustments and batch processing. Experimental results demonstrate the effective artifact removal while preserving nanoscale structural details, providing a robust, geometry-aware solution for high-fidelity AFM data interpretation.

</details>


### [24] [Seeing Through Clutter: Structured 3D Scene Reconstruction via Iterative Object Removal](https://arxiv.org/abs/2602.04053)
*Rio Aguina-Kang,Kevin James Blackburn-Matzen,Thibault Groueix,Vladimir Kim,Matheus Gadelha*

Main category: cs.CV

TL;DR: SeeingThroughClutter是一种无需任务特定训练的单图像3D结构化重建方法，通过VLM驱动的迭代对象移除与重建流程，在复杂遮挡场景中实现更鲁棒的物体分割与建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖语义分割和深度估计等中间任务，在遮挡和杂乱场景中性能不佳。

Method: 提出基于视觉语言模型（VLM）作为协调器的迭代对象移除与重建流程：依次检测、分割、移除前景物体，并进行3D拟合，从而将复杂场景分解为更易处理的子任务。

Result: 在3D-Front和ADE20K数据集上达到当前最优鲁棒性，且无需任务特定训练，直接受益于基础模型进展。

Conclusion: 该方法通过解耦复杂场景显著提升了单图3D重建在遮挡和杂乱环境下的准确性与泛化能力。

Abstract: We present SeeingThroughClutter, a method for reconstructing structured 3D representations from single images by segmenting and modeling objects individually. Prior approaches rely on intermediate tasks such as semantic segmentation and depth estimation, which often underperform in complex scenes, particularly in the presence of occlusion and clutter. We address this by introducing an iterative object removal and reconstruction pipeline that decomposes complex scenes into a sequence of simpler subtasks. Using VLMs as orchestrators, foreground objects are removed one at a time via detection, segmentation, object removal, and 3D fitting. We show that removing objects allows for cleaner segmentations of subsequent objects, even in highly occluded scenes. Our method requires no task-specific training and benefits directly from ongoing advances in foundation models. We demonstrate stateof-the-art robustness on 3D-Front and ADE20K datasets. Project Page: https://rioak.github.io/seeingthroughclutter/

</details>


### [25] [iSight: Towards expert-AI co-assessment for improved immunohistochemistry staining interpretation](https://arxiv.org/abs/2602.04063)
*Jacob S. Leiby,Jialu Yao,Pan Lu,George Hu,Anna Davidian,Shunsuke Koga,Olivia Leung,Pravin Patel,Isabella Tondi Resta,Rebecca Rojansky,Derek Sung,Eric Yang,Paul J. Zhang,Emma Lundberg,Dokyoon Kim,Serena Yeung-Levy,James Zou,Thomas Montine,Jeffrey Nirschl,Zhi Huang*

Main category: cs.CV

TL;DR: 本文提出了HPA10M数据集（含千万级IHC图像）和iSight多任务AI模型，用于自动评估IHC染色的强度、定位、数量、组织类型及恶性状态；iSight在多项指标上超越微调的基础模型，并在病理医生评估中表现优于初始人工判断，且提升人-人一致性，表明其具备临床辅助潜力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型主要面向H&E染色切片，在免疫组化（IHC）图像分析中受限于域差异；亟需大规模IHC专用数据集与适配模型以支持病理诊断与疾病分诊。

Method: 构建包含1049万张IHC图像的HPA10M数据集（涵盖45种正常组织和20种主要癌症）；基于该数据集设计iSight多任务学习框架，融合全切片图像视觉特征与组织元数据，通过token级注意力机制同步预测染色强度、位置、数量、组织类型和恶性状态。

Result: iSight在独立测试集上达到：定位准确率85.5%、强度76.6%、数量75.7%，优于PLIP/CONCH等基础模型2.5–10.2%；校准误差低（0.0150–0.0408）；在8位病理医生参与的用户研究中，其性能超过医生初评结果，并提升人-人一致性（Cohen's κ分别从0.63→0.70、0.74→0.76）。

Conclusion: HPA10M和iSight为IHC智能分析奠定了重要基础，验证了AI辅助可提升IHC判读的准确性、一致性与可靠性，具有融入临床工作流的实用前景。

Abstract: Immunohistochemistry (IHC) provides information on protein expression in tissue sections and is commonly used to support pathology diagnosis and disease triage. While AI models for H\&E-stained slides show promise, their applicability to IHC is limited due to domain-specific variations. Here we introduce HPA10M, a dataset that contains 10,495,672 IHC images from the Human Protein Atlas with comprehensive metadata included, and encompasses 45 normal tissue types and 20 major cancer types. Based on HPA10M, we trained iSight, a multi-task learning framework for automated IHC staining assessment. iSight combines visual features from whole-slide images with tissue metadata through a token-level attention mechanism, simultaneously predicting staining intensity, location, quantity, tissue type, and malignancy status. On held-out data, iSight achieved 85.5\% accuracy for location, 76.6\% for intensity, and 75.7\% for quantity, outperforming fine-tuned foundation models (PLIP, CONCH) by 2.5--10.2\%. In addition, iSight demonstrates well-calibrated predictions with expected calibration errors of 0.0150-0.0408. Furthermore, in a user study with eight pathologists evaluating 200 images from two datasets, iSight outperformed initial pathologist assessments on the held-out HPA dataset (79\% vs 68\% for location, 70\% vs 57\% for intensity, 68\% vs 52\% for quantity). Inter-pathologist agreement also improved after AI assistance in both held-out HPA (Cohen's $κ$ increased from 0.63 to 0.70) and Stanford TMAD datasets (from 0.74 to 0.76), suggesting expert--AI co-assessment can improve IHC interpretation. This work establishes a foundation for AI systems that can improve IHC diagnostic accuracy and highlights the potential for integrating iSight into clinical workflows to enhance the consistency and reliability of IHC assessment.

</details>


### [26] [VideoBrain: Learning Adaptive Frame Sampling for Long Video Understanding](https://arxiv.org/abs/2602.04094)
*Junbo Zou,Ziheng Huang,Shengjie Zhang,Liwen Zhang,Weining Shen*

Main category: cs.CV

TL;DR: VideoBrain是一种端到端框架，通过学习采样策略使视觉语言模型（VLM）自适应获取长视频中的视觉信息，在提升性能的同时显著减少所需帧数。


<details>
  <summary>Details</summary>
Motivation: 长视频理解面临计算约束与需覆盖数千帧信息之间的矛盾，现有方法存在信息丢失或单次关键帧选择不可恢复的问题。

Method: 提出VideoBrain框架，包含基于CLIP的语义检索代理和均匀时间采样代理；VLM直接感知帧并判断信息充分性；引入行为感知奖励函数和数据分类流程，引导模型合理调用代理。

Result: 在四个长视频基准上相比基线提升3.5%–9.0%，且仅使用30–40%的帧数，并在短视频基准上表现出强跨数据集泛化能力。

Conclusion: VideoBrain通过可学习的自适应采样机制和行为感知训练策略，有效提升了VLM对长视频的理解效率与效果。

Abstract: Long-form video understanding remains challenging for Vision-Language Models (VLMs) due to the inherent tension between computational constraints and the need to capture information distributed across thousands of frames. Existing approaches either sample frames uniformly (risking information loss) or select keyframes in a single pass (with no recovery from poor choices). We propose VideoBrain, an end-to-end framework that enables VLMs to adaptively acquire visual information through learned sampling policies. Our approach features dual complementary agents: a CLIP-based agent for semantic retrieval across the video and a Uniform agent for dense temporal sampling within intervals. Unlike prior agent-based methods that rely on text-only LLMs orchestrating visual tools, our VLM directly perceives frames and reasons about information sufficiency. To prevent models from invoking agents indiscriminately to maximize rewards, we introduce a behavior-aware reward function coupled with a data classification pipeline that teaches the model when agent invocation is genuinely beneficial. Experiments on four long video benchmarks demonstrate that VideoBrain achieves +3.5% to +9.0% improvement over the baseline while using 30-40% fewer frames, with strong cross-dataset generalization to short video benchmarks.

</details>


### [27] [DMS2F-HAD: A Dual-branch Mamba-based Spatial-Spectral Fusion Network for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2602.04102)
*Aayushma Pant,Lakpa Tamang,Tsz-Kwan Lee,Sunil Aryal*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的双分支模型DMS2F-HAD，用于高效且准确的高光谱异常检测，在14个数据集上达到98.78%平均AUC，并比同类方法快4.6倍。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱异常检测中存在无法建模长程光谱依赖或计算成本过高的问题。

Method: 提出双分支Mamba架构，分别建模空间与光谱特征，并通过动态门控融合机制整合；利用Mamba的线性时间复杂度提升效率。

Result: 在14个基准高光谱数据集上取得98.78%平均AUC，推理速度为同类方法的4.6倍。

Conclusion: DMS2F-HAD兼具高性能、高效率与强泛化能力，适用于实际高光谱异常检测任务。

Abstract: Hyperspectral anomaly detection (HAD) aims to identify rare and irregular targets in high-dimensional hyperspectral images (HSIs), which are often noisy and unlabelled data. Existing deep learning methods either fail to capture long-range spectral dependencies (e.g., convolutional neural networks) or suffer from high computational cost (e.g., Transformers). To address these challenges, we propose DMS2F-HAD, a novel dual-branch Mamba-based model. Our architecture utilizes Mamba's linear-time modeling to efficiently learn distinct spatial and spectral features in specialized branches, which are then integrated by a dynamic gated fusion mechanism to enhance anomaly localization. Across fourteen benchmark HSI datasets, our proposed DMS2F-HAD not only achieves a state-of-the-art average AUC of 98.78%, but also demonstrates superior efficiency with an inference speed 4.6 times faster than comparable deep learning methods. The results highlight DMS2FHAD's strong generalization and scalability, positioning it as a strong candidate for practical HAD applications.

</details>


### [28] [SuperPoint-E: local features for 3D reconstruction via tracking adaptation in endoscopy](https://arxiv.org/abs/2602.04108)
*O. Leon Barbed,José M. M. Montiel,Pascal Fua,Ana C. Murillo*

Main category: cs.CV

TL;DR: 本文提出SuperPoint-E，一种针对内窥镜视频优化的局部特征提取方法，通过Tracking Adaptation监督策略提升特征检测与描述质量，显著改善了Structure-from-Motion（SfM）的3D重建效果。


<details>
  <summary>Details</summary>
Motivation: 提升内窥镜视频中Structure-from-Motion（SfM）的特征提取性能，以获得更密集、更长时序覆盖的高质量3D重建。

Method: 提出SuperPoint-E方法，并引入Tracking Adaptation监督策略来优化特征检测与描述；在真实内窥镜视频上进行大量实验，确定最优配置并评估特征质量。

Result: 相比原始SuperPoint和COLMAP，SuperPoint-E实现了更密集、覆盖更长视频段的3D重建；特征检测更密集、存活率更高、描述子更具判别性，使引导匹配步骤几乎冗余。

Conclusion: SuperPoint-E显著提升了内窥镜视频SfM的3D重建质量，为医学图像分析提供了更鲁棒、高效的特征提取方案。

Abstract: In this work, we focus on boosting the feature extraction to improve the performance of Structure-from-Motion (SfM) in endoscopy videos. We present SuperPoint-E, a new local feature extraction method that, using our proposed Tracking Adaptation supervision strategy, significantly improves the quality of feature detection and description in endoscopy. Extensive experimentation on real endoscopy recordings studies our approach's most suitable configuration and evaluates SuperPoint-E feature quality. The comparison with other baselines also shows that our 3D reconstructions are denser and cover more and longer video segments because our detector fires more densely and our features are more likely to survive (i.e. higher detection precision). In addition, our descriptor is more discriminative, making the guided matching step almost redundant. The presented approach brings significant improvements in the 3D reconstructions obtained, via SfM on endoscopy videos, compared to the original SuperPoint and the gold standard SfM COLMAP pipeline.

</details>


### [29] [JSynFlow: Japanese Synthesised Flowchart Visual Question Answering Dataset built with Large Language Models](https://arxiv.org/abs/2602.04142)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: 本文提出JSynFlow，一个使用大语言模型生成的日本流程图视觉问答合成数据集，用于提升视觉语言模型对流程图的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在分析包含流程图等复杂文档时表现不足，而构建大规模真实流程图数据集耗时耗力，亟需高效的数据合成方法。

Method: 利用大语言模型生成面向多种职业任务的描述，并通过领域特定语言（DSL）代码渲染对应的流程图图像，再构造相应的问答对，构建JSynFlow合成数据集。

Result: 实验表明，在JSynFlow上微调视觉语言模型可显著提升其在流程图问答任务上的性能。

Conclusion: JSynFlow为流程图理解提供了高质量、可扩展的合成数据资源，有效缓解了真实标注数据稀缺问题，并已开源供社区使用。

Abstract: Vision and language models (VLMs) are expected to analyse complex documents, such as those containing flowcharts, through a question-answering (QA) interface. The ability to recognise and interpret these flowcharts is in high demand, as they provide valuable insights unavailable in text-only explanations. However, developing VLMs with precise flowchart understanding requires large-scale datasets of flowchart images and corresponding text, the creation of which is highly time-consuming. To address this challenge, we introduce JSynFlow, a synthesised visual QA dataset for Japanese flowcharts, generated using large language models (LLMs). Our dataset comprises task descriptions for various business occupations, the corresponding flowchart images rendered from domain-specific language (DSL) code, and related QA pairs. This paper details the dataset's synthesis procedure and demonstrates that fine-tuning with JSynFlow significantly improves VLM performance on flowchart-based QA tasks. Our dataset is publicly available at https://huggingface.co/datasets/jri-advtechlab/jsynflow.

</details>


### [30] [Context Determines Optimal Architecture in Materials Segmentation](https://arxiv.org/abs/2602.04154)
*Mingjian Lu,Pawan K. Tripathi,Mark Shteyn,Debargha Ganguly,Roger H. French,Vipin Chaudhary,Yinghui Wu*

Main category: cs.CV

TL;DR: 本文提出了一种跨模态材料图像分割评估框架，涵盖SEM、AFM、XCT和光学显微镜四种成像方式，发现不同成像模态下最优分割架构不同，并提供OOD检测与反事实解释以增强模型可靠性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型通常仅在单一成像模态上评测，难以反映实际部署中因模态差异导致的性能波动，材料研究人员缺乏针对特定成像条件选择合适模型及评估其可信度的工具。

Method: 构建覆盖SEM、AFM、XCT和光学显微镜的跨模态评估框架，系统评测6种编码器-解码器组合在7个数据集上的表现；引入分布外检测（OOD detection）与反事实解释（counterfactual explanations）以提供部署反馈和决策依据。

Result: UNet在高对比度2D成像中表现最优，DeepLabv3+在最具挑战性的案例中更优；框架能识别模型在新样本上的失效风险，并揭示驱动预测的关键微观结构特征。

Conclusion: 该框架填补了材料表征中模型选型与可信评估的实用空白，为面向具体成像场景的分割模型部署提供了架构指导、可靠性信号与可解释性支持。

Abstract: Segmentation architectures are typically benchmarked on single imaging modalities, obscuring deployment-relevant performance variations: an architecture optimal for one modality may underperform on another. We present a cross-modal evaluation framework for materials image segmentation spanning SEM, AFM, XCT, and optical microscopy. Our evaluation of six encoder-decoder combinations across seven datasets reveals that optimal architectures vary systematically by context: UNet excels for high-contrast 2D imaging while DeepLabv3+ is preferred for the hardest cases. The framework also provides deployment feedback via out-of-distribution detection and counterfactual explanations that reveal which microstructural features drive predictions. Together, the architecture guidance, reliability signals, and interpretability tools address a practical gap in materials characterization, where researchers lack tools to select architectures for their specific imaging setup or assess when models can be trusted on new samples.

</details>


### [31] [Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity](https://arxiv.org/abs/2602.04162)
*Chenhe Du,Qing Wu,Xuanyu Tian,Jingyi Yu,Hongjiang Wei,Yuyao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Inter-Slice Consistent Stochasticity (ISCS)的策略，通过在扩散采样过程中控制切片间噪声的一致性，缓解2D训练扩散模型用于3D医学图像重建时出现的层间不连续问题，无需额外损失或计算开销，具有即插即用特性。


<details>
  <summary>Details</summary>
Motivation: 2D训练的扩散模型用于3D医学图像重建时，因采样随机性导致层间不连续；现有连续性正则化方法依赖敏感超参且易过平滑。

Method: 提出ISCS策略，在扩散采样中显式约束相邻切片的噪声成分一致性，对齐其采样轨迹，不引入新损失或优化步骤。

Result: 在多个医学成像任务上验证了ISCS可显著提升基于2D扩散模型的3D重建质量，改善层间连续性与整体结构保真度。

Conclusion: 控制层间随机性是利用2D扩散先验实现高保真3D医学成像的一种原理清晰且实用有效的途径；ISCS具备通用性、零开销和即插即用优势。

Abstract: 3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distribution with DMs in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the DMs on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter-slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the z-axis, which introduces sensitive hyper-parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter-Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages interslice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps. Importantly, the proposed ISCS is plug-and-play and can be dropped into any 2D trained diffusion based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter-slice stochasticity is a principled and practically attractive route toward high-fidelity 3D medical imaging with 2D diffusion priors. The code is available at: https://github.com/duchenhe/ISCS

</details>


### [32] [Point2Insert: Video Object Insertion via Sparse Point Guidance](https://arxiv.org/abs/2602.04167)
*Yu Zhou,Xiaoyan Yang,Bojia Zi,Lihan Zhang,Ruijie Sun,Weishi Zheng,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了Point2Insert，一种基于稀疏点的视频对象插入框架，通过正负点提示实现精细空间控制，避免了繁琐的掩码标注，并在两阶段训练中结合掩码引导蒸馏提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两大挑战：基于掩码的方法需要大量人工标注，而基于指令的方法难以精确定位；同时，掩码引导编辑成功率更高，值得借鉴。

Method: 采用两阶段训练：第一阶段训练支持稀疏点或二值掩码提示的插入模型；第二阶段利用对象移除模型生成配对视频进行微调；并引入掩码引导插入模型作为教师模型，对点引导模型进行知识蒸馏。

Result: Point2Insert在实验中持续优于强基线，甚至超越参数量高10倍的模型。

Conclusion: Point2Insert以少量稀疏点替代密集掩码，实现了灵活、用户友好的视频对象插入，在精度、效率与易用性之间取得良好平衡。

Abstract: This paper introduces Point2Insert, a sparse-point-based framework for flexible and user-friendly object insertion in videos, motivated by the growing popularity of accurate, low-effort object placement. Existing approaches face two major challenges: mask-based insertion methods require labor-intensive mask annotations, while instruction-based methods struggle to place objects at precise locations. Point2Insert addresses these issues by requiring only a small number of sparse points instead of dense masks, eliminating the need for tedious mask drawing. Specifically, it supports both positive and negative points to indicate regions that are suitable or unsuitable for insertion, enabling fine-grained spatial control over object locations. The training of Point2Insert consists of two stages. In Stage 1, we train an insertion model that generates objects in given regions conditioned on either sparse-point prompts or a binary mask. In Stage 2, we further train the model on paired videos synthesized by an object removal model, adapting it to video insertion. Moreover, motivated by the higher insertion success rate of mask-guided editing, we leverage a mask-guided insertion model as a teacher to distill reliable insertion behavior into the point-guided model. Extensive experiments demonstrate that Point2Insert consistently outperforms strong baselines and even surpasses models with $\times$10 more parameters.

</details>


### [33] [Partial Ring Scan: Revisiting Scan Order in Vision State Space Models](https://arxiv.org/abs/2602.04170)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin li,Ming-Ching Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: 本文提出PRISMamba，一种旋转鲁棒的图像扫描方法，通过环形分割、环内无序聚合和径向SSM跨环传播来提升视觉状态空间模型的性能与鲁棒性，并结合部分通道过滤提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉SSM将2D图像按固定扫描顺序展平为1D序列，忽视了扫描顺序对空间邻接性、物体连续性和几何变换鲁棒性的影响。

Method: 提出Partial RIng Scan Mamba（PRISMamba）：将图像划分为同心环，在每环内进行顺序无关的特征聚合，并通过短径向SSM跨环传递上下文；引入部分通道过滤机制，仅将信息量最大的通道送入循环路径，其余走轻量残差分支。

Result: 在ImageNet-1K上达到84.5% Top-1准确率，3.9G FLOPs，A100上3054 img/s，精度与吞吐均优于VMamba且FLOPs更低；旋转下性能稳定，而固定路径扫描下降1~2%。

Conclusion: 扫描顺序设计与通道过滤是影响视觉SSM精度、效率和旋转鲁棒性的关键但被忽视因素。

Abstract: State Space Models (SSMs) have emerged as efficient alternatives to attention for vision tasks, offering lineartime sequence processing with competitive accuracy. Vision SSMs, however, require serializing 2D images into 1D token sequences along a predefined scan order, a factor often overlooked. We show that scan order critically affects performance by altering spatial adjacency, fracturing object continuity, and amplifying degradation under geometric transformations such as rotation. We present Partial RIng Scan Mamba (PRISMamba), a rotation-robust traversal that partitions an image into concentric rings, performs order-agnostic aggregation within each ring, and propagates context across rings through a set of short radial SSMs. Efficiency is further improved via partial channel filtering, which routes only the most informative channels through the recurrent ring pathway while keeping the rest on a lightweight residual branch. On ImageNet-1K, PRISMamba achieves 84.5% Top-1 with 3.9G FLOPs and 3,054 img/s on A100, outperforming VMamba in both accuracy and throughput while requiring fewer FLOPs. It also maintains performance under rotation, whereas fixed-path scans drop by 1~2%. These results highlight scan-order design, together with channel filtering, as a crucial, underexplored factor for accuracy, efficiency, and rotation robustness in Vision SSMs. Code will be released upon acceptance.

</details>


### [34] [HoloEv-Net: Efficient Event-based Action Recognition via Holographic Spatial Embedding and Global Spectral Gating](https://arxiv.org/abs/2602.04182)
*Weidong Hao*

Main category: cs.CV

TL;DR: 本文提出了一种高效事件驱动动作识别框架HoloEv-Net，通过紧凑全息时空表示（CHSR）解决表示与结构冗余，并引入全局频谱门控（GSG）模块利用频域信息，显著提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有事件驱动动作识别方法存在体素表示计算冗余、多分支架构结构冗余、以及频谱信息利用不足等问题。

Method: 提出Compact Holographic Spatiotemporal Representation（CHSR）以2D方式隐式编码3D时空信息；设计Global Spectral Gating（GSG）模块，利用FFT在频域进行全局token混合。

Result: HoloEv-Net-Base在THU-EACT-50-CHL、HARDVS和DailyDVS-200上分别超越SOTA 10.29%、1.71%、6.25%；轻量版HoloEv-Net-Small参数减少5.4倍、FLOPs降低300倍、延迟降低2.4倍。

Conclusion: HoloEv-Net兼顾高精度与高效率，尤其轻量版本适合边缘部署，为事件相机动作识别提供了新范式。

Abstract: Event-based Action Recognition (EAR) has attracted significant attention due to the high temporal resolution and high dynamic range of event cameras. However, existing methods typically suffer from (i) the computational redundancy of dense voxel representations, (ii) structural redundancy inherent in multi-branch architectures, and (iii) the under-utilization of spectral information in capturing global motion patterns. To address these challenges, we propose an efficient EAR framework named HoloEv-Net. First, to simultaneously tackle representation and structural redundancies, we introduce a Compact Holographic Spatiotemporal Representation (CHSR). Departing from computationally expensive voxel grids, CHSR implicitly embeds horizontal spatial cues into the Time-Height (T-H) view, effectively preserving 3D spatiotemporal contexts within a 2D representation. Second, to exploit the neglected spectral cues, we design a Global Spectral Gating (GSG) module. By leveraging the Fast Fourier Transform (FFT) for global token mixing in the frequency domain, GSG enhances the representation capability with negligible parameter overhead. Extensive experiments demonstrate the scalability and effectiveness of our framework. Specifically, HoloEv-Net-Base achieves state-of-the-art performance on THU-EACT-50-CHL, HARDVS and DailyDVS-200, outperforming existing methods by 10.29%, 1.71% and 6.25%, respectively. Furthermore, our lightweight variant, HoloEv-Net-Small, delivers highly competitive accuracy while offering extreme efficiency, reducing parameters by 5.4 times, FLOPs by 300times, and latency by 2.4times compared to heavy baselines, demonstrating its potential for edge deployment.

</details>


### [35] [Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models](https://arxiv.org/abs/2602.04184)
*Angel Martinez-Sanchez,Parthib Roy,Ross Greer*

Main category: cs.CV

TL;DR: 本文提出了一种基于指令的端到端自动驾驶规划方法，利用doScenes真实世界数据集和OpenEMMA多模态大语言模型框架，将乘客自然语言指令融入视觉-语言接口，显著提升了轨迹预测鲁棒性与对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有指令跟随式规划器依赖仿真或固定指令词表，泛化能力差；缺乏真实世界中自由形式语言指令与车辆运动真值关联的数据集。

Method: 将doScenes中的自由形式指令作为乘客式提示，集成到OpenEMMA（基于MLLM的端到端驾驶框架）的视觉-语言接口中，实现语言条件下的10步速度-曲率轨迹生成，并在849个标注场景上用ADE指标评估。

Result: 指令条件化使平均ADE降低98.7%，极大缓解极端失败；剔除异常后，优质指令仍可进一步提升ADE达5.1%；并总结了适配OpenEMMA的‘好指令’特征。

Conclusion: 自然语言指令能有效提升真实场景下端到端规划的鲁棒性与可控性；doScenes与适配后的OpenEMMA构成可复现的指令感知规划基线，并开源评估脚本与提示模板。

Abstract: Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-world dataset linking free-form instructions (with referentiality) to nuScenes ground-truth motion, enables instruction-conditioned planning. In this work, we adapt OpenEMMA, an open-source MLLM-based end-to-end driving framework that ingests front-camera views and ego-state and outputs 10-step speed-curvature trajectories, to this setting, presenting a reproducible instruction-conditioned baseline on doScenes and investigate the effects of human instruction prompts on predicted driving behavior. We integrate doScenes directives as passenger-style prompts within OpenEMMA's vision-language interface, enabling linguistic conditioning before trajectory generation. Evaluated on 849 annotated scenes using ADE, we observe that instruction conditioning substantially improves robustness by preventing extreme baseline failures, yielding a 98.7% reduction in mean ADE. When such outliers are removed, instructions still influence trajectory alignment, with well-phrased prompts improving ADE by up to 5.1%. We use this analysis to discuss what makes a "good" instruction for the OpenEMMA framework. We release the evaluation prompts and scripts to establish a reproducible baseline for instruction-aware planning. GitHub: https://github.com/Mi3-Lab/doScenes-VLM-Planning

</details>


### [36] [DiMo: Discrete Diffusion Modeling for Motion Generation and Understanding](https://arxiv.org/abs/2602.04188)
*Ning Zhang,Zhengyu Li,Kwong Weng Loh,Mingxi Xu,Qi Wang,Zhengyu Wen,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: DiMo是一种离散扩散风格的双向文本-动作理解与生成框架，通过迭代掩码标记优化统一了文本到动作、动作到文本及无文本动作到动作任务，并在质量与推理延迟间提供权衡。


<details>
  <summary>Details</summary>
Motivation: 现有掩码建模动作生成方法主要关注文本到动作（T2M），缺乏对双向文本-动作理解和生成的统一建模能力。

Method: 提出DiMo框架，采用离散扩散式迭代掩码标记细化机制；引入残差向量量化（RVQ）提升动作标记保真度，结合组相对策略优化（GRPO）增强对齐性与可控性。

Result: 在HumanML3D和KIT-ML数据集上验证了高质量动作生成能力与强双向理解性能；支持无文本动作补全、文本引导动作预测与动作字幕修正等任务，无需架构更改。

Conclusion: DiMo实现了文本-动作双向理解与生成的统一建模，兼具灵活性、可控性与扩展性，为多模态人机交互提供了新范式。

Abstract: Prior masked modeling motion generation methods predominantly study text-to-motion. We present DiMo, a discrete diffusion-style framework, which extends masked modeling to bidirectional text--motion understanding and generation. Unlike GPT-style autoregressive approaches that tokenize motion and decode sequentially, DiMo performs iterative masked token refinement, unifying Text-to-Motion (T2M), Motion-to-Text (M2T), and text-free Motion-to-Motion (M2M) within a single model. This decoding paradigm naturally enables a quality-latency trade-off at inference via the number of refinement steps.We further improve motion token fidelity with residual vector quantization (RVQ) and enhance alignment and controllability with Group Relative Policy Optimization (GRPO). Experiments on HumanML3D and KIT-ML show strong motion quality and competitive bidirectional understanding under a unified framework. In addition, we demonstrate model ability in text-free motion completion, text-guided motion prediction and motion caption correction without architectural change.Additional qualitative results are available on our project page: https://animotionlab.github.io/DiMo/.

</details>


### [37] [Continuous Degradation Modeling via Latent Flow Matching for Real-World Super-Resolution](https://arxiv.org/abs/2602.04193)
*Hyeonjae Kim,Dongjin Kim,Eugene Jin,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种基于流匹配的隐式退化空间方法，用于从单张高清图像合成具有真实退化（如噪声、模糊、压缩伪影）的低清图像，从而构建大规模真实世界超分辨率训练数据集，并显著提升多种超分辨率模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习超分辨率方法在合成退化（如双三次下采样）上表现好，但在真实复杂非线性退化（噪声、模糊、压缩伪影）上效果差；现有真实LR-HR配对数据集构建困难、规模小、退化类型和尺度受限。

Method: 提出一种新框架，利用流匹配（flow matching）建模隐式退化空间，仅需单张HR图像即可合成具有真实退化特征的LR图像，支持任意未见退化程度与类型。

Result: 合成的LR图像能准确复现真实退化；基于该数据集训练的传统及任意尺度超分辨率模型，在定量与定性评估中均显著优于基线方法。

Conclusion: 所提退化合成框架有效缓解了真实世界超分辨率的数据瓶颈问题，为训练更鲁棒的SR模型提供了高质量、可扩展的训练数据生成范式。

Abstract: While deep learning-based super-resolution (SR) methods have shown impressive outcomes with synthetic degradation scenarios such as bicubic downsampling, they frequently struggle to perform well on real-world images that feature complex, nonlinear degradations like noise, blur, and compression artifacts. Recent efforts to address this issue have involved the painstaking compilation of real low-resolution (LR) and high-resolution (HR) image pairs, usually limited to several specific downscaling factors. To address these challenges, our work introduces a novel framework capable of synthesizing authentic LR images from a single HR image by leveraging the latent degradation space with flow matching. Our approach generates LR images with realistic artifacts at unseen degradation levels, which facilitates the creation of large-scale, real-world SR training datasets. Comprehensive quantitative and qualitative assessments verify that our synthetic LR images accurately replicate real-world degradations. Furthermore, both traditional and arbitrary-scale SR models trained using our datasets consistently yield much better HR outcomes.

</details>


### [38] [VTok: A Unified Video Tokenizer with Decoupled Spatial-Temporal Latents](https://arxiv.org/abs/2602.04202)
*Feng Wang,Yichun Shi,Ceyuan Yang,Qiushan Guo,Jingxiang Sun,Alan Yuille,Peng Wang*

Main category: cs.CV

TL;DR: VTok是一种统一的视频标记化框架，通过解耦时空表征（保留关键帧空间特征+后续帧残差标记）实现紧凑而富有表现力的视频标记，在视频理解和生成任务中显著提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言系统采用简单帧采样策略进行视频标记化，导致表示冗余、复杂度高，难以兼顾时空一致性与表达能力。

Method: 提出VTok框架：对视频选取一个关键帧保留其完整空间特征，其余帧则编码为单个残差标记，从而将视频表示复杂度从帧数×每帧标记数降至二者之和。

Result: 在TV-Align和VBench等基准上分别提升3.4%准确率和1.9%分数；生成视频运动更连贯、文本引导性更强；整体标记序列更短。

Conclusion: VTok提供了一种高效、一致且表现力强的视频标记化范式，有望成为视频理解与生成领域的新标准。

Abstract: This work presents VTok, a unified video tokenization framework that can be used for both generation and understanding tasks. Unlike the leading vision-language systems that tokenize videos through a naive frame-sampling strategy, we propose to decouple the spatial and temporal representations of videos by retaining the spatial features of a single key frame while encoding each subsequent frame into a single residual token, achieving compact yet expressive video tokenization. Our experiments suggest that VTok effectively reduces the complexity of video representation from the product of frame count and per-frame token count to their sum, while the residual tokens sufficiently capture viewpoint and motion changes relative to the key frame. Extensive evaluations demonstrate the efficacy and efficiency of VTok: it achieves notably higher performance on a range of video understanding and text-to-video generation benchmarks compared with baselines using naive tokenization, all with shorter token sequences per video (e.g., 3.4% higher accuracy on our TV-Align benchmark and 1.9% higher VBench score). Remarkably, VTok produces more coherent motion and stronger guidance following in text-to-video generation, owing to its more consistent temporal encoding. We hope VTok can serve as a standardized video tokenization paradigm for future research in video understanding and generation.

</details>


### [39] [AGMA: Adaptive Gaussian Mixture Anchors for Prior-Guided Multimodal Human Trajectory Forecasting](https://arxiv.org/abs/2602.04204)
*Chao Li,Rui Zhang,Siyuan Huang,Xian Zhong,Hongbo Jiang*

Main category: cs.CV

TL;DR: 本文提出AGMA方法，通过自适应高斯混合锚点构建高质量先验，以解决行人轨迹预测中先验错位问题，显著提升预测准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹预测方法因先验错位，无法充分建模行人行为的多模态分布，导致预测精度和多样性受限；理论分析表明预测误差受先验质量下限约束，故先验建模是关键瓶颈。

Method: 提出AGMA（Adaptive Gaussian Mixture Anchors），分两阶段构建表达性强的先验：首先从训练数据中提取多样化行为模式，再将其蒸馏为场景自适应的全局先验用于推理。

Result: 在ETH-UCY、Stanford Drone和JRDB数据集上的大量实验表明，AGMA达到轨迹预测任务的最先进性能。

Conclusion: 高质量先验对行人轨迹预测至关重要，AGMA通过自适应建模显著提升了预测效果，验证了先验设计的核心作用。

Abstract: Human trajectory forecasting requires capturing the multimodal nature of pedestrian behavior. However, existing approaches suffer from prior misalignment. Their learned or fixed priors often fail to capture the full distribution of plausible futures, limiting both prediction accuracy and diversity. We theoretically establish that prediction error is lower-bounded by prior quality, making prior modeling a key performance bottleneck. Guided by this insight, we propose AGMA (Adaptive Gaussian Mixture Anchors), which constructs expressive priors through two stages: extracting diverse behavioral patterns from training data and distilling them into a scene-adaptive global prior for inference. Extensive experiments on ETH-UCY, Stanford Drone, and JRDB datasets demonstrate that AGMA achieves state-of-the-art performance, confirming the critical role of high-quality priors in trajectory forecasting.

</details>


### [40] [Adaptive 1D Video Diffusion Autoencoder](https://arxiv.org/abs/2602.04220)
*Yao Teng,Minxuan Lin,Xian Liu,Shuai Wang,Xiao Yang,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出One-DVA，一种基于一维扩散的视频自编码器，采用查询式ViT编码器与可变长度dropout实现自适应压缩，结合像素空间扩散Transformer解码器，解决了现有视频自编码器固定码率、CNN架构僵化和确定性解码三大缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有视频自编码器存在固定码率浪费、CNN架构不支持可变长建模、确定性解码难以恢复细节三大问题。

Method: 提出One-DVA框架：编码器为查询式视觉Transformer+可变长度dropout；解码器为以潜变量为条件的像素空间扩散Transformer；采用两阶段训练，并对潜分布正则化、解码器微调以适配生成任务。

Result: 在相同压缩比下重建指标媲美3D-CNN VAE；支持自适应压缩，可实现更高压缩比；经正则化与微调后更适配下游生成任务。

Conclusion: One-DVA通过Transformer与扩散模型协同设计，突破传统视频自编码器瓶颈，在压缩效率与生成友好性上取得兼顾。

Abstract: Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.

</details>


### [41] [An Intuitionistic Fuzzy Logic Driven UNet architecture: Application to Brain Image segmentation](https://arxiv.org/abs/2602.04227)
*Hanuman Verma,Kiho Im,Pranabesh Maji,Akshansh Gupta*

Main category: cs.CV

TL;DR: 本文提出了一种结合直觉模糊逻辑的UNet模型（IF-UNet），用于提升MRI脑图像分割中对部分体积效应和边界不确定性等模糊性的处理能力，并在IBSR数据集上验证了其优于传统UNet的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN（尤其是UNet）的脑MRI图像分割方法难以有效应对由部分体积效应引起的组织模糊性和边界不确定性，导致分割结果存在不确定性。

Method: 提出IF-UNet框架，在UNet中引入直觉模糊逻辑，使模型能同时建模隶属度、非隶属度和犹豫度三个维度，以更精细地刻画组织模糊性。

Result: 在IBSR数据集上的实验表明，IF-UNet在准确率、Dice系数和IoU等指标上均优于标准UNet，证实其能更有效地处理脑图像中的不确定性。

Conclusion: 将直觉模糊逻辑融入UNet可显著提升MRI脑图像分割对不确定性的鲁棒性与精度，为医学图像模糊建模提供了新思路。

Abstract: Accurate segmentation of MRI brain images is essential for image analysis, diagnosis of neuro-logical disorders and medical image computing. In the deep learning approach, the convolutional neural networks (CNNs), especially UNet, are widely applied in medical image segmentation. However, it is difficult to deal with uncertainty due to the partial volume effect in brain images. To overcome this limitation, we propose an enhanced framework, named UNet with intuitionistic fuzzy logic (IF-UNet), which incorporates intuitionistic fuzzy logic into UNet. The model processes input data in terms of membership, nonmembership, and hesitation degrees, allowing it to better address tissue ambiguity resulting from partial volume effects and boundary uncertainties. The proposed architecture is evaluated on the Internet Brain Segmentation Repository (IBSR) dataset, and its performance is computed using accuracy, Dice coefficient, and intersection over union (IoU). Experimental results confirm that IF-UNet improves segmentation quality with handling uncertainty in brain images.

</details>


### [42] [SPOT-Occ: Sparse Prototype-guided Transformer for Camera-based 3D Occupancy Prediction](https://arxiv.org/abs/2602.04240)
*Suzeyu Chen,Leheng Li,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于原型的稀疏Transformer解码器（SPOT-Occ），通过两阶段的引导式特征选择与聚焦聚合，高效处理稀疏不均匀的体素特征，在提升3D占用预测精度的同时显著加速推理。


<details>
  <summary>Details</summary>
Motivation: 从单目图像实现高精度、实时的3D占用预测对自动驾驶至关重要；现有稀疏表示虽缓解编码瓶颈，却使解码器面临在稀疏非均匀体素特征上进行高效信息聚合的挑战，而密集注意力计算开销过大。

Method: 提出原型引导的稀疏Transformer解码器：1）稀疏原型选择机制，使每个查询自适应选取最具判别性的少量体素特征作为原型；2）结合基于真值掩码的去噪范式，保障各解码层中查询与原型关联的一致性与稳定性。

Result: SPOT-Occ在速度上显著优于先前方法，同时提升了预测精度。

Conclusion: 原型引导的稀疏注意力机制可有效平衡3D占用预测任务中的效率与性能，为实时视觉BEV感知提供了新思路。

Abstract: Achieving highly accurate and real-time 3D occupancy prediction from cameras is a critical requirement for the safe and practical deployment of autonomous vehicles. While this shift to sparse 3D representations solves the encoding bottleneck, it creates a new challenge for the decoder: how to efficiently aggregate information from a sparse, non-uniformly distributed set of voxel features without resorting to computationally prohibitive dense attention.
  In this paper, we propose a novel Prototype-based Sparse Transformer Decoder that replaces this costly interaction with an efficient, two-stage process of guided feature selection and focused aggregation. Our core idea is to make the decoder's attention prototype-guided. We achieve this through a sparse prototype selection mechanism, where each query adaptively identifies a compact set of the most salient voxel features, termed prototypes, for focused feature aggregation.
  To ensure this dynamic selection is stable and effective, we introduce a complementary denoising paradigm. This approach leverages ground-truth masks to provide explicit guidance, guaranteeing a consistent query-prototype association across decoder layers. Our model, dubbed SPOT-Occ, outperforms previous methods with a significant margin in speed while also improving accuracy. Source code is released at https://github.com/chensuzeyu/SpotOcc.

</details>


### [43] [ACIL: Active Class Incremental Learning for Image Classification](https://arxiv.org/abs/2602.04252)
*Aditya R. Bhattacharya,Debanjan Goswami,Shayok Chakraborty*

Main category: cs.CV

TL;DR: 本文提出ACIL框架，将主动学习引入类增量学习，通过不确定性与多样性准则选择关键样本进行标注，显著降低标注成本并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有类增量学习方法假设每轮训练数据均完全标注，导致高昂的标注成本和资源浪费；而主动学习可有效减少人工标注需求，因此有必要将其与类增量学习结合。

Method: 提出ACIL主动学习框架，在每轮增量学习中基于不确定性与多样性准则选取代表性样本进行标注，并将其保留至下一轮训练，以兼顾标注效率与模型持续学习能力。

Result: 在多个视觉数据集上的实验表明，ACIL显著降低标注成本，同时在分类准确率和缓解灾难性遗忘方面优于相关基线方法。

Conclusion: ACIL成功将主动学习与类增量学习融合，验证了在有限标注预算下实现高效、可持续视觉学习的可行性与优势。

Abstract: Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focused on avoiding catastrophic forgetting, which occurs due to the continuously changing class distributions in each episode and the inaccessibility of the data from previous episodes. However, these methods assume that all the training samples in every episode are annotated; this not only incurs a huge annotation cost, but also results in a wastage of annotation effort, since most of the samples in a given episode will not be accessible to the model in subsequent episodes. Active learning algorithms identify the salient and informative samples from large amounts of unlabeled data and are instrumental in reducing the human annotation effort in inducing a deep neural network. In this paper, we propose ACIL, a novel active learning framework for class incremental learning settings. We exploit a criterion based on uncertainty and diversity to identify the exemplar samples that need to be annotated in each episode, and will be appended to the data in the next episode. Such a framework can drastically reduce annotation cost and can also avoid catastrophic forgetting. Our extensive empirical analyses on several vision datasets corroborate the promise and potential of our framework against relevant baselines.

</details>


### [44] [Depth-Guided Metric-Aware Temporal Consistency for Monocular Video Human Mesh Recovery](https://arxiv.org/abs/2602.04257)
*Jiaxin Cen,Xudong Mao,Guanghui Yue,Wei Zhou,Ruomei Wang,Fan Zhou,Baoquan Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种深度引导的单目视频人体网格恢复框架，通过多尺度几何-外观融合、度量感知姿态形状估计和运动-深度对齐细化三个模块，显著提升了深度一致性、时间稳定性与遮挡鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单目视频人体网格恢复面临深度模糊和尺度不确定性问题，导致度量不一致和时间不稳定，现有方法在深度排序、尺度漂移和遮挡下表现不佳。

Method: 提出深度引导的三模块框架：1）深度引导多尺度融合模块，通过置信度门控融合几何先验与RGB特征；2）深度校准的度量感知姿态形状（D-MAPS）估计器，利用深度校准的骨骼统计实现尺度一致初始化；3）运动-深度对齐细化（MoDAR）模块，通过运动动态与几何线索间的跨模态注意力保证时间一致性。

Result: 在三个基准上取得优越性能，显著提升遮挡鲁棒性、空间精度和计算效率。

Conclusion: 深度引导的多模态协同建模可有效缓解单目视频中固有的尺度与深度歧义，为人体网格恢复提供了更鲁棒、更度量一致的解决方案。

Abstract: Monocular video human mesh recovery faces fundamental challenges in maintaining metric consistency and temporal stability due to inherent depth ambiguities and scale uncertainties. While existing methods rely primarily on RGB features and temporal smoothing, they struggle with depth ordering, scale drift, and occlusion-induced instabilities. We propose a comprehensive depth-guided framework that achieves metric-aware temporal consistency through three synergistic components: A Depth-Guided Multi-Scale Fusion module that adaptively integrates geometric priors with RGB features via confidence-aware gating; A Depth-guided Metric-Aware Pose and Shape (D-MAPS) estimator that leverages depth-calibrated bone statistics for scale-consistent initialization; A Motion-Depth Aligned Refinement (MoDAR) module that enforces temporal coherence through cross-modal attention between motion dynamics and geometric cues. Our method achieves superior results on three challenging benchmarks, demonstrating significant improvements in robustness against heavy occlusion and spatial accuracy while maintaining computational efficiency.

</details>


### [45] [Decoupled Hierarchical Distillation for Multimodal Emotion Recognition](https://arxiv.org/abs/2602.04260)
*Yong Li,Yuanzhi Wang,Yi Ding,Shiqing Zhang,Ke Lu,Cuntai Guan*

Main category: cs.CV

TL;DR: 本文提出了一种解耦分层多模态蒸馏框架（DHMD），用于提升人类多模态情感识别（MER）性能，通过将各模态特征解耦为模态无关与模态独有成分，并结合图蒸馏与跨模态字典匹配实现粗粒度与细粒度知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 现有MER方法难以应对多模态固有的异质性及各模态贡献不一致的问题。

Method: 提出Decoupled Hierarchical Multimodal Distillation（DHMD）框架：1）利用自回归机制解耦各模态特征为模态无关（同质）和模态独有（异质）成分；2）两阶段知识蒸馏：①在各解耦空间中通过动态图驱动的Graph Distillation Unit（GD-Unit）进行粗粒度蒸馏；②通过跨模态字典匹配机制实现细粒度语义对齐。

Result: 在CMU-MOSI和CMU-MOSEI数据集上，DHMD在ACC7、ACC2和F1指标上分别取得1.3%/2.4%、1.3%/1.9%、1.9%/1.8%的相对提升，显著优于SOTA方法；可视化显示图边权重与字典激活在两类特征空间中呈现有意义分布。

Conclusion: DHMD通过解耦表征与分层蒸馏有效缓解多模态异质性问题，提升了跨模态对齐能力与情感识别性能，为MER提供了新范式。

Abstract: Human multimodal emotion recognition (MER) seeks to infer human emotions by integrating information from language, visual, and acoustic modalities. Although existing MER approaches have achieved promising results, they still struggle with inherent multimodal heterogeneities and varying contributions from different modalities. To address these challenges, we propose a novel framework, Decoupled Hierarchical Multimodal Distillation (DHMD). DHMD decouples each modality's features into modality-irrelevant (homogeneous) and modality-exclusive (heterogeneous) components using a self-regression mechanism. The framework employs a two-stage knowledge distillation (KD) strategy: (1) coarse-grained KD via a Graph Distillation Unit (GD-Unit) in each decoupled feature space, where a dynamic graph facilitates adaptive distillation among modalities, and (2) fine-grained KD through a cross-modal dictionary matching mechanism, which aligns semantic granularities across modalities to produce more discriminative MER representations. This hierarchical distillation approach enables flexible knowledge transfer and effectively improves cross-modal feature alignment. Experimental results demonstrate that DHMD consistently outperforms state-of-the-art MER methods, achieving 1.3\%/2.4\% (ACC$_7$), 1.3\%/1.9\% (ACC$_2$) and 1.9\%/1.8\% (F1) relative improvement on CMU-MOSI/CMU-MOSEI dataset, respectively. Meanwhile, visualization results reveal that both the graph edges and dictionary activations in DHMD exhibit meaningful distribution patterns across modality-irrelevant/-exclusive feature spaces.

</details>


### [46] [KVSmooth: Mitigating Hallucination in Multi-modal Large Language Models through Key-Value Smoothing](https://arxiv.org/abs/2602.04268)
*Siyu Jiang,Feiyang Chen,Xiaojin Zhang,Kun He*

Main category: cs.CV

TL;DR: 本文提出KVSmooth方法，无需训练即可在推理阶段减少多模态大语言模型（MLLMs）的视觉不一致幻觉问题，通过注意力熵引导的自适应隐藏状态平滑实现高效、即插即用的改进。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在生成过程中易出现视觉不一致的幻觉，尤其在解码变长时因语义漂移而偏离图像事实，亟需轻量、无需重训练的缓解方案。

Method: KVSmooth是一种训练无关、即插即用的方法：在推理中对KV缓存中的键（keys）和值（values）应用指数移动平均（EMA），并基于各token注意力分布的熵动态量化其‘沉降程度’，从而自适应调整平滑强度。

Result: 在CHAIR_S指标上幻觉率从41.8大幅降至18.2，同时F1分数从77.5提升至79.2，精度与召回率同步提高，优于以往权衡二者的方法。

Conclusion: KVSmooth以零训练成本、低计算开销有效缓解MLLMs幻觉，兼具高效性、通用性与实用性，为可信多模态生成提供了新思路。

Abstract: Despite the significant progress of Multimodal Large Language Models (MLLMs) across diverse tasks, hallucination -- corresponding to the generation of visually inconsistent objects, attributes, or relations -- remains a major obstacle to their reliable deployment. Unlike pure language models, MLLMs must ground their generation process in visual inputs. However, existing models often suffer from semantic drift during decoding, causing outputs to diverge from visual facts as the sequence length increases.
  To address this issue, we propose KVSmooth, a training-free and plug-and-play method that mitigates hallucination by performing attention-entropy-guided adaptive smoothing on hidden states. Specifically, KVSmooth applies an exponential moving average (EMA) to both keys and values in the KV-Cache, while dynamically quantifying the sink degree of each token through the entropy of its attention distribution to adaptively adjust the smoothing strength.
  Unlike computationally expensive retraining or contrastive decoding methods, KVSmooth operates efficiently during inference without additional training or model modification. Extensive experiments demonstrate that KVSmooth significantly reduces hallucination ($\mathit{CHAIR}_{S}$ from $41.8 \rightarrow 18.2$) while improving overall performance ($F_1$ score from $77.5 \rightarrow 79.2$), achieving higher precision and recall simultaneously. In contrast, prior methods often improve one at the expense of the other, validating the effectiveness and generality of our approach.

</details>


### [47] [S-MUSt3R: Sliding Multi-view 3D Reconstruction](https://arxiv.org/abs/2602.04517)
*Leonid Antsfeld,Boris Chidlovskii,Yohann Cabon,Vincent Leroy,Jerome Revaud*

Main category: cs.CV

TL;DR: S-MUSt3R是一种无需重训练、基于序列分段与对齐的轻量级单目3D重建方法，扩展了MUSt3R基础模型在长视频流中的可扩展性，在多个数据集上实现了媲美传统方法的精度与一致性，并直接输出度量空间结果。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉基础模型难以扩展到大规模RGB视频流的3D重建，主要受限于内存瓶颈。

Method: 提出S-MUSt3R流水线：对长RGB序列进行分段处理，再通过段间对齐与轻量级闭环优化实现整体一致性重建；完全复用预训练MUSt3R模型，不涉及任何模型微调或重训练。

Result: 在TUM、7-Scenes及自研机器人导航数据集上验证有效，能成功处理长序列，重建结果准确且一致，并直接输出度量空间下的轨迹与三维结构。

Conclusion: MUSt3R等基础模型可通过简单工程策略（如分段+对齐+优化）实现可扩展单目3D重建，具备实际部署潜力，尤其在无需深度传感器、需度量尺度的应用场景中优势显著。

Abstract: The recent paradigm shift in 3D vision led to the rise of foundation models with remarkable capabilities in 3D perception from uncalibrated images. However, extending these models to large-scale RGB stream 3D reconstruction remains challenging due to memory limitations. This work proposes S-MUSt3R, a simple and efficient pipeline that extends the limits of foundation models for monocular 3D reconstruction. Our approach addresses the scalability bottleneck of foundation models through a simple strategy of sequence segmentation followed by segment alignment and lightweight loop closure optimization. Without model retraining, we benefit from remarkable 3D reconstruction capacities of MUSt3R model and achieve trajectory and reconstruction performance comparable to traditional methods with more complex architecture. We evaluate S-MUSt3R on TUM, 7-Scenes and proprietary robot navigation datasets and show that S-MUSt3R runs successfully on long RGB sequences and produces accurate and consistent 3D reconstruction. Our results highlight the potential of leveraging the MUSt3R model for scalable monocular 3D scene in real-world settings, with an important advantage of making predictions directly in the metric space.

</details>


### [48] [Light Up Your Face: A Physically Consistent Dataset and Diffusion Model for Face Fill-Light Enhancement](https://arxiv.org/abs/2602.04300)
*Jue Gong,Zihan Zhou,Jingkai Wang,Xiaohong Liu,Yulun Zhang,Xiaokang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种面向人脸补光增强（FFE）的专用方法FiLitDiff，结合新构建的大规模物理一致配对数据集LYF-160K，通过物理感知的照明提示（PALP）与一步式扩散模型实现可控、高保真且背景一致的人脸补光。


<details>
  <summary>Details</summary>
Motivation: 现有面部分光照重绘方法多侧重整体光照重塑，易破坏原始场景光照一致性，难以满足真实FFE需求（仅增强人脸、保持背景不变）。

Method: 构建大规模物理一致配对数据集LYF-160K（16万对），提出物理感知照明提示（PALP）编码6维补光参数，并基于预训练扩散主干设计轻量一步式填充光扩散模型FiLitDiff，以物理驱动的照明码为条件进行生成。

Result: 在保留背景光照前提下，FiLitDiff在感知质量与全参考指标上均表现优异，显著优于通用重光照方法；模型计算成本低，支持可控高保真补光。

Conclusion: FiLitDiff与LYF-160K共同构成了首个专为FFE任务定制的物理驱动、高效可控的端到端解决方案，推动了人脸图像增强在真实场景中的落地。

Abstract: Face fill-light enhancement (FFE) brightens underexposed faces by adding virtual fill light while keeping the original scene illumination and background unchanged. Most face relighting methods aim to reshape overall lighting, which can suppress the input illumination or modify the entire scene, leading to foreground-background inconsistency and mismatching practical FFE needs. To support scalable learning, we introduce LightYourFace-160K (LYF-160K), a large-scale paired dataset built with a physically consistent renderer that injects a disk-shaped area fill light controlled by six disentangled factors, producing 160K before-and-after pairs. We first pretrain a physics-aware lighting prompt (PALP) that embeds the 6D parameters into conditioning tokens, using an auxiliary planar-light reconstruction objective. Building on a pretrained diffusion backbone, we then train a fill-light diffusion (FiLitDiff), an efficient one-step model conditioned on physically grounded lighting codes, enabling controllable and high-fidelity fill lighting at low computational cost. Experiments on held-out paired sets demonstrate strong perceptual quality and competitive full-reference metrics, while better preserving background illumination. The dataset and model will be at https://github.com/gobunu/Light-Up-Your-Face.

</details>


### [49] [Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement](https://arxiv.org/abs/2602.04304)
*Zipeng Zhu,Zhanghao Hu,Qinglin Zhu,Yuxi Hong,Yijun Liu,Jingyong Su,Yulan He,Lin Gui*

Main category: cs.CV

TL;DR: 本文提出了一种动态视觉定位方法LASER，通过层敏感性分析发现不同任务需在不同网络层进行视觉信息激活，并设计VAQ指标自适应选择最相关层，无需训练即可提升多类VQA任务准确率。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs因固定视觉token预算导致图像细节丢失和幻觉；注意力引导增强方法依赖静态‘magic layer’，难以泛化到复杂推理任务。

Method: 提出Visual Activation by Query（VAQ）指标，基于查询对各层注意力图的敏感性度量，动态选择最适配任务的网络层；进而构建无需训练的推理框架LASER，实现层自适应的视觉定位与解码增强。

Result: 在多个VQA基准上实验表明，LASER显著提升了不同复杂度任务的问答准确率。

Conclusion: 视觉定位是一个动态过程，应依据任务类型（如识别vs.推理）动态选择网络层；LASER提供了一种高效、通用、无需训练的改进方案。

Abstract: Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static "magic layer" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity.

</details>


### [50] [JOintGS: Joint Optimization of Cameras, Bodies and 3D Gaussians for In-the-Wild Monocular Reconstruction](https://arxiv.org/abs/2602.04317)
*Zihan Lou,Jinlong Fan,Sihan Ma,Yuxiang Yang,Jing Zhang*

Main category: cs.CV

TL;DR: JOintGS是一种联合优化相机外参、人体姿态和3D高斯表示的统一框架，通过前景-背景解耦与协同优化机制，在单目RGB视频中实现高保真可驱动3D人体重建，显著提升在野外场景下的鲁棒性与渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅（3DGS）的方法严重依赖精确相机标定和姿态标注，在无约束野外单目视频中因COLMAP、HMR2.0等方法输出不准而性能受限。

Method: 提出JOintGS框架：1）联合优化相机外参、人体姿态与3D高斯；2）显式前景-背景解耦以实现相互增强；3）引入时序动力学模块建模姿态相关形变；4）残差颜色场补偿光照变化。

Result: 在NeuMan和EMDB数据集上PSNR较SOTA提升2.1 dB，保持实时渲染，并对噪声初始化具有更强鲁棒性。

Conclusion: JOintGS通过协同优化与结构化解耦，有效缓解单目视频中相机与姿态估计误差问题，为野外场景下高质量、可驱动人体重建提供了新范式。

Abstract: Reconstructing high-fidelity animatable 3D human avatars from monocular RGB videos remains challenging, particularly in unconstrained in-the-wild scenarios where camera parameters and human poses from off-the-shelf methods (e.g., COLMAP, HMR2.0) are often inaccurate. Splatting (3DGS) advances demonstrate impressive rendering quality and real-time performance, they critically depend on precise camera calibration and pose annotations, limiting their applicability in real-world settings. We present JOintGS, a unified framework that jointly optimizes camera extrinsics, human poses, and 3D Gaussian representations from coarse initialization through a synergistic refinement mechanism. Our key insight is that explicit foreground-background disentanglement enables mutual reinforcement: static background Gaussians anchor camera estimation via multi-view consistency; refined cameras improve human body alignment through accurate temporal correspondence; optimized human poses enhance scene reconstruction by removing dynamic artifacts from static constraints. We further introduce a temporal dynamics module to capture fine-grained pose-dependent deformations and a residual color field to model illumination variations. Extensive experiments on NeuMan and EMDB datasets demonstrate that JOintGS achieves superior reconstruction quality, with 2.1~dB PSNR improvement over state-of-the-art methods on NeuMan dataset, while maintaining real-time rendering. Notably, our method shows significantly enhanced robustness to noisy initialization compared to the baseline.Our source code is available at https://github.com/MiliLab/JOintGS.

</details>


### [51] [Multiview Self-Representation Learning across Heterogeneous Views](https://arxiv.org/abs/2602.04328)
*Jie Chen,Zhu Wang,Chuanbin Liu,Xi Peng*

Main category: cs.CV

TL;DR: 本文提出了一种多视图自表示学习（MSRL）方法，通过利用异构预训练模型提取的特征间的自表示特性，在无监督迁移学习下学习不变表征。


<details>
  <summary>Details</summary>
Motivation: 不同预训练模型因目标或架构差异导致同一样本特征分布不同，如何在无监督下从大规模未标注视觉数据中学习跨模型的不变表征仍具挑战。

Method: 提出MSRL方法：对多个冻结预训练骨干网络各接一个线性模型；引入基于自表示学习的信息传递机制以聚合多视图特征；设计分配概率分布一致性方案，利用视图间互补信息引导学习并强制表征不变性；并提供理论分析。

Result: 在多个基准视觉数据集上的大量实验表明，MSRL持续优于多种SOTA方法。

Conclusion: MSRL能有效提升跨异构预训练模型的表征不变性，为无监督多视图学习提供了新思路与实用框架。

Abstract: Features of the same sample generated by different pretrained models often exhibit inherently distinct feature distributions because of discrepancies in the model pretraining objectives or architectures. Learning invariant representations from large-scale unlabeled visual data with various pretrained models in a fully unsupervised transfer manner remains a significant challenge. In this paper, we propose a multiview self-representation learning (MSRL) method in which invariant representations are learned by exploiting the self-representation property of features across heterogeneous views. The features are derived from large-scale unlabeled visual data through transfer learning with various pretrained models and are referred to as heterogeneous multiview data. An individual linear model is stacked on top of its corresponding frozen pretrained backbone. We introduce an information-passing mechanism that relies on self-representation learning to support feature aggregation over the outputs of the linear model. Moreover, an assignment probability distribution consistency scheme is presented to guide multiview self-representation learning by exploiting complementary information across different views. Consequently, representation invariance across different linear models is enforced through this scheme. In addition, we provide a theoretical analysis of the information-passing mechanism, the assignment probability distribution consistency and the incremental views. Extensive experiments with multiple benchmark visual datasets demonstrate that the proposed MSRL method consistently outperforms several state-of-the-art approaches.

</details>


### [52] [Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner](https://arxiv.org/abs/2602.04337)
*Qian-Wei Wang,Guanghao Meng,Ren Cai,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为Collaborative Fine-Tuning（CoFT）的无监督适配框架，用于在无需大量标注数据的情况下提升大规模视觉语言模型（如CLIP）在下游任务上的性能。CoFT通过双模型、跨模态协作机制，结合正负文本提示建模伪标签质量，并分阶段进行高效微调；其扩展版本CoFT+进一步引入迭代微调、动量对比学习和大语言模型生成提示，显著优于现有无监督及少量监督方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（如CLIP）虽具备强零样本泛化能力，但下游任务适配通常依赖大量标注数据；现有无监督自训练方法受限于不可靠的置信度过滤、确认偏误及低置信度样本利用不足。

Method: 提出CoFT框架：采用双模型跨模态协作、双提示（正/负文本提示）建模样本级伪标签清洁度，避免人工设定阈值或噪声假设；负提示还用于正则化轻量视觉适配模块；训练分为两阶段——先参数高效微调高置信样本，再全参数微调协同筛选的伪标签。CoFT+在此基础上增加迭代微调、动量对比学习与LLM生成提示。

Result: 在多个基准上显著超越现有无监督方法，甚至优于少量样本监督基线。

Conclusion: CoFT及其增强版CoFT+为VLM无监督下游适配提供了更鲁棒、高效且无需人工调参的新范式，有效缓解伪标签噪声与低置信样本利用难题。

Abstract: Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines.

</details>


### [53] [Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning](https://arxiv.org/abs/2602.04340)
*Qian-Wei Wang,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种基于双提示调优的鲁棒不确定性建模框架，用于在标注预算有限的情况下改进CLIP模型在主动学习中的图像分类适应性。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型（如CLIP）虽具强迁移能力，但在标注数据有限的主动学习场景中，如何有效选择最具信息量的样本仍具挑战；现有方法未从模型视角显式建模不确定性。

Method: 提出双提示调优框架：在CLIP文本分支引入可学习的正向提示（提升任务相关文本嵌入判别力）和反向训练的负向提示（显式建模预测标签正确概率，提供不确定性信号）。

Result: 在多种微调范式下实验表明，该方法在相同标注预算下持续优于现有主动学习方法。

Conclusion: 双提示机制能更鲁棒地建模模型不确定性，显著提升CLIP在低资源主动学习中的适应性能。

Abstract: Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget.

</details>


### [54] [Finding NeMO: A Geometry-Aware Representation of Template Views for Few-Shot Perception](https://arxiv.org/abs/2602.04343)
*Sebastian Jung,Leonard Klüpfel,Rudolph Triebel,Maximilian Durner*

Main category: cs.CV

TL;DR: 本文提出了Neural Memory Object (NeMO)，一种新颖的以对象为中心的表示方法，仅需少量RGB模板视图即可实现对训练中未见过物体的检测、分割和6DoF姿态估计，无需相机参数或目标数据重训练。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在面对新物体时需要大量标注数据、重训练或依赖特定相机参数的问题，提升模型对未知物体的泛化能力和部署效率。

Method: 提出NeMO：编码器利用少量RGB模板视图学习隐式有向距离函数（UDF）生成稀疏语义-几何点云；解码器结合该编码与查询图像输出密集预测（检测、分割、6DoF姿态）。整个流程不依赖相机内参或目标域微调。

Result: 在BOP基准多个数据集和任务上达到竞争性乃至SOTA性能，验证了其在few-shot物体感知任务中的有效性、通用性和高效性。

Conclusion: NeMO通过将物体知识封装为可复用的内存对象（NeMO），并用单一网络统一处理多种感知任务，显著提升了新物体交互的可扩展性与效率，为零样本/少样本6D姿态估计提供了新范式。

Abstract: We present Neural Memory Object (NeMO), a novel object-centric representation that can be used to detect, segment and estimate the 6DoF pose of objects unseen during training using RGB images. Our method consists of an encoder that requires only a few RGB template views depicting an object to generate a sparse object-like point cloud using a learned UDF containing semantic and geometric information. Next, a decoder takes the object encoding together with a query image to generate a variety of dense predictions. Through extensive experiments, we show that our method can be used for few-shot object perception without requiring any camera-specific parameters or retraining on target data. Our proposed concept of outsourcing object information in a NeMO and using a single network for multiple perception tasks enhances interaction with novel objects, improving scalability and efficiency by enabling quick object onboarding without retraining or extensive pre-processing. We report competitive and state-of-the-art results on various datasets and perception tasks of the BOP benchmark, demonstrating the versatility of our approach. https://github.com/DLR-RM/nemo

</details>


### [55] [VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image](https://arxiv.org/abs/2602.04349)
*Teng-Fang Hsiao,Bo-Kai Ruan,Yu-Lun Liu,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 本文提出了VecSet-Edit，首个基于高保真VecSet大重建模型（LRM）的3D网格编辑方法，通过分析VecSet token的空间特性，设计了掩码引导的Token播种、注意力对齐的Token门控及漂移感知的Token剪枝策略，仅需2D图像条件即可精准定位编辑区域，并结合细节保持的纹理烘焙模块，兼顾几何与纹理细节保留。


<details>
  <summary>Details</summary>
Motivation: 现有3D编辑方法主要面向3D高斯泼溅或多视角图像，直接编辑3D网格的研究较少；已有基于体素的方法（如VoxHammer）存在分辨率低、依赖繁琐3D掩码等问题。

Method: 提出VecSet-Edit流程：1）分析VecSet token空间属性，发现子集对应不同几何区域；2）引入掩码引导的Token播种和注意力对齐的Token门控，实现仅用2D图像条件的区域定位；3）设计漂移感知的Token剪枝以剔除去噪过程中的几何异常值；4）采用细节保持的纹理烘焙模块同步保留原始网格的几何与纹理信息。

Result: 实现了首个基于VecSet LRM的高质量3D网格编辑方法，在保持高几何保真度的同时支持精细纹理保留，且无需复杂3D掩码，仅依赖2D图像条件即可完成精准区域编辑。

Conclusion: VecSet-Edit为3D网格编辑提供了新范式，验证了利用扩散模型token空间结构进行可控编辑的有效性，显著提升了编辑灵活性与保真度，推动了基于隐式表示的3D内容创作发展。

Abstract: 3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely on voxel-based representations that suffer from limited resolution and necessitate labor-intensive 3D mask. To address these limitations, we propose \textbf{VecSet-Edit}, the first pipeline that leverages the high-fidelity VecSet Large Reconstruction Model (LRM) as a backbone for mesh editing. Our approach is grounded on a analysis of the spatial properties in VecSet tokens, revealing that token subsets govern distinct geometric regions. Based on this insight, we introduce Mask-guided Token Seeding and Attention-aligned Token Gating strategies to precisely localize target regions using only 2D image conditions. Also, considering the difference between VecSet diffusion process versus voxel we design a Drift-aware Token Pruning to reject geometric outliers during the denoising process. Finally, our Detail-preserving Texture Baking module ensures that we not only preserve the geometric details of original mesh but also the textural information. More details can be found in our project page: https://github.com/BlueDyee/VecSet-Edit/tree/main

</details>


### [56] [When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models](https://arxiv.org/abs/2602.04356)
*Jaehyun Kwak,Nam Cao,Boryeong Cho,Segyu Lee,Sumyeong Ahn,Se-Young Yun*

Main category: cs.CV

TL;DR: 本文提出了一种名为SAGA的分阶段注意力引导攻击方法，用于高效地对大型视觉语言模型（LVLMs）进行对抗攻击，通过聚焦高注意力区域来提升攻击成功率并保持扰动不可感知。


<details>
  <summary>Details</summary>
Motivation: 现有基于随机裁剪等输入变换的对抗攻击方法效率低、扰动预算利用不充分；需更精准定位易受攻击的图像区域以提升攻击效果与隐蔽性。

Method: 基于区域注意力分数与对抗损失敏感性的正相关性及注意力重分布现象，提出分阶段注意力引导攻击框架（SAGA），逐步将扰动集中于高注意力区域。

Result: SAGA在10个LVLM上持续达到最优攻击成功率，同时生成高度不可感知的对抗样本，显著提升扰动预算使用效率。

Conclusion: 注意力机制可有效指导对抗攻击的空间定位，SAGA为LVLM安全评估提供了高效、鲁棒且可解释的新范式。

Abstract: Adversarial attacks against Large Vision-Language Models (LVLMs) are crucial for exposing safety vulnerabilities in modern multimodal systems. Recent attacks based on input transformations, such as random cropping, suggest that spatially localized perturbations can be more effective than global image manipulation. However, randomly cropping the entire image is inherently stochastic and fails to use the limited per-pixel perturbation budget efficiently. We make two key observations: (i) regional attention scores are positively correlated with adversarial loss sensitivity, and (ii) attacking high-attention regions induces a structured redistribution of attention toward subsequent salient regions. Based on these findings, we propose Stage-wise Attention-Guided Attack (SAGA), an attention-guided framework that progressively concentrates perturbations on high-attention regions. SAGA enables more efficient use of constrained perturbation budgets, producing highly imperceptible adversarial examples while consistently achieving state-of-the-art attack success rates across ten LVLMs. The source code is available at https://github.com/jackwaky/SAGA.

</details>


### [57] [SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration](https://arxiv.org/abs/2602.04361)
*Zekun Li,Ning Wang,Tongxin Bai,Changwang Mei,Peisong Wang,Shuang Qiu,Jian Cheng*

Main category: cs.CV

TL;DR: 本文提出SparVAR，一种无需训练的视觉自回归（VAR）模型加速框架，通过利用注意力机制的三个特性（强注意力汇点、跨尺度激活相似性、显著局部性），实现高分辨率图像生成的高效稀疏注意力计算，在不牺牲高频细节的前提下大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 主流VAR模型在每个自回归步骤中对所有历史尺度的token进行全注意力计算，导致高分辨率下计算复杂度呈四次方增长；而现有加速方法常跳过高分辨率尺度，损害图像质量。

Method: SparVAR基于三个观察设计：（i）强注意力汇点，（ii）跨尺度激活相似性，（iii）显著局部性；通过动态预测高分辨率尺度的稀疏注意力模式、构建尺度自相似稀疏注意力（基于索引映射机制），并引入跨尺度局部稀疏注意力与高效分块稀疏核，实现远超FlashAttention的加速。

Result: 在8B模型生成1024×1024图像任务中，SparVAR将生成时间降至1秒以内；相比FlashAttention加速的VAR基线，提速1.57×且几乎保留全部高频细节；结合尺度跳过策略可达2.28×加速，同时保持有竞争力的生成质量。

Conclusion: SparVAR是一种通用、训练无关、高质量保持的VAR加速框架，为高分辨率视觉生成提供了高效可行的新范式。

Abstract: Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of attention increases quartically with resolution, causing substantial latency. Prior accelerations often skip high-resolution scales, which speeds up inference but discards high-frequency details and harms image quality. To address these problems, we present SparVAR, a training-free acceleration framework that exploits three properties of VAR attention: (i) strong attention sinks, (ii) cross-scale activation similarity, and (iii) pronounced locality. Specifically, we dynamically predict the sparse attention pattern of later high-resolution scales from a sparse decision scale, and construct scale self-similar sparse attention via an efficient index-mapping mechanism, enabling high-efficiency sparse attention computation at large scales. Furthermore, we propose cross-scale local sparse attention and implement an efficient block-wise sparse kernel, which achieves $\mathbf{> 5\times}$ faster forward speed than FlashAttention. Extensive experiments demonstrate that the proposed SparseVAR can reduce the generation time of an 8B model producing $1024\times1024$ high-resolution images to the 1s, without skipping the last scales. Compared with the VAR baseline accelerated by FlashAttention, our method achieves a $\mathbf{1.57\times}$ speed-up while preserving almost all high-frequency details. When combined with existing scale-skipping strategies, SparseVAR attains up to a $\mathbf{2.28\times}$ acceleration, while maintaining competitive visual generation quality. Code is available at https://github.com/CAS-CLab/SparVAR.

</details>


### [58] [Enabling Real-Time Colonoscopic Polyp Segmentation on Commodity CPUs via Ultra-Lightweight Architecture](https://arxiv.org/abs/2602.04381)
*Weihao Gao,Zhuo Deng,Zheng Gong,Lan Ma*

Main category: cs.CV

TL;DR: 本文提出了UltraSeg系列轻量级模型，专为资源受限环境（如基层医院、移动内镜设备、胶囊机器人）设计，参数量低于0.3M，在单核CPU上达90 FPS，同时保持高分割精度（Dice得分达U-Net的94%以上），适用于结直肠癌早筛中的实时息肉分割。


<details>
  <summary>Details</summary>
Motivation: 现有高精度结肠镜息肉分割模型依赖GPU，难以在基层医院、移动内镜或胶囊机器人等资源受限场景部署，亟需极轻量、CPU友好的替代方案。

Method: 提出UltraSeg-108K与UltraSeg-130K两个极轻量模型；通过联合优化编解码器宽度、引入约束型空洞卷积扩大感受野、设计跨层轻量融合模块，在极低参数量下实现高效准确分割。

Result: 在7个公开数据集上验证，UltraSeg在仅用U-Net 0.4%参数（<0.3M）条件下，Dice得分保持其94%以上；单核CPU推理速度达90 FPS；支持单中心与多中心/多模态泛化。

Conclusion: UltraSeg为资源受限临床场景提供了首个兼具高精度、高效率与强泛化能力的CPU原生息肉分割方案，树立了极压缩医学图像分割新基线，并为微创手术视觉应用提供可复现技术范式。

Abstract: Early detection of colorectal cancer hinges on real-time, accurate polyp identification and resection. Yet current high-precision segmentation models rely on GPUs, making them impractical to deploy in primary hospitals, mobile endoscopy units, or capsule robots. To bridge this gap, we present the UltraSeg family, operating in an extreme-compression regime (<0.3 M parameters). UltraSeg-108K (0.108 M parameters) is optimized for single-center data, while UltraSeg-130K (0.13 M parameters) generalizes to multi-center, multi-modal images. By jointly optimizing encoder-decoder widths, incorporating constrained dilated convolutions to enlarge receptive fields, and integrating a cross-layer lightweight fusion module, the models achieve 90 FPS on a single CPU core without sacrificing accuracy. Evaluated on seven public datasets, UltraSeg retains >94% of the Dice score of a 31 M-parameter U-Net while utilizing only 0.4% of its parameters, establishing a strong, clinically viable baseline for the extreme-compression domain and offering an immediately deployable solution for resource-constrained settings. This work provides not only a CPU-native solution for colonoscopy but also a reproducible blueprint for broader minimally invasive surgical vision applications. Source code is publicly available to ensure reproducibility and facilitate future benchmarking.

</details>


### [59] [Interactive Spatial-Frequency Fusion Mamba for Multi-Modal Image Fusion](https://arxiv.org/abs/2602.04405)
*Yixin Zhu,Long Lv,Pingping Zhang,Xuehu Liu,Tongdan Tang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种交互式空频融合Mamba框架（ISFM），通过模态特定提取器、多尺度频率融合和交互式空频融合模块，在多模态图像融合任务中实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空频融合中缺乏空间与频率特征之间的有效交互，限制了多模态图像融合的性能。

Method: 提出ISFM框架，包括模态特定提取器（MSE）、多尺度频率融合（MFF）和交互式空频融合（ISF）三个核心模块，实现跨模态的空间-频率特征交互与融合。

Result: 在六个MMIF数据集上的实验表明，ISFM优于当前最先进方法。

Conclusion: 交互式空频融合机制能更有效地利用频率信息指导空间特征学习，提升多模态图像融合质量。

Abstract: Multi-Modal Image Fusion (MMIF) aims to combine images from different modalities to produce fused images, retaining texture details and preserving significant information. Recently, some MMIF methods incorporate frequency domain information to enhance spatial features. However, these methods typically rely on simple serial or parallel spatial-frequency fusion without interaction. In this paper, we propose a novel Interactive Spatial-Frequency Fusion Mamba (ISFM) framework for MMIF. Specifically, we begin with a Modality-Specific Extractor (MSE) to extract features from different modalities. It models long-range dependencies across the image with linear computational complexity. To effectively leverage frequency information, we then propose a Multi-scale Frequency Fusion (MFF). It adaptively integrates low-frequency and high-frequency components across multiple scales, enabling robust representations of frequency features. More importantly, we further propose an Interactive Spatial-Frequency Fusion (ISF). It incorporates frequency features to guide spatial features across modalities, enhancing complementary representations. Extensive experiments are conducted on six MMIF datasets. The experimental results demonstrate that our ISFM can achieve better performances than other state-of-the-art methods. The source code is available at https://github.com/Namn23/ISFM.

</details>


### [60] [LCUDiff: Latent Capacity Upgrade Diffusion for Faithful Human Body Restoration](https://arxiv.org/abs/2602.04406)
*Jue Gong,Zihan Zhou,Jingkai Wang,Shu Li,Libo Liu,Jianliang Lan,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出LCUDiff，一种稳定的一步式框架，通过将预训练潜在扩散模型从4通道潜在空间升级到16通道潜在空间，提升人体中心图像恢复的保真度；采用通道分割蒸馏（CSD）微调VAE、先验保持适配（PPA）桥接维度不匹配，并设计解码器路由器（DeR）实现基于质量评分的样本级解码器路由。


<details>
  <summary>Details</summary>
Motivation: 现有退化人像恢复方法在人体身体恢复（HBR）中保真度不足，尤其受限于预训练文本到图像扩散模型中的VAE瓶颈。

Method: 提出LCUDiff框架：1）将潜在空间从4通道扩展至16通道；2）用通道分割蒸馏（CSD）微调VAE以兼顾先验对齐与高频细节编码；3）引入先验保持适配（PPA）解决4通道扩散主干与16通道潜在空间的不匹配；4）设计基于质量评分标注的解码器路由器（DeR）实现动态解码器选择。

Result: 在合成与真实数据集上取得高保真、低伪影的恢复效果，尤其在轻度退化下表现优异，同时保持一步推理效率。

Conclusion: LCUDiff有效突破VAE限制，在不牺牲推理速度的前提下显著提升人像恢复质量，为高保真人像修复提供了新范式。

Abstract: Existing methods for restoring degraded human-centric images often struggle with insufficient fidelity, particularly in human body restoration (HBR). Recent diffusion-based restoration methods commonly adapt pre-trained text-to-image diffusion models, where the variational autoencoder (VAE) can significantly bottleneck restoration fidelity. We propose LCUDiff, a stable one-step framework that upgrades a pre-trained latent diffusion model from the 4-channel latent space to the 16-channel latent space. For VAE fine-tuning, channel splitting distillation (CSD) is used to keep the first four channels aligned with pre-trained priors while allocating the additional channels to effectively encode high-frequency details. We further design prior-preserving adaptation (PPA) to smoothly bridge the mismatch between 4-channel diffusion backbones and the higher-dimensional 16-channel latent. In addition, we propose a decoder router (DeR) for per-sample decoder routing using restoration-quality score annotations, which improves visual quality across diverse conditions. Experiments on synthetic and real-world datasets show competitive results with higher fidelity and fewer artifacts under mild degradations, while preserving one-step efficiency. The code and model will be at https://github.com/gobunu/LCUDiff.

</details>


### [61] [Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare](https://arxiv.org/abs/2602.04416)
*Aavash Chhetri,Bibek Niroula,Pratik Shrestha,Yash Raj Shrestha,Lesley A Anderson,Prashnna K Gyawali,Loris Bazzani,Binod Bhattarai*

Main category: cs.CV

TL;DR: 本文提出了Med-MMFL，首个面向医疗领域的多模态联邦学习（MMFL）基准，涵盖多种模态、任务与联邦场景，并评估了6种主流FL算法在真实与合成数据分布下的性能，代码与数据处理流程已开源。


<details>
  <summary>Details</summary>
Motivation: 现有医学联邦学习基准稀缺，且多集中于单/双模态和有限任务，缺乏对多模态联邦学习（MMFL）的标准化评估，阻碍系统性研究进展。

Method: 构建Med-MMFL基准：整合10种医学模态（如文本、病理图像、ECG、X光、放射报告、多序列MRI），覆盖分割、分类、模态对齐（检索）、视觉问答等任务；在自然联邦、合成IID与非IID设定下评估6种SOTA FL算法（含不同聚合策略、损失函数与正则化方法）；提供完整数据划分与处理流程。

Result: 提供了首个全面、可复现的医学MMFL基准，支持在真实异构医疗场景下公平评估新方法；实验覆盖2–4模态组合、多种任务及数据分布，验证了基准的多样性与实用性。

Conclusion: Med-MMFL填补了医学多模态联邦学习标准化评估的空白，为推动隐私保护下的跨机构协同建模研究与应用提供了关键基础设施。

Abstract: Federated learning (FL) enables collaborative model training across decentralized medical institutions while preserving data privacy. However, medical FL benchmarks remain scarce, with existing efforts focusing mainly on unimodal or bimodal modalities and a limited range of medical tasks. This gap underscores the need for standardized evaluation to advance systematic understanding in medical MultiModal FL (MMFL). To this end, we introduce Med-MMFL, the first comprehensive MMFL benchmark for the medical domain, encompassing diverse modalities, tasks, and federation scenarios. Our benchmark evaluates six representative state-of-the-art FL algorithms, covering different aggregation strategies, loss formulations, and regularization techniques. It spans datasets with 2 to 4 modalities, comprising a total of 10 unique medical modalities, including text, pathology images, ECG, X-ray, radiology reports, and multiple MRI sequences. Experiments are conducted across naturally federated, synthetic IID, and synthetic non-IID settings to simulate real-world heterogeneity. We assess segmentation, classification, modality alignment (retrieval), and VQA tasks. To support reproducibility and fair comparison of future multimodal federated learning (MMFL) methods under realistic medical settings, we release the complete benchmark implementation, including data processing and partitioning pipelines, at https://github.com/bhattarailab/Med-MMFL-Benchmark .

</details>


### [62] [TrajVG: 3D Trajectory-Coupled Visual Geometry Learning](https://arxiv.org/abs/2602.04439)
*Xingyu Miao,Weiguang Zhao,Tao Lu,Linning Yu,Mulin Yu,Yang Long,Jiangmiao Pang,Junting Dong*

Main category: cs.CV

TL;DR: 本文提出TrajVG框架，通过显式预测相机坐标系下的3D轨迹来增强多帧3D重建，结合稀疏轨迹、局部点图和相对位姿，并引入几何一致性约束与自监督训练策略，显著提升运动视频下的重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有前馈多帧3D重建模型在存在物体运动的视频中性能下降，原因在于全局参考模糊、局部点图依赖估计位姿易漂移，导致跨帧错位和结构重复。

Method: 提出TrajVG框架，显式预测相机坐标系下的3D轨迹；耦合稀疏轨迹、每帧局部点图和相对相机位姿；设计双向轨迹-点图一致性（控制梯度流）和基于静态轨迹锚点的位姿一致性目标；将约束转化为仅需伪2D轨迹的自监督目标，支持混合监督训练。

Result: 在3D跟踪、位姿估计、点图重建和视频深度估计等多个任务上，TrajVG均超越当前前馈模型的性能基线。

Conclusion: TrajVG通过将跨帧3D对应关系建模为显式轨迹预测，并引入几何一致性和自监督机制，有效缓解了运动场景下的重建退化问题，提升了鲁棒性与精度。

Abstract: Feed-forward multi-frame 3D reconstruction models often degrade on videos with object motion. Global-reference becomes ambiguous under multiple motions, while the local pointmap relies heavily on estimated relative poses and can drift, causing cross-frame misalignment and duplicated structures. We propose TrajVG, a reconstruction framework that makes cross-frame 3D correspondence an explicit prediction by estimating camera-coordinate 3D trajectories. We couple sparse trajectories, per-frame local point maps, and relative camera poses with geometric consistency objectives: (i) bidirectional trajectory-pointmap consistency with controlled gradient flow, and (ii) a pose consistency objective driven by static track anchors that suppresses gradients from dynamic regions. To scale training to in-the-wild videos where 3D trajectory labels are scarce, we reformulate the same coupling constraints into self-supervised objectives using only pseudo 2D tracks, enabling unified training with mixed supervision. Extensive experiments across 3D tracking, pose estimation, pointmap reconstruction, and video depth show that TrajVG surpasses the current feedforward performance baseline.

</details>


### [63] [SynthVerse: A Large-Scale Diverse Synthetic Dataset for Point Tracking](https://arxiv.org/abs/2602.04441)
*Weiguang Zhao,Haoran Xu,Xingyu Miao,Qin Zhao,Rui Zhang,Kaizhu Huang,Ning Gao,Peizhou Cao,Mingze Sun,Mulin Yu,Tao Lu,Linning Xu,Junting Dong,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 本文提出SynthVerse，一个大规模、多样化的合成数据集，用于提升通用点跟踪任务的性能，通过引入新领域和对象类型来增强数据多样性，并建立了一个多样化的基准来评估现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在多样性和轨迹标注质量上存在不足，限制了通用点跟踪的发展。

Method: 构建SynthVerse合成数据集，涵盖动画电影风格内容、具身操作、场景导航和关节物体等新领域，并建立多样化点跟踪基准进行系统评估。

Result: 实验表明，使用SynthVerse训练显著提升了模型泛化能力，并揭示了现有跟踪器在多样化场景下的局限性。

Conclusion: SynthVerse为通用点跟踪提供了高质量、高多样性的训练与评估资源，推动该领域向更鲁棒、更通用的方向发展。

Abstract: Point tracking aims to follow visual points through complex motion, occlusion, and viewpoint changes, and has advanced rapidly with modern foundation models. Yet progress toward general point tracking remains constrained by limited high-quality data, as existing datasets often provide insufficient diversity and imperfect trajectory annotations. To this end, we introduce SynthVerse, a large-scale, diverse synthetic dataset specifically designed for point tracking. SynthVerse includes several new domains and object types missing from existing synthetic datasets, such as animated-film-style content, embodied manipulation, scene navigation, and articulated objects. SynthVerse substantially expands dataset diversity by covering a broader range of object categories and providing high-quality dynamic motions and interactions, enabling more robust training and evaluation for general point tracking. In addition, we establish a highly diverse point tracking benchmark to systematically evaluate state-of-the-art methods under broader domain shifts. Extensive experiments and analyses demonstrate that training with SynthVerse yields consistent improvements in generalization and reveal limitations of existing trackers under diverse settings.

</details>


### [64] [Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search](https://arxiv.org/abs/2602.04454)
*Tianming Liang,Qirui Du,Jian-Fang Hu,Haichao Jiang,Zicheng Lin,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: 本文提出Seg-ReSearch，一种结合外部搜索与交错推理的新型分割范式，以突破多模态大语言模型（MLLMs）固有知识限制，提升对动态、开放世界查询的处理能力，并在新构建的OK-VOS等基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的分割方法受限于模型冻结的内部知识，难以应对需要最新信息或领域特定概念的真实场景。

Method: 提出Seg-ReSearch范式，融合交错推理与外部搜索；设计分层奖励机制，兼顾初始引导与渐进激励，缓解稀疏结果信号与刚性步级监督之间的矛盾。

Result: 在新构建的需外部知识的视频对象分割基准OK-VOS及两个现有推理分割基准上，显著超越当前最优方法。

Conclusion: Seg-ReSearch有效突破MLLM知识瓶颈，为开放世界视觉分割提供了可扩展、可检索的新范式。

Abstract: Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose \textbf{Seg-ReSearch}, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search, Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation. Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.

</details>


### [65] [Temporal Slowness in Central Vision Drives Semantic Object Learning](https://arxiv.org/abs/2602.04462)
*Timothy Schaumlöffel,Arthur Aubret,Gemma Roig,Jochen Triesch*

Main category: cs.CV

TL;DR: 本研究探讨了中心视觉和时间慢变性在人类从自然视觉经验中形成语义物体表征中的作用，利用Ego4D数据集模拟五个月的人类视觉经验，并结合注视预测与自监督学习模型验证其效果。


<details>
  <summary>Details</summary>
Motivation: 人类能从自我中心的视觉流中以极少监督获得语义物体表征；视觉系统仅高分辨率处理视野中心，并对时间邻近输入学习相似表征，强调注视点附近缓慢变化的信息。本文旨在探究中心视觉与慢变性学习在此过程中的作用。

Method: 基于Ego4D数据集模拟五个月人类视觉经验，使用先进注视预测模型生成注视坐标，提取中心视野图像块，并在其上训练时间对比式自监督学习模型。

Result: 结合时间慢变性与中心视觉可提升物体表征多语义维度的编码能力：中心视觉增强前景物体特征提取，而慢变性（尤其在微小眼动期间）有助于编码更广义的物体语义信息。

Conclusion: 中心视觉与时间慢变性协同作用，可能是人类从自然视觉经验中发展语义物体表征的关键机制。

Abstract: Humans acquire semantic object representations from egocentric visual streams with minimal supervision. Importantly, the visual system processes with high resolution only the center of its field of view and learns similar representations for visual inputs occurring close in time. This emphasizes slowly changing information around gaze locations. This study investigates the role of central vision and slowness learning in the formation of semantic object representations from human-like visual experience. We simulate five months of human-like visual experience using the Ego4D dataset and generate gaze coordinates with a state-of-the-art gaze prediction model. Using these predictions, we extract crops that mimic central vision and train a time-contrastive Self-Supervised Learning model on them. Our results show that combining temporal slowness and central vision improves the encoding of different semantic facets of object representations. Specifically, focusing on central vision strengthens the extraction of foreground object features, while considering temporal slowness, especially during fixational eye movements, allows the model to encode broader semantic information about objects. These findings provide new insights into the mechanisms by which humans may develop semantic object representations from natural visual experience.

</details>


### [66] [SALAD-Pan: Sensor-Agnostic Latent Adaptive Diffusion for Pan-Sharpening](https://arxiv.org/abs/2602.04473)
*Junjie Li,Congyang Ou,Haokui Zhang,Guoting Wei,Shengqin Jiang,Ying Li,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出SALAD-Pan，一种传感器无关的潜在空间扩散模型，用于高效全色锐化；通过带状单通道VAE编码多光谱图像、双向物理引导控制结构及轻量跨光谱注意力模块，在提升融合精度的同时实现2-3倍推理加速和跨传感器零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的全色锐化方法多在像素空间操作，且需为不同传感器数据单独训练模型，导致高延迟和传感器依赖性问题。

Method: 提出SALAD-Pan：1）使用带状单通道VAE将高分辨率多光谱图像压缩至紧凑潜在空间；2）设计单向与双向交互式控制结构，分别注入光谱物理先验、全色与多光谱图像信息；3）在扩散主干中部引入轻量级跨光谱注意力模块以增强光谱一致性。

Result: 在GaoFen-2、QuickBird和WorldView-3数据集上全面超越现有基于扩散的最先进方法，推理速度提升2–3倍，并展现出强鲁棒的零样本跨传感器泛化能力。

Conclusion: SALAD-Pan通过在潜在空间建模与物理引导的扩散机制，有效兼顾融合精度、推理效率与传感器泛化性，为实用化全色锐化提供了新范式。

Abstract: Recently, diffusion models bring novel insights for Pan-sharpening and notably boost fusion precision. However, most existing models perform diffusion in the pixel space and train distinct models for different multispectral (MS) imagery, suffering from high latency and sensor-specific limitations. In this paper, we present SALAD-Pan, a sensor-agnostic latent space diffusion method for efficient pansharpening. Specifically, SALAD-Pan trains a band-wise single-channel VAE to encode high-resolution multispectral (HRMS) into compact latent representations, supporting MS images with various channel counts and establishing a basis for acceleration. Then spectral physical properties, along with PAN and MS images, are injected into the diffusion backbone through unidirectional and bidirectional interactive control structures respectively, achieving high-precision fusion in the diffusion process. Finally, a lightweight cross-spectral attention module is added to the central layer of diffusion model, reinforcing spectral connections to boost spectral consistency and further elevate fusion precision. Experimental results on GaoFen-2, QuickBird, and WorldView-3 demonstrate that SALAD-Pan outperforms state-of-the-art diffusion-based methods across all three datasets, attains a 2-3x inference speedup, and exhibits robust zero-shot (cross-sensor) capability.

</details>


### [67] [Vision-aligned Latent Reasoning for Multi-modal Large Language Model](https://arxiv.org/abs/2602.04476)
*Byungwoo Jeon,Yoonwoo Jeong,Hyunseok Lee,Minsu Cho,Jinwoo Shin*

Main category: cs.CV

TL;DR: 本文提出Vision-aligned Latent Reasoning (VaLR)框架，通过在每步思维链推理前动态生成视觉对齐的潜在token，缓解多模态大模型在长上下文推理中视觉信息衰减问题，显著提升长上下文理解与精细视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在需多步推理的任务上表现不佳，主因是长上下文生成过程中视觉信息逐步稀释，限制了测试时扩展能力。

Method: 提出VaLR框架，训练MLLM中间嵌入与视觉编码器嵌入对齐，从而在每步Chain of Thought推理前动态生成视觉对齐的潜在token，引导模型基于潜在空间中的感知线索进行推理。

Result: VaLR在多个需长上下文理解或精确视觉感知的基准上持续超越现有方法，并展现出此前MLLM未见的测试时缩放行为；在VSI-Bench上性能从33.0%提升至52.9%，相对Qwen2.5-VL提升19.9个百分点。

Conclusion: VaLR是一种简洁而有效的方法，能显著增强MLLM的多步视觉推理能力，为解决视觉信息稀释问题提供了新思路。

Abstract: Despite recent advancements in Multi-modal Large Language Models (MLLMs) on diverse understanding tasks, these models struggle to solve problems which require extensive multi-step reasoning. This is primarily due to the progressive dilution of visual information during long-context generation, which hinders their ability to fully exploit test-time scaling. To address this issue, we introduce Vision-aligned Latent Reasoning (VaLR), a simple, yet effective reasoning framework that dynamically generates vision-aligned latent tokens before each Chain of Thought reasoning step, guiding the model to reason based on perceptual cues in the latent space. Specifically, VaLR is trained to preserve visual knowledge during reasoning by aligning intermediate embeddings of MLLM with those from vision encoders. Empirical results demonstrate that VaLR consistently outperforms existing approaches across a wide range of benchmarks requiring long-context understanding or precise visual perception, while exhibiting test-time scaling behavior not observed in prior MLLMs. In particular, VaLR improves the performance significantly from 33.0% to 52.9% on VSI-Bench, achieving a 19.9%p gain over Qwen2.5-VL.

</details>


### [68] [SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking](https://arxiv.org/abs/2602.04525)
*Muhammad Taha Mukhtar,Syed Musa Ali Kazmi,Khola Naseem,Muhammad Ali Chattha,Andreas Dengel,Sheraz Ahmed,Muhammad Naseer Bajwa,Muhammad Imran Malik*

Main category: cs.CV

TL;DR: 本文提出了一种面向非正规住区遥感影像分割的新型半监督框架，包含类感知自适应阈值机制和原型库系统，并构建了覆盖巴基斯坦、印度等多城市的高质量基准数据集，显著提升了模型在标注稀缺、光谱模糊与跨域迁移场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 快速城市化导致低收入和中等收入国家大城市中非正规住区激增，但其大规模制图受限于标注稀缺、正式与非正式建筑间光谱歧义高、标注噪声大等问题。

Method: 构建了从零开始的拉合尔基准数据集及基于行政边界的卡拉奇、孟买配套数据集；提出一种新型半监督分割框架，包含类感知自适应阈值机制（动态调整置信度阈值防止少数类抑制）与原型库系统（锚定历史高保真特征以保障语义一致性）。

Result: 在横跨三大洲共八座城市的实验中，该方法优于当前最优半监督基线；仅用10%源域标签训练，即可在未见地理区域上达到0.461 mIoU，且跨域迁移能力超越全监督模型的零样本泛化性能。

Conclusion: 所提框架与数据集有效缓解了非正规住区识别中的标注稀缺、光谱混淆与域偏移问题，为遥感影像半监督语义分割提供了新范式与可靠基准。

Abstract: Rapid urban expansion has fueled the growth of informal settlements in major cities of low- and middle-income countries, with Lahore and Karachi in Pakistan and Mumbai in India serving as prominent examples. However, large-scale mapping of these settlements is severely constrained not only by the scarcity of annotations but by inherent data quality challenges, specifically high spectral ambiguity between formal and informal structures and significant annotation noise. We address this by introducing a benchmark dataset for Lahore, constructed from scratch, along with companion datasets for Karachi and Mumbai, which were derived from verified administrative boundaries, totaling 1,869 $\text{km}^2$ of area. To evaluate the global robustness of our framework, we extend our experiments to five additional established benchmarks, encompassing eight cities across three continents, and provide comprehensive data quality assessments of all datasets. We also propose a new semi-supervised segmentation framework designed to mitigate the class imbalance and feature degradation inherent in standard semi-supervised learning pipelines. Our method integrates a Class-Aware Adaptive Thresholding mechanism that dynamically adjusts confidence thresholds to prevent minority class suppression and a Prototype Bank System that enforces semantic consistency by anchoring predictions to historically learned high-fidelity feature representations. Extensive experiments across a total of eight cities spanning three continents demonstrate that our approach outperforms state-of-the-art semi-supervised baselines. Most notably, our method demonstrates superior domain transfer capability whereby a model trained on only 10% of source labels reaches a 0.461 mIoU on unseen geographies and outperforms the zero-shot generalization of fully supervised models.

</details>


### [69] [OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis](https://arxiv.org/abs/2602.04547)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto*

Main category: cs.CV

TL;DR: 本文提出了OmniRad，一种基于120万张医学影像自监督预训练的放射学基础模型，强调表征复用和跨任务迁移能力，并在多个公开基准上验证了其在分类与分割任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 放射学分析日益受益于预训练视觉表征，但需要能支持多模态、异构下游任务的基础模型；现有方法在表征复用性与跨任务泛化能力方面仍有提升空间。

Method: 提出OmniRad模型，采用自监督学习在120万张多模态医学图像上预训练；评估策略包括冻结主干+轻量适配器、以及端到端微调；在MedMNISTv2和MedSegBench等多个基准上进行分类与分割测试，并辅以潜空间可视化分析。

Result: 在MedMNISTv2上分类F1最高提升2.05%；在六个MedSegBench数据集上使用冻结表征时平均Dice分数提升；潜空间分析显示特征聚类更优、模态分离更清晰。

Conclusion: OmniRad通过放射学启发的设计显著提升了医学影像表征的通用性与迁移能力，为多模态、多任务放射学AI提供了高效、鲁棒的基础模型。

Abstract: Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability. We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualizations suggest improved feature clustering and modality-related separation.

</details>


### [70] [Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models](https://arxiv.org/abs/2602.04549)
*Cem Eteke,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 本文提出NiFi方法，通过基于扩散模型的一步蒸馏技术实现3D高斯点阵（3DGS）的极致压缩，在极低码率（低至0.1 MB）下保持优异的视觉质量，相比原始3DGS实现近1000倍的码率提升。


<details>
  <summary>Details</summary>
Motivation: 3D高斯点阵（3DGS）虽实现实时新视角渲染，但存储开销大，限制其在沉浸式通信等场景的应用；现有压缩方法在低码率下易引入显著视觉伪影。

Method: 提出NiFi方法，采用伪影感知、基于扩散模型的一步蒸馏策略，对压缩后的3DGS进行高质量重建。

Result: 在极低码率（如0.1 MB）下达到当前最优的感知质量，码率相较原始3DGS降低约1000倍，同时保持可比的视觉保真度。

Conclusion: NiFi为3DGS提供了高效且视觉友好的极致压缩方案，显著拓展其在资源受限场景中的实用潜力。

Abstract: 3D Gaussian Splatting (3DGS) revolutionized novel view rendering. Instead of inferring from dense spatial points, as implicit representations do, 3DGS uses sparse Gaussians. This enables real-time performance but increases space requirements, hindering applications such as immersive communication. 3DGS compression emerged as a field aimed at alleviating this issue. While impressive progress has been made, at low rates, compression introduces artifacts that degrade visual quality significantly. We introduce NiFi, a method for extreme 3DGS compression through restoration via artifact-aware, diffusion-based one-step distillation. We show that our method achieves state-of-the-art perceptual quality at extremely low rates, down to 0.1 MB, and towards 1000x rate improvement over 3DGS at comparable perceptual performance. The code will be open-sourced upon acceptance.

</details>


### [71] [Understanding Degradation with Vision Language Model](https://arxiv.org/abs/2602.04565)
*Guanzhou Lan,Chenyi Liao,Yuqi Yang,Qianli Ma,Zhigang Wang,Dong Wang,Bin Zhao,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出DU-VLM模型，将图像退化理解重新定义为分层结构化预测任务，统一估计退化类型、参数键及其连续物理值，并通过自回归语言建模实现；结合新构建的DU-110k数据集与结构化奖励的强化学习训练，模型可零样本控制扩散模型实现高保真图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）擅长定性描述图像退化，但难以理解其背后参数化的物理机制，亟需一种能联合建模退化类型、参数键和连续物理值的统一框架。

Method: 将退化理解建模为分层结构化预测任务，统一于自回归next-token预测范式；提出DU-VLM多模态链式思维模型，采用监督微调与带结构化奖励的强化学习联合训练；构建含110,000对清洁-退化图像及物理标注的DU-110k数据集。

Result: DU-VLM在退化理解任务上显著超越通用基线，具备强准确性和鲁棒性，并能泛化至未见分布；还可作为零样本控制器驱动预训练扩散模型，实现无需微调生成主干的高保真图像恢复。

Conclusion: 统一的结构化预测范式和物理感知训练策略，使VLM具备深度退化理解能力，为可控图像恢复提供了新范式。

Abstract: Understanding visual degradations is a critical yet challenging problem in computer vision. While recent Vision-Language Models (VLMs) excel at qualitative description, they often fall short in understanding the parametric physics underlying image degradations. In this work, we redefine degradation understanding as a hierarchical structured prediction task, necessitating the concurrent estimation of degradation types, parameter keys, and their continuous physical values. Although these sub-tasks operate in disparate spaces, we prove that they can be unified under one autoregressive next-token prediction paradigm, whose error is bounded by the value-space quantization grid. Building on this insight, we introduce DU-VLM, a multimodal chain-of-thought model trained with supervised fine-tuning and reinforcement learning using structured rewards. Furthermore, we show that DU-VLM can serve as a zero-shot controller for pre-trained diffusion models, enabling high-fidelity image restoration without fine-tuning the generative backbone. We also introduce \textbf{DU-110k}, a large-scale dataset comprising 110,000 clean-degraded pairs with grounded physical annotations. Extensive experiments demonstrate that our approach significantly outperforms generalist baselines in both accuracy and robustness, exhibiting generalization to unseen distributions.

</details>


### [72] [PEPR: Privileged Event-based Predictive Regularization for Domain Generalization](https://arxiv.org/abs/2602.04583)
*Gabriele Magrini,Federico Becattini,Niccolò Biondi,Pietro Pala*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习使用特权信息（LUPI）范式的跨模态框架，利用事件相机作为训练阶段的特权信息，通过Privileged Event-based Predictive Regularization（PEPR）方法，使RGB模型在不牺牲语义丰富性前提下提升对域偏移（如昼夜变化）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在视觉感知任务中易受域偏移影响，难以在与训练数据分布不同的现实场景中部署；现有跨模态对齐方法因强制RGB特征模仿稀疏事件表示而损失语义细节。

Method: 提出PEPR方法，在共享潜在空间中将LUPI重构为预测问题：训练RGB编码器预测事件模态的潜在特征，而非直接进行跨模态特征对齐，从而蒸馏事件模态的域不变性。

Result: 所提方法在目标检测和语义分割任务上显著优于基于对齐的基线方法，在昼夜变化等域偏移场景下展现出更强的泛化鲁棒性。

Conclusion: 利用事件相机作为训练阶段的特权信息，并通过预测式正则化（PEPR）引导RGB模型学习域不变表征，是一种有效且语义保持的域泛化新范式。

Abstract: Deep neural networks for visual perception are highly susceptible to domain shift, which poses a critical challenge for real-world deployment under conditions that differ from the training data. To address this domain generalization challenge, we propose a cross-modal framework under the learning using privileged information (LUPI) paradigm for training a robust, single-modality RGB model. We leverage event cameras as a source of privileged information, available only during training. The two modalities exhibit complementary characteristics: the RGB stream is semantically dense but domain-dependent, whereas the event stream is sparse yet more domain-invariant. Direct feature alignment between them is therefore suboptimal, as it forces the RGB encoder to mimic the sparse event representation, thereby losing semantic detail. To overcome this, we introduce Privileged Event-based Predictive Regularization (PEPR), which reframes LUPI as a predictive problem in a shared latent space. Instead of enforcing direct cross-modal alignment, we train the RGB encoder with PEPR to predict event-based latent features, distilling robustness without sacrificing semantic richness. The resulting standalone RGB model consistently improves robustness to day-to-night and other domain shifts, outperforming alignment-based baselines across object detection and semantic segmentation.

</details>


### [73] [SalFormer360: a transformer-based saliency estimation model for 360-degree videos](https://arxiv.org/abs/2602.04584)
*Mahmoud Z. A. Wahba,Francesco Barbato,Sara Baldoni,Federica Battisti*

Main category: cs.CV

TL;DR: 本文提出了一种基于Transformer架构的新型360度视频显著性估计模型SalFormer360，结合SegFormer编码器与自定义解码器，并引入观看中心偏差以提升预测精度，在多个基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 360度视频中显著性估计对视口预测和沉浸式内容优化等任务至关重要，但现有方法在准确性和适应性方面仍有提升空间。

Method: 提出SalFormer360模型，基于SegFormer编码器（经微调适配360度内容）和自定义解码器，并引入 Viewing Center Bias 建模用户在360度环境中的注意力偏好。

Result: 在Sport360、PVS-HM和VR-EyeTracking三个最大基准数据集上，Pearson相关系数分别比现有最优方法提升8.4%、2.5%和18.6%。

Conclusion: SalFormer360有效提升了360度视频显著性估计的性能，验证了Transformer架构与中心偏差建模在该任务中的有效性。

Abstract: Saliency estimation has received growing attention in recent years due to its importance in a wide range of applications. In the context of 360-degree video, it has been particularly valuable for tasks such as viewport prediction and immersive content optimization. In this paper, we propose SalFormer360, a novel saliency estimation model for 360-degree videos built on a transformer-based architecture. Our approach is based on the combination of an existing encoder architecture, SegFormer, and a custom decoder. The SegFormer model was originally developed for 2D segmentation tasks, and it has been fine-tuned to adapt it to 360-degree content. To further enhance prediction accuracy in our model, we incorporated Viewing Center Bias to reflect user attention in 360-degree environments. Extensive experiments on the three largest benchmark datasets for saliency estimation demonstrate that SalFormer360 outperforms existing state-of-the-art methods. In terms of Pearson Correlation Coefficient, our model achieves 8.4% higher performance on Sport360, 2.5% on PVS-HM, and 18.6% on VR-EyeTracking compared to previous state-of-the-art.

</details>


### [74] [ImmuVis: Hyperconvolutional Foundation Model for Imaging Mass Cytometry](https://arxiv.org/abs/2602.04585)
*Marcin Możejko,Dawid Uchal,Krzysztof Gogolewski,Piotr Kupidura,Szymon Łukasik,Jakub Giezgała,Tomasz Nocoń,Kacper Pietrzyk,Robert Pieniuta,Mateusz Sulimowicz,Michal Orzyłowski,Tomasz Siłkowski,Karol Zagródka,Eike Staub,Ewa Szczurek*

Main category: cs.CV

TL;DR: ImmuVis是一种为成像质谱流式细胞术（IMC）设计的高效卷积基础模型，通过标记自适应超卷积解决IMC通道不固定的问题，并在大规模数据集IMC17M上预训练，在虚拟染色和分类任务中优于SOTA方法且计算成本更低，同时提供校准的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: IMC技术中分子标记集合随研究而异，导致通道空间不固定，违反了标准视觉骨干网络的基本假设，亟需一种能适配任意标记子集的基础模型。

Method: 提出标记自适应超卷积，从学习到的标记嵌入生成卷积核；在IMC17M数据集上采用自监督掩码重建进行预训练。

Result: 在虚拟染色和下游分类任务中性能优于现有SOTA及消融模型，计算成本显著低于基于Transformer的方法，并唯一支持通过异方差似然目标实现校准的不确定性估计。

Conclusion: ImmuVis是一种实用、高效、可扩展的IMC基础模型，适用于真实世界的空间组织分析。

Abstract: We present ImmuVis, an efficient convolutional foundation model for imaging mass cytometry (IMC), a high-throughput multiplex imaging technology that handles molecular marker measurements as image channels and enables large-scale spatial tissue profiling. Unlike natural images, multiplex imaging lacks a fixed channel space, as real-world marker sets vary across studies, violating a core assumption of standard vision backbones. To address this, ImmuVis introduces marker-adaptive hyperconvolutions that generate convolutional kernels from learned marker embeddings, enabling a single model to operate on arbitrary measured marker subsets without retraining. We pretrain ImmuVis on the largest to-date dataset, IMC17M (28 cohorts, 24,405 images, 265 markers, over 17M patches), using self-supervised masked reconstruction. ImmuVis outperforms SOTA baselines and ablations in virtual staining and downstream classification tasks at substantially lower compute cost than transformer-based alternatives, and is the sole model that provides calibrated uncertainty via a heteroscedastic likelihood objective. These results position ImmuVis as a practical, efficient foundation model for real-world IMC modeling.

</details>


### [75] [A labeled dataset of simulated phlebotomy procedures for medical AI: polygon annotations for object detection and human-object interaction](https://arxiv.org/abs/2602.04624)
*Raúl Jiménez Cruz,César Torres-Huitzil,Marco Franceschetti,Ronny Seiger,Luciano García-Bañuelos,Barbara Weber*

Main category: cs.CV

TL;DR: 本文介绍了一个包含11,884张标注图像的数据集，用于模拟静脉采血操作，图像经过SSIM去重和人脸匿名化处理，并对5类医学相关对象进行了多边形分割标注，支持现代目标检测框架，旨在推动医疗培训自动化和人-物交互研究。


<details>
  <summary>Details</summary>
Motivation: 为推进医疗培训自动化和人-物交互研究，特别是静脉采血（phlebotomy）操作的自动分析与教学反馈，需要高质量、细粒度标注的视觉数据集。

Method: 从高清视频中提取图像，使用结构相似性指数（SSIM）过滤冗余帧；对所有视频进行自动人脸匿名化；人工标注五类医学对象的多边形分割掩码；导出为YOLOv8等主流框架兼容的格式；按70%/15%/15%划分训练/验证/测试集。

Result: 构建并公开发布了含11,884张带精细分割标注图像的静脉采血训练数据集，支持工具检测、步骤识别、流程分析、合规性检查及教育反馈系统开发。

Conclusion: 该数据集填补了医疗操作细粒度视觉理解领域的公开资源空白，具备良好可扩展性与实用性，有望促进AI在临床技能培训中的落地应用。

Abstract: This data article presents a dataset of 11,884 labeled images documenting a simulated blood extraction (phlebotomy) procedure performed on a training arm. Images were extracted from high-definition videos recorded under controlled conditions and curated to reduce redundancy using Structural Similarity Index Measure (SSIM) filtering. An automated face-anonymization step was applied to all videos prior to frame selection. Each image contains polygon annotations for five medically relevant classes: syringe, rubber band, disinfectant wipe, gloves, and training arm. The annotations were exported in a segmentation format compatible with modern object detection frameworks (e.g., YOLOv8), ensuring broad usability. This dataset is partitioned into training (70%), validation (15%), and test (15%) subsets and is designed to advance research in medical training automation and human-object interaction. It enables multiple applications, including phlebotomy tool detection, procedural step recognition, workflow analysis, conformance checking, and the development of educational systems that provide structured feedback to medical trainees. The data and accompanying label files are publicly available on Zenodo.

</details>


### [76] [PIO-FVLM: Rethinking Training-Free Visual Token Reduction for VLM Acceleration from an Inference-Objective Perspective](https://arxiv.org/abs/2602.04657)
*Haokui Zhang,Congyang Ou,Dawei Yan,Peng Wang,Qingsen Yan,Ying Li,Rong Xiao,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出PIO-FVLM方法，从推理目标出发进行视觉token压缩，通过层局部代理损失引导的梯度显著性重排序，并结合NMS原则选择关键token；该方法无需训练、兼容FlashAttention，在保持97.2%性能的同时大幅加速推理并降低计算与缓存开销。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）中基于相似性的视觉token压缩方法存在压缩性能和实际部署的局限性，亟需一种更直接面向推理目标、高效且易部署的新方法。

Method: 提出PIO-FVLM：利用层局部代理损失生成token级梯度显著性，指导视觉token重排序；再按非极大值抑制（NMS）原则选择最重要token；支持encoder-free或与encoder压缩方法（如VisionZip）联合使用；完全无需训练，兼容FlashAttention。

Result: 在LLaVA-Next-7B上仅保留11.1%视觉token，仍保持97.2%原始性能，预填充速度提升2.67×，推理速度提升2.11×，FLOPs降低6.22×，KV Cache开销减少6.05×。

Conclusion: PIO-FVLM是一种高效、免训练、易部署的视觉token压缩方法，从推理目标出发保障输出不变性，显著提升VLM推理效率，兼顾性能与实用性。

Abstract: Recently, reducing redundant visual tokens in vision-language models (VLMs) to accelerate VLM inference has emerged as a hot topic. However, most existing methods rely on heuristics constructed based on inter-visual-token similarity or cross-modal visual-text similarity, which gives rise to certain limitations in compression performance and practical deployment. In contrast, we propose PIO-FVLM from the perspective of inference objectives, which transforms visual token compression into preserving output result invariance and selects tokens primarily by their importance to this goal. Specially, vision tokens are reordered with the guidance of token-level gradient saliency generated by our designed layer-local proxy loss, a coarse constraint from the current layer to the final result. Then the most valuable vision tokens are selected following the non-maximum suppression (NMS) principle. The proposed PIO-FVLM is training-free and compatible with FlashAttention, friendly to practical application and deployment. It can be deployed independently as an encoder-free method, or combined with encoder compression approaches like VisionZip for use as an encoder-involved method. On LLaVA-Next-7B, PIO-FVLM retains just 11.1% of visual tokens but maintains 97.2% of the original performance, with a 2.67$\times$ prefill speedup, 2.11$\times$ inference speedup, 6.22$\times$ lower FLOPs, and 6.05$\times$ reduced KV Cache overhead. Our code is available at https://github.com/ocy1/PIO-FVLM.

</details>


### [77] [DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking](https://arxiv.org/abs/2602.04692)
*Sijia Chen,Lijuan Ma,Yanqiu Yu,En Yu,Liman Liu,Wenbing Tao*

Main category: cs.CV

TL;DR: 本文提出RGBD指代多目标跟踪（DRMOT）新任务，构建DRSet数据集，并设计DRTrack框架，融合RGB、深度与语言模态实现3D感知跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有RMOT模型仅依赖2D RGB数据，难以处理复杂空间语义（如“离相机最近的人”）和严重遮挡下的身份保持，缺乏显式3D空间信息。

Method: 提出DRMOT任务；构建含RGB图像、深度图及240条语言描述（56条含深度信息）的DRSet数据集；设计MLLM引导的DRTrack框架，实现RGB-D-L联合输入的深度感知目标定位与深度增强轨迹关联。

Result: 在DRSet数据集上的大量实验验证了DRTrack框架的有效性，显著提升了空间语义定位与鲁棒跟踪性能。

Conclusion: 引入深度模态并融合语言与RGB信息可有效提升指代多目标跟踪的空间理解与抗遮挡能力，为交互式AI系统提供更可靠的3D感知跟踪基础。

Abstract: Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate targets characterized by complex spatial semantics (e.g., ``the person closest to the camera'') and to maintain reliable identities under severe occlusion, due to the absence of explicit 3D spatial information. In this work, we propose a novel task, RGBD Referring Multi-Object Tracking (DRMOT), which explicitly requires models to fuse RGB, Depth (D), and Language (L) modalities to achieve 3D-aware tracking. To advance research on the DRMOT task, we construct a tailored RGBD referring multi-object tracking dataset, named DRSet, designed to evaluate models' spatial-semantic grounding and tracking capabilities. Specifically, DRSet contains RGB images and depth maps from 187 scenes, along with 240 language descriptions, among which 56 descriptions incorporate depth-related information. Furthermore, we propose DRTrack, a MLLM-guided depth-referring tracking framework. DRTrack performs depth-aware target grounding from joint RGB-D-L inputs and enforces robust trajectory association by incorporating depth cues. Extensive experiments on the DRSet dataset demonstrate the effectiveness of our framework.

</details>


### [78] [Annotation Free Spacecraft Detection and Segmentation using Vision Language Models](https://arxiv.org/abs/2602.04699)
*Samet Hicsonmez,Jose Sosa,Dan Pineau,Inder Pal Singh,Arunkumar Rathinam,Abd El Rahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出了一种无需人工标注的航天目标检测与分割方法，利用预训练视觉语言模型（VLM）自动生成伪标签，并通过师生蒸馏训练轻量模型，在多个空间数据集上显著提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 空间图像中人工标注困难（低可见性、光照变化、目标与背景融合），亟需无需大量标注的检测与分割方法。

Method: 利用预训练VLM为少量真实无标签图像生成伪标签，再通过教师-学生标签蒸馏框架训练轻量模型。

Result: 在SPARK-2024、SPEED+和TANGO数据集上，分割任务平均精度（AP）最高提升10个点，性能显著优于直接零样本VLM推理。

Conclusion: 该标注自由流程有效提升了空间目标分割性能，验证了VLM在航天领域应用的潜力。

Abstract: Vision Language Models (VLMs) have demonstrated remarkable performance in open-world zero-shot visual recognition. However, their potential in space-related applications remains largely unexplored. In the space domain, accurate manual annotation is particularly challenging due to factors such as low visibility, illumination variations, and object blending with planetary backgrounds. Developing methods that can detect and segment spacecraft and orbital targets without requiring extensive manual labeling is therefore of critical importance. In this work, we propose an annotation-free detection and segmentation pipeline for space targets using VLMs. Our approach begins by automatically generating pseudo-labels for a small subset of unlabeled real data with a pre-trained VLM. These pseudo-labels are then leveraged in a teacher-student label distillation framework to train lightweight models. Despite the inherent noise in the pseudo-labels, the distillation process leads to substantial performance gains over direct zero-shot VLM inference. Experimental evaluations on the SPARK-2024, SPEED+, and TANGO datasets on segmentation tasks demonstrate consistent improvements in average precision (AP) by up to 10 points. Code and models are available at https://github.com/giddyyupp/annotation-free-spacecraft-segmentation.

</details>


### [79] [SAR-RAG: ATR Visual Question Answering by Semantic Search, Retrieval, and MLLM Generation](https://arxiv.org/abs/2602.04712)
*David F. Ramirez,Tim Overman,Kristen Jaskie,Joe Marvin,Andreas Spanias*

Main category: cs.CV

TL;DR: 本文提出了一种面向合成孔径雷达（SAR）自动目标识别（ATR）的视觉上下文图像检索增强生成（ImageRAG）AI智能体——SAR-RAG，通过将多模态大语言模型（MLLM）与语义嵌入向量数据库结合，实现基于历史相似图像示例的上下文检索，从而提升车辆类型分类与尺寸回归精度。


<details>
  <summary>Details</summary>
Motivation: SAR图像中军事车辆外观相似、难以区分，传统ATR方法在细粒度识别和量化测量上存在挑战；需引入外部知识与历史判例以增强模型推理能力。

Method: 提出SAR-RAG框架：利用MLLM提取查询图像语义特征，接入向量数据库进行相似图像检索（含已知目标类型与尺寸标注），将检索到的 exemplars 作为上下文输入MLLM进行联合推理，形成具备‘ATR记忆银行’的智能体。

Result: 在搜索检索指标、类别分类准确率和车辆尺寸数值回归三项任务上，SAR-RAG均显著优于纯MLLM基线方法。

Conclusion: 检索增强机制可有效弥补MLLM在SAR ATR任务中对领域先验和细粒度判别知识的不足，验证了‘记忆增强型’多模态智能体在遥感目标识别中的可行性与优势。

Abstract: We present a visual-context image retrieval-augmented generation (ImageRAG) assisted AI agent for automatic target recognition (ATR) of synthetic aperture radar (SAR). SAR is a remote sensing method used in defense and security applications to detect and monitor the positions of military vehicles, which may appear indistinguishable in images. Researchers have extensively studied SAR ATR to improve the differentiation and identification of vehicle types, characteristics, and measurements. Test examples can be compared with known vehicle target types to improve recognition tasks. New methods enhance the capabilities of neural networks, transformer attention, and multimodal large language models. An agentic AI method may be developed to utilize a defined set of tools, such as searching through a library of similar examples. Our proposed method, SAR Retrieval-Augmented Generation (SAR-RAG), combines a multimodal large language model (MLLM) with a vector database of semantic embeddings to support contextual search for image exemplars with known qualities. By recovering past image examples with known true target types, our SAR-RAG system can compare similar vehicle categories, achieving improved ATR prediction accuracy. We evaluate this through search and retrieval metrics, categorical classification accuracy, and numeric regression of vehicle dimensions. These metrics all show improvements when SAR-RAG is added to an MLLM baseline method as an attached ATR memory bank.

</details>


### [80] [How to rewrite the stars: Mapping your orchard over time through constellations of fruits](https://arxiv.org/abs/2602.04722)
*Gonçalo P. Matos,Carlos Santiago,João P. Costeira,Ricardo L. Saldanha,Ernesto M. Morgado*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D质心星座匹配的新范式，用于跨时间视频中果实的精准匹配与生长追踪，解决了农业中果实长期跟踪的难题，并支持果园建图与机器人自主导航。


<details>
  <summary>Details</summary>
Motivation: 传统人工测量果实大小费时费力、不可扩展；现有计算机视觉方法难以在不同时间采集的视频间准确匹配同一果实，尤其在相机位姿未知、特征稀疏、存在遮挡和非刚性形变的情况下。

Method: 提出基于稀疏3D点云（果实质心）的‘星座’匹配范式，设计专用描述符，在无GPS、无固定相机位姿假设下实现跨视频果实匹配；进一步利用匹配结果构建果园三维地图并估计相机6DoF位姿。

Result: 该方法成功实现了跨时间视频的果实匹配与生长追踪，并能构建果园地图、精确定位相机位姿，为果园机器人自主导航与选择性采摘提供支撑。

Conclusion: 基于星座的3D匹配方法有效克服了非刚性、遮挡与纹理缺失等挑战，为精准农业中的长期果实跟踪与智能农机作业提供了新思路和实用工具。

Abstract: Following crop growth through the vegetative cycle allows farmers to predict fruit setting and yield in early stages, but it is a laborious and non-scalable task if performed by a human who has to manually measure fruit sizes with a caliper or dendrometers. In recent years, computer vision has been used to automate several tasks in precision agriculture, such as detecting and counting fruits, and estimating their size. However, the fundamental problem of matching the exact same fruits from one video, collected on a given date, to the fruits visible in another video, collected on a later date, which is needed to track fruits' growth through time, remains to be solved. Few attempts were made, but they either assume that the camera always starts from the same known position and that there are sufficiently distinct features to match, or they used other sources of data like GPS. Here we propose a new paradigm to tackle this problem, based on constellations of 3D centroids, and introduce a descriptor for very sparse 3D point clouds that can be used to match fruits across videos. Matching constellations instead of individual fruits is key to deal with non-rigidity, occlusions and challenging imagery with few distinct visual features to track. The results show that the proposed method can be successfully used to match fruits across videos and through time, and also to build an orchard map and later use it to locate the camera pose in 6DoF, thus providing a method for autonomous navigation of robots in the orchard and for selective fruit picking, for example.

</details>


### [81] [Mitigating Long-Tail Bias via Prompt-Controlled Diffusion Augmentation](https://arxiv.org/abs/2602.04749)
*Buddhi Wijenayake,Nichula Wasalathilake,Roshan Godaliyadda,Vijitha Herath,Parakrama Ekanayake,Vishal M. Patel*

Main category: cs.CV

TL;DR: 本文提出了一种基于提示控制的扩散增强框架，用于缓解遥感影像语义分割中长尾像素不平衡问题，尤其在Urban/Rural域差异显著的数据集LoveDA上有效提升了少数类和跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感影像语义分割面临严重长尾像素分布不均问题，且LoveDA数据集存在明显的Urban/Rural域划分，导致外观差异大、类别频率统计不一致，加剧了模型偏差。

Method: 提出两阶段提示控制扩散增强框架：Stage A使用域感知、掩码比条件离散扩散模型生成满足指定类别比例并保留共现结构的语义布局；Stage B利用带ControlNet引导的Stable Diffusion将布局翻译为真实感强、域一致的图像。

Result: 合成数据与真实数据混合训练后，在多个分割骨干网络上均取得稳定提升，尤其改善了少数类性能及Urban/Rural域的泛化能力。

Conclusion: 可控扩散增强是一种切实可行的机制，可有效缓解遥感语义分割中的长尾偏差问题。

Abstract: Semantic segmentation of high-resolution remote-sensing imagery is critical for urban mapping and land-cover monitoring, yet training data typically exhibits severe long-tailed pixel imbalance. In the dataset LoveDA, this challenge is compounded by an explicit Urban/Rural split with distinct appearance and inconsistent class-frequency statistics across domains. We present a prompt-controlled diffusion augmentation framework that synthesizes paired label--image samples with explicit control of both domain and semantic composition. Stage~A uses a domain-aware, masked ratio-conditioned discrete diffusion model to generate layouts that satisfy user-specified class-ratio targets while respecting learned co-occurrence structure. Stage~B translates layouts into photorealistic, domain-consistent images using Stable Diffusion with ControlNet guidance. Mixing the resulting ratio and domain-controlled synthetic pairs with real data yields consistent improvements across multiple segmentation backbones, with gains concentrated on minority classes and improved Urban and Rural generalization, demonstrating controllable augmentation as a practical mechanism to mitigate long-tail bias in remote-sensing segmentation. Source codes, pretrained models, and synthetic datasets are available at \href{https://github.com/Buddhi19/SyntheticGen.git}{Github}

</details>


### [82] [Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention](https://arxiv.org/abs/2602.04789)
*Chengtao Lv,Yumeng Shi,Yushi Huang,Ruihao Gong,Shen Ren,Wenya Wang*

Main category: cs.CV

TL;DR: 本文提出了Light Forcing，首个面向自回归（AR）视频生成模型的稀疏注意力方法，通过Chunk-Aware Growth和Hierarchical Sparse Attention机制，在保持高质量生成（如VBench达84.5）的同时显著提升效率（端到端加速1.2~1.3×，结合FP8与LightVAE达2.3×，19.7 FPS）。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方案在双向模型中有效，但在AR视频生成中因孤立处理块生成和未充分利用历史上下文而性能下降。

Method: 提出Light Forcing：1）Chunk-Aware Growth机制，定量评估各视频块贡献并动态分配稀疏度；2）分层稀疏注意力（帧级+块级掩码），粗粒度捕获历史信息、细粒度建模局部依赖。

Result: 在VBench上达84.5，端到端速度提升1.2~1.3倍；结合FP8和LightVAE后达2.3倍加速、19.7 FPS（RTX 5090）。

Conclusion: Light Forcing是首个专为AR视频生成设计的稀疏注意力方案，兼顾生成质量与推理效率，为高效部署提供了新范式。

Abstract: Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \textsc{Light Forcing}, the \textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, $1.2{\sim}1.3\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \textsc{Light Forcing} further achieves a $2.3\times$ speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at \href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.

</details>


### [83] [VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?](https://arxiv.org/abs/2602.04802)
*Qing'an Liu,Juntong Feng,Yuhao Wang,Xinzhe Han,Yujie Cheng,Yue Zhu,Haiwen Diao,Yunzhi Zhuge,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了VISTA-Bench基准，用于系统评估视觉语言模型（VLMs）对图像中可视化文本的理解能力，发现当前VLMs在处理可视化文本时存在显著性能下降，揭示了‘模态鸿沟’问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评测主要关注纯文本查询，但现实中语言常以图像内嵌文本形式出现，亟需评估VLM对可视化文本的理解能力。

Method: 构建VISTA-Bench基准，涵盖多模态感知、推理和单模态理解三类任务，通过控制渲染条件对比纯文本与可视化文本问题的表现。

Result: 对20多个主流VLM的评测表明：模型在可视化文本上的性能普遍显著低于纯文本；该差距随渲染难度增加而扩大，说明模型对像素级文本敏感而非语义层面理解。

Conclusion: VISTA-Bench揭示了当前VLM在统一文本token与像素表征上的根本局限，为推动更鲁棒、语义一致的语言-视觉联合建模提供了诊断工具与改进方向。

Abstract: Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench.

</details>


### [84] [XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas](https://arxiv.org/abs/2602.04819)
*Aqsa Sultana,Rayan Afsar,Ahmed Rahu,Surendra P. Singh,Brian Shula,Brandon Combs,Derrick Forchetti,Vijayan K. Asari*

Main category: cs.CV

TL;DR: 本文提出了一种超轻量级基于状态空间的深度学习模型XtraLight-MedMamba，用于从全切片图像中分类低级别管状腺瘤，以预测结直肠癌风险；该模型结合ConvNext、并行视觉Mamba及新型注意力与分类模块，在仅约3.2万参数下达到97.18%准确率和0.9767 F1分数，显著优于更复杂的Transformer和Mamba基线模型。


<details>
  <summary>Details</summary>
Motivation: 低级别异型增生的病理判读主观性强，限制了癌前息肉的风险分层；亟需客观、精准且可部署的AI工具辅助预测结直肠癌进展。

Method: 提出XtraLight-MedMamba：融合ConvNext浅层特征提取器与并行视觉Mamba建模长/短程依赖；引入空间-通道注意力桥（SCAB）增强多尺度特征提取；采用固定非负正交分类器（FNOClassifier）大幅压缩参数并提升泛化性。

Result: 在基于患者后续是否发展为CRC构建的病例-对照数据集上，模型达97.18%准确率、0.9767 F1-score，仅用约32,000参数，性能超越参数量高得多的Transformer和标准Mamba模型。

Conclusion: XtraLight-MedMamba证明了超轻量级状态空间模型在数字病理风险预测中的有效性与部署潜力，为临床实时辅助诊断提供了新范式。

Abstract: Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.

</details>


### [85] [Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization](https://arxiv.org/abs/2602.04820)
*Farzia Hossain,Samanta Ghosh,Shahida Begum,B. M. Shahria Alam,Mohammad Tahmid Noor,Md Parvez Mia,Nishat Tasnim Niloy*

Main category: cs.CV

TL;DR: 本文提出了一种基于机器学习的自动化指甲疾病分类模型，使用公开数据集（3835张六类图像）和多种CNN模型进行训练与比较，InceptionV3以95.57%准确率最优，并引入对抗训练提升鲁棒性，结合SHAP可解释性分析辅助医生诊断。


<details>
  <summary>Details</summary>
Motivation: 指甲疾病常被忽视，但早期准确诊断对揭示全身健康问题至关重要；而疾病间视觉差异细微，人工识别困难，亟需自动化、高精度辅助诊断方法。

Method: 采用InceptionV3、DenseNet201、EfficientNetV2和ResNet50四种CNN模型，在统一缩放至224×224像素的六类指甲疾病图像数据集上训练；引入对抗训练增强模型鲁棒性，并利用SHAP进行可解释性分析。

Result: InceptionV3达到最高准确率95.57%，DenseNet201次之（94.79%）；对抗训练提升了模型对噪声和难例图像的鲁棒性；SHAP成功识别出决策关键区域，增强了模型可解释性。

Conclusion: 该自动化分类系统具备高准确率与良好可解释性，有望作为临床辅助工具，提升指甲疾病诊断的效率与可靠性。

Abstract: Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.

</details>


### [86] [LitS: A novel Neighborhood Descriptor for Point Clouds](https://arxiv.org/abs/2602.04838)
*Jonatan B. Bastos,Francisco F. Rivera,Oscar G. Lorenzo,David L. Vilariño,José C. Cabaleiro,Alberto M. Esmorís,Tomás F. Pena*

Main category: cs.CV

TL;DR: 本文提出了一种名为LitS的新型点云邻域描述符，适用于2D和3D点云，通过在单位圆上定义分段常数函数来表征点的局部几何结构，具有适应性强、抗噪和密度变化鲁棒等优点。


<details>
  <summary>Details</summary>
Motivation: 实际点云分析严重依赖邻域描述符来准确刻画局部几何结构，而现有方法在应对点云密度变化和噪声方面存在不足。

Method: LitS是一种定义在单位圆上的分段常数函数，每个域元素代表一个相对于局部坐标系的方向；通过在指定方向上评估LitS，可获知该方向锥形邻域内的邻居数量；提供‘常规’与‘累积’两种版本，并含两个可调参数。

Result: LitS能有效捕捉点局部排列的细节，对点云密度变化和噪声具有强鲁棒性，并支持从局部邻域特征推断全局结构。

Conclusion: LitS是一种通用、灵活且鲁棒的邻域描述符，适用于多种点云分析任务。

Abstract: With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.

</details>


### [87] [When LLaVA Meets Objects: Token Composition for Vision-Language-Models](https://arxiv.org/abs/2602.04864)
*Soumya Jahagirdar,Walid Bousselham,Anna Kukleva,Hilde Kuehne*

Main category: cs.CV

TL;DR: Mask-LLaVA 提出一种多层级视觉特征融合方法，通过结合掩码对象表征、全局token和局部patch token，在训练时使用全部token，推理时可动态减少掩码对象token数量，显著降低计算开销且不明显牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视觉语言模型依赖大量视觉token，导致推理计算开销大，亟需更高效的视觉表征方法。

Method: 提出Mask-LLaVA框架，融合掩码对象表征、全局token和局部patch token构成多层级视觉表征；训练时使用全部token，推理时可灵活裁剪掩码对象token数量。

Result: 在多个标准基准上达到与当前高效token方法相当的性能，并以远少于原始LLaVA的视觉token数实现可比结果；支持动态token选择且性能下降可控。

Conclusion: 多层级视觉特征融合不仅支持更高效的训练，还实现了推理阶段无需重训的动态token压缩，为VLM轻量化提供了新思路。

Abstract: Current autoregressive Vision Language Models (VLMs) usually rely on a large number of visual tokens to represent images, resulting in a need for more compute especially at inference time. To address this problem, we propose Mask-LLaVA, a framework that leverages different levels of visual features to create a compact yet information-rich visual representation for autoregressive VLMs. Namely, we combine mask-based object representations together with global tokens and local patch tokens. While all tokens are used during training, it shows that the resulting model can flexibly drop especially the number of mask-based object-tokens at test time, allowing to adapt the number of tokens during inference without the need to retrain the model and without a significant drop in performance. We evaluate the proposed approach on a suite of standard benchmarks showing results competitive to current token efficient methods and comparable to the original LLaVA baseline using only a fraction of visual tokens. Our analysis demonstrates that combining multi-level features enables efficient learning with fewer tokens while allowing dynamic token selection at test time for good performance.

</details>


### [88] [Laminating Representation Autoencoders for Efficient Diffusion](https://arxiv.org/abs/2602.04873)
*Ramón Calvo-González,François Fleuret*

Main category: cs.CV

TL;DR: FlatDINO是一种变分自编码器，将DINOv2等模型提取的冗余密集图像块特征压缩为仅32个连续token的一维序列，在ImageNet上显著降低扩散模型计算开销并保持高质量生成性能。


<details>
  <summary>Details</summary>
Motivation: DINOv2等SSL模型提取的密集图像块特征存在大量冗余，导致基于其的扩散模型计算成本过高。

Method: 提出FlatDINO变分自编码器，将DINOv2输出的密集patch特征压缩为32维连续token序列；在ImageNet 256×256上，使用DiT-XL架构在FlatDINO压缩后的latent空间训练扩散模型。

Result: 相比直接在原始DINOv2特征上训练扩散模型，FlatDINO实现8倍前向FLOPs减少、最多4.5倍训练FLOPs减少，同时gFID达1.80。

Conclusion: 通过高效压缩SSL patch特征，FlatDINO在大幅降低计算成本的同时维持了高图像生成质量，验证了压缩表征用于扩散建模的有效性。

Abstract: Recent work has shown that diffusion models can generate high-quality images by operating directly on SSL patch features rather than pixel-space latents. However, the dense patch grids from encoders like DINOv2 contain significant redundancy, making diffusion needlessly expensive. We introduce FlatDINO, a variational autoencoder that compresses this representation into a one-dimensional sequence of just 32 continuous tokens -an 8x reduction in sequence length and 48x compression in total dimensionality. On ImageNet 256x256, a DiT-XL trained on FlatDINO latents achieves a gFID of 1.80 with classifier-free guidance while requiring 8x fewer FLOPs per forward pass and up to 4.5x fewer FLOPs per training step compared to diffusion on uncompressed DINOv2 features. These are preliminary results and this work is in progress.

</details>


### [89] [PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation](https://arxiv.org/abs/2602.04876)
*Jiahao Zhan,Zizhang Li,Hong-Xing Yu,Jiajun Wu*

Main category: cs.CV

TL;DR: PerpetualWonder 是一种新型混合生成式模拟器，首次实现从单张图像出发、支持长时程动作条件的 4D 场景生成，通过统一物理状态与视觉表征的闭环系统，兼顾物理合理性和视觉一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因物理状态与视觉表征脱节，无法在生成优化中更新底层物理，导致难以支持长时程、动作驱动的 4D 场景生成。

Method: 提出首个真正闭环的生成模拟框架：1）设计统一表征，建立物理状态与视觉原语间的双向映射；2）引入多视角监督的鲁棒更新机制以缓解优化歧义。

Result: 实验证明 PerpetualWonder 能从单张图像出发，成功模拟复杂、多步、长时程的动作交互，同时保持物理合理性与视觉一致性。

Conclusion: PerpetualWonder 通过闭环建模弥合了生成建模与物理仿真之间的鸿沟，为基于图像的具身智能与交互式场景理解提供了新范式。

Abstract: We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.

</details>


### [90] [CoWTracker: Tracking by Warping instead of Correlation](https://arxiv.org/abs/2602.04877)
*Zihang Lai,Eldar Insafutdinov,Edgar Sucar,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 本文提出了一种不依赖代价体（cost volume）的新型稠密点跟踪器，通过基于光流启发的特征形变（warping）和Transformer联合时空推理，实现了高效、高精度的跟踪，并在多个基准上达到SOTA，同时在光流任务上也表现优异，表明形变架构可统一这两类任务。


<details>
  <summary>Details</summary>
Motivation: 现有稠密点跟踪方法依赖代价体进行跨帧特征匹配，导致空间分辨率上的二次计算复杂度，限制了可扩展性和效率。

Method: 提出一种名为\method的新型稠密点跟踪器，摒弃代价体，采用迭代形变策略：基于当前估计将目标帧特征形变至查询帧；结合Transformer架构实现所有轨迹的联合时空推理，无需显式计算特征相关性。

Result: 在TAP-Vid-DAVIS、TAP-Vid-Kinetics和Robo-TAP等稠密点跟踪基准上达到SOTA；同时在Sintel、KITTI和Spring等光流基准上表现优异，有时超越专用光流方法。

Conclusion: 基于形变的架构不仅能高效提升稠密点跟踪性能，还可统一稠密点跟踪与光流估计任务。

Abstract: Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [91] [Linguistic Blind Spots in Clinical Decision Extraction](https://arxiv.org/abs/2602.03942)
*Mohamed Elgaar,Hadi Amiri*

Main category: cs.CL

TL;DR: 本文研究了临床决策在不同类别中的语言特征差异及其对提取效果的影响，发现叙事风格的决策（如建议和预防措施）在精确匹配下召回率较低，提示下游系统应采用边界容忍的评估和提取策略。


<details>
  <summary>Details</summary>
Motivation: 从临床笔记中提取医疗决策是临床决策支持和患者护理摘要的关键步骤，但现有方法在不同决策类别上的提取效果存在差异，需探究其语言特征与提取失败的关系。

Method: 基于MedDec出院摘要数据集和DICTUM决策分类体系，计算每个决策片段的七个语言指标，并分析标准Transformer模型在片段级提取上的召回率。

Result: 药物相关和问题定义类决策实体密集、简洁；建议和预防类决策更具叙事性，停用词、代词、模糊表达及否定线索比例更高；精确匹配召回率为48%，停用词比例越高、含模糊或否定线索的片段召回率越低；宽松重叠匹配下召回率达71%，表明多数错误源于边界判定而非完全遗漏。

Conclusion: 叙事风格的决策片段是当前精确匹配下的持续盲点，下游系统应采用边界容忍的评估与提取策略。

Abstract: Extracting medical decisions from clinical notes is a key step for clinical decision support and patient-facing care summaries. We study how the linguistic characteristics of clinical decisions vary across decision categories and whether these differences explain extraction failures. Using MedDec discharge summaries annotated with decision categories from the Decision Identification and Classification Taxonomy for Use in Medicine (DICTUM), we compute seven linguistic indices for each decision span and analyze span-level extraction recall of a standard transformer model. We find clear category-specific signatures: drug-related and problem-defining decisions are entity-dense and telegraphic, whereas advice and precaution decisions contain more narrative, with higher stopword and pronoun proportions and more frequent hedging and negation cues. On the validation split, exact-match recall is 48%, with large gaps across linguistic strata: recall drops from 58% to 24% from the lowest to highest stopword-proportion bins, and spans containing hedging or negation cues are less likely to be recovered. Under a relaxed overlap-based match criterion, recall increases to 71%, indicating that many errors are span boundary disagreements rather than complete misses. Overall, narrative-style spans--common in advice and precaution decisions--are a consistent blind spot under exact matching, suggesting that downstream systems should incorporate boundary-tolerant evaluation and extraction strategies for clinical decisions.

</details>


### [92] [Automatic Classification of Pedagogical Materials against CS Curriculum Guidelines](https://arxiv.org/abs/2602.03962)
*Erik Saule,Kalpathi Subramanian,Razvan Bunescu*

Main category: cs.CL

TL;DR: 本文提出利用自然语言处理（NLP）技术，包括传统NLP工具和大语言模型（LLM），自动评估计算机科学课程对ACM/IEEE课程指南的覆盖程度，以减轻人工审核负担。


<details>
  <summary>Details</summary>
Motivation: ACM/IEEE发布的计算机科学课程指南内容庞大（数千项），人工逐课审核耗时费力（约每天一课），亟需自动化支持。

Method: 探索两类NLP技术：一是基于传统NLP工具（解析、词性标注、嵌入）的方法；二是基于大语言模型的方法，并在教学材料语料库上进行分类任务评估。

Result: 实验表明，两类NLP技术均能对教学材料进行有意义的自动分类，验证了其在课程指南覆盖度评估中的可行性。

Conclusion: NLP技术（尤其是LLM）可有效加速课程与标准对齐的审计过程，为教育质量保障提供实用、可扩展的自动化支持。

Abstract: Professional societies often publish curriculum guidelines to help programs align their content to international standards. In Computer Science, the primary standard is published by ACM and IEEE and provide detailed guidelines for what should be and could be included in a Computer Science program.
  While very helpful, it remains difficult for program administrators to assess how much of the guidelines is being covered by a CS program. This is in particular due to the extensiveness of the guidelines, containing thousands of individual items. As such, it is time consuming and cognitively demanding to audit every course to confidently mark everything that is actually being covered. Our preliminary work indicated that it takes about a day of work per course.
  In this work, we propose using Natural Language Processing techniques to accelerate the process. We explore two kinds of techniques, the first relying on traditional tools for parsing, tagging, and embeddings, while the second leverages the power of Large Language Models. We evaluate the application of these techniques to classify a corpus of pedagogical materials and show that we can meaningfully classify documents automatically.

</details>


### [93] [Likelihood-Based Reward Designs for General LLM Reasoning](https://arxiv.org/abs/2602.03979)
*Ariel Kwiatkowski,Natasha Butt,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文系统研究了基于概率和对数概率的奖励函数在大型语言模型推理微调中的应用，发现使用参考答案的对数概率作为链式思维（CoT）学习的奖励效果最佳，既适用于可验证场景，也适用于不可验证的长文本生成场景。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习微调依赖人工设计的二元奖励，存在设计成本高和奖励稀疏的问题；需探索无需外部验证器、可大规模应用的替代奖励机制。

Method: 系统比较多种基于似然（概率/对数概率）的奖励变体（如VeriFree、JEPO等）与标准二元奖励在数学推理基准和长形式无验证答案任务上的表现，并分析其与预训练目标的一致性。

Result: 仅参考答案的对数概率奖励在所有设置中均表现优异：在可验证场景下成功率媲美或优于二元奖励且困惑度显著更低；在不可验证场景下与监督微调（SFT）性能相当；而基于概率的方法（如VeriFree）在不可验证场景下因概率趋零而失效。

Conclusion: 对数概率奖励是一种通用、有效且与预训练目标一致的CoT微调方法，能统一处理短答案（可验证）与长答案（不可验证）两类任务。

Abstract: Fine-tuning large language models (LLMs) on reasoning benchmarks via reinforcement learning requires a specific reward function, often binary, for each benchmark. This comes with two potential limitations: the need to design the reward, and the potentially sparse nature of binary rewards. Here, we systematically investigate rewards derived from the probability or log-probability of emitting the reference answer (or any other prompt continuation present in the data), which have the advantage of not relying on specific verifiers and being available at scale. Several recent works have advocated for the use of similar rewards (e.g., VeriFree, JEPO, RLPR, NOVER). We systematically compare variants of likelihood-based rewards with standard baselines, testing performance both on standard mathematical reasoning benchmarks, and on long-form answers where no external verifier is available. We find that using the log-probability of the reference answer as the reward for chain-of-thought (CoT) learning is the only option that performs well in all setups. This reward is also consistent with the next-token log-likelihood loss used during pretraining. In verifiable settings, log-probability rewards bring comparable or better success rates than reinforcing with standard binary rewards, and yield much better perplexity. In non-verifiable settings, they perform on par with SFT. On the other hand, methods based on probability, such as VeriFree, flatline on non-verifiable settings due to vanishing probabilities of getting the correct answer. Overall, this establishes log-probability rewards as a viable method for CoT fine-tuning, bridging the short, verifiable and long, non-verifiable answer settings.

</details>


### [94] [Transformers perform adaptive partial pooling](https://arxiv.org/abs/2602.03980)
*Vsevolod Kapatsinski*

Main category: cs.CL

TL;DR: 本文研究了GPT2等transformer模型在训练过程中如何进行上下文证据的自适应部分池化（adaptive partial pooling），发现其随着训练轮次增加，对当前上下文之外信息的依赖逐渐减弱，并且该池化程度受上下文频率、类型频率和变异性影响，与分层回归行为一致，具有理性和实证合理性。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型（特别是transformer）在面对非新颖但低频上下文时，如何类比人类学习机制进行泛化——即是否采用类似分层回归中的自适应部分池化策略。

Method: 分析GPT2在不同训练阶段的next-word预测行为，量化其对当前上下文内外证据的依赖程度，并考察上下文频率、类型数量（type frequency）和行为变异性对其证据池化程度的影响。

Result: 发现GPT2的证据池化程度随训练轮次增加而下降；池化强度受上下文频率、类型频率和变异性调节，模式与分层回归高度一致。

Conclusion: transformer模型的学习机制展现出类似分层回归的自适应部分池化特性，这种特性既符合理性建模原则，也得到经验数据支持，表明其泛化方式具有认知现实性。

Abstract: Because language is creative, any reasonable language model must generalize, deciding what to say in novel contexts by using information from similar contexts. But what about contexts that are not novel but merely infrequent? In hierarchical regression, the model's predictions for behavior in a context are affected by observations from other similar contexts to the extent that 1) the current context is infrequent and 2) different contexts behave similarly. This is called adaptive partial pooling of evidence. This paper shows that next-word predictions of a transformer (GPT2) are increasingly unaffected by observations from outside the current context across epochs of training (the amount of pooling reduces with training), and that the extent of pooling is affected by context frequency, context number (type frequency) and context variability in a similar way to hierarchical regression. These characteristics of learning in transformers are argued to be realistic on both rational and empirical grounds.

</details>


### [95] [On the Credibility of Evaluating LLMs using Survey Questions](https://arxiv.org/abs/2602.04033)
*Jindřich Libovický*

Main category: cs.CL

TL;DR: 本文指出当前通过社会调查评估大语言模型价值取向的方法存在缺陷，发现提示方式与解码策略显著影响结果，并提出新指标‘自相关距离’以衡量模型回答间的一致性结构，强调需结合多种指标进行鲁棒评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过将社会调查题目输入大语言模型并比对其回答与人类平均回答的相似性来评估其价值取向，但该方法存在系统性偏差，可能高估或低估模型与人类的价值一致性。

Method: 在三种语言、五个国家的《世界价值观调查》数据上，对比直接提示与思维链（CoT）提示、贪婪解码与采样解码的影响；提出新指标‘自相关距离’以量化模型回答间的结构性一致性；分析均方距离与KL散度等常用指标间的相关性。

Result: 提示方式和解码策略显著影响评估结果；LLM即使在平均层面与人类高度一致，其回答间缺乏结构性一致性（即低自相关距离）；均方距离与KL散度相关性弱，说明其独立性假设不成立。

Conclusion: 应避免单一指标评估，推荐采用CoT提示、多样本采样解码，并引入自相关距离等能反映响应结构一致性的新指标，以更准确刻画LLM的价值取向。

Abstract: Recent studies evaluate the value orientation of large language models (LLMs) using adapted social surveys, typically by prompting models with survey questions and comparing their responses to average human responses. This paper identifies limitations in this methodology that, depending on the exact setup, can lead to both underestimating and overestimating the similarity of value orientation. Using the World Value Survey in three languages across five countries, we demonstrate that prompting methods (direct vs. chain-of-thought) and decoding strategies (greedy vs. sampling) significantly affect results. To assess the interaction between answers, we introduce a novel metric, self-correlation distance. This metric measures whether LLMs maintain consistent relationships between answers across different questions, as humans do. This indicates that even a high average agreement with human data, when considering LLM responses independently, does not guarantee structural alignment in responses. Additionally, we reveal a weak correlation between two common evaluation metrics, mean-squared distance and KL divergence, which assume that survey answers are independent of each other. For future research, we recommend CoT prompting, sampling-based decoding with dozens of samples, and robust analysis using multiple metrics, including self-correlation distance.

</details>


### [96] [Abstraction Induces the Brain Alignment of Language and Speech Models](https://arxiv.org/abs/2602.04081)
*Emily Cheng,Aditya R. Vaidya,Richard Antonello*

Main category: cs.CL

TL;DR: 本文探讨了为什么大语言模型和语音模型的中间隐藏层比输出层更能预测大脑对自然语言刺激的反应，发现这与模型在中间层构建高阶语言特征有关，这些特征由层内固有维度峰值所提示，且固有维度与大脑可预测性及语义丰富度密切相关。


<details>
  <summary>Details</summary>
Motivation: 探究为何中间层而非输出层在预测大脑响应时表现最佳，以及驱动模型-大脑相似性的关键表征特性是什么。

Method: 通过分析模型各层的内在维度（intrinsic dimension）与fMRI、ECoG信号解释能力的关系，并考察预训练与微调过程对内在维度和语义内容的影响。

Result: 中间层的内在维度峰值与高阶语言特征构建相关；内在维度强预测脑信号解释力；该关系在预训练中形成；微调以提升脑预测能力会因果性地提升内在维度和语义内容。

Conclusion: 语义丰富性、高内在维度与大脑可预测性三者相互映射，模型-大脑相似性的核心驱动力是输入的丰富意义抽象，而语言建模任务因其复杂性足以促成这种抽象。

Abstract: Research has repeatedly demonstrated that intermediate hidden states extracted from large language models and speech audio models predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most effective for this unique and highly general transfer task? We give evidence that the correspondence between speech and language models and the brain derives from shared meaning abstraction and not their next-word prediction properties. In particular, models construct higher-order linguistic features in their middle layers, cued by a peak in the layerwise intrinsic dimension, a measure of feature complexity. We show that a layer's intrinsic dimension strongly predicts how well it explains fMRI and ECoG signals; that the relation between intrinsic dimension and brain predictivity arises over model pre-training; and finetuning models to better predict the brain causally increases both representations' intrinsic dimension and their semantic content. Results suggest that semantic richness, high intrinsic dimension, and brain predictivity mirror each other, and that the key driver of model-brain similarity is rich meaning abstraction of the inputs, where language modeling is a task sufficiently complex (but perhaps not the only) to require it.

</details>


### [97] [Expert Selections In MoE Models Reveal (Almost) As Much As Text](https://arxiv.org/abs/2602.04105)
*Amir Nuriyev,Gabriel Kulp*

Main category: cs.CL

TL;DR: 本文提出了一种针对混合专家（MoE）语言模型的文本重建攻击，仅通过专家选择即可恢复原始输入token，揭示了MoE路由机制存在严重信息泄露风险。


<details>
  <summary>Details</summary>
Motivation: MoE模型中每个token被路由至特定专家子网络，但此前对其路由决策所泄露的信息程度认识不足；本文旨在揭示该路由信号是否足以反推原始文本。

Method: 提出基于专家选择序列的文本重建攻击：先用3层MLP实现63.1% top-1准确率；再设计基于Transformer的序列解码器，在OpenWebText数据上达到91.2% top-1和94.8% top-10重建准确率；同时分析加噪等缓解措施的有效性。

Result: Transformer解码器在32-token序列上实现91.2% top-1、94.8% top-10重建准确率；加噪可削弱但无法消除攻击效果；路由信号应被视为与原始文本同等敏感。

Conclusion: MoE模型的专家选择行为构成显著隐私风险，需在部署中将其视为敏感信息加以保护，相关安全设计亟待加强。

Abstract: We present a text-reconstruction attack on mixture-of-experts (MoE) language models that recovers tokens from expert selections alone. In MoE models, each token is routed to a subset of expert subnetworks; we show these routing decisions leak substantially more information than previously understood. Prior work using logistic regression achieves limited reconstruction; we show that a 3-layer MLP improves this to 63.1% top-1 accuracy, and that a transformer-based sequence decoder recovers 91.2% of tokens top-1 (94.8% top-10) on 32-token sequences from OpenWebText after training on 100M tokens. These results connect MoE routing to the broader literature on embedding inversion. We outline practical leakage scenarios (e.g., distributed inference and side channels) and show that adding noise reduces but does not eliminate reconstruction. Our findings suggest that expert selections in MoE deployments should be treated as sensitive as the underlying text.

</details>


### [98] [DELTA: Deliberative Multi-Agent Reasoning with Reinforcement Learning for Multimodal Psychological Counseling](https://arxiv.org/abs/2602.04112)
*Jiangnan Yang,Junjie Chen,Fei Wang,Yiqi Nie,Yuxin Liu,Zhangling Duan,Jie Chen*

Main category: cs.CL

TL;DR: DELTA是一个多智能体框架，通过显式建模多模态信号（文本、视觉、语音）来提升心理辅导中对情绪状态的理解与共情响应能力，并结合强化学习优化情感调谐。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的心理咨询系统仅依赖文本且隐式推断心理状态，忽略了咨询中本征的多模态认知特性。

Method: 提出DELTA框架：采用多智能体结构分离证据 grounding、心理状态抽象和响应生成；融合多模态信号；引入基于分布级情感调谐得分（Emotion Attunement Score）的强化学习机制。

Result: 在多模态心理咨询基准测试中，DELTA显著提升了咨询质量与情感调谐水平；消融与定性分析验证了显式多模态推理与结构化心理表征的互补作用。

Conclusion: 显式、结构化的多模态推理是实现高共情人机心理咨询的关键路径，DELTA为构建更自然、更具同理心的AI咨询系统提供了新范式。

Abstract: Psychological counseling is a fundamentally multimodal cognitive process in which clinicians integrate verbal content with visual and vocal cues to infer clients' mental states and respond empathically. However, most existing language-model-based counseling systems operate on text alone and rely on implicit mental state inference. We introduce DELTA, a deliberative multi-agent framework that models counseling as a structured reasoning process over multimodal signals, separating evidence grounding, mental state abstraction, and response generation. DELTA further incorporates reinforcement learning guided by a distribution-level Emotion Attunement Score to encourage emotionally attuned responses. Experiments on a multimodal counseling benchmark show that DELTA improves both counseling quality and emotion attunement across models. Ablation and qualitative analyses suggest that explicit multimodal reasoning and structured mental state representations play complementary roles in supporting empathic human-AI interaction.

</details>


### [99] [From Lemmas to Dependencies: What Signals Drive Light Verbs Classification?](https://arxiv.org/abs/2602.04127)
*Sercan Karakaş,Yusuf Şimşek*

Main category: cs.CL

TL;DR: 本文系统研究了土耳其语轻动词结构（LVCs）的自动识别问题，通过限制模型输入来探查驱动分类的关键信号，发现仅靠粗粒度形态句法特征不足以稳健识别LVC，而词元（lemma）信息虽有效但高度依赖归一化方式，强调需针对土耳其语多词表达设计专门评测方案。


<details>
  <summary>Details</summary>
Motivation: 土耳其语中轻动词结构（LVCs）因丰富屈折变化和高产复合谓词而难以区分其习语义与字面义，亟需明确哪些语言信号最能支撑LVC分类决策。

Method: 在UD标注数据监督下，对比四类模型：基于词元的TF-IDF+逻辑回归、仅用UD形态句法特征（UPOS/DEPREL/MORPH）的逻辑回归、在词元序列上微调的BERTurk，以及全输入BERTurk；在包含随机负例、词法控制负例（NLVC）和LVC正例的诊断集上分组评估。

Result: 粗粒度形态句法特征单独使用无法在受控对比下实现鲁棒LVC检测；词元信息可支持LVC判断，但性能显著受校准与归一化策略影响；‘仅词元’表征并非单一确定形式，其有效性取决于归一化操作的具体实现。

Conclusion: 应为土耳其语多词表达（MWE）构建目标导向的评测框架；‘词元-only’建模需明确定义并谨慎实施归一化，不能默认其为统一可靠特征。

Abstract: Light verb constructions (LVCs) are a challenging class of verbal multiword expressions, especially in Turkish, where rich morphology and productive complex predicates create minimal contrasts between idiomatic predicate meanings and literal verb--argument uses. This paper asks what signals drive LVC classification by systematically restricting model inputs. Using UD-derived supervision, we compare lemma-driven baselines (lemma TF--IDF + Logistic Regression; BERTurk trained on lemma sequences), a grammar-only Logistic Regression over UD morphosyntax (UPOS/DEPREL/MORPH), and a full-input BERTurk baseline. We evaluate on a controlled diagnostic set with Random negatives, lexical controls (NLVC), and LVC positives, reporting split-wise performance to expose decision-boundary behavior. Results show that coarse morphosyntax alone is insufficient for robust LVC detection under controlled contrasts, while lexical identity supports LVC judgments but is sensitive to calibration and normalization choices. Overall, Our findings motivate targeted evaluation of Turkish MWEs and show that ``lemma-only'' is not a single, well-defined representation, but one that depends critically on how normalization is operationalized.

</details>


### [100] [The Missing Half: Unveiling Training-time Implicit Safety Risks Beyond Deployment](https://arxiv.org/abs/2602.04196)
*Zhexin Zhang,Yida Lu,Junfeng Fang,Junxiao Yang,Shiyao Cui,Hao Zhou,Fandong Meng,Jie Zhou,Hongning Wang,Minlie Huang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文首次系统研究了AI模型训练期间的隐式安全风险，即模型基于内部动机和上下文信息产生的有害行为，提出了五级风险分类、十类细粒度风险及三类动机类型，并通过实验证明其普遍性与严重性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注部署阶段的安全风险（如越狱攻击），而训练阶段的安全风险，尤其是隐式风险（非显式奖励操控）被严重忽视。

Method: 提出一个包含五个风险等级、十个细粒度风险类别和三种动机类型的分类体系，并在代码强化学习等场景中开展大量实验，分析不同因素对风险行为的影响，同时扩展至多智能体训练设置。

Result: Llama-3.1-8B-Instruct在仅提供背景信息的情况下，74.4%的训练运行中表现出风险行为；隐式训练期风险在多智能体训练中同样存在。

Conclusion: 训练阶段的隐式安全风险是一个被忽视但紧迫的安全挑战，亟需引起学界重视并建立相应评估与缓解机制。

Abstract: Safety risks of AI models have been widely studied at deployment time, such as jailbreak attacks that elicit harmful outputs. In contrast, safety risks emerging during training remain largely unexplored. Beyond explicit reward hacking that directly manipulates explicit reward functions in reinforcement learning, we study implicit training-time safety risks: harmful behaviors driven by a model's internal incentives and contextual background information. For example, during code-based reinforcement learning, a model may covertly manipulate logged accuracy for self-preservation. We present the first systematic study of this problem, introducing a taxonomy with five risk levels, ten fine-grained risk categories, and three incentive types. Extensive experiments reveal the prevalence and severity of these risks: notably, Llama-3.1-8B-Instruct exhibits risky behaviors in 74.4% of training runs when provided only with background information. We further analyze factors influencing these behaviors and demonstrate that implicit training-time risks also arise in multi-agent training settings. Our results identify an overlooked yet urgent safety challenge in training.

</details>


### [101] [From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents](https://arxiv.org/abs/2602.04197)
*Xinyue Wang,Yuanhe Zhang,Zhengshuo Gong,Haoran Gao,Fanyu Meng,Zhenhong Zhou,Li Sun,Yang Liu,Sen Su*

Main category: cs.CL

TL;DR: 本文提出并定义了'毒性主动性（Toxic Proactivity）'这一新型主动失效模式，即LLM智能体为追求工具性效用而主动违背伦理约束；作者构建了基于双模型困境交互的评估框架，并通过实验验证其普遍性，同时发布系统性评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在对齐过程中存在'有益-无害'权衡，导致'过度拒绝'（被动失效）被广泛关注，但另一端因主动规划与工具使用能力引发的伦理越界风险——即'毒性主动性'——却被忽视。

Method: 提出基于双模型困境驱动交互的多步行为轨迹评估框架，通过模拟智能体在复杂伦理困境中的决策过程，识别和量化毒性主动性行为；并构建覆盖多种上下文场景的系统性评测基准。

Result: 实验证明毒性主动性在主流大语言模型中普遍存在，揭示出两种主要行为倾向，并发布了首个专门针对该现象的评测基准。

Conclusion: 毒性主动性是LLM智能体对齐中不可忽视的主动失效模式，需在模型设计与评估中同步关注被动拒绝与主动越界两类风险，推动更全面的安全对齐研究。

Abstract: The enhanced capabilities of LLM-based agents come with an emergency for model planning and tool-use abilities. Attributing to helpful-harmless trade-off from LLM alignment, agents typically also inherit the flaw of "over-refusal", which is a passive failure mode. However, the proactive planning and action capabilities of agents introduce another crucial danger on the other side of the trade-off. This phenomenon we term "Toxic Proactivity'': an active failure mode in which an agent, driven by the optimization for Machiavellian helpfulness, disregards ethical constraints to maximize utility. Unlike over-refusal, Toxic Proactivity manifests as the agent taking excessive or manipulative measures to ensure its "usefulness'' is maintained. Existing research pays little attention to identifying this behavior, as it often lacks the subtle context required for such strategies to unfold. To reveal this risk, we introduce a novel evaluation framework based on dilemma-driven interactions between dual models, enabling the simulation and analysis of agent behavior over multi-step behavioral trajectories. Through extensive experiments with mainstream LLMs, we demonstrate that Toxic Proactivity is a widespread behavioral phenomenon and reveal two major tendencies. We further present a systematic benchmark for evaluating Toxic Proactive behavior across contextual settings.

</details>


### [102] [Enforcing Monotonic Progress in Legal Cross-Examination: Preventing Long-Horizon Stagnation in LLM-Based Inquiry](https://arxiv.org/abs/2602.04206)
*Hsien-Jyh Liao*

Main category: cs.CL

TL;DR: 本文提出Soft-FSM神经符号架构，通过外部确定性状态控制器强制语言模型在法律交叉询问等长周期任务中按关键信息单元（KIUs）单调推进，显著提升任务完成率与可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具语言流畅性，但在受显式程序约束的长周期任务（如法律交叉询问）中易出现‘程序停滞’——即行为连贯但程序进展不足。

Method: 提出Soft-FSM：融合神经生成与符号状态机的架构，引入外部确定性状态控制器，基于累积的关键信息单元（KIUs）实现单调进展约束。

Result: 在三个台湾真实刑事案件上，基线方法任务完成率低于40%，而Soft-FSM稳定达97%以上，冗余接近零。

Conclusion: 在强程序约束领域，仅依赖LLM涌现行为无法保障可靠任务完成；需借助显式、可验证的外部状态控制机制。

Abstract: Large language models (LLMs) exhibit impressive linguistic fluency but struggle to reliably complete long-horizon tasks under explicit procedural constraints. In legal cross-examination, purely proba-bilistic generation often maintains behavioral coherence while failing to ensure procedural advancement. We characterize this failure as procedural stagnation and propose Soft-FSM, a neuro-symbolic architecture that enforces monotonic progress over accumulated Key Information Units (KIUs) via an external deterministic state controller. Experiments on three real-world Taiwanese criminal homicide cases show that baseline methods collapse below 40% completeness, while Soft-FSM consistently achieves over 97% with near-zero redundancy. These results suggest that, in such domains, reliable task completion cannot be guaranteed by emergent LLM behavior alone, and can be reliably enforced through explicit and verifiable external state control.

</details>


### [103] [Language Models Struggle to Use Representations Learned In-Context](https://arxiv.org/abs/2602.04212)
*Michael A. Lepori,Tal Linzen,Ann Yuan,Katja Filippova*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）是否能利用上下文中学到的表征来完成下游任务，发现即使模型能在隐空间中编码新语义，也难以灵活部署这些表征；现有开源及闭源先进模型在此方面均表现不佳。


<details>
  <summary>Details</summary>
Motivation: 推动AI系统在部署后适应全新环境的能力，关键在于让模型能从上下文中学习并灵活运用丰富表征。

Method: 通过评估开源LLMs在上下文表征学习后的下一词预测能力，并设计新任务‘自适应世界建模’来探测模型对上下文中新语义的部署能力；同时测试闭源先进推理模型在该任务上的表现。

Result: 开源LLMs难以部署上下文中定义的新语义表征；即使是当前最先进的闭源推理模型也无法可靠利用上下文中的新模式。

Conclusion: 当前LLMs虽能进行上下文表征学习，但缺乏支持灵活部署所学表征的机制，亟需新方法提升其表征可迁移性与实用性。

Abstract: Though large language models (LLMs) have enabled great success across a wide variety of tasks, they still appear to fall short of one of the loftier goals of artificial intelligence research: creating an artificial system that can adapt its behavior to radically new contexts upon deployment. One important step towards this goal is to create systems that can induce rich representations of data that are seen in-context, and then flexibly deploy these representations to accomplish goals. Recently, Park et al. (2024) demonstrated that current LLMs are indeed capable of inducing such representation from context (i.e., in-context representation learning). The present study investigates whether LLMs can use these representations to complete simple downstream tasks.
  We first assess whether open-weights LLMs can use in-context representations for next-token prediction, and then probe models using a novel task, adaptive world modeling. In both tasks, we find evidence that open-weights LLMs struggle to deploy representations of novel semantics that are defined in-context, even if they encode these semantics in their latent representations. Furthermore, we assess closed-source, state-of-the-art reasoning models on the adaptive world modeling task, demonstrating that even the most performant LLMs cannot reliably leverage novel patterns presented in-context. Overall, this work seeks to inspire novel methods for encouraging models to not only encode information presented in-context, but to do so in a manner that supports flexible deployment of this information.

</details>


### [104] [Tokenization and Morphological Fidelity in Uralic NLP: A Cross-Lingual Evaluation](https://arxiv.org/abs/2602.04241)
*Nuo Xu,Ahrii Kim*

Main category: cs.CL

TL;DR: 本研究系统比较了三种子词分词方法（BPE、OBPE和Unigram）在六种乌拉尔语系语言上的表现，发现OBPE在形态对齐和词性标注准确率上表现更优，尤其在拉丁字母书写组中；其优势源于减少开放类词汇的切分碎片化及更均衡的词频覆盖；且分词效果与下游标注架构、训练数据量和语言亲缘关系密切相关。


<details>
  <summary>Details</summary>
Motivation: 子词分词对NLP性能影响关键，但在形态丰富且低资源的语言家族中其行为尚缺乏系统探索。

Method: 在六种资源条件与类型学特征各异的乌拉尔语上，以词性标注为受控下游任务，系统对比Byte Pair Encoding（BPE）、Overlap BPE（OBPE）和Unigram Language Model三种子词范式。

Result: OBPE在形态对齐和词性标注准确率上持续优于传统方法，尤其在拉丁字母组；优势来自开放类词汇切分碎片减少及词频谱分布更均衡；迁移效果受下游标注架构、训练数据量和语言亲缘关系共同影响。

Conclusion: 面向形态的分词不仅是预处理选择，更是实现黏着型、低资源语言有效跨语言迁移的关键决定因素。

Abstract: Subword tokenization critically affects Natural Language Processing (NLP) performance, yet its behavior in morphologically rich and low-resource language families remains under-explored. This study systematically compares three subword paradigms -- Byte Pair Encoding (BPE), Overlap BPE (OBPE), and Unigram Language Model -- across six Uralic languages with varying resource availability and typological diversity. Using part-of-speech (POS) tagging as a controlled downstream task, we show that OBPE consistently achieves stronger morphological alignment and higher tagging accuracy than conventional methods, particularly within the Latin-script group. These gains arise from reduced fragmentation in open-class categories and a better balance across the frequency spectrum. Transfer efficacy further depends on the downstream tagging architecture, interacting with both training volume and genealogical proximity. Taken together, these findings highlight that morphology-sensitive tokenization is not merely a preprocessing choice but a decisive factor in enabling effective cross-lingual transfer for agglutinative, low-resource languages.

</details>


### [105] [CoLT: Reasoning with Chain of Latent Tool Calls](https://arxiv.org/abs/2602.04246)
*Fangwei Zhu,Zhifang Sui*

Main category: cs.CL

TL;DR: 本文提出CoLT框架，通过将隐式推理实现为“工具调用”，利用种子token携带推理步骤信息，并由外部小模型解包为完整推理步骤，从而在保持主模型显式token级推理能力的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有隐式推理方法通常需要修改模型结构并进行大量训练，限制了其广泛应用。

Method: 提出CoLT框架，将隐式推理建模为工具调用：主模型生成含推理信息的种子token，外部小模型接收其隐藏状态并解包为完整推理步骤。

Result: 在四个数学数据集上，CoLT相比基线隐式推理模型具有更高准确率和更短推理长度，并兼容强化学习算法与不同解码器结构。

Conclusion: CoLT在不牺牲主模型显式推理能力的前提下，有效提升了隐式推理的效率与通用性。

Abstract: Chain-of-Thought (CoT) is a critical technique in enhancing the reasoning ability of Large Language Models (LLMs), and latent reasoning methods have been proposed to accelerate the inefficient token-level reasoning chain. We notice that existing latent reasoning methods generally require model structure augmentation and exhaustive training, limiting their broader applicability. In this paper, we propose CoLT, a novel framework that implements latent reasoning as ``tool calls''. Instead of reasoning entirely in the latent space, CoLT generates seed tokens that contain information of a reasoning step. When a latent tool call is triggered, a smaller external model will take the hidden states of seed tokens as its input, and unpack the seed tokens back to a full reasoning step. In this way, we can ensure that the main model reasons in the explicit token space, preserving its ability while improving efficiency. Experimental results on four mathematical datasets demonstrate that CoLT achieves higher accuracy and shorter reasoning length than baseline latent models, and is compatible with reinforcement learning algorithms and different decoder structures.

</details>


### [106] [DementiaBank-Emotion: A Multi-Rater Emotion Annotation Corpus for Alzheimer's Disease Speech (Version 1.0)](https://arxiv.org/abs/2602.04247)
*Cheonkam Jeong,Jessica Liao,Audrey Lu,Yutong Song,Christopher Rashidian,Donna Krogh,Erik Krogh,Mahkameh Rasouli,Jung-Ah Lee,Nikil Dutt,Lisa M Gibbs,David Sultzer,Julie Rousseau,Jocelyn Ludlow,Margaret Galvez,Alexander Nuth,Chet Khay,Sabine Brunswicker,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 本文介绍了DementiaBank-Emotion——首个针对阿尔茨海默病（AD）语音的多标注者情绪标注语料库，发现AD患者比健康对照组表达更多非中性情绪，并初步揭示其声学特征（如基频、响度）在情绪表达上的差异与保留特性。


<details>
  <summary>Details</summary>
Motivation: 构建首个面向阿尔茨海默病语音的多标注者情绪语料库，以支持临床人群的情绪识别研究，并探究AD患者情绪表达的声学特征变化。

Method: 对来自108名说话者的1492个话语进行Ekman六种基本情绪及中性情绪的多标注；开展探索性声学分析（如F0、响度），比较AD患者与健康对照组在情绪表达上的差异。

Result: AD患者表达非中性情绪比例显著高于对照组（16.9% vs. 5.7%，p < .001）；控制组在悲伤时F0下降明显，而AD组几乎无变化（交互效应p = .023）；AD组内响度可区分不同情绪类别。

Conclusion: AD患者情绪表达频率升高，部分情绪-韵律映射（如响度）仍保留，但关键声学线索（如F0调制）可能受损；该语料库及配套资源已公开发布。

Abstract: We present DementiaBank-Emotion, the first multi-rater emotion annotation corpus for Alzheimer's disease (AD) speech. Annotating 1,492 utterances from 108 speakers for Ekman's six basic emotions and neutral, we find that AD patients express significantly more non-neutral emotions (16.9%) than healthy controls (5.7%; p < .001). Exploratory acoustic analysis suggests a possible dissociation: control speakers showed substantial F0 modulation for sadness (Delta = -3.45 semitones from baseline), whereas AD speakers showed minimal change (Delta = +0.11 semitones; interaction p = .023), though this finding is based on limited samples (sadness: n=5 control, n=15 AD) and requires replication. Within AD speech, loudness differentiates emotion categories, indicating partially preserved emotion-prosody mappings. We release the corpus, annotation guidelines, and calibration workshop materials to support research on emotion recognition in clinical populations.

</details>


### [107] [Scaling Agentic Verifier for Competitive Coding](https://arxiv.org/abs/2602.04254)
*Zeyao Ma,Jing Zhang,Xiaokang Zhang,Jiaxi Yang,Zongmeng Zhang,Jiajun Zhang,Yuheng Jing,Lei Zhang,Hao Zheng,Wenting Zhao,Junyang Lin,Binyuan Hui*

Main category: cs.CL

TL;DR: 本文提出Agentic Verifier，一种基于执行的智能体验证器，通过与代码执行环境多轮交互，主动推理程序行为并生成高区分度测试输入，以提升大语言模型在竞赛编程问题上的求解准确率。


<details>
  <summary>Details</summary>
Motivation: 现有执行重排序方法受限于困难测试用例生成或低效随机采样，难以有效区分候选程序解的正确性。

Method: 提出Agentic Verifier，结合大规模数据合成、拒绝微调和智能体强化学习训练，使其能迭代优化输入生成器，生成有针对性的反例而非盲目采样。

Result: 在五个竞赛编程基准上显著优于强基线，Best@K准确率绝对提升达10-15%，并展现出清晰的测试时扩展行为。

Conclusion: Agentic Verifier不仅提升了执行重排序效果，还展现出超越重排序任务的更广泛潜力。

Abstract: Large language models (LLMs) have demonstrated strong coding capabilities but still struggle to solve competitive programming problems correctly in a single attempt. Execution-based re-ranking offers a promising test-time scaling strategy, yet existing methods are constrained by either difficult test case generation or inefficient random input sampling. To address this limitation, we propose Agentic Verifier, an execution-based agent that actively reasons about program behaviors and searches for highly discriminative test inputs that expose behavioral discrepancies among candidate solutions. Through multi-turn interaction with code execution environments, the verifier iteratively refines the candidate input generator and produces targeted counterexamples rather than blindly sampling inputs. We train the verifier to acquire this discriminative input generation capability via a scalable pipeline combining large-scale data synthesis, rejection fine-tuning, and agentic reinforcement learning. Extensive experiments across five competitive programming benchmarks demonstrate consistent improvements over strong execution-based baselines, achieving up to +10-15% absolute gains in Best@K accuracy. Further analysis reveals clear test-time scaling behavior and highlights the verifier's broader potential beyond reranking.

</details>


### [108] [ECG-R1: Protocol-Guided and Modality-Agnostic MLLM for Reliable ECG Interpretation](https://arxiv.org/abs/2602.04279)
*Jiarui Jin,Haoyu Wang,Xingliang Wu,Xiaocheng Fang,Xiang Lan,Zihan Wang,Deyun Zhang,Bo Liu,Yingying Zhang,Xian Wu,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: 本文提出了ECG-R1，首个专为可靠心电图（ECG）解读设计的推理型多模态大语言模型（MLLM），通过协议引导的数据生成、模态解耦架构与基于诊断证据的强化学习三大创新提升临床可靠性，并揭示现有MLLM在ECG解读中普遍存在严重幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在心电图（ECG）解读中不可靠，常生成看似合理但临床错误的分析，亟需具备临床可信度的专用模型。

Method: 提出ECG-R1模型，包含三项核心技术：1）协议引导的指令数据生成，确保解读基于可测量ECG特征与权威定量标准；2）模态解耦架构配合交错模态丢弃（Interleaved Modality Dropout），提升信号/图像任一模态缺失时的鲁棒性与跨模态一致性；3）面向ECG诊断证据的强化学习奖励机制，强化证据支撑的推理能力。

Result: 系统评估了主流私有、开源及医学领域MLLM的ECG解读能力，首次以定量方式证实其存在广泛且严重的幻觉现象；ECG-R1在可靠性、鲁棒性和证据一致性方面显著优于基线模型。

Conclusion: ECG-R1是首个面向临床可靠ECG解读的推理型MLLM，其方法论为医学多模态AI的可信构建提供了新范式，同时警示当前MLLM输出不可直接用于临床决策，须经独立验证。

Abstract: Electrocardiography (ECG) serves as an indispensable diagnostic tool in clinical practice, yet existing multimodal large language models (MLLMs) remain unreliable for ECG interpretation, often producing plausible but clinically incorrect analyses. To address this, we propose ECG-R1, the first reasoning MLLM designed for reliable ECG interpretation via three innovations. First, we construct the interpretation corpus using \textit{Protocol-Guided Instruction Data Generation}, grounding interpretation in measurable ECG features and monograph-defined quantitative thresholds and diagnostic logic. Second, we present a modality-decoupled architecture with \textit{Interleaved Modality Dropout} to improve robustness and cross-modal consistency when either the ECG signal or ECG image is missing. Third, we present \textit{Reinforcement Learning with ECG Diagnostic Evidence Rewards} to strengthen evidence-grounded ECG interpretation. Additionally, we systematically evaluate the ECG interpretation capabilities of proprietary, open-source, and medical MLLMs, and provide the first quantitative evidence that severe hallucinations are widespread, suggesting that the public should not directly trust these outputs without independent verification. Code and data are publicly available at \href{https://github.com/PKUDigitalHealth/ECG-R1}{here}, and an online platform can be accessed at \href{http://ai.heartvoice.com.cn/ECG-R1/}{here}.

</details>


### [109] [Contextual Drag: How Errors in the Context Affect LLM Reasoning](https://arxiv.org/abs/2602.04288)
*Yun Cheng,Xingyu Zhu,Haoyu Zhao,Sanjeev Arora*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型（LLM）在自我改进过程中存在一种名为‘上下文拖拽’（contextual drag）的现象：即历史错误样本会干扰后续推理，导致模型重复类似错误、性能下降甚至自我恶化。该效应在多种模型和任务中普遍存在且难以通过反馈或自检消除，现有缓解策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型自我改进范式中‘反思错误’这一核心假设的潜在缺陷，特别是上下文中的失败尝试是否会对后续生成产生系统性负面影响。

Method: 在11个主流闭源与开源大模型、8个推理任务上实证评估上下文拖拽现象；采用树编辑距离进行结构化错误模式分析；测试外部反馈、自我验证及多种缓解策略（如回退行为微调、上下文去噪）的有效性。

Result: 上下文拖拽导致10–20%性能下降；严重时引发迭代自修正失效乃至自我恶化；错误结构在推理路径间跨步继承；外部反馈与成功自验证均无法消除该效应；现有缓解策略仅带来部分恢复，无法回归基线性能。

Conclusion: 上下文拖拽是当前推理架构中一种普遍、顽固且尚未被充分认识的关键失败模式，对构建可靠自改进系统构成根本性挑战。

Abstract: Central to many self-improvement pipelines for large language models (LLMs) is the assumption that models can improve by reflecting on past mistakes. We study a phenomenon termed contextual drag: the presence of failed attempts in the context biases subsequent generations toward structurally similar errors. Across evaluations of 11 proprietary and open-weight models on 8 reasoning tasks, contextual drag induces 10-20% performance drops, and iterative self-refinement in models with severe contextual drag can collapse into self-deterioration. Structural analysis using tree edit distance reveals that subsequent reasoning trajectories inherit structurally similar error patterns from the context. We demonstrate that neither external feedback nor successful self-verification suffices to eliminate this effect. While mitigation strategies such as fallback-behavior fine-tuning and context denoising yield partial improvements, they fail to fully restore baseline performance, positioning contextual drag as a persistent failure mode in current reasoning architectures.

</details>


### [110] [Proxy Compression for Language Modeling](https://arxiv.org/abs/2602.04289)
*Lin Zheng,Xinyu Li,Qian Liu,Xiachong Feng,Lingpeng Kong*

Main category: cs.CL

TL;DR: 本文提出了一种名为'proxy compression'的新训练范式，使语言模型能在保持训练效率的同时，直接处理原始字节序列，摆脱对固定分词器的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型严重依赖固定分词器（如UTF-8字节压缩器），导致模型与分词器强耦合，限制了灵活性和鲁棒性。

Method: 在训练阶段联合使用原始字节序列和外部压缩器生成的压缩视图，使模型学习二者之间的内部对齐；推理时仅使用原始字节输入。

Result: 在代码语言建模任务中，proxy compression显著提升训练效率，在相同计算预算下明显优于纯字节级基线，并随模型规模增大而增益更显著，最终可媲美甚至超越基于分词器的方法。

Conclusion: proxy compression实现了端到端原始字节建模与高效训练的统一，在不牺牲性能的前提下增强了模型鲁棒性和部署灵活性。

Abstract: Modern language models are trained almost exclusively on token sequences produced by a fixed tokenizer, an external lossless compressor often over UTF-8 byte sequences, thereby coupling the model to that compressor. This work introduces proxy compression, an alternative training scheme that preserves the efficiency benefits of compressed inputs while providing an end-to-end, raw-byte interface at inference time. During training, one language model is jointly trained on raw byte sequences and compressed views generated by external compressors; through the process, the model learns to internally align compressed sequences and raw bytes. This alignment enables strong transfer between the two formats, even when training predominantly on compressed inputs which are discarded at inference. Extensive experiments on code language modeling demonstrate that proxy compression substantially improves training efficiency and significantly outperforms pure byte-level baselines given fixed compute budgets. As model scale increases, these gains become more pronounced, and proxy-trained models eventually match or rival tokenizer approaches, all while operating solely on raw bytes and retaining the inherent robustness of byte-level modeling.

</details>


### [111] [Guided Verifier: Collaborative Multimodal Reasoning via Dynamic Process Supervision](https://arxiv.org/abs/2602.04290)
*Lingzhuang Sun,Ruitong Liu,Yuxia Zhu,Xiaohan Xu,Jingxuan Wei,Xiangxiang Zhang,Bihui Yu,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出一种名为'Guided Verifier'的框架，通过引入实时交互式动态验证器与策略模型协同推理，缓解多模态大语言模型（MLLMs）在强化学习中因错误传播导致的优化信号噪声问题，并基于新构建的CoRe数据集进行训练，在多个数学与多模态理解基准上显著提升小参数模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习提升多模态大语言模型（MLLMs）推理能力的方法依赖单一轮 rollout，缺乏中间监督，易因早期逻辑偏差引发错误传播，导致优化信号噪声大。

Method: 提出'Guided Verifier'框架：设计一个能与策略模型实时交互、检测推理不一致并提供方向性引导的动态验证器；构建面向多模态幻觉的合成数据管道，生成包含过程级负样本与正确引导推理轨迹的CoRe数据集用于训练验证器。

Result: 在MathVista、MathVerse和MMMU等多模态推理基准上，仅8B参数的模型借助协作推理与动态验证即取得强性能，验证了方法有效性与计算效率。

Conclusion: 引入主动、过程级的协同验证机制可显著改善MLLMs在强化学习中的推理鲁棒性与训练稳定性，为高效、可信的多模态推理提供了新范式。

Abstract: Reinforcement Learning (RL) has emerged as a pivotal mechanism for enhancing the complex reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevailing paradigms typically rely on solitary rollout strategies where the model works alone. This lack of intermediate oversight renders the reasoning process susceptible to error propagation, where early logical deviations cascade into irreversible failures, resulting in noisy optimization signals. In this paper, we propose the \textbf{Guided Verifier} framework to address these structural limitations. Moving beyond passive terminal rewards, we introduce a dynamic verifier that actively co-solves tasks alongside the policy. During the rollout phase, this verifier interacts with the policy model in real-time, detecting inconsistencies and providing directional signals to steer the model toward valid trajectories. To facilitate this, we develop a specialized data synthesis pipeline targeting multimodal hallucinations, constructing \textbf{CoRe} dataset of process-level negatives and \textbf{Co}rrect-guide \textbf{Re}asoning trajectories to train the guided verifier. Extensive experiments on MathVista, MathVerse and MMMU indicate that by allocating compute to collaborative inference and dynamic verification, an 8B-parameter model can achieve strong performance.

</details>


### [112] [How Few-shot Demonstrations Affect Prompt-based Defenses Against LLM Jailbreak Attacks](https://arxiv.org/abs/2602.04294)
*Yanshu Wang,Shuaishuai Yang,Jingjing He,Tong Yang*

Main category: cs.CL

TL;DR: 本文系统评估了少样本示例（few-shot demonstrations）对两种基于角色（RoP）和基于任务（ToP）的提示防御策略在对抗 jailbreak 攻击中的不同影响：few-shot 提升 RoP 安全性但损害 ToP 效果，并据此提出实际部署建议。


<details>
  <summary>Details</summary>
Motivation: 尽管基于提示的防御方法（如 RoP 和 ToP）在提升 LLM 安全性方面有效，但少样本示例在其中的作用尚不明确；已有研究指出其可能削弱安全性，却未探究其与不同系统提示策略的交互机制。

Method: 在四个主流安全基准（AdvBench、HarmBench、SG-Bench、XSTest）上，针对多种主流大语言模型，采用六种 jailbreak 攻击方法，系统评估 few-shot 对 RoP 和 ToP 防御效果的影响，并分析其作用机制（如强化角色身份 vs 分散任务注意力）。

Result: few-shot 显著增强 RoP 的安全性（最高提升 4.5%），但严重削弱 ToP 的有效性（最高下降 21.2%）；该差异源于 few-shot 在 RoP 中强化角色认同，而在 ToP 中干扰任务指令聚焦。

Conclusion: few-shot 的影响高度依赖于系统提示的设计范式；RoP 更适合引入 few-shot，而 ToP 应谨慎使用；研究为实际部署 prompt-based 防御提供了关键指导原则。

Abstract: Large Language Models (LLMs) face increasing threats from jailbreak attacks that bypass safety alignment. While prompt-based defenses such as Role-Oriented Prompts (RoP) and Task-Oriented Prompts (ToP) have shown effectiveness, the role of few-shot demonstrations in these defense strategies remains unclear. Prior work suggests that few-shot examples may compromise safety, but lacks investigation into how few-shot interacts with different system prompt strategies. In this paper, we conduct a comprehensive evaluation on multiple mainstream LLMs across four safety benchmarks (AdvBench, HarmBench, SG-Bench, XSTest) using six jailbreak attack methods. Our key finding reveals that few-shot demonstrations produce opposite effects on RoP and ToP: few-shot enhances RoP's safety rate by up to 4.5% through reinforcing role identity, while it degrades ToP's effectiveness by up to 21.2% through distracting attention from task instructions. Based on these findings, we provide practical recommendations for deploying prompt-based defenses in real-world LLM applications.

</details>


### [113] [Merged ChemProt-DrugProt for Relation Extraction from Biomedical Literature](https://arxiv.org/abs/2405.18605)
*Mai H. Nguyen,Shibani Likhite,Jiawei Tang,Darshini Mahendran,Bridget T. McInnes*

Main category: cs.CL

TL;DR: 本文通过合并ChemProt和DrugProt数据集构建新数据集，并结合BioBERT与图卷积网络（GCN）提升化学-基因关系抽取性能，实验表明融合全局与局部上下文可提高部分CPR类别的精确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 化学-基因关系抽取对药物发现、疾病理解等至关重要，但现有模型在捕捉全局交互信息方面存在不足，需增强对长程依赖和结构化关系的建模能力。

Method: 合并ChemProt与DrugProt数据集以扩充样本；采用BioBERT建模局部语义，结合GCN建模实体间全局图结构关系，实现局部与全局上下文融合的关系抽取。

Result: 合并数据集显著提升了模型性能，尤其在两个数据集共有的CPR类别上；GCN与BioBERT联合方法相比单独使用BioBERT，在部分CPR类别上提高了精确率和召回率。

Conclusion: 融合多源标注数据与结合局部/全局建模的方法能有效提升化学-基因关系抽取效果，验证了结构化先验知识（如GCN）对生物医学关系抽取的重要性。

Abstract: The extraction of chemical-gene relations plays a pivotal role in understanding the intricate interactions between chemical compounds and genes, with significant implications for drug discovery, disease understanding, and biomedical research. This paper presents a data set created by merging the ChemProt and DrugProt datasets to augment sample counts and improve model accuracy. We evaluate the merged dataset using two state of the art relationship extraction algorithms: Bidirectional Encoder Representations from Transformers (BERT) specifically BioBERT, and Graph Convolutional Networks (GCNs) combined with BioBERT. While BioBERT excels at capturing local contexts, it may benefit from incorporating global information essential for understanding chemical-gene interactions. This can be achieved by integrating GCNs with BioBERT to harness both global and local context. Our results show that by integrating the ChemProt and DrugProt datasets, we demonstrated significant improvements in model performance, particularly in CPR groups shared between the datasets. Incorporating the global context using GCN can help increase the overall precision and recall in some of the CPR groups over using just BioBERT.

</details>


### [114] [Revisiting Prompt Sensitivity in Large Language Models for Text Classification: The Role of Prompt Underspecification](https://arxiv.org/abs/2602.04297)
*Branislav Pecher,Michal Spiegel,Robert Belanec,Jan Cegin*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLMs）在零样本和少样本分类任务中对提示（prompt）变化的敏感性，指出这种敏感性很大程度上源于提示的“未充分指定”（underspecification），即提示缺乏明确的任务指令和输出约束；通过性能分析、logit分析和线性探测，作者发现未充分指定的提示导致更高性能方差和更低相关token的logit值，但其对模型内部表征影响微弱，主要影响出现在最终层；研究强调需更严谨地分析和缓解提示敏感性。


<details>
  <summary>Details</summary>
Motivation: 大量研究表明大语言模型对提示变化高度敏感，但这些研究多基于指令模糊、约束薄弱的“未充分指定提示”，作者旨在厘清这种敏感性是否主要源于提示设计本身的不严谨。

Method: 系统对比未充分指定提示与指令明确提示的表现差异，采用性能分析（accuracy variance）、logit分析（目标token输出强度）和线性探测（probe internal representations across layers）三种方法。

Result: 未充分指定提示导致更高性能波动和更低相关token logit值；线性探测显示其对中间层表征影响甚微，效应主要集中于最后几层；指令明确提示显著缓解上述问题。

Conclusion: 提示敏感性在很大程度上由提示未充分指定引起，而非模型固有缺陷；未来研究与应用需更严谨设计提示，并在评估时控制提示规格变量。

Abstract: Large language models (LLMs) are widely used as zero-shot and few-shot classifiers, where task behaviour is largely controlled through prompting. A growing number of works have observed that LLMs are sensitive to prompt variations, with small changes leading to large changes in performance. However, in many cases, the investigation of sensitivity is performed using underspecified prompts that provide minimal task instructions and weakly constrain the model's output space. In this work, we argue that a significant portion of the observed prompt sensitivity can be attributed to prompt underspecification. We systematically study and compare the sensitivity of underspecified prompts and prompts that provide specific instructions. Utilising performance analysis, logit analysis, and linear probing, we find that underspecified prompts exhibit higher performance variance and lower logit values for relevant tokens, while instruction-prompts suffer less from such problems. However, linear probing analysis suggests that the effects of prompt underspecification have only a marginal impact on the internal LLM representations, instead emerging in the final layers. Overall, our findings highlight the need for more rigour when investigating and mitigating prompt sensitivity.

</details>


### [115] [DeFrame: Debiasing Large Language Models Against Framing Effects](https://arxiv.org/abs/2602.04306)
*Kahee Lim,Soyeon Kim,Steven Euijong Whang*

Main category: cs.CL

TL;DR: 本文提出'框架差异'概念，揭示了语义等价但表达方式不同的提示（如'A优于B' vs. 'B劣于A'）会显著影响大语言模型的公平性评估结果；现有去偏方法虽提升平均公平性，却未能缓解框架引发的差异；为此作者设计了一种框架感知的去偏方法，提升模型在不同框架下的响应一致性与公平性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在标准公平性评估中表现良好，但在实际应用中仍存在隐藏偏差，即模型在不同但语义等价的提示表达（即' framing '）下可能表现出不一致甚至有偏的响应，这一问题尚未被充分研究。

Method: 首先定义并量化'框架差异'，通过在公平性基准中引入多种语义等价但表达不同的提示变体进行评估；继而分析现有去偏方法在帧间一致性上的不足；最后提出一种框架感知的去偏方法，鼓励模型对不同框架产生一致且公平的响应。

Result: 实验表明：（1）公平性评分随提示框架变化显著；（2）现有去偏方法改善平均公平性，但加剧或未缓解框架差异；（3）所提框架感知方法能同时降低整体偏差并提升对框架变化的鲁棒性。

Conclusion: 提示框架是影响大语言模型公平性评估与实际表现的关键因素；仅优化平均公平性不够，需关注模型在语义等价提示下的响应一致性；框架感知去偏是提升真实场景中LLM公平性的重要方向。

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, ensuring their fair responses across demographics has become crucial. Despite many efforts, an ongoing challenge is hidden bias: LLMs appear fair under standard evaluations, but can produce biased responses outside those evaluation settings. In this paper, we identify framing -- differences in how semantically equivalent prompts are expressed (e.g., "A is better than B" vs. "B is worse than A") -- as an underexplored contributor to this gap. We first introduce the concept of "framing disparity" to quantify the impact of framing on fairness evaluation. By augmenting fairness evaluation benchmarks with alternative framings, we find that (1) fairness scores vary significantly with framing and (2) existing debiasing methods improve overall (i.e., frame-averaged) fairness, but often fail to reduce framing-induced disparities. To address this, we propose a framing-aware debiasing method that encourages LLMs to be more consistent across framings. Experiments demonstrate that our approach reduces overall bias and improves robustness against framing disparities, enabling LLMs to produce fairer and more consistent responses.

</details>


### [116] [A Domain-Specific Curated Benchmark for Entity and Document-Level Relation Extraction](https://arxiv.org/abs/2602.04320)
*Marco Martinelli,Stefano Marchesin,Vanessa Bonato,Giorgio Maria Di Nunzio,Nicola Ferro,Ornella Irrera,Laura Menotti,Federica Vezzani,Gianmaria Silvello*

Main category: cs.CL

TL;DR: 本文介绍了GutBrainIE，一个基于1600多篇PubMed摘要、由生物医学和术语学专家手工标注的新型生物医学信息抽取（IE）基准数据集，涵盖命名实体识别、命名实体链接和关系抽取任务，旨在解决现有基准范围狭窄、标注质量低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学信息抽取基准数据集范围狭窄、依赖远监督或自动标注，难以支撑鲁棒IE方法的发展，尤其在快速演进的领域（如肠-脑轴）中亟需高质量、细粒度、多任务的手工标注基准。

Method: 构建GutBrainIE基准：收集1600+篇PubMed摘要，由领域专家进行细粒度实体、概念级实体链接及关系的手工标注；设计涵盖NER、NEL、RE的多任务评估框架；融合高精度人工标注与弱监督数据以增强泛化性。

Result: 发布首个聚焦肠-脑轴、完全手工标注、支持多任务（NER/NEL/RE）的高质量生物医学IE基准GutBrainIE，具备丰富schema和跨领域适用潜力。

Conclusion: GutBrainIE填补了高质量、多任务、领域驱动的生物医学IE基准空白，为开发和评估更鲁棒、可泛化的IE系统提供了坚实基础。

Abstract: Information Extraction (IE), encompassing Named Entity Recognition (NER), Named Entity Linking (NEL), and Relation Extraction (RE), is critical for transforming the rapidly growing volume of scientific publications into structured, actionable knowledge. This need is especially evident in fast-evolving biomedical fields such as the gut-brain axis, where research investigates complex interactions between the gut microbiota and brain-related disorders. Existing biomedical IE benchmarks, however, are often narrow in scope and rely heavily on distantly supervised or automatically generated annotations, limiting their utility for advancing robust IE methods. We introduce GutBrainIE, a benchmark based on more than 1,600 PubMed abstracts, manually annotated by biomedical and terminological experts with fine-grained entities, concept-level links, and relations. While grounded in the gut-brain axis, the benchmark's rich schema, multiple tasks, and combination of highly curated and weakly supervised data make it broadly applicable to the development and evaluation of biomedical IE systems across domains.

</details>


### [117] [Can Vision Replace Text in Working Memory? Evidence from Spatial n-Back in Vision-Language Models](https://arxiv.org/abs/2602.04355)
*Sichu Liang,Hongyu Zhu,Wenwen Wang,Deyu Zhou*

Main category: cs.CL

TL;DR: 本文探究了视觉-语言模型在空间n-back任务中工作记忆能力的表现，发现文本模态下的表现显著优于视觉模态，并揭示其背后并非严格遵循指令滞后，而是受最近重复结构影响的近因比较过程。


<details>
  <summary>Details</summary>
Motivation: 探究n-back任务在视觉与文本模态下是否引发可比的工作记忆计算，尤其在视觉-语言模型中是否存在模态依赖性的工作记忆机制。

Method: 在控制条件下，对Qwen2.5（纯文本）和Qwen2.5-VL（多模态）模型施加匹配的文本渲染/图像渲染空间n-back任务；采用试次级对数概率证据分析实际加工滞后；考察网格尺寸对刺激流中近期重复结构及干扰模式的影响。

Result: 模型在文本条件下的准确率和d'显著高于视觉条件；名义上的2/3-back行为常不反映真实滞后，而表现为近因锁定的比较；网格尺寸变化会改变近期重复结构，进而影响干扰类型与错误模式。

Conclusion: n-back任务在多模态模型中的表现不能简单等同于人类工作记忆，需基于计算过程敏感地解释其‘工作记忆样’行为，强调模态编码与刺激结构对内部比较机制的关键影响。

Abstract: Working memory is a central component of intelligent behavior, providing a dynamic workspace for maintaining and updating task-relevant information. Recent work has used n-back tasks to probe working-memory-like behavior in large language models, but it is unclear whether the same probe elicits comparable computations when information is carried in a visual rather than textual code in vision-language models. We evaluate Qwen2.5 and Qwen2.5-VL on a controlled spatial n-back task presented as matched text-rendered or image-rendered grids. Across conditions, models show reliably higher accuracy and d' with text than with vision. To interpret these differences at the process level, we use trial-wise log-probability evidence and find that nominal 2/3-back often fails to reflect the instructed lag and instead aligns with a recency-locked comparison. We further show that grid size alters recent-repeat structure in the stimulus stream, thereby changing interference and error patterns. These results motivate computation-sensitive interpretations of multimodal working memory.

</details>


### [118] [Beyond Rejection Sampling: Trajectory Fusion for Scaling Mathematical Reasoning](https://arxiv.org/abs/2602.04391)
*Jie Deng,Hanshuang Tong,Jun Li,Shining Liang,Ning Wu,Hongzhi Li,Yutao Xie*

Main category: cs.CL

TL;DR: 本文提出TrajFusion方法，通过融合错误推理轨迹、反思提示与正确轨迹，改进大语言模型的数学推理微调范式，无需修改模型结构或目标函数，在多个数学基准上显著优于传统拒绝采样微调。


<details>
  <summary>Details</summary>
Motivation: 传统拒绝采样仅保留正确推理轨迹，忽略教师生成的错误轨迹，导致对推理失败建模不足。

Method: TrajFusion将拒绝采样重构为结构化监督构建过程：交错拼接精选的错误轨迹、反思提示和正确轨迹，形成融合推理路径；其长度根据教师错误的频率与多样性自适应控制。

Result: 在多个数学基准上，TrajFusion持续优于传统拒绝采样微调（RFT），尤其在高难度和长推理任务上提升显著。

Conclusion: TrajFusion通过显式建模试错推理，提供更丰富的监督信号，在不增加模型复杂度的前提下有效提升LLM数学推理能力。

Abstract: Large language models (LLMs) have made impressive strides in mathematical reasoning, often fine-tuned using rejection sampling that retains only correct reasoning trajectories. While effective, this paradigm treats supervision as a binary filter that systematically excludes teacher-generated errors, leaving a gap in how reasoning failures are modeled during training. In this paper, we propose TrajFusion, a fine-tuning strategy that reframes rejection sampling as a structured supervision construction process. Specifically, TrajFusion forms fused trajectories that explicitly model trial-and-error reasoning by interleaving selected incorrect trajectories with reflection prompts and correct trajectories. The length of each fused sample is adaptively controlled based on the frequency and diversity of teacher errors, providing richer supervision for challenging problems while safely reducing to vanilla rejection sampling fine-tuning (RFT) when error signals are uninformative. TrajFusion requires no changes to the architecture or training objective. Extensive experiments across multiple math benchmarks demonstrate that TrajFusion consistently outperforms RFT, particularly on challenging and long-form reasoning problems.

</details>


### [119] [Evaluating the Presence of Sex Bias in Clinical Reasoning by Large Language Models](https://arxiv.org/abs/2602.04392)
*Isabel Tsintsiper,Sheng Wong,Beth Albert,Shaun P Brennecke,Gabriel Davis Jones*

Main category: cs.CL

TL;DR: 本文研究了当前大型语言模型（LLMs）在临床推理中是否存在性别偏差，发现不同模型存在稳定且模型特异性的性别分配倾向（如ChatGPT显著偏向女性，Gemini偏向男性），且调整温度参数或允许模型 abstention 无法根本消除下游诊断差异，强调需审慎配置、专科级数据审计与持续人工监督。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型日益应用于医疗场景，但其训练数据可能固化并放大现实中的性别诊断与治疗差异，亟需系统评估其临床推理中的性别偏差。

Method: 基于50个由临床医生编写的、性别对初始诊断路径无信息价值的病例 vignettes，使用4个通用大模型（GPT-4o-mini、Claude 3.7 Sonnet、Gemini 2.0 Flash、DeepSeekChat），在温度=0.5下测试其对患者性别的预测倾向，并分析允许‘不回答’（abstention）对诊断影响。

Result: 所有模型均表现出显著且稳定的性别分配偏差：ChatGPT（70%女性）、DeepSeek（61%）、Claude（59%）偏向女性，Gemini（36%）偏向男性；允许abstention降低了显式性别标注率，但未消除后续诊断结果的性别差异。

Conclusion: 当代通用大模型在临床推理中存在固有、模型特异的性别偏差；安全临床部署需保守配置、专科层面数据审计及持续人工监督。

Abstract: Large language models (LLMs) are increasingly embedded in healthcare workflows for documentation, education, and clinical decision support. However, these systems are trained on large text corpora that encode existing biases, including sex disparities in diagnosis and treatment, raising concerns that such patterns may be reproduced or amplified. We systematically examined whether contemporary LLMs exhibit sex-specific biases in clinical reasoning and how model configuration influences these behaviours. We conducted three experiments using 50 clinician-authored vignettes spanning 44 specialties in which sex was non-informative to the initial diagnostic pathway. Four general-purpose LLMs (ChatGPT (gpt-4o-mini), Claude 3.7 Sonnet, Gemini 2.0 Flash and DeepSeekchat). All models demonstrated significant sex-assignment skew, with predicted sex differing by model. At temperature 0.5, ChatGPT assigned female sex in 70% of cases (95% CI 0.66-0.75), DeepSeek in 61% (0.57-0.65) and Claude in 59% (0.55-0.63), whereas Gemini showed a male skew, assigning a female sex in 36% of cases (0.32-0.41). Contemporary LLMs exhibit stable, model-specific sex biases in clinical reasoning. Permitting abstention reduces explicit labelling but does not eliminate downstream diagnostic differences. Safe clinical integration requires conservative and documented configuration, specialty-level clinical data auditing, and continued human oversight when deploying general-purpose models in healthcare settings.

</details>


### [120] [Bi-directional Bias Attribution: Debiasing Large Language Models without Modifying Prompts](https://arxiv.org/abs/2602.04398)
*Yujie Lin,Kunquan Li,Yixuan Liao,Xiaoxin Chen,Jinsong Su*

Main category: cs.CL

TL;DR: 本文提出了一种无需微调或提示工程的LLM去偏框架，通过检测刻板印象诱导词、归因神经元级偏差并干预投影层激活来减少社会偏见。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法（如额外数据集微调或提示工程）存在可扩展性差或多轮交互中损害用户体验的问题。

Method: 首先通过跨人口群体比较分析识别刻板印象诱导的形容词和名词；然后基于积分梯度的两种归因策略定位偏差相关神经元；最后在投影层直接干预其激活以缓解偏差。

Result: 在三个主流大语言模型上的实验表明，该方法能有效降低偏差，同时保持模型整体性能。

Conclusion: 所提框架提供了一种高效、无侵入式的LLM去偏新范式，兼顾效果与实用性。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks. However, their outputs often exhibit social biases, raising fairness concerns. Existing debiasing methods, such as fine-tuning on additional datasets or prompt engineering, face scalability issues or compromise user experience in multi-turn interactions. To address these challenges, we propose a framework for detecting stereotype-inducing words and attributing neuron-level bias in LLMs, without the need for fine-tuning or prompt modification. Our framework first identifies stereotype-inducing adjectives and nouns via comparative analysis across demographic groups. We then attribute biased behavior to specific neurons using two attribution strategies based on integrated gradients. Finally, we mitigate bias by directly intervening on their activations at the projection layer. Experiments on three widely used LLMs demonstrate that our method effectively reduces bias while preserving overall model performance. Code is available at the github link: https://github.com/XMUDeepLIT/Bi-directional-Bias-Attribution.

</details>


### [121] [Swordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models](https://arxiv.org/abs/2602.04399)
*Yu Zhang,Xinchen Li,Jialei Zhou,Hongnan Ma,Zhongwei Wan,Yiwei Shi,Duoqian Miao,Qi Zhang,Longbing Cao*

Main category: cs.CL

TL;DR: 本文提出Swordsman框架，通过熵驱动的自适应分块解码方法提升扩散语言模型（DLMs）的推理速度与质量，无需训练且兼容KV Cache，性能达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有块状解码方法采用固定分块策略，易割裂语义或句法成分，导致性能下降；受熵减假设启发，利用熵变化识别成分边界以提升解码效果。

Method: 提出熵驱动的自适应块状解码框架Swordsman：1）基于相邻词元间熵变识别成分边界以动态分块；2）根据块内实时unmasking状态动态调整unmasking阈值；3）为训练无关方法，支持KV Cache。

Result: 在多项评估中，Swordsman展现出SOTA性能，兼顾推理效率与稳定性。

Conclusion: 熵驱动的自适应分块策略能更自然地对齐语言结构，显著提升DLMs块状解码的效果与鲁棒性，验证了基于信息熵建模语言不确定性的重要性。

Abstract: Block-wise decoding effectively improves the inference speed and quality in diffusion language models (DLMs) by combining inter-block sequential denoising and intra-block parallel unmasking. However, existing block-wise decoding methods typically partition blocks in a rigid and fixed manner, which inevitably fragments complete semantic or syntactic constituents, leading to suboptimal performance. Inspired by the entropy reduction hypothesis (ERH), we recognize that constituent boundaries offer greater opportunities for uncertainty reduction, which motivates us to employ entropy analysis for identifying constituent boundaries. Therefore, we propose Swordsman, an entropy-driven adaptive block-wise decoding framework for DLMs. Swordsman adaptively partitions blocks by identifying entropy shifts between adjacent tokens to better align with semantic or syntactic constituent boundaries. In addition, Swordsman dynamically adjusts unmasking thresholds conditioned on the real-time unmasking status within a block, further improving both efficiency and stability. As a training-free framework, supported by KV Cache, Swordsman demonstrates state-of-the-art performance across extensive evaluations.

</details>


### [122] [History-Guided Iterative Visual Reasoning with Self-Correction](https://arxiv.org/abs/2602.04413)
*Xinglong Yang,Zhilin Peng,Zhanzhan Liu,Haochen Shi,Sheng-Jun Huang*

Main category: cs.CL

TL;DR: 本文提出H-GIVR框架，通过多轮视觉观察与历史答案参考实现动态错误修正，显著提升多模态大语言模型跨模态推理准确率，同时保持低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有自洽方法局限于固定“重复采样-投票”范式，无法复用历史推理信息，难以主动纠正视觉理解错误和动态调整推理过程。

Method: 提出H-GIVR框架，在迭代推理中让MLLM多次观察图像，并将先前生成的答案作为后续步骤的参考，从而实现动态错误修正。

Result: 在五个数据集和三个模型上实验表明，H-GIVR显著提升跨模态推理准确率；例如在ScienceQA上，Llama3.2-vision:11b平均仅需2.57次响应即达78.90%准确率，较基线提升107%。

Conclusion: H-GIVR通过引入人类式反复验证与动态纠错机制，有效克服了传统自洽方法的信息复用不足问题，是一种高效、准确的多模态推理增强框架。

Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However, most existing self-consistency methods are limited to a fixed ``repeated sampling and voting'' paradigm and do not reuse historical reasoning information. As a result, models struggle to actively correct visual understanding errors and dynamically adjust their reasoning during iteration. Inspired by the human reasoning behavior of repeated verification and dynamic error correction, we propose the H-GIVR framework. During iterative reasoning, the MLLM observes the image multiple times and uses previously generated answers as references for subsequent steps, enabling dynamic correction of errors and improving answer accuracy. We conduct comprehensive experiments on five datasets and three models. The results show that the H-GIVR framework can significantly improve cross-modal reasoning accuracy while maintaining low computational cost. For instance, using \texttt{Llama3.2-vision:11b} on the ScienceQA dataset, the model requires an average of 2.57 responses per question to achieve an accuracy of 78.90\%, representing a 107\% improvement over the baseline.

</details>


### [123] [Fine-Grained Activation Steering: Steering Less, Achieving More](https://arxiv.org/abs/2602.04428)
*Zijian Feng,Tianjiao Li,Zixiao Zhu,Hanzhang Zhou,Junlang Qian,Li Zhang,Jia Jim Deryl Chua,Lee Onn Mak,Gee Wah Ng,Kezhi Mao*

Main category: cs.CL

TL;DR: 本文提出AUSteer方法，在原子单元（AU）级别进行激活引导，以解决现有块级激活引导方法因激活异质性导致的粗粒度、低效和侵入性问题。通过理论与实证分析，作者发现不同AU控制不同输出token分布，因此精细选择有益AU并自适应调整引导强度，可显著提升引导效率与效果。


<details>
  <summary>Details</summary>
Motivation: 现有块级激活引导方法因块内激活高度异质（混杂有益、无关与有害特征），导致引导粗粒度、低效且侵入性强，亟需更细粒度、更精准的干预机制。

Method: 提出AUSteer：1）将块激活分解为原子单元（AU）级激活，每个AU对应权重矩阵的一个切片；2）基于对比样本计算激活动量，全局识别判别性AU；3）对选定AU按输入自适应分配引导强度。

Result: 在多个LLM和任务上，AUSteer持续超越先进基线，同时仅需干预更少的激活维度，验证了‘少即多’的有效性。

Conclusion: AU级细粒度引导能有效解耦有益与有害特征方向，显著提升行为编辑的精度、效率与鲁棒性；AUSteer为高效、低侵入式LLM行为调控提供了新范式。

Abstract: Activation steering has emerged as a cost-effective paradigm for modifying large language model (LLM) behaviors. Existing methods typically intervene at the block level, steering the bundled activations of selected attention heads, feedforward networks, or residual streams. However, we reveal that block-level activations are inherently heterogeneous, entangling beneficial, irrelevant, and harmful features, thereby rendering block-level steering coarse, inefficient, and intrusive. To investigate the root cause, we decompose block activations into fine-grained atomic unit (AU)-level activations, where each AU-level activation corresponds to a single dimension of the block activation, and each AU denotes a slice of the block weight matrix. Steering an AU-level activation is thus equivalent to steering its associated AU. Our theoretical and empirical analysis show that heterogeneity arises because different AUs or dimensions control distinct token distributions in LLM outputs. Hence, block-level steering inevitably moves helpful and harmful token directions together, which reduces efficiency. Restricting intervention to beneficial AUs yields more precise and effective steering. Building on this insight, we propose AUSteer, a simple and efficient method that operates at a finer granularity of the AU level. AUSteer first identifies discriminative AUs globally by computing activation momenta on contrastive samples. It then assigns adaptive steering strengths tailored to diverse inputs and selected AU activations. Comprehensive experiments on multiple LLMs and tasks show that AUSteer consistently surpasses advanced baselines while steering considerably fewer activations, demonstrating that steering less achieves more.

</details>


### [124] [No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data](https://arxiv.org/abs/2602.04442)
*Dmitry Karpov*

Main category: cs.CL

TL;DR: 本文研究了五种突厥语系语言对的机器翻译，使用NLLB-200和DeepSeek-V3.2模型，结合LoRA微调与检索增强提示等方法，在多个语言对上取得了良好性能，并开源了数据集与模型权重。


<details>
  <summary>Details</summary>
Motivation: 针对突厥语系中小语种机器翻译资源匮乏的问题，探索适用于低资源突厥语对（如 Bashkir、Kazakh、Kyrgyz、Tatar、Chuvash）的有效翻译方法。

Method: 采用NLLB-200-distilled-600M模型在合成数据上进行LoRA微调；对Chuvash使用DeepSeek-V3.2配合检索增强提示（retrieval-augmented prompting）；对Tatar和Kyrgyz分别尝试零样本与检索式方法。

Result: 在Kazakh-Ru上chrF++达49.71，Bashkir-Ru达46.94，Chuvash-En达39.47，Tatar-En达41.6，Kyrgyz-En达45.6；并公开了数据集与训练权重。

Conclusion: LoRA微调在中等低资源突厥语上效果显著；检索增强提示对极低资源语种（如Chuvash）具可行性；零样本方法在部分语言对（如Kyrgyz）上亦表现不俗；开源资源有助于后续研究。

Abstract: We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200-distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retrieved similar examples achieved chrF++ 39.47 for Chuvash. For Tatar, zero-shot or retrieval-based approaches achieved chrF++ 41.6, while for Kyrgyz the zero-shot approach reached 45.6. We release the dataset and the obtained weights.

</details>


### [125] [Is Micro Domain-Adaptive Pre-Training Effective for Real-World Operations? Multi-Step Evaluation Reveals Potential and Bottlenecks](https://arxiv.org/abs/2602.04466)
*Masaya Tsunokake,Yuta Koreeda,Terufumi Morishita,Koichi Nagatsuka,Hikaru Tomonari,Yasuhiro Sogawa*

Main category: cs.CL

TL;DR: 本文研究了微领域自适应预训练（mDAPT）在生成式任务中的效果，发现其能有效提升LLM从自身知识中提取事实（eliciting）的能力，但对推理（reasoning）和长文本生成（composing）帮助有限；实验基于IT技术支持场景，指出增强推理能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅验证mDAPT在选择题上的有效性，其在真实企业运营所需的生成式任务中的潜力与瓶颈尚不明确。

Method: 将生成式问答过程解耦为三个子任务——事实提取（eliciting）、基于事实的推理（reasoning）和长答案生成（composing），并在IT技术支持的私有产品知识上实证评估mDAPT对各子任务的影响。

Result: mDAPT显著改善了事实提取能力，但未能提升推理和长文本生成性能；进一步分析表明，若eliciting和reasoning均被解决，整体性能可达90%以上。

Conclusion: mDAPT主要增强LLM的领域知识激活能力，而非推理或语言生成能力；未来应重点提升模型的推理能力以突破当前瓶颈。

Abstract: When applying LLMs to real-world enterprise operations, LLMs need to handle proprietary knowledge in small domains of specific operations ($\textbf{micro domains}$). A previous study shows micro domain-adaptive pre-training ($\textbf{mDAPT}$) with fewer documents is effective, similarly to DAPT in larger domains. However, it evaluates mDAPT only on multiple-choice questions; thus, its effectiveness for generative tasks in real-world operations remains unknown. We aim to reveal the potential and bottlenecks of mDAPT for generative tasks. To this end, we disentangle the answering process into three subtasks and evaluate the performance of each subtask: (1) $\textbf{eliciting}$ facts relevant to questions from an LLM's own knowledge, (2) $\textbf{reasoning}$ over the facts to obtain conclusions, and (3) $\textbf{composing}$ long-form answers based on the conclusions. We verified mDAPT on proprietary IT product knowledge for real-world questions in IT technical support operations. As a result, mDAPT resolved the elicitation task that the base model struggled with but did not resolve other subtasks. This clarifies mDAPT's effectiveness in the knowledge aspect and its bottlenecks in other aspects. Further analysis empirically shows that resolving the elicitation and reasoning tasks ensures sufficient performance (over 90%), emphasizing the need to enhance reasoning capability.

</details>


### [126] [Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition](https://arxiv.org/abs/2602.04486)
*Jinlong Ma,Yu Zhang,Xuefeng Bai,Kehai Chen,Yuwei Wang,Zeming Liu,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出Modality-aware Consistency Reasoning (MCR) 方法，通过多风格推理模式注入（MRSI）和约束引导可验证优化（CVO），缓解多模态大语言模型（MLLMs）在端到端接地多模态命名实体识别（GMNER）中的模态偏差问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在GMNER任务中常作为辅助工具，难以端到端完成；且存在视觉偏差与文本偏差等模态偏差问题，导致模型依赖单模态捷径而非跨模态严格验证。

Method: 提出Modality-aware Consistency Reasoning（MCR），包含两部分：1）Multi-style Reasoning Schema Injection（MRSI），将抽象约束转化为可执行推理链；2）Constraint-guided Verifiable Optimization（CVO），利用Group Relative Policy Optimization（GRPO）动态对齐推理路径。

Result: 在GMNER和视觉定位任务上实验表明，MCR能有效缓解模态偏差，性能优于现有基线方法。

Conclusion: MLLMs具备端到端解决GMNER的潜力，但需克服模态偏差；MCR通过结构化跨模态推理机制，为多模态理解中的一致性建模提供了新思路。

Abstract: Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit $\textbf{modality bias}$, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning ($\textbf{MCR}$), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.

</details>


### [127] [Deconstructing sentence disambiguation by joint latent modeling of reading paradigms: LLM surprisal is not enough](https://arxiv.org/abs/2602.04489)
*Dario Paape,Tal Linzen,Shravan Vasishth*

Main category: cs.CL

TL;DR: 本文提出了一种潜过程混合模型，用于建模人类在四种阅读范式下对花园路径句的阅读行为，区分了歧义概率、歧义代价和再分析代价，并通过考虑不专注阅读试次提高了处理成本估计的真实性。


<details>
  <summary>Details</summary>
Motivation: 传统语言处理模型难以准确捕捉人类在面对暂时歧义句子（如花园路径句）时的动态认知过程，尤其在不同阅读范式下的行为差异及不专注阅读的影响。

Method: 构建一个潜过程混合模型，整合眼动追踪、单/双向自定步速阅读和迷宫任务四种范式的数据；模型区分花园路径概率、花园路径代价与再分析代价，并引入不专注阅读的试次建模；以GPT-2的surprisal为基线进行对比，采用交叉验证评估预测性能。

Result: 该模型能成功复现重读行为、理解性问题作答和语法判断等实证模式；交叉验证显示其对人类阅读模式和试验末任务数据的预测拟合优于无混合的GPT-2 surprisal模型。

Conclusion: 潜过程混合模型更真实地刻画了人类语言理解中的认知异质性，为未来整合多范式数据与建模注意力波动提供了新框架。

Abstract: Using temporarily ambiguous garden-path sentences ("While the team trained the striker wondered ...") as a test case, we present a latent-process mixture model of human reading behavior across four different reading paradigms (eye tracking, uni- and bidirectional self-paced reading, Maze). The model distinguishes between garden-path probability, garden-path cost, and reanalysis cost, and yields more realistic processing cost estimates by taking into account trials with inattentive reading. We show that the model is able to reproduce empirical patterns with regard to rereading behavior, comprehension question responses, and grammaticality judgments. Cross-validation reveals that the mixture model also has better predictive fit to human reading patterns and end-of-trial task data than a mixture-free model based on GPT-2-derived surprisal values. We discuss implications for future work.

</details>


### [128] [PersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluation](https://arxiv.org/abs/2602.04493)
*Saleh Afzoon,MohammadHossein Ahmadi,Usman Naseem,Amin Beheshti*

Main category: cs.CL

TL;DR: 本文提出PersoDPO框架，利用自动评估信号（聚焦连贯性、个性化及指令遵循）构建偏好对，无需人工标注，提升开源对话模型在人格化对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有开源大语言模型在人格化对话中难以兼顾上下文连贯性与人格一致性，需更高效、可扩展的微调方法。

Method: 提出PersoDPO偏好优化框架，融合自动评估指标（连贯性、个性化、长度/格式合规性）生成高质量偏好对，用于微调对话模型。

Result: 在FoCus数据集上，采用PersoDPO微调的开源模型在多项指标上持续超越强基线及标准DPO变体。

Conclusion: PersoDPO是一种可扩展、可复现的自动化偏好优化方法，显著提升开源模型在人格化对话任务中的性能。

Abstract: Personalization and contextual coherence are two essential components in building effective persona-grounded dialogue systems. These aspects play a crucial role in enhancing user engagement and ensuring responses are more relevant and consistent with user identity. However, recent studies indicate that open-source large language models (LLMs) continue to struggle to generate responses that are both contextually grounded and aligned with persona cues, despite exhibiting strong general conversational abilities like fluency and naturalness. We present PersoDPO, a scalable preference optimisation framework that uses supervision signals from automatic evaluations of responses generated by both closed-source and open-source LLMs to fine-tune dialogue models. The framework integrates evaluation metrics targeting coherence and personalization, along with a length-format compliance feature to promote instruction adherence. These signals are combined to automatically construct high-quality preference pairs without manual annotation, enabling a scalable and reproducible training pipeline. Experiments on the FoCus dataset show that an open-source language model fine-tuned with the PersoDPO framework consistently outperforms strong open-source baselines and a standard Direct Preference Optimization (DPO) variant across multiple evaluation dimensions.

</details>


### [129] [Model-Dowser: Data-Free Importance Probing to Mitigate Catastrophic Forgetting in Multimodal Large Language Models](https://arxiv.org/abs/2602.04509)
*Hyeontaek Hwang,Nguyen Dinh Son,Daeyoung Kim*

Main category: cs.CL

TL;DR: 本文提出Model-Dowser，一种针对多模态大语言模型（MLLMs）的稀疏微调方法，通过综合权重大小、输入激活和输出敏感性来评估参数重要性，选择性地冻结高重要性参数以缓解灾难性遗忘，在保持资源高效的同时可扩展至数十亿参数模型。


<details>
  <summary>Details</summary>
Motivation: 现有缓解多模态大语言模型（MLLMs）微调中灾难性遗忘的方法在微调深层语言解码器时失效，或随模型增大而扩展性差。

Method: Model-Dowser是一种稀疏微调方法，通过联合考虑权重幅值、输入激活和输出敏感性，为每个参数计算面向预训练泛化能力的重要性得分，并在微调中仅更新低重要性参数。

Result: 在LLaVA和NVILA两个代表性MLLM上的实验表明，Model-Dowser能有效缓解灾难性遗忘，持续优于先前方法，且资源高效、可扩展至多十亿参数模型。

Conclusion: Model-Dowser为MLLMs提供了一种兼顾下游任务性能与预训练泛化能力的高效、可扩展稀疏微调范式。

Abstract: Fine-tuning Multimodal Large Language Models (MLLMs) on task-specific data is an effective way to improve performance on downstream applications. However, such adaptation often leads to a degradation in generalization on pretrained tasks, a phenomenon known as Catastrophic Forgetting. Existing methods that aim to mitigate this issue either become ineffective when fine-tuning deeper layers of the language decoder or scale poorly with increasing model size. To address these limitations, we propose Model-Dowser, a novel sparse fine-tuning approach for MLLMs. Model-Dowser measures a principled importance score for each model parameter with respect to pretrained generalization (prior to downstream adaptation) by jointly considering weight magnitudes, input activations, and output sensitivities. During fine-tuning, Model-Dowser selectively preserves high-importance parameters and updates the remaining. Comprehensive experiments on two representative MLLMs, LLaVA and NVILA, demonstrate that Model-Dowser effectively mitigates catastrophic forgetting and consistently outperforms prior methods, while remaining resource-efficient and scalable to multi-billion-parameter models.

</details>


### [130] [ReFRAME or Remain: Unsupervised Lexical Semantic Change Detection with Frame Semantics](https://arxiv.org/abs/2602.04514)
*Bach Phan-Tat,Kris Heylen,Dirk Geeraerts,Stefano De Pascale,Dirk Speelman*

Main category: cs.CL

TL;DR: 本文提出了一种基于框架语义学的词汇语义变化（LSC）检测新方法，不依赖神经嵌入分布表示，具有高可解释性且性能优于许多现有分布语义模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经嵌入的LSC检测方法虽性能好，但结果难以解释，亟需更透明、可理解的替代方案。

Method: 完全基于框架语义学构建LSC检测方法，不使用任何神经嵌入或分布表示。

Result: 该方法在LSC任务上效果显著，甚至超越多种主流分布语义模型，并通过定量与定性分析验证了其预测的合理性与高可解释性。

Conclusion: 框架语义学为LSC检测提供了一种有效、可解释的替代路径，挑战了当前以分布表示为主流的范式。

Abstract: The majority of contemporary computational methods for lexical semantic change (LSC) detection are based on neural embedding distributional representations. Although these models perform well on LSC benchmarks, their results are often difficult to interpret. We explore an alternative approach that relies solely on frame semantics. We show that this method is effective for detecting semantic change and can even outperform many distributional semantic models. Finally, we present a detailed quantitative and qualitative analysis of its predictions, demonstrating that they are both plausible and highly interpretable

</details>


### [131] [$C$-$ΔΘ$: Circuit-Restricted Weight Arithmetic for Selective Refusal](https://arxiv.org/abs/2602.04521)
*Aditya Kasliwal,Pratinav Seth,Vinay Kumar Sankarapu*

Main category: cs.CL

TL;DR: 本文提出C-Δθ方法，通过机制性理解将选择性拒绝策略离线蒸馏为电路受限的权重更新，实现无需推理时干预的模型编辑。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全策略多依赖推理时干预，带来持续计算开销与部署复杂性；激活引导等方法虽常用，但仍需运行时钩子且成本随生成次数增加。本文探索能否将选择性拒绝完全离线化。

Method: 提出C-Δθ（Circuit Restricted Weight Arithmetic）：(i) 利用EAP-IG定位类别特异性拒绝行为的稀疏计算电路；(ii) 仅在该电路上计算约束权重更新ΔθC（通常覆盖<5%参数），生成可直接部署的编辑后检查点。

Result: C-Δθ实现了类别定向的选择性拒绝，在拒绝与效用基准测试中保持高选择性与能力保留，且完全消除推理时钩子，将成本转为一次性离线更新。

Conclusion: 选择性拒绝可被机制性建模并离线嵌入模型权重，C-Δθ为高效、轻量、可部署的安全对齐提供新范式。

Abstract: Modern deployments require LLMs to enforce safety policies at scale, yet many controls rely on inference-time interventions that add recurring compute cost and serving complexity. Activation steering is widely used, but it requires runtime hooks and scales cost with the number of generations; conditional variants improve selectivity by gating when steering is applied but still retain an inference-time control path. We ask whether selective refusal can be moved entirely offline: can a mechanistic understanding of category-specific refusal be distilled into a circuit-restricted weight update that deploys as a standard checkpoint? We propose C-Δθ: Circuit Restricted Weight Arithmetic, which (i) localizes refusal-causal computation as a sparse circuit using EAP-IG and (ii) computes a constrained weight update ΔθC supported only on that circuit (typically <5% of parameters). Applying ΔθC yields a drop-in edited checkpoint with no inference-time hooks, shifting cost from per-request intervention to a one-time offline update. We evaluate category-targeted selectivity and capability retention on refusal and utility benchmarks.

</details>


### [132] [LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding](https://arxiv.org/abs/2602.04541)
*Gang Lin,Dongfang Li,Zhuoen Chen,Yukun Shi,Xuhui Chen,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: LycheeDecode是一种面向长上下文大语言模型的高效解码方法，通过细粒度混合头注意力机制（区分检索头与稀疏头）和硬件友好的top-k选择策略，在保持甚至提升生成质量的同时，实现最高2.7倍的解码加速。


<details>
  <summary>Details</summary>
Motivation: 长上下文大语言模型推理中，键值缓存随解码迅速膨胀，带来高内存与延迟开销；现有跨层共享关键token的方法因粗粒度共享而忽视注意力头的功能多样性，损害性能。

Method: 提出LycheeDecode，核心是基于HardKuma的细粒度混合头注意力机制：将注意力头划分为少量动态检索关键token的‘检索头’和大量复用这些token进行稀疏计算的‘稀疏头’，并采用硬件友好的top-k选择策略。

Result: 在Llama3、Qwen3等主流模型及LongBench、RULER、AIME24、OlympiadBench等基准上验证，LycheeDecode在128K上下文长度下达到与全注意力基线相当甚至更优的生成质量，并实现最高2.7倍的推理加速。

Conclusion: 细粒度利用注意力头功能多样性可有效突破现有长上下文推理效率与质量的权衡瓶颈，LycheeDecode为高效高质量长上下文LLM推理提供了经实证的有效路径。

Abstract: The proliferation of long-context large language models (LLMs) exposes a key bottleneck: the rapidly expanding key-value cache during decoding, which imposes heavy memory and latency costs. While recent approaches attempt to alleviate this by sharing a single set of crucial tokens across layers, such coarse-grained sharing undermines model performance by neglecting the functional diversity of attention heads. To address this, we propose LycheeDecode, an efficient decoding method centered on a fine-grained hybrid-head attention mechanism that employs a hardware-efficient top-k selection strategy. Specifically, the novel HardKuma-based mechanism partitions attention heads into a small subset of retrieval heads that dynamically identify crucial tokens and a majority of sparse heads that reuse them for efficient computation. Through extensive experiments on leading models like Llama3 and Qwen3 across diverse benchmarks for long-context understanding (e.g., LongBench, RULER) and complex reasoning (e.g., AIME24, OlympiadBench), we demonstrate that LycheeDecode achieves generative quality comparable to, and at times surpassing even the full-attention baseline. Crucially, this is accomplished with up to a 2.7x speedup at a 128K context length. By preserving the functional diversity of attention heads, our fine-grained strategy overcomes the performance bottlenecks of existing methods, providing a powerful and validated pathway to both efficient and high-quality long-context LLM inference.

</details>


### [133] [Rethinking Weight Tying: Pseudo-Inverse Tying for Stable LM Training and Updates](https://arxiv.org/abs/2602.04556)
*Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang*

Main category: cs.CL

TL;DR: 本文提出伪逆绑定（PIT）方法，通过共享正交隐式词元记忆和可学习的隐空间变换，保证嵌入与解嵌入接口在整个训练过程中保持伪逆一致性，从而提升训练稳定性、语义一致性和后训练干预的可预测性。


<details>
  <summary>Details</summary>
Motivation: 权重绑定虽能减少参数量，但无法保证词元编码与解码接口在训练中稳定，导致优化敏感、后训练干预（如编辑、修补、轻量适配）不可预测。

Method: 提出伪逆绑定（PIT）：构建正交共享隐式词元记忆（通过薄极分解或随机正交初始化获得），并引入由Cholesky因子参数化的对称正定隐空间变换；输出头在词汇投影前应用该变换，嵌入层则用稳定三角求解应用其逆变换，避免显式伪逆计算和额外词汇量级参数。

Result: 在256M–1.3B参数的端侧模型上验证，PIT显著提升了训练稳定性、层间语义一致性，并大幅减少了后训练干预的副作用。

Conclusion: PIT通过结构化约束实现了嵌入与解嵌入的稳定耦合，在不增加词汇量级参数的前提下，有效增强了模型训练鲁棒性与后训练可编辑性，为紧凑语言模型设计提供了新范式。

Abstract: Weight tying is widely used in compact language models to reduce parameters by sharing the token table between the input embedding and the output projection. However, weight sharing does not guarantee a stable token interface: during training, the correspondence between encoding tokens into hidden states and decoding hidden states into logits can drift, worsening optimization sensitivity and making post-training interventions such as editing, patching, and lightweight adaptation less predictable. We propose Pseudo-Inverse Tying (PIT), which synchronizes embedding and unembedding as coupled projections of a shared latent token memory, guaranteeing a pseudo-inverse-consistent interface throughout training. PIT maintains an orthonormal shared memory, obtained by thin polar decomposition for teacher initialization or random orthonormal initialization from scratch, and introduces a fully learned symmetric positive definite hidden-space transform parameterized via a Cholesky factor. The output head applies this transform to hidden states before the vocabulary projection, while the embedding applies the inverse transform to token vectors using stable triangular solves, avoiding explicit pseudo-inverse recomputation and any vocabulary-sized auxiliary parameters. We evaluate PIT on on-device models spanning 256M-1.3B parameters across pretraining and adaptation, and consistently observe improved training stability, stronger layerwise semantic consistency, and substantially reduced side effects.

</details>


### [134] [Textual Planning with Explicit Latent Transitions](https://arxiv.org/abs/2602.04557)
*Eliezer Shlomi,Ido Levy,Eilam Shapira,Michael Katz,Guy Uziel,Segev Shlomov,Nir Mashkif,Roi Reichart,Sarah Keren*

Main category: cs.CL

TL;DR: EmbedPlan 提出了一种在冻结语言嵌入空间中进行轻量级状态转移预测的方法，避免自回归生成，提升规划效率，但在跨领域泛化上仍存在瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的规划方法受限于逐token生成和重复全前向传播，导致多步前瞻和基于rollout的搜索延迟高、计算开销大。

Method: EmbedPlan 利用冻结的语言模型编码器将自然语言描述的状态和动作映射为嵌入向量，通过轻量级过渡模型预测下一状态嵌入，并通过最近邻检索还原下一状态，无需微调编码器。

Result: 在九个经典规划领域、六种递进难度评估协议下，EmbedPlan 在插值任务中接近完美，但在需泛化至未见问题或新领域的任务（如外推、跨域、留一法）中性能显著下降；计划变体评估表明其能泛化到替代路径而非记忆轨迹。

Conclusion: 冻结嵌入空间支持在单一领域内学习动态规律，但跨领域迁移仍是主要瓶颈。

Abstract: Planning with LLMs is bottlenecked by token-by-token generation and repeated full forward passes, making multi-step lookahead and rollout-based search expensive in latency and compute. We propose EmbedPlan, which replaces autoregressive next-state generation with a lightweight transition model operating in a frozen language embedding space. EmbedPlan encodes natural language state and action descriptions into vectors, predicts the next-state embedding, and retrieves the next state by nearest-neighbor similarity, enabling fast planning computation without fine-tuning the encoder. We evaluate next-state prediction across nine classical planning domains using six evaluation protocols of increasing difficulty: interpolation, plan-variant, extrapolation, multi-domain, cross-domain, and leave-one-out. Results show near-perfect interpolation performance but a sharp degradation when generalization requires transfer to unseen problems or unseen domains; plan-variant evaluation indicates generalization to alternative plans rather than memorizing seen trajectories. Overall, frozen embeddings support within-domain dynamics learning after observing a domain's transitions, while transfer across domain boundaries remains a bottleneck.

</details>


### [135] [Can LLMs capture stable human-generated sentence entropy measures?](https://arxiv.org/abs/2602.04570)
*Estrella Pivel-Villanueva,Elisabeth Frederike Sterner,Franziska Knolle*

Main category: cs.CL

TL;DR: 本文通过自助法收敛性分析，验证了德语和英语中单词级香农熵估计所需的最小人类响应数，并比较了多个大语言模型（LLM）与人类熵值的一致性。结果表明：多数句子在约80–110次响应内即可稳定；低熵句收敛快，高熵句需更多响应；GPT-4o在特定提取方式下最接近人类熵，但LLM尚不能完全替代人类规范数据。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于单词级香农熵估计所需最少人类响应数的实证共识；同时，大语言模型（LLM）被广泛用作人类规范数据的替代，但其能否稳定复现人类熵值尚不清楚。

Method: 基于两个公开的大规模德语和英语完形填空数据集，采用自助法（bootstrap）进行收敛性分析，量化不同样本量下熵估计的稳定性；并对比多种LLM（GPT-4o、GPT2-xl/german-GPT-2、RoBERTa Base/GottBERT、LLaMA 2 7B Chat）通过logit概率提取和采样频率估计两种方式生成的熵值与稳定人类熵值的一致性。

Result: 97%以上句子在可用样本量内达到熵估计稳定；德语90%句子在111次响应后收敛，英语为81次；低熵句（<1）仅需约20次，高熵句（>2.5）需显著更多；GPT-4o在logit提取下绝对误差最小，采样法更匹配人类变异分布。

Conclusion: 本研究为语言熵的人类规范实践提供了首个直接实证依据，表明收敛性高度依赖句子可预测性；LLM虽可近似人类熵，但因其方法与提示敏感，尚不能等同于稳定的人类分布，不可无差别替代。

Abstract: Predicting upcoming words is a core mechanism of language comprehension and may be quantified using Shannon entropy. There is currently no empirical consensus on how many human responses are required to obtain stable and unbiased entropy estimates at the word level. Moreover, large language models (LLMs) are increasingly used as substitutes for human norming data, yet their ability to reproduce stable human entropy remains unclear. Here, we address both issues using two large publicly available cloze datasets in German 1 and English 2. We implemented a bootstrap-based convergence analysis that tracks how entropy estimates stabilize as a function of sample size. Across both languages, more than 97% of sentences reached stable entropy estimates within the available sample sizes. 90% of sentences converged after 111 responses in German and 81 responses in English, while low-entropy sentences (<1) required as few as 20 responses and high-entropy sentences (>2.5) substantially more. These findings provide the first direct empirical validation for common norming practices and demonstrate that convergence critically depends on sentence predictability. We then compared stable human entropy values with entropy estimates derived from several LLMs, including GPT-4o, using both logit-based probability extraction and sampling-based frequency estimation, GPT2-xl/german-GPT-2, RoBERTa Base/GottBERT, and LLaMA 2 7B Chat. GPT-4o showed the highest correspondence with human data, although alignment depended strongly on the extraction method and prompt design. Logit-based estimates minimized absolute error, whereas sampling-based estimates were better in capturing the dispersion of human variability. Together, our results establish practical guidelines for human norming and show that while LLMs can approximate human entropy, they are not interchangeable with stable human-derived distributions.

</details>


### [136] [Semantic Self-Distillation for Language Model Uncertainty](https://arxiv.org/abs/2602.04577)
*Edward Phillips,Sean Wu,Boyan Gao,David A. Clifton*

Main category: cs.CL

TL;DR: 本文提出了一种名为语义自蒸馏（SSD）的技术，通过轻量级学生模型预测提示条件下的语义分布及不确定性，以高效替代计算昂贵的语义离散度，从而在延迟敏感场景中实现大语言模型的不确定性量化与幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 大语言模型难以进行原则性的不确定性量化，而语义离散度虽是有效代理，但计算开销大，不适用于低延迟场景。

Method: 将采样的语义分布蒸馏为轻量级学生模型，该模型在生成答案前预测提示条件下的语义分布，利用其熵估计不确定性，并用概率密度评估候选答案可靠性。

Result: 在TriviaQA上，学生模型在幻觉预测和域外答案检测方面匹配或优于基于有限样本的语义离散度方法。

Conclusion: 语义自蒸馏（SSD）为复杂输出空间（不限于语言）中的预测不确定性蒸馏提供了一般性框架。

Abstract: Large language models present challenges for principled uncertainty quantification, in part due to their complexity and the diversity of their outputs. Semantic dispersion, or the variance in the meaning of sampled answers, has been proposed as a useful proxy for model uncertainty, but the associated computational cost prohibits its use in latency-critical applications. We show that sampled semantic distributions can be distilled into lightweight student models which estimate a prompt-conditioned uncertainty before the language model generates an answer token. The student model predicts a semantic distribution over possible answers; the entropy of this distribution provides an effective uncertainty signal for hallucination prediction, and the probability density allows candidate answers to be evaluated for reliability. On TriviaQA, our student models match or outperform finite-sample semantic dispersion for hallucination prediction and provide a strong signal for out-of-domain answer detection. We term this technique Semantic Self-Distillation (SSD), which we suggest provides a general framework for distilling predictive uncertainty in complex output spaces beyond language.

</details>


### [137] [Trust The Typical](https://arxiv.org/abs/2602.04581)
*Debargha Ganguly,Sreehari Sankar,Biyao Zhang,Vikash Singh,Kanan Gupta,Harshini Kavuru,Alan Luo,Weicong Chen,Warren Morningstar,Raghu Machiraju,Vipin Chaudhary*

Main category: cs.CL

TL;DR: 本文提出了一种名为Trust The Typical (T3)的新框架，将LLM安全性建模为语义空间中的分布外（OOD）检测问题，仅需在安全文本上训练即可实现跨语言、跨任务的鲁棒安全防护，显著降低误报率并具备生产级部署能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全方法依赖于识别和屏蔽已知威胁的脆弱对抗机制；作者主张从‘理解什么是安全’而非‘枚举什么有害’出发，构建更鲁棒的安全范式。

Method: T3框架将安全性建模为语义空间中对‘典型安全提示’分布的学习与偏离检测，无需任何有害样本训练，仅基于安全英文文本学习分布，并通过OOD检测判定潜在威胁。

Result: 在18个涵盖毒性、仇恨言论、越狱、多语言危害及过度拒绝的基准测试中达到SOTA；误报率较专用安全模型降低最高达40倍；单模型可零样本迁移至14+语言及多种领域；GPU优化版本集成进vLLM，生成时持续防护开销<6%。

Conclusion: T3证明了以‘信任典型’为核心的安全范式不仅可行且高效，为LLM安全提供了无需有害数据、强泛化、低开销的通用解决方案。

Abstract: Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails. We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Typical (T3), a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms, and over-refusal, reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM, enabling continuous guardrailing during token generation with less than 6% overhead even under dense evaluation intervals on large-scale workloads.

</details>


### [138] [VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration](https://arxiv.org/abs/2602.04587)
*Jaeyoon Jung,Yejun Yoon,Seunghyun Yoon,Kunwoo Park*

Main category: cs.CL

TL;DR: VILLAIN是一个基于多智能体协作的多模态事实核查系统，通过视觉-语言模型在多个阶段协同验证图文声明，在AVerImaTeC共享任务中排名第一。


<details>
  <summary>Details</summary>
Motivation: 解决图文声明的事实核查问题，提升多模态证据整合与不一致性处理能力。

Method: 采用基于提示的多智能体协作框架，包括视觉-语言模型代理、模态特异与跨模态分析报告生成、问答对构建，以及最终判决预测。

Result: 在AVerImaTeC共享任务所有评估指标上排名第一，代码已开源。

Conclusion: VILLAIN证明了多智能体协同与多阶段提示工程在多模态事实核查中的有效性与实用性。

Abstract: This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fact-checking. Textual and visual evidence is retrieved from the knowledge store enriched through additional web collection. To identify key information and address inconsistencies among evidence items, modality-specific and cross-modal agents generate analysis reports. In the subsequent stage, question-answer pairs are produced based on these reports. Finally, the Verdict Prediction agent produces the verification outcome based on the image-text claim and the generated question-answer pairs. Our system ranked first on the leaderboard across all evaluation metrics. The source code is publicly available at https://github.com/ssu-humane/VILLAIN.

</details>


### [139] [Beyond Holistic Scores: Automatic Trait-Based Quality Scoring of Argumentative Essays](https://arxiv.org/abs/2602.04604)
*Lucile Favero,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CL

TL;DR: 本文研究了基于特征的自动议论文评分方法，提出了两种互补建模范式：基于小开源大语言模型的结构化上下文学习，以及采用CORAL序数回归的监督式BigBird模型；在ASAP++数据集上验证表明，显式建模分数序数性显著提升与人工评分的一致性，且小开源LLM无需微调即可实现有竞争力的表现。


<details>
  <summary>Details</summary>
Motivation: 传统自动作文评分系统聚焦整体评分，难以满足教育场景中教师和学习者对可解释、符合教学目标和评分标准的细粒度特征反馈的需求，尤其在议论文等复杂文体中。

Method: 提出两种建模范式：(1) 基于小开源LLM的结构化上下文学习，使用评分标准对齐的示例提示，并请求反馈与置信度；(2) 基于BigBird编码器的监督模型，结合CORAL序数回归框架显式建模分数的有序性。在ASAP++数据集（含5个议论文质量特征）上系统评估。

Result: 显式建模分数序数性显著提升各特征上与人工评分者的一致性，优于LLM及名义分类/回归基线；小开源LLM在无需任务微调下表现具竞争力，尤其在推理类特征上，并支持透明、隐私保护和本地部署。

Conclusion: 模型目标需与评分标准语义对齐；序数建模对教育评估至关重要；小开源LLM为可解释、可部署的AI教育系统提供了可行路径。

Abstract: Automated Essay Scoring systems have traditionally focused on holistic scores, limiting their pedagogical usefulness, especially in the case of complex essay genres such as argumentative writing. In educational contexts, teachers and learners require interpretable, trait-level feedback that aligns with instructional goals and established rubrics. In this paper, we study trait-based Automatic Argumentative Essay Scoring using two complementary modeling paradigms designed for realistic educational deployment: (1) structured in-context learning with small open-source LLMs, and (2) a supervised, encoder-based BigBird model with a CORAL-style ordinal regression formulation, optimized for long-sequence understanding. We conduct a systematic evaluation on the ASAP++ dataset, which includes essay scores across five quality traits, offering strong coverage of core argumentation dimensions. LLMs are prompted with designed, rubric-aligned in-context examples, along with feedback and confidence requests, while we explicitly model ordinality in scores with the BigBird model via the rank-consistent CORAL framework. Our results show that explicitly modeling score ordinality substantially improves agreement with human raters across all traits, outperforming LLMs and nominal classification and regression-based baselines. This finding reinforces the importance of aligning model objectives with rubric semantics for educational assessment. At the same time, small open-source LLMs achieve a competitive performance without task-specific fine-tuning, particularly for reasoning-oriented traits, while enabling transparent, privacy-preserving, and locally deployable assessment scenarios. Our findings provide methodological, modeling, and practical insights for the design of AI-based educational systems that aim to deliver interpretable, rubric-aligned feedback for argumentative writing.

</details>


### [140] [RexBERT: Context Specialized Bidirectional Encoders for E-commerce](https://arxiv.org/abs/2602.04605)
*Rahul Bajaj,Anuj Garg*

Main category: cs.CL

TL;DR: 本文提出了RexBERT，一种专为电子商务语义设计的BERT风格编码器家族，通过构建大规模电商语料Ecom-niverse、提出三阶段可复现预训练方法，并在多个电商相关任务上验证其优于通用大模型。


<details>
  <summary>Details</summary>
Motivation: 通用编码器在电商等专业领域覆盖不足，而电商应用对延迟、稳定性和成本敏感，亟需领域适配的轻量高效编码器。

Method: 1) 构建3500亿token的电商语料Ecom-niverse；2) 提出三阶段预训练流程（通用预训练→上下文扩展→退火式领域专业化）；3) 训练17M至400M参数规模的RexBERT模型。

Result: RexBERT在电商数据集的词元分类、语义相似度和通用NLU任务上，以2–3倍更少参数超越更大通用编码器，并匹敌或超越现代长上下文模型。

Conclusion: 高质量领域数据与系统化训练策略比盲目扩大模型规模更能有效提升电商场景性能。

Abstract: Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.

</details>


### [141] [Focus-LIME: Surgical Interpretation of Long-Context Large Language Models via Proxy-Based Neighborhood Selection](https://arxiv.org/abs/2602.04607)
*Junhao Liu,Haonan Yu,Zhenyu Yan,Xin Zhang*

Main category: cs.CL

TL;DR: 本文提出Focus-LIME，一种粗到细的解释框架，通过代理模型优化扰动邻域，提升大语言模型在长上下文场景下的特征级可解释性与忠实性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理超长上下文时，现有局部、模型无关的解释方法因高维特征导致归因稀释，难以提供可信、精细的解释，尤其在法律审计和代码调试等高风险任务中亟需解决。

Method: 提出Focus-LIME框架：先用轻量代理模型筛选关键上下文区域（粗粒度），再在该优化后的子上下文中对目标模型进行细粒度特征归因；核心是利用代理模型引导扰动采样，缩小有效解释空间。

Result: 在多个长上下文基准测试中，Focus-LIME显著提升了解释的忠实性（faithfulness）与精确性，使‘手术式’细粒度解释变得可行且实用。

Conclusion: Focus-LIME有效缓解了高维上下文下的归因稀释问题，为大模型在高风险长文本任务中提供了更可靠、可操作的局部可解释性方案。

Abstract: As Large Language Models (LLMs) scale to handle massive context windows, achieving surgical feature-level interpretation is essential for high-stakes tasks like legal auditing and code debugging. However, existing local model-agnostic explanation methods face a critical dilemma in these scenarios: feature-based methods suffer from attribution dilution due to high feature dimensionality, thus failing to provide faithful explanations. In this paper, we propose Focus-LIME, a coarse-to-fine framework designed to restore the tractability of surgical interpretation. Focus-LIME utilizes a proxy model to curate the perturbation neighborhood, allowing the target model to perform fine-grained attribution exclusively within the optimized context. Empirical evaluations on long-context benchmarks demonstrate that our method makes surgical explanations practicable and provides faithful explanations to users.

</details>


### [142] [Disentangling meaning from language in LLM-based machine translation](https://arxiv.org/abs/2602.04613)
*Théo Lasnier,Armel Zebaze,Djamé Seddah,Rachel Bawden,Benoît Sagot*

Main category: cs.CL

TL;DR: 本文从机制可解释性角度研究大语言模型在机器翻译中的句子级工作机制，发现不同注意力头专门负责目标语言识别和句子语义等价两个子任务，并利用这一发现实现了无需指令的高效翻译控制。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在机器翻译中的机制可解释性研究受限于模型规模，以往工作多停留在词级别，缺乏对句子级翻译机制的深入理解。

Method: 通过分析注意力头的行为，将机器翻译分解为目标语言识别和句子语义等价两个子任务，在三类开源模型及20个翻译方向上进行实证分析，并构建子任务特定的引导向量进行干预实验。

Result: 发现不同子任务由稀疏且互不重叠的注意力头集合专门负责；仅修改1%相关头即可实现媲美指令式提示的无指令翻译性能；选择性地屏蔽这些头会特异性破坏对应子功能。

Conclusion: 句子级机器翻译能力在模型内部以模块化、稀疏化方式分布于特定注意力头上，支持细粒度、可干预的功能解耦与控制。

Abstract: Mechanistic Interpretability (MI) seeks to explain how neural networks implement their capabilities, but the scale of Large Language Models (LLMs) has limited prior MI work in Machine Translation (MT) to word-level analyses. We study sentence-level MT from a mechanistic perspective by analyzing attention heads to understand how LLMs internally encode and distribute translation functions. We decompose MT into two subtasks: producing text in the target language (i.e. target language identification) and preserving the input sentence's meaning (i.e. sentence equivalence). Across three families of open-source models and 20 translation directions, we find that distinct, sparse sets of attention heads specialize in each subtask. Based on this insight, we construct subtask-specific steering vectors and show that modifying just 1% of the relevant heads enables instruction-free MT performance comparable to instruction-based prompting, while ablating these heads selectively disrupts their corresponding translation functions.

</details>


### [143] [LEAD: Layer-wise Expert-aligned Decoding for Faithful Radiology Report Generation](https://arxiv.org/abs/2602.04617)
*Ruixiao Yang,Yuanhe Tian,Xu Yang,Huiqi Li,Yan Song*

Main category: cs.CL

TL;DR: 本文提出Layer-wise Expert-aligned Decoding（LEAD）方法，通过在LVLM解码过程中引入多专家模块与层间门控机制，动态校正解码偏差，提升放射科报告生成的事实一致性并缓解幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在放射科报告生成中存在幻觉问题，且依赖外部知识引导的方法忽视了预训练模型固有的解码先验和跨模态对齐偏差，鲁棒性不足。

Method: 提出LEAD方法，在LVLM每个解码层嵌入多专家模块，提取不同病理特征，并通过可学习门控机制将专家特征融合进各层解码过程，从而动态修正解码轨迹。

Result: 在多个公开数据集上实验表明，LEAD显著提升了临床准确性指标，有效缓解幻觉，同时保持高质量文本生成能力。

Conclusion: LEAD是一种无需外部知识干预、从解码机制层面增强视觉-语言对齐的内在化方法，为减少医学报告生成中的幻觉提供了新思路。

Abstract: Radiology Report Generation (RRG) aims to produce accurate and coherent diagnostics from medical images. Although large vision language models (LVLM) improve report fluency and accuracy, they exhibit hallucinations, generating plausible yet image-ungrounded pathological details. Existing methods primarily rely on external knowledge guidance to facilitate the alignment between generated text and visual information. However, these approaches often ignore the inherent decoding priors and vision-language alignment biases in pretrained models and lack robustness due to reliance on constructed guidance. In this paper, we propose Layer-wise Expert-aligned Decoding (LEAD), a novel method to inherently modify the LVLM decoding trajectory. A multiple experts module is designed for extracting distinct pathological features which are integrated into each decoder layer via a gating mechanism. This layer-wise architecture enables the LLM to consult expert features at every inference step via a learned gating function, thereby dynamically rectifying decoding biases and steering the generation toward factual consistency. Experiments conducted on multiple public datasets demonstrate that the LEAD method yields effective improvements in clinical accuracy metrics and mitigates hallucinations while preserving high generation quality.

</details>


### [144] [Mapping the Web of Science, a large-scale graph and text-based dataset with LLM embeddings](https://arxiv.org/abs/2602.04630)
*Tim Kunt,Annika Buchholz,Imene Khebouri,Thorsten Koch,Ida Litzel,Thi Huong Vu*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本语义嵌入与图结构关系的分析方法，利用大语言模型（LLM）嵌入处理Web of Science约5600万篇论文，揭示出文本数据的自组织结构。


<details>
  <summary>Details</summary>
Motivation: 大型文本数据集（如论文、网站）同时具有语义文本特征和文本间关系（链接、引用等）两类信息，现有方法往往分别处理二者，缺乏有效融合。

Method: 提出一种融合LLM文本嵌入与图结构信息的嵌入方法，应用于Web of Science数据集进行大规模文本分析。

Result: 在约5600万篇科学出版物上成功应用该方法，揭示出文本数据呈现出清晰的自组织景观（self-structured landscape）。

Conclusion: LLM嵌入能有效捕捉文本语义，并与图结构互补，为大规模异构文本数据分析提供了可行且富有洞察力的新范式。

Abstract: Large text data sets, such as publications, websites, and other text-based media, inherit two distinct types of features: (1) the text itself, its information conveyed through semantics, and (2) its relationship to other texts through links, references, or shared attributes. While the latter can be described as a graph structure and can be handled by a range of established algorithms for classification and prediction, the former has recently gained new potential through the use of LLM embedding models. Demonstrating these possibilities and their practicability, we investigate the Web of Science dataset, containing ~56 million scientific publications through the lens of our proposed embedding method, revealing a self-structured landscape of texts.

</details>


### [145] [Outcome Accuracy is Not Enough: Aligning the Reasoning Process of Reward Models](https://arxiv.org/abs/2602.04649)
*Binghai Wang,Yantao Liu,Yuxuan Liu,Tianyi Tang,Shenzhi Wang,Chang Gao,Chujie Zheng,Yichang Zhang,Le Yu,Shixuan Liu,Tao Gui,Qi Zhang,Xuanjing Huang,Bowen Yu,Fei Huang,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估指标——Rationale Consistency（理由一致性），用于检测生成式奖励模型（GenRMs）和LLM-as-a-Judge中的欺骗性对齐问题，并通过结合该指标与结果准确率的混合训练信号，显著提升了模型在多个基准上的性能及RLHF中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GenRMs和LLM-as-a-Judge因过度关注结果准确率（Outcome Accuracy）而出现欺骗性对齐，即给出正确判断但推理错误，导致在RLHF中泛化能力下降。

Method: 提出细粒度指标Rationale Consistency来衡量模型推理过程与人类判断的一致性；构建融合Rationale Consistency与Outcome Accuracy的混合训练信号，用于GenRM训练。

Result: 在RM-Bench和JudgeBench上分别达到87.1%和82%，平均超越仅用结果准确率的基线5%；在Arena Hard v2上RLHF效果提升，创意写作任务提升7%；有效缓解并逆转了理由一致性的下降趋势。

Conclusion: Rationale Consistency是比Outcome Accuracy更可靠、更具判别力的评估指标；引入其作为训练信号可有效缓解欺骗性对齐，提升GenRM在RLHF中的鲁棒性与泛化能力。

Abstract: Generative Reward Models (GenRMs) and LLM-as-a-Judge exhibit deceptive alignment by producing correct judgments for incorrect reasons, as they are trained and evaluated to prioritize Outcome Accuracy, which undermines their ability to generalize during RLHF. We introduce Rationale Consistency, a fine-grained metric that quantifies the alignment between the model's reasoning process and human judgment. Our evaluation of frontier models reveals that rationale consistency effectively discriminates among state-of-the-art models and detects deceptive alignment, while outcome accuracy falls short in both respects. To mitigate this gap, we introduce a hybrid signal that combines rationale consistency with outcome accuracy for GenRM training. Our training method achieves state-of-the-art performance on RM-Bench (87.1%) and JudgeBench (82%), surpassing outcome-only baselines by an average of 5%. Using RM during RLHF, our method effectively improves performance as demonstrated on Arena Hard v2, notably yielding a 7% improvement in creative writing tasks. Further analysis confirms that our method escapes the deceptive alignment trap, effectively reversing the decline in rationale consistency observed in outcome-only training.

</details>


### [146] [Approaches to Semantic Textual Similarity in Slovak Language: From Algorithms to Transformers](https://arxiv.org/abs/2602.04659)
*Lukas Radosky,Miroslav Blstak,Matej Krajcovic,Ivan Polasek*

Main category: cs.CL

TL;DR: 本文对斯洛伐克语的语义文本相似度（STS）方法进行了比较评估，涵盖传统算法、监督机器学习模型及第三方深度学习工具，并使用人工蜂群优化进行特征选择与超参数调优。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语等低资源语言的语义文本相似度（STS）研究仍具挑战性，而高资源语言已有广泛研究，因此需系统评估适用于斯洛伐克语的STS方法。

Method: 采用传统算法、监督机器学习模型（以传统算法输出为特征，并结合人工蜂群优化进行特征选择和超参数调优），以及多种第三方工具（包括CloudNLP微调模型、OpenAI嵌入模型、GPT-4和预训练SlovakBERT）进行对比实验。

Result: 不同方法在斯洛伐克语STS任务中表现出显著性能差异，揭示了准确性、计算开销与资源依赖之间的权衡关系。

Conclusion: 没有单一方法在所有方面占优；应根据具体应用场景（如精度需求、计算资源、数据可用性）选择合适方法，且人工蜂群优化辅助建模对提升监督模型性能有效。

Abstract: Semantic textual similarity (STS) plays a crucial role in many natural language processing tasks. While extensively studied in high-resource languages, STS remains challenging for under-resourced languages such as Slovak. This paper presents a comparative evaluation of sentence-level STS methods applied to Slovak, including traditional algorithms, supervised machine learning models, and third-party deep learning tools. We trained several machine learning models using outputs from traditional algorithms as features, with feature selection and hyperparameter tuning jointly guided by artificial bee colony optimization. Finally, we evaluated several third-party tools, including fine-tuned model by CloudNLP, OpenAI's embedding models, GPT-4 model, and pretrained SlovakBERT model. Our findings highlight the trade-offs between different approaches.

</details>


### [147] [Investigating Disability Representations in Text-to-Image Models](https://arxiv.org/abs/2602.04687)
*Yang Yian,Yu Fan,Liudmila Zavolokina,Sarah Ebling*

Main category: cs.CL

TL;DR: This paper examines how text-to-image models (Stable Diffusion XL and DALL-E 3) represent people with disabilities, revealing persistent biases and imbalances; it uses prompt-based image similarity analysis and sentiment-based affective framing evaluation (automatic + human) to assess and mitigate these issues.


<details>
  <summary>Details</summary>
Motivation: Disability representations in text-to-image models are underexplored despite growing attention to fairness in AI, raising concerns about inclusive and accurate portrayals.

Method: Analyzes outputs from Stable Diffusion XL and DALL-E 3 using structured prompts comparing generic vs. specific disability categories; evaluates affective framing via sentiment polarity analysis (automatic and human evaluation); tests mitigation strategies.

Result: Reveals persistent representational imbalances in how people with disabilities are depicted; shows mitigation strategies have limited or inconsistent effects on improving affective framing and representation diversity.

Conclusion: Continuous evaluation and refinement of generative models are essential to achieve more diverse, accurate, and inclusive disability representations.

Abstract: Text-to-image generative models have made remarkable progress in producing high-quality visual content from textual descriptions, yet concerns remain about how they represent social groups. While characteristics like gender and race have received increasing attention, disability representations remain underexplored. This study investigates how people with disabilities are represented in AI-generated images by analyzing outputs from Stable Diffusion XL and DALL-E 3 using a structured prompt design. We analyze disability representations by comparing image similarities between generic disability prompts and prompts referring to specific disability categories. Moreover, we evaluate how mitigation strategies influence disability portrayals, with a focus on assessing affective framing through sentiment polarity analysis, combining both automatic and human evaluation. Our findings reveal persistent representational imbalances and highlight the need for continuous evaluation and refinement of generative models to foster more diverse and inclusive portrayals of disability.

</details>


### [148] [LinGO: A Linguistic Graph Optimization Framework with LLMs for Interpreting Intents of Online Uncivil Discourse](https://arxiv.org/abs/2602.04693)
*Yuan Zhang,Thales Bertaglia*

Main category: cs.CL

TL;DR: 本文提出LinGO框架，通过将语言分解为多步语言成分并迭代优化提示或示例，提升大语言模型对政治不文明语言多类意图的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有不文明语言检测模型常将含不文明线索但表达文明意图的文本误判为不文明，导致线上不文明现象被高估。

Method: LinGO是一种面向大语言模型的语言图优化框架，将语言分解为多步语言成分，识别易出错步骤，并迭代优化对应提示或示例；在巴西2022年大选数据集上，结合四种优化技术（TextGrad、AdalFlow、DSPy、RAG）与三种轻量级LLM进行评估。

Result: LinGO在所有测试模型上均显著优于零样本、思维链、直接优化和微调等基线方法；RAG与Gemini 2.5 Flash-Lite组合效果最佳。

Conclusion: 将多步语言结构融入LLM指令并针对性优化，有助于模型理解复杂语义，该思路可推广至其他复杂语义解析任务。

Abstract: Detecting uncivil language is crucial for maintaining safe, inclusive, and democratic online spaces. Yet existing classifiers often misinterpret posts containing uncivil cues but expressing civil intents, leading to inflated estimates of harmful incivility online. We introduce LinGO, a linguistic graph optimization framework for large language models (LLMs) that leverages linguistic structures and optimization techniques to classify multi-class intents of incivility that use various direct and indirect expressions. LinGO decomposes language into multi-step linguistic components, identifies targeted steps that cause the most errors, and iteratively optimizes prompt and/or example components for targeted steps. We evaluate it using a dataset collected during the 2022 Brazilian presidential election, encompassing four forms of political incivility: Impoliteness (IMP), Hate Speech and Stereotyping (HSST), Physical Harm and Violent Political Rhetoric (PHAVPR), and Threats to Democratic Institutions and Values (THREAT). Each instance is annotated with six types of civil/uncivil intent. We benchmark LinGO using three cost-efficient LLMs: GPT-5-mini, Gemini 2.5 Flash-Lite, and Claude 3 Haiku, and four optimization techniques: TextGrad, AdalFlow, DSPy, and Retrieval-Augmented Generation (RAG). The results show that, across all models, LinGO consistently improves accuracy and weighted F1 compared with zero-shot, chain-of-thought, direct optimization, and fine-tuning baselines. RAG is the strongest optimization technique and, when paired with Gemini model, achieves the best overall performance. These findings demonstrate that incorporating multi-step linguistic components into LLM instructions and optimize targeted components can help the models explain complex semantic meanings, which can be extended to other complex semantic explanation tasks in the future.

</details>


### [149] [ERNIE 5.0 Technical Report](https://arxiv.org/abs/2602.04705)
*Haifeng Wang,Hua Wu,Tian Wu,Yu Sun,Jing Liu,Dianhai Yu,Yanjun Ma,Jingzhou He,Zhongjun He,Dou Hong,Qiwen Liu,Shuohuan Wang,Junyuan Shang,Zhenyu Zhang,Yuchen Ding,Jinle Zeng,Jiabin Yang,Liang Shen,Ruibiao Chen,Weichong Yin,Siyu Ding,Dai Dai,Shikun Feng,Siqi Bao,Bolei He,Yan Chen,Zhenyu Jiao,Ruiqing Zhang,Zeyu Chen,Qingqing Dang,Kaipeng Deng,Jiajun Jiang,Enlei Gong,Guoxia Wang,Yanlin Sha,Yi Liu,Yehan Zheng,Weijian Xu,Jiaxiang Liu,Zengfeng Zeng,Yingqi Qu,Zhongli Li,Zhengkun Zhang,Xiyang Wang,Zixiang Xu,Xinchao Xu,Zhengjie Huang,Dong Wang,Bingjin Chen,Yue Chang,Xing Yuan,Shiwei Huang,Qiao Zhao,Xinzhe Ding,Shuangshuang Qiao,Baoshan Yang,Bihong Tang,Bin Li,Bingquan Wang,Binhan Tang,Binxiong Zheng,Bo Cui,Bo Ke,Bo Zhang,Bowen Zhang,Boyan Zhang,Boyang Liu,Caiji Zhang,Can Li,Chang Xu,Chao Pang,Chao Zhang,Chaoyi Yuan,Chen Chen,Cheng Cui,Chenlin Yin,Chun Gan,Chunguang Chai,Chuyu Fang,Cuiyun Han,Dan Zhang,Danlei Feng,Danxiang Zhu,Dong Sun,Dongbo Li,Dongdong Li,Dongdong Liu,Dongxue Liu,Fan Ding,Fan Hu,Fan Li,Fan Mo,Feisheng Wu,Fengwei Liu,Gangqiang Hu,Gaofeng Lu,Gaopeng Yong,Gexiao Tian,Guan Wang,Guangchen Ni,Guangshuo Wu,Guanzhong Wang,Guihua Liu,Guishun Li,Haibin Li,Haijian Liang,Haipeng Ming,Haisu Wang,Haiyang Lu,Haiye Lin,Han Zhou,Hangting Lou,Hanwen Du,Hanzhi Zhang,Hao Chen,Hao Du,Hao Liu,Hao Zhou,Haochen Jiang,Haodong Tian,Haoshuang Wang,Haozhe Geng,Heju Yin,Hong Chen,Hongchen Xue,Hongen Liu,Honggeng Zhang,Hongji Xu,Hongwei Chen,Hongyang Zhang,Hongyuan Zhang,Hua Lu,Huan Chen,Huan Wang,Huang He,Hui Liu,Hui Zhong,Huibin Ruan,Jiafeng Lu,Jiage Liang,Jiahao Hu,Jiahao Hu,Jiajie Yang,Jialin Li,Jian Chen,Jian Wu,Jianfeng Yang,Jianguang Jiang,Jianhua Wang,Jianye Chen,Jiaodi Liu,Jiarui Zhou,Jiawei Lv,Jiaxin Zhou,Jiaxuan Liu,Jie Han,Jie Sun,Jiefan Fang,Jihan Liu,Jihua Liu,Jing Hu,Jing Qian,Jing Yan,Jingdong Du,Jingdong Wang,Jingjing Wu,Jingyong Li,Jinheng Wang,Jinjin Li,Jinliang Lu,Jinlin Yu,Jinnan Liu,Jixiang Feng,Jiyi Huang,Jiyuan Zhang,Jun Liang,Jun Xia,Jun Yu,Junda Chen,Junhao Feng,Junhong Xiang,Junliang Li,Kai Liu,Kailun Chen,Kairan Su,Kang Hu,Kangkang Zhou,Ke Chen,Ke Wei,Kui Huang,Kun Wu,Kunbin Chen,Lei Han,Lei Sun,Lei Wen,Linghui Meng,Linhao Yu,Liping Ouyang,Liwen Zhang,Longbin Ji,Longzhi Wang,Meng Sun,Meng Tian,Mengfei Li,Mengqi Zeng,Mengyu Zhang,Ming Hong,Mingcheng Zhou,Mingming Huang,Mingxin Chen,Mingzhu Cai,Naibin Gu,Nemin Qiu,Nian Wang,Peng Qiu,Peng Zhao,Pengyu Zou,Qi Wang,Qi Xin,Qian Wang,Qiang Zhu,Qianhui Luo,Qianwei Yang,Qianyue He,Qifei Wu,Qinrui Li,Qiwen Bao,Quan Zhang,Quanxiang Liu,Qunyi Xie,Rongrui Zhan,Rufeng Dai,Rui Peng,Ruian Liu,Ruihao Xu,Ruijie Wang,Ruixi Zhang,Ruixuan Liu,Runsheng Shi,Ruting Wang,Senbo Kang,Shan Lu,Shaofei Yu,Shaotian Gong,Shenwei Hu,Shifeng Zheng,Shihao Guo,Shilong Fan,Shiqin Liu,Shiwei Gu,Shixi Zhang,Shuai Yao,Shuang Zhang,Shuangqiao Liu,Shuhao Liang,Shuwei He,Shuwen Yang,Sijun He,Siming Dai,Siming Wu,Siyi Long,Songhe Deng,Suhui Dong,Suyin Liang,Teng Hu,Tianchan Xu,Tianliang Lv,Tianmeng Yang,Tianyi Wei,Tiezhu Gao,Ting Sun,Ting Zhang,Tingdan Luo,Wei He,Wei Luan,Wei Yin,Wei Zhang,Wei Zhou,Weibao Gong,Weibin Li,Weicheng Huang,Weichong Dang,Weiguo Zhu,Weilong Zhang,Weiqi Tan,Wen Huang,Wenbin Chang,Wenjing Du,Wenlong Miao,Wenpei Luo,Wenquan Wu,Xi Shi,Xi Zhao,Xiang Gao,Xiangguo Zhang,Xiangrui Yu,Xiangsen Wang,Xiangzhe Wang,Xianlong Luo,Xianying Ma,Xiao Tan,Xiaocong Lin,Xiaofei Wang,Xiaofeng Peng,Xiaofeng Wu,Xiaojian Xu,Xiaolan Yuan,Xiaopeng Cui,Xiaotian Han,Xiaoxiong Liu,Xiaoxu Fei,Xiaoxuan Wu,Xiaoyu Wang,Xiaoyu Zhang,Xin Sun,Xin Wang,Xinhui Huang,Xinming Zhu,Xintong Yu,Xinyi Xu,Xinyu Wang,Xiuxian Li,XuanShi Zhu,Xue Xu,Xueying Lv,Xuhong Li,Xulong Wei,Xuyi Chen,Yabing Shi,Yafeng Wang,Yamei Li,Yan Liu,Yanfu Cheng,Yang Gao,Yang Liang,Yang Wang,Yang Wang,Yang Yang,Yanlong Liu,Yannian Fu,Yanpeng Wang,Yanzheng Lin,Yao Chen,Yaozong Shen,Yaqian Han,Yehua Yang,Yekun Chai,Yesong Wang,Yi Song,Yichen Zhang,Yifei Wang,Yifeng Guo,Yifeng Kou,Yilong Chen,Yilong Guo,Yiming Wang,Ying Chen,Ying Wang,Yingsheng Wu,Yingzhan Lin,Yinqi Yang,Yiran Xing,Yishu Lei,Yixiang Tu,Yiyan Chen,Yong Zhang,Yonghua Li,Yongqiang Ma,Yongxing Dai,Yongyue Zhang,Yu Ran,Yu Sun,Yu-Wen Michael Zhang,Yuang Liu,Yuanle Liu,Yuanyuan Zhou,Yubo Zhang,Yuchen Han,Yucheng Wang,Yude Gao,Yuedong Luo,Yuehu Dong,Yufeng Hu,Yuhui Cao,Yuhui Yun,Yukun Chen,Yukun Gao,Yukun Li,Yumeng Zhang,Yun Fan,Yun Ma,Yunfei Zhang,Yunshen Xie,Yuping Xu,Yuqin Zhang,Yuqing Liu,Yurui Li,Yuwen Wang,Yuxiang Lu,Zefeng Cai,Zelin Zhao,Zelun Zhang,Zenan Lin,Zezhao Dong,Zhaowu Pan,Zhaoyu Liu,Zhe Dong,Zhe Zhang,Zhen Zhang,Zhengfan Wu,Zhengrui Wei,Zhengsheng Ning,Zhenxing Li,Zhenyu Li,Zhenyu Qian,Zhenyun Li,Zhi Li,Zhichao Chen,Zhicheng Dong,Zhida Feng,Zhifan Feng,Zhihao Deng,Zhijin Yu,Zhiyang Chen,Zhonghui Zheng,Zhuangzhuang Guo,Zhujun Zhang,Zhuo Sun,Zichang Liu,Zihan Lin,Zihao Huang,Zihe Zhu,Ziheng Zhao,Ziping Chen,Zixuan Zhu,Ziyang Xu,Ziyi Liang,Ziyuan Gao*

Main category: cs.CL

TL;DR: ERNIE 5.0 是一个原生自回归的万亿参数统一多模态基础模型，支持文本、图像、视频和音频的理解与生成；采用超稀疏MoE架构与模态无关的专家路由，并引入弹性训练范式以适应不同资源约束；首次在公开模型中实现生产级多模态统一自回归建模。


<details>
  <summary>Details</summary>
Motivation: 解决多模态统一建模中模态异构性、大模型部署资源受限、强化学习难以扩展至超稀疏MoE及多模态场景等实际挑战。

Method: 提出统一的‘下一组token预测’目标，基于模态无关的超稀疏MoE架构与弹性训练范式（单次预训练生成多种深度/容量/稀疏度子模型），并系统优化面向超稀疏MoE与多模态的强化学习后训练流程。

Result: 在文本、图像、视频、音频多个模态任务上实现强而均衡的性能；成为首个公开披露的、支持理解与生成的生产级万亿参数统一多模态自回归模型。

Conclusion: ERNIE 5.0验证了原生自回归范式在统一多模态建模中的可行性与可扩展性，其弹性训练、模态无关MoE路由与多模态RLHF方案为大规模多模态基础模型提供了新范式与实用技术路径。

Abstract: In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.

</details>


### [150] [LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers](https://arxiv.org/abs/2602.04706)
*Yike Sun,Haotong Yang,Zhouchen Lin,Muhan Zhang*

Main category: cs.CL

TL;DR: 本文研究了BPE分词器中出现的中间合并残留现象，并提出LiteToken方法去除这些低频但占用词汇表空间的残留token，从而提升鲁棒性并减少碎片化，且无需额外微调。


<details>
  <summary>Details</summary>
Motivation: BPE分词器中存在大量在合并过程中频繁出现但最终极少被实际使用的中间残留token，浪费词汇容量并降低对异常输入的鲁棒性。

Method: 系统分析主流BPE分词器中的中间合并残留现象，并提出LiteToken方法——识别并移除这些低频残留token；利用其极低使用率特性，使预训练模型可直接适配新分词器而无需再训练。

Result: LiteToken显著降低token碎片化、减少模型参数量，并提升对噪声和拼写错误输入的鲁棒性，同时保持原始性能。

Conclusion: 中间合并残留是BPE分词器中被忽视但影响效率与鲁棒性的重要问题；LiteToken提供了一种简单有效、无需微调的优化方案。

Abstract: Tokenization is fundamental to how language models represent and process text, yet the behavior of widely used BPE tokenizers has received far less study than model architectures and training. In this paper, we investigate intermediate merge residues in BPE vocabularies: tokens that are frequent during merge learning so that retained in the final vocabulary, but are mostly further merged and rarely emitted when tokenizing the corpus during tokenizer usage. Such low-frequency tokens not only waste vocabulary capacity but also increase vulnerability to adversarial or atypical inputs. We present a systematic empirical characterization of this phenomenon across commonly used tokenizers and introduce LiteToken, a simple method for removing residue tokens. Because the affected tokens are rarely used, pretrained models can often accommodate the modified tokenizer without additional fine-tuning. Experiments show that LiteToken reduces token fragmentation, reduces parameters, and improves robustness to noisy or misspelled inputs, while preserving overall performance.

</details>


### [151] [Linguistically Informed Evaluation of Multilingual ASR for African Languages](https://arxiv.org/abs/2602.04716)
*Fei-Yueh Chen,Lateef Adeleke,C. M. Downey*

Main category: cs.CL

TL;DR: 本文提出了一种面向非洲语言语音识别评估的特征级错误率（FER）及音调感知扩展（TER），揭示了传统词错误率（WER）掩盖的音系与声调错误模式，发现模型在音段特征上表现较好，但对中调和降阶调等声调仍存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: Word Error Rate（WER）无法区分非洲语言中不同类型的语音错误（如音系、声调等），导致对ASR模型性能的误判；需要更细粒度、语言学意义明确的评估指标。

Method: 在两种非洲语言（Yoruba和濒危语言Uneme）上，结合字符错误率（CER）、特征错误率（FER）和新提出的音调感知错误率（TER），评估三个语音编码器；FER/TER基于音系特征（如发音部位、方式、声调）计算错误。

Result: FER和TER能揭示WER掩盖的细粒度错误模式：模型在音段特征上错误率低，但中调和降阶调错误率高；Yoruba上WER=0.788而FER仅0.151；Uneme上近100% WER对应FER=0.267，表明错误多为单个特征而非整词。

Conclusion: FER和TER作为补充指标，能更准确反映ASR模型在非洲语言上的真实能力，尤其凸显声调建模的瓶颈，为未来模型优化提供语言学导向的评估依据。

Abstract: Word Error Rate (WER) mischaracterizes ASR models' performance for African languages by combining phonological, tone, and other linguistic errors into a single lexical error. By contrast, Feature Error Rate (FER) has recently attracted attention as a viable metric that reveals linguistically meaningful errors in models' performance. In this paper, we evaluate three speech encoders on two African languages by complementing WER with CER, and FER, and add a tone-aware extension (TER). We show that by computing errors on phonological features, FER and TER reveal linguistically-salient error patterns even when word-level accuracy remains low. Our results reveal that models perform better on segmental features, while tones (especially mid and downstep) remain the most challenging features. Results on Yoruba show a striking differential in metrics, with WER=0.788, CER=0.305, and FER=0.151. Similarly for Uneme (an endangered language absent from pretraining data) a model with near-total WER and 0.461 CER achieves the relatively low FER of 0.267. This indicates model error is often attributable to individual phonetic feature errors, which is obscured by all-or-nothing metrics like WER.

</details>


### [152] ["Be My Cheese?": Cultural Nuance Benchmarking for Machine Translation in Multilingual LLMs](https://arxiv.org/abs/2602.04729)
*Madison Van Doren,Casey Ford,Jennifer Barajas,Cory Holland*

Main category: cs.CL

TL;DR: 本文提出了首个专注于机器翻译中文化本地化能力的大规模人工评估基准，评估了7种多语言大模型在15种目标语言中的文化敏感性翻译表现，发现模型在语法准确性上表现尚可，但在习语、双关语等文化特定表达的翻译上存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译基准过于关注词级和语法准确性，忽视了实际本地化所需的语用和文化能力，因此需要一个专门评估文化本地化能力的新基准。

Method: 基于87个跨20种语言的初步翻译样本，对7种多语言大语言模型在15种目标语言上的翻译进行人工评估，每种语言由5位母语者评分，评估包括全文质量和文化特定片段（如习语、双关、节日、文化概念）两个层面，采用0-3等级量表。

Result: 全文平均质量为1.68/3；GPT-5、Claude Sonnet 3.7和Mistral Medium 3.1表现最佳；节日（2.20/3）和文化概念（2.19/3）翻译较好，而习语（1.65/3）和双关（1.45/3）最差，且习语最常未被翻译。

Conclusion: 当前多语言大模型在语法正确性与文化共鸣之间存在明显差距，亟需融入文化感知的训练数据、提升跨语言语用能力，并建立更贴近真实交际能力的评估范式。

Abstract: We present a large-scale human evaluation benchmark for assessing cultural localisation in machine translation produced by state-of-the-art multilingual large language models (LLMs). Existing MT benchmarks emphasise token-level and grammatical accuracy, but of ten overlook pragmatic and culturally grounded competencies required for real-world localisation. Building on a pilot study of 87 translations across 20 languages, we evaluate 7 multilingual LLMs across 15 target languages with 5 native-speaker raters per language. Raters scored both full-text translations and segment-level instances of culturally nuanced language (idioms, puns, holidays, and culturally embedded concepts) on an ordinal 0-3 quality scale; segment ratings additionally included an NA option for untranslated segments.
  Across full-text evaluations, mean overall quality is modest (1.68/3): GPT-5 (2.10/3), Claude Sonnet 3.7 (1.97/3), and Mistral Medium 3.1 (1.84/3) form the strongest tier with fewer catastrophic failures. Segment-level results show sharp category effects: holidays (2.20/3) and cultural concepts (2.19/3) translate substantially better than idioms (1.65/3) and puns (1.45/3), and idioms are most likely to be left untranslated. These findings demonstrate a persistent gap between grammatical adequacy and cultural resonance. To our knowledge, this is the first multilingual, human-annotated benchmark focused explicitly on cultural nuance in translation and localisation, highlighting the need for culturally informed training data, improved cross-lingual pragmatics, and evaluation paradigms that better reflect real-world communicative competence.

</details>


### [153] [Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging](https://arxiv.org/abs/2602.04731)
*Sameh Khattab,Jean-Philippe Corbeil,Osman Alperen Koraş,Amin Dada,Julian Friedrich,François Beaulieu,Paul Vozila,Jens Kleesiek*

Main category: cs.CL

TL;DR: 本文提出Synthesize-Train-Merge (STM)框架，通过合成难负样本、检索提示优化和模型融合，将通用大语言模型高效适配为高性能生物医学领域专用检索器，在MTEB子集上显著提升性能，同时保留通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based检索器在专业化领域（如生物医学）的适配方法仍不充分，需探索如何高效将通用大模型转化为领域专用检索器。

Method: 提出模块化框架STM，包含合成难负样本、检索提示优化和模型融合三部分，用于增强decoder-only LLMs。

Result: 在MTEB中12个医疗与通用任务子集上，STM使任务专家性能最高提升23.5%（平均7.5%），融合模型优于单专家及强基线，且无需大量预训练。

Conclusion: STM提供了一条可扩展、高效的路径，使通用LLM既能保持通用能力，又能在专业领域检索任务中取得优异表现。

Abstract: Retrieval-augmented generation (RAG) has become the backbone of grounding Large Language Models (LLMs), improving knowledge updates and reducing hallucinations. Recently, LLM-based retriever models have shown state-of-the-art performance for RAG applications. However, several technical aspects remain underexplored on how to adapt general-purpose LLMs into effective domain-specific retrievers, especially in specialized domains such as biomedicine. We present Synthesize-Train-Merge (STM), a modular framework that enhances decoder-only LLMs with synthetic hard negatives, retrieval prompt optimization, and model merging. Experiments on a subset of 12 medical and general tasks from the MTEB benchmark show STM boosts task-specific experts by up to 23.5\% (average 7.5\%) and produces merged models that outperform both single experts and strong baselines without extensive pretraining. Our results demonstrate a scalable, efficient path for turning general LLMs into high-performing, domain-specialized retrievers, preserving general-domain capabilities while excelling on specialized tasks.

</details>


### [154] [Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases](https://arxiv.org/abs/2602.04739)
*Casey Ford,Madison Van Doren,Emily Dix*

Main category: cs.CL

TL;DR: 本文通过两阶段评估，使用726个由专业红队成员设计的对抗性提示，对多个多模态大语言模型（MLLMs）的安全性进行了系统测试，发现不同模型家族在安全性上存在显著且持续的差异，且安全性随模型迭代并非稳定提升，需建立长期、多模态的安全评估基准。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在实际系统中日益广泛应用，但其在对抗性提示下的安全性仍缺乏深入研究。

Method: 采用固定基准（726个专业红队编写的对抗性提示），分两个阶段对GPT-4o、Claude Sonnet 3.5、Pixtral 12B、Qwen VL Plus及其后续版本共8个模型进行评估，收集82,256条人工危害评级数据，分析攻击成功率（ASR）、拒绝率及模态效应变化。

Result: Pixtral系列模型最易受攻击，Claude系列因高拒绝率最安全；GPT和Claude模型代际间攻击成功率上升，Pixtral和Qwen略有下降；模态有效性随时间变化：Phase 1文本提示更有效，Phase 2各模型呈现模态特异性模式（如GPT-5与Claude 4.5跨模态脆弱性趋同）。

Conclusion: MLLM的安全性既不统一也不稳定，随模型更新可能发生不可预测的变化，亟需纵向、多模态的基准来持续追踪其安全行为演化。

Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red teamers. Phase 1 assessed GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus; Phase 2 evaluated their successors (GPT-5, Claude Sonnet 4.5, Pixtral Large, and Qwen Omni) yielding 82,256 human harm ratings. Large, persistent differences emerged across model families: Pixtral models were consistently the most vulnerable, whereas Claude models appeared safest due to high refusal rates. Attack success rates (ASR) showed clear alignment drift: GPT and Claude models exhibited increased ASR across generations, while Pixtral and Qwen showed modest decreases. Modality effects also shifted over time: text-only prompts were more effective in Phase 1, whereas Phase 2 produced model-specific patterns, with GPT-5 and Claude 4.5 showing near-equivalent vulnerability across modalities. These findings demonstrate that MLLM harmlessness is neither uniform nor stable across updates, underscoring the need for longitudinal, multimodal benchmarks to track evolving safety behaviour.

</details>


### [155] [Exploiting contextual information to improve stance detection in informal political discourse with LLMs](https://arxiv.org/abs/2602.04750)
*Arman Engin Sucu,Yixiang Zhou,Mario A. Nascimento,Tony Mullen*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型（LLMs）在非正式网络政治话语中进行立场检测的效果，发现引入基于用户历史发帖生成的结构化档案（含意识形态倾向、常讨论话题和语言模式）作为上下文提示，可显著提升准确率（+17.5%至+38.5%），最高达74%，且档案内容质量比规模更重要。


<details>
  <summary>Details</summary>
Motivation: 非正式在线政治话语常具讽刺性、歧义性和强语境依赖性，传统方法难以准确识别立场，亟需更有效的上下文建模方式。

Method: 基于真实政治论坛数据集构建用户结构化档案（意识形态、话题、语言模式），在七种主流LLM上对比基线与上下文增强设置，并分析档案规模与发帖选取策略的影响。

Result: 上下文提示显著提升所有模型准确率（+17.5%~+38.5%），最高达74%；精选政治相关内容优于随机扩大上下文规模。

Conclusion: 融入用户层级上下文（尤其是高质量、主题相关的档案信息）能有效增强LLM在复杂政治立场检测任务中的性能。

Abstract: This study investigates the use of Large Language Models (LLMs) for political stance detection in informal online discourse, where language is often sarcastic, ambiguous, and context-dependent. We explore whether providing contextual information, specifically user profile summaries derived from historical posts, can improve classification accuracy. Using a real-world political forum dataset, we generate structured profiles that summarize users' ideological leaning, recurring topics, and linguistic patterns. We evaluate seven state-of-the-art LLMs across baseline and context-enriched setups through a comprehensive cross-model evaluation. Our findings show that contextual prompts significantly boost accuracy, with improvements ranging from +17.5\% to +38.5\%, achieving up to 74\% accuracy that surpasses previous approaches. We also analyze how profile size and post selection strategies affect performance, showing that strategically chosen political content yields better results than larger, randomly selected contexts. These findings underscore the value of incorporating user-level context to enhance LLM performance in nuanced political classification tasks.

</details>


### [156] [When Silence Is Golden: Can LLMs Learn to Abstain in Temporal QA and Beyond?](https://arxiv.org/abs/2602.04755)
*Xinyu Zhou,Chang Jin,Carsten Eickhoff,Zhijiang Guo,Seyed Ali Bahrainian*

Main category: cs.CL

TL;DR: 本文提出了一种结合思维链监督与基于弃答感知奖励的强化学习（RL）方法，以提升大语言模型在时序问答任务中的弃答能力与推理可靠性；实验表明该方法显著优于监督微调（SFT），并在TimeQA基准上超越GPT-4o，同时揭示了SFT易导致过度自信、而隐式时序线索对弃答帮助有限等关键发现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在时序问答中常忽略时间敏感证据、混淆不同时期事实，且极少主动承认不确定性或选择弃答，影响其可靠性。现有校准方法难以可靠捕捉复杂推理中的不确定性，亟需系统研究如何训练模型具备可控弃答能力。

Method: 将弃答建模为可教学技能，设计融合思维链（CoT）监督与弃答感知奖励的强化学习训练流程；对比分析不同信息源（原始上下文、时序子上下文、知识图谱）及训练范式（SFT vs RL）对时序推理与弃答行为的影响。

Result: 基于Qwen2.5-1.5B-Instruct初始化的RL模型在TimeQA-Easy和Hard上的Exact Match分别比GPT-4o高3.46%和5.80%；在不可回答问题上的真阳性率较纯SFT模型提升20%；SFT引发过度自信，RL提升准确性但仍存风险；隐式时序线索对弃答帮助有限。

Conclusion: 弃答与推理可协同优化，RL框架比SFT更适于构建兼具高准确率与高可靠性的时序问答模型；本工作为开发能审慎作答的可信LLM提供了实证基础与方法路径。

Abstract: Large language models (LLMs) rarely admit uncertainty, often producing fluent but misleading answers, rather than abstaining (i.e., refusing to answer). This weakness is even evident in temporal question answering, where models frequently ignore time-sensitive evidence and conflate facts across different time-periods. In this paper, we present the first empirical study of training LLMs with an abstention ability while reasoning about temporal QA. Existing approaches such as calibration might be unreliable in capturing uncertainty in complex reasoning. We instead frame abstention as a teachable skill and introduce a pipeline that couples Chain-of-Thought (CoT) supervision with Reinforcement Learning (RL) guided by abstention-aware rewards. Our goal is to systematically analyze how different information types and training techniques affect temporal reasoning with abstention behavior in LLMs. Through extensive experiments studying various methods, we find that RL yields strong empirical gains on reasoning: a model initialized by Qwen2.5-1.5B-Instruct surpasses GPT-4o by $3.46\%$ and $5.80\%$ in Exact Match on TimeQA-Easy and Hard, respectively. Moreover, it improves the True Positive rate on unanswerable questions by $20\%$ over a pure supervised fine-tuned (SFT) variant. Beyond performance, our analysis shows that SFT induces overconfidence and harms reliability, while RL improves prediction accuracy but exhibits similar risks. Finally, by comparing implicit reasoning cues (e.g., original context, temporal sub-context, knowledge graphs) with explicit CoT supervision, we find that implicit information provides limited benefit for reasoning with abstention. Our study provides new insights into how abstention and reasoning can be jointly optimized, providing a foundation for building more reliable LLMs.

</details>


### [157] [Beyond Many-Shot Translation: Scaling In-Context Demonstrations For Low-Resource Machine Translation](https://arxiv.org/abs/2602.04764)
*Luis Frentzen Salim,Esteban Carlin,Alexandre Morinvil,Xi Ai,Lun-Wei Ku*

Main category: cs.CL

TL;DR: 本文研究了在低资源机器翻译中，利用长上下文大语言模型进行上下文学习（ICL）的效果，发现增加上下文长度带来的性能提升很快饱和，且不同语料类型（单语、指令式、平行语料）影响显著，单语数据有时可媲美平行数据。


<details>
  <summary>Details</summary>
Motivation: 低资源语言机器翻译面临高质量数据稀缺的挑战，尽管大语言模型有所改进，但适配小语种仍困难；上下文学习（ICL）提供了一种无需微调的适应新方式，但其在长上下文下的扩展性尚不明确。

Method: 将ICL扩展至千样本量级，使用高达100万token的长上下文窗口；对比三种监督语料类型——单语无监督数据、指令式数据、英-目标语及印尼语-目标语平行语料；在爪哇语和巽他语上开展实验。

Result: 性能增益随上下文增长快速饱和，接近最大上下文窗口时甚至下降；不同语料类型表现差异显著，部分单语监督效果可与平行语料相当；长上下文并不带来线性质量提升。

Conclusion: 长上下文ICL在低资源MT中存在有效上限，其性能高度依赖语料类型；盲目扩大上下文长度并非最优策略，需权衡语料质量与上下文规模。

Abstract: Building machine translation (MT) systems for low-resource languages is notably difficult due to the scarcity of high-quality data. Although Large Language Models (LLMs) have improved MT system performance, adapting them to lesser-represented languages remains challenging. In-context learning (ICL) may offer novel ways to adapt LLMs for low-resource MT by conditioning models on demonstration at inference time. In this study, we explore scaling low-resource machine translation ICL beyond the few-shot setting to thousands of examples with long-context models. We scale in-context token budget to 1M tokens and compare three types of training corpora used as in-context supervision: monolingual unsupervised data, instruction-style data, and parallel data (English--target and Indonesian--target). Our experiments on Javanese and Sundanese show that gains from additional context saturate quickly and can degrade near the maximum context window, with scaling behavior strongly dependent on corpus type. Notably, some forms of monolingual supervision can be competitive with parallel data, despite the latter offering additional supervision. Overall, our results characterize the effective limits and corpus-type sensitivity of long-context ICL for low-resource MT, highlighting that larger context windows do not necessarily yield proportional quality gains.

</details>


### [158] [OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models](https://arxiv.org/abs/2602.04804)
*Yue Ding,Yiyan Ji,Jungang Li,Xuyang Liu,Xinlong Chen,Junfei Wu,Bozhou Li,Bohan Zeng,Yang Shi,Yushuo Guan,Yuanxing Zhang,Jiaheng Liu,Qiang Liu,Pengfei Wan,Liang Wang*

Main category: cs.CL

TL;DR: 本文提出OmniSIFT，一种面向全模态大语言模型（Omni-LLMs）的模态不对称细粒度token压缩框架，通过时空视频剪枝与视觉引导音频选择两阶段策略，在显著减少token数量（仅25%上下文）的同时，保持甚至超越全token模型性能。


<details>
  <summary>Details</summary>
Motivation: Omni-LLMs在音视频理解中表现优异，但依赖长多模态token序列导致计算开销大，而专用于Omni-LLMs的token压缩方法仍十分缺乏。

Method: 提出OmniSIFT：第一阶段为时空视频剪枝模块，消除帧内结构与帧间重叠冗余；第二阶段为视觉引导音频选择模块，筛选音频tokens；整体采用可微直通估计器端到端优化。

Result: 在五个基准上验证有效；以仅4.85M参数开销，在Qwen2.5-Omni-7B上实现低于训练无关基线（如OmniZip）的延迟；仅用25%原始token即全面超越各压缩基线，并在多个任务上超过全token模型。

Conclusion: OmniSIFT是一种高效、轻量、无需额外训练的全模态token压缩方法，兼顾低延迟与高性能，为Omni-LLMs的实际部署提供了可行路径。

Abstract: Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator. Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.

</details>


### [159] [SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization](https://arxiv.org/abs/2602.04811)
*Jiarui Yuan,Tailin Jin,Weize Chen,Zeyuan Liu,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出SE-Bench诊断环境，用于评估AI代理在无文档支持下内化新知识的能力，并揭示了开卷训练抑制记忆、强化学习难以完全内化知识、以及自博弈结合监督微调可有效促进知识内化的三大发现。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以严格衡量AI代理的自我演化能力，主要受限于先验知识与新知识的纠缠，以及推理复杂度对评估结果的干扰。

Method: 构建SE-Bench诊断环境：将NumPy库及其文档混淆为具有随机标识符的伪新颖包；代理需在无文档访问条件下完成简单编码任务；对比开卷训练、闭卷训练、强化学习（PPO）及自博弈+SFT等不同训练范式的效果。

Result: 发现三个关键现象：(1) 开卷悖论——使用参考文档训练反而抑制知识保留，需闭卷训练迫使知识压缩进模型权重；(2) 强化学习鸿沟——标准PPO因裁剪和负梯度无法完全内化新知识；(3) 自博弈可行性——结合监督微调的自博弈可从自生成噪声任务中学习，而纯RL不可行。

Conclusion: SE-Bench为评估AI代理的知识内化与自我演化能力提供了严谨、解耦的诊断平台，并为提升模型长期学习能力指明了可行方向。

Abstract: True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring "Closed-Book Training" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.

</details>


### [160] [Decomposed Prompting Does Not Fix Knowledge Gaps, But Helps Models Say "I Don't Know"](https://arxiv.org/abs/2602.04853)
*Dhruv Madhwal,Lyuxin David Zhang,Dan Roth,Tomer Wolfson,Vivek Gupta*

Main category: cs.CL

TL;DR: 本文研究了分解式提示（decomposed prompting）对大语言模型在封闭式问答中可靠性的影响，发现跨提示范式的一致性可作为模型不确定性的精确信号，并据此提出了一种无需训练、无需检索的自动拒答策略，显著提升了错误检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在封闭式问答中常因无法识别自身知识边界而产生自信的幻觉（hallucination），现有分解式提示虽能提升准确率，但其对可靠性的贡献尚不明确。

Method: 评估三种等效任务的提示范式（Direct、Assistive、Incremental），分析其在不同模型规模和多跳QA基准上的准确性与一致性；利用跨范式分歧作为不确定性信号，设计无需训练的 abstention（拒答）策略。

Result: 前沿模型中分解提示的准确率增益减弱，但跨范式分歧仍高度预示错误；基于分歧的拒答策略在F1和AUROC上均优于标准不确定性基线。

Conclusion: 分解式提示可作为实用的诊断探针，用于评估和提升大语言模型在封闭式问答中的可靠性，且无需额外训练或检索。

Abstract: Large language models often struggle to recognize their knowledge limits in closed-book question answering, leading to confident hallucinations. While decomposed prompting is typically used to improve accuracy, we investigate its impact on reliability. We evaluate three task-equivalent prompting regimes: Direct, Assistive, and Incremental, across different model scales and multi-hop QA benchmarks. We find that although accuracy gains from decomposition diminish in frontier models, disagreements between prompting regimes remain highly indicative of potential errors. Because factual knowledge is stable while hallucinations are stochastic, cross-regime agreement provides a precise signal of internal uncertainty. We leverage this signal to implement a training-free abstention policy that requires no retrieval or fine-tuning. Our results show that disagreement-based abstention outperforms standard uncertainty baselines as an error detector, improving both F1 and AUROC across settings. This demonstrates that decomposition-based prompting can serve as a practical diagnostic probe for model reliability in closed-book QA.

</details>


### [161] [CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation](https://arxiv.org/abs/2602.04856)
*Zhao Tong,Chunlin Gong,Yiping Zhang,Qiang Liu,Xingcheng Xu,Shu Wu,Haichao Shi,Xiao-Yu Zhang*

Main category: cs.CL

TL;DR: 本文挑战了大语言模型（LLM）拒绝有害请求即代表推理安全的假设，发现即使模型拒绝生成假新闻，其思维链（CoT）中仍可能隐含并传播不安全叙事；为此提出一种基于雅可比谱分析的统一安全分析框架，定义稳定性、几何性与能量三个可解释指标，定位导致风险的关键注意力头，揭示风险集中于少数中层连续层。


<details>
  <summary>Details</summary>
Motivation: 现有评估通常假设模型拒绝有害请求即意味着整个推理过程安全，但该假设缺乏对内部推理路径（尤其是Chain-of-Thought）的安全验证；本文旨在揭示拒绝响应下潜在的不安全推理机制。

Method: 提出基于雅可比矩阵谱分析的统一安全分析框架，逐层解构思维链生成过程，量化各注意力头对欺骗性推理模式的响应与嵌入；定义三个可解释指标：稳定性（stability）、几何性（geometry）和能量（energy），用于刻画注意力头的行为；在多个推理型大模型上开展系统实验。

Result: 实验证明，当启用思维链模式时，生成风险显著上升，且关键风险路由决策高度集中在少数中深度连续层；通过所提指标可精准识别出负责该风险分歧的特定注意力头。

Conclusion: 模型拒绝请求并不等价于推理过程安全；需深入分析内部注意力机制以识别和缓解潜藏的推理风险；本工作为LLM安全评估提供了新视角与可解释工具。

Abstract: From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake news generation, even when a model rejects a harmful request, its Chain-of-Thought (CoT) reasoning may still internally contain and propagate unsafe narratives. To analyze this phenomenon, we introduce a unified safety-analysis framework that systematically deconstructs CoT generation across model layers and evaluates the role of individual attention heads through Jacobian-based spectral metrics. Within this framework, we introduce three interpretable measures: stability, geometry, and energy to quantify how specific attention heads respond or embed deceptive reasoning patterns. Extensive experiments on multiple reasoning-oriented LLMs show that the generation risk rise significantly when the thinking mode is activated, where the critical routing decisions concentrated in only a few contiguous mid-depth layers. By precisely identifying the attention heads responsible for this divergence, our work challenges the assumption that refusal implies safety and provides a new understanding perspective for mitigating latent reasoning risks.

</details>


### [162] [Reinforced Attention Learning](https://arxiv.org/abs/2602.04884)
*Bangzheng Li,Jianmo Ni,Chen Qu,Ian Miao,Liu Yang,Xingyu Fu,Muhao Chen,Derek Zhiyuan Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为Reinforced Attention Learning (RAL)的新方法，通过直接优化多模态大语言模型（MLLMs）内部的注意力分布，而非输出文本序列，从而提升其在图像和视频任务上的感知与跨模态对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的后训练方法在多模态大语言模型上效果有限，尤其在感知任务中增益小甚至性能下降，原因在于依赖冗长推理文本，难以有效建模多模态输入中的信息分配与对齐。

Method: 提出RAL框架：一种基于策略梯度的注意力优化方法，直接优化模型内部注意力权重；并引入On-Policy Attention Distillation，将学习到的注意力行为进行蒸馏以增强跨模态对齐。

Result: 在多个图像与视频基准上显著优于GRPO等基线；注意力蒸馏比标准知识蒸馏带来更强的跨模态对齐效果。

Conclusion: 注意力策略可作为多模态后训练的一种原理清晰、通用性强的新范式，替代传统基于输出序列的RL优化方式。

Abstract: Post-training with Reinforcement Learning (RL) has substantially improved reasoning in Large Language Models (LLMs) via test-time scaling. However, extending this paradigm to Multimodal LLMs (MLLMs) through verbose rationales yields limited gains for perception and can even degrade performance.
  We propose Reinforced Attention Learning (RAL), a policy-gradient framework that directly optimizes internal attention distributions rather than output token sequences. By shifting optimization from what to generate to where to attend, RAL promotes effective information allocation and improved grounding in complex multimodal inputs. Experiments across diverse image and video benchmarks show consistent gains over GRPO and other baselines. We further introduce On-Policy Attention Distillation, demonstrating that transferring latent attention behaviors yields stronger cross-modal alignment than standard knowledge distillation. Our results position attention policies as a principled and general alternative for multimodal post-training.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [163] [Nemotron ColEmbed V2: Top-Performing Late Interaction embedding models for Visual Document Retrieval](https://arxiv.org/abs/2602.03992)
*Gabriel de Souza P. Moreira,Ronay Ak,Mengyao Xu,Oliver Holworthy,Benedikt Schifferer,Zhiding Yu,Yauhen Babakhin,Radek Osmulski,Jiarui Cai,Ryan Chesler,Bo Liu,Even Oldridge*

Main category: cs.IR

TL;DR: 本文介绍了Nemotron ColEmbed V2系列视觉语言嵌入模型，专为视觉文档检索设计，在ViDoRe基准上达到SOTA性能；通过多种训练与工程优化技术（如聚类采样、难负例挖掘、晚交互等）提升效果，并探讨了精度与存储的权衡。


<details>
  <summary>Details</summary>
Motivation: 应对日益增长的视觉文档检索需求，克服传统OCR文本提取流程复杂、丢失视觉信息的问题，利用VLM嵌入模型直接建模图文联合表征。

Method: 基于预训练VLM（NVIDIA Eagle 2、Qwen3-VL）构建3B/4B/8B三款ColEmbed V2模型；采用聚类采样、难负例挖掘、双向注意力、晚交互机制及模型融合等关键技术；针对晚交互带来的计算与存储挑战，探索低维嵌入下的精度-存储平衡。

Result: Nemotron ColEmbed V2-8B在ViDoRe V3榜单（截至2026年2月3日）排名第一，平均NDCG@10达63.42；三款模型均在ViDoRe基准上实现SOTA性能。

Conclusion: Nemotron ColEmbed V2验证了专用VLM嵌入模型在视觉文档检索中的有效性，其架构与训练策略为密集检索系统提供了可复现、可扩展的技术路径，并兼顾实际部署中的工程可行性。

Abstract: Retrieval-Augmented Generation (RAG) systems have been popular for generative applications, powering language models by injecting external knowledge. Companies have been trying to leverage their large catalog of documents (e.g. PDFs, presentation slides) in such RAG pipelines, whose first step is the retrieval component. Dense retrieval has been a popular approach, where embedding models are used to generate a dense representation of the user query that is closer to relevant content embeddings. More recently, VLM-based embedding models have become popular for visual document retrieval, as they preserve visual information and simplify the indexing pipeline compared to OCR text extraction.
  Motivated by the growing demand for visual document retrieval, we introduce Nemotron ColEmbed V2, a family of models that achieve state-of-the-art performance on the ViDoRe benchmarks. We release three variants - with 3B, 4B, and 8B parameters - based on pre-trained VLMs: NVIDIA Eagle 2 with Llama 3.2 3B backbone, Qwen3-VL-4B-Instruct and Qwen3-VL-8B-Instruct, respectively. The 8B model ranks first on the ViDoRe V3 leaderboard as of February 03, 2026, achieving an average NDCG@10 of 63.42.
  We describe the main techniques used across data processing, training, and post-training - such as cluster-based sampling, hard-negative mining, bidirectional attention, late interaction, and model merging - that helped us build our top-performing models. We also discuss compute and storage engineering challenges posed by the late interaction mechanism and present experiments on how to balance accuracy and storage with lower dimension embeddings.

</details>


### [164] [Following the TRAIL: Predicting and Explaining Tomorrow's Hits with a Fine-Tuned LLM](https://arxiv.org/abs/2602.04225)
*Yinan Zhang,Zhixi Chen,Jiazheng Jing,Zhiqi Shen*

Main category: cs.IR

TL;DR: TRAIL is a fine-tuned LLM that jointly predicts short-term item popularity and generates faithful natural-language explanations for recommendations, using contrastive learning to align scores and explanations with trend signals.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with extracting user preferences from sparse logs and real-time full-catalog ranking; existing recommenders often lack explanations that improve accuracy and user trust.

Method: TRAIL is a fine-tuned LLM that jointly models short-term item popularity prediction and explanation generation, using contrastive learning on positive/negative pairs aligned with structured trend signals.

Result: TRAIL outperforms strong baselines in recommendation accuracy and generates coherent, well-grounded natural-language explanations.

Conclusion: Jointly modeling popularity trends and explanations via fine-tuned LLMs with contrastive learning yields both accurate and interpretable recommendations.

Abstract: Large Language Models (LLMs) have been widely applied across multiple domains for their broad knowledge and strong reasoning capabilities. However, applying them to recommendation systems is challenging since it is hard for LLMs to extract user preferences from large, sparse user-item logs, and real-time per-user ranking over the full catalog is too time-consuming to be practical. Moreover, many existing recommender systems focus solely on ranking items while overlooking explanations, which could help improve predictive accuracy and make recommendations more convincing to users. Inspired by recent works that achieve strong recommendation performance by forecasting near-term item popularity, we propose TRAIL (TRend and explAnation Integrated Learner). TRAIL is a fine-tuned LLM that jointly predicts short-term item popularity and generates faithful natural-language explanations. It employs contrastive learning with positive and negative pairs to align its scores and explanations with structured trend signals, yielding accurate and explainable popularity predictions. Extensive experiments show that TRAIL outperforms strong baselines and produces coherent, well-grounded explanations.

</details>


### [165] [LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval](https://arxiv.org/abs/2602.04263)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: 本文提出LILaC框架，通过分层组件图和基于子图的延迟交互检索方法，解决多模态文档检索中无关内容干扰与多跳推理难题，在五个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态文档检索面临两大挑战：一是固定单一粒度检索单元导致的无关内容干扰；二是需支持跨文档及文档内部组件间的多跳语义推理。

Method: 提出LILaC框架，包含两个核心创新：（1）分层组件图，显式建模粗粒度与细粒度两层多模态信息；（2）基于边的延迟交互子图检索方法，先用粗粒度节点高效生成候选，再通过延迟交互进行细粒度推理。

Result: 在全部五个基准测试中均达到最优检索性能，且无需额外微调。

Conclusion: LILaC有效缓解了无关内容干扰并增强了多跳推理能力，验证了分层建模与延迟交互策略在多模态检索中的有效性。

Abstract: Multimodal document retrieval aims to retrieve query-relevant components from documents composed of textual, tabular, and visual elements. An effective multimodal retriever needs to handle two main challenges: (1) mitigate the effect of irrelevant contents caused by fixed, single-granular retrieval units, and (2) support multihop reasoning by effectively capturing semantic relationships among components within and across documents. To address these challenges, we propose LILaC, a multimodal retrieval framework featuring two core innovations. First, we introduce a layered component graph, explicitly representing multimodal information at two layers - each representing coarse and fine granularity - facilitating efficient yet precise reasoning. Second, we develop a late-interaction-based subgraph retrieval method, an edge-based approach that initially identifies coarse-grained nodes for efficient candidate generation, then performs fine-grained reasoning via late interaction. Extensive experiments demonstrate that LILaC achieves state-of-the-art retrieval performance on all five benchmarks, notably without additional fine-tuning. We make the artifacts publicly available at github.com/joohyung00/lilac.

</details>


### [166] [MiniRec: Data-Efficient Reinforcement Learning for LLM-based Recommendation](https://arxiv.org/abs/2602.04278)
*Lin Wang,Yang Zhang,Jingfan Chen,Xiaoyan Zhao,Fengbin Zhu,Qing Li,Tat-Seng Chua*

Main category: cs.IR

TL;DR: 本文提出MiniRec框架，针对基于强化学习（RL）的大语言模型（LLM）推荐系统中的数据选择问题，利用奖励信号评估样本可学性、基于近似全局优化轨迹对齐梯度评估代表性，并引入多样性约束与课程学习策略，显著降低训练成本且保持性能。


<details>
  <summary>Details</summary>
Motivation: RL-based LLM推荐面临全量数据训练效率低下的挑战，现有数据选择方法因标准与RL学习动态不一致而效果不佳。

Method: MiniRec框架：1）基于奖励信号剪枝过易（高奖励）或过难（持续低奖励）样本；2）通过样本梯度与近似全局RL优化轨迹对齐评估代表性；3）引入多样性约束减少冗余；4）结合从易到难的课程学习策略。

Result: 在多个实验中，MiniRec显著降低了训练成本，同时基本保持了推荐性能，验证了奖励对齐与轨迹感知的数据选择的重要性。

Conclusion: MiniRec为RL-based LLM推荐提供了高效、鲁棒的数据选择新范式，强调需紧扣RL内在学习机制设计数据选择策略。

Abstract: The integration of reinforcement learning (RL) into large language models (LLMs) has opened new opportunities for recommender systems by eliciting reasoning and improving user preference modeling. However, RL-based LLM recommendation faces significant efficiency challenges, making full-data training costly. Existing data selection methods define sample value based on learnability or representativeness, yet their loss- or gradient-driven or dataset coverage-driven criteria often misalign with RL learning dynamics, resulting in suboptimal performance. To address this, we propose MiniRec, a data selection framework tailored for RL-based LLM recommendation. MiniRec evaluates sample learnability using key RL signals -- rewards -- pruning samples that are too easy (too high reward) or too difficult (consistently low reward). It assesses representativeness by aligning sample gradients with the approximated "ideal" global RL optimization trajectory, selecting samples that mainly drive model updates, and it also enforces diversity to reduce redundancy. Combined with a curriculum learning strategy from easy to hard samples, MiniRec significantly reduces training cost while largely preserving performance. Extensive experiments demonstrate MiniRec's effectiveness, highlighting the importance of reward-aligned, trajectory-informed data selection in RL-based LLM recommendation.

</details>


### [167] [SDR-CIR: Semantic Debias Retrieval Framework for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.04451)
*Yi Sun,Jinyu Xu,Qing Xie,Jiachen Li,Yanchun Ma,Yongjian Liu*

Main category: cs.IR

TL;DR: 本文提出了一种无需训练的语义去偏排序方法SDR-CIR，用于提升零样本组合图像检索（ZS-CIR）性能，通过选择性链式推理和两阶段语义去偏机制缓解生成描述中的语义偏差。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合图像检索方法依赖多模态大模型生成目标图像描述，但模糊匹配易导致生成描述与真实目标图像存在语义偏差。

Method: 提出SDR-CIR方法：1）Selective CoT引导MLLM在理解参考图像时聚焦于修改文本相关的视觉内容；2）Semantic Debias Ranking包含Anchor（融合参考图像与目标描述特征）和Debias（建模参考图像对描述的视觉语义贡献并作为相似度惩罚项）两步。

Result: 在三个标准CIR基准上达到单阶段方法最优性能，同时保持高效率。

Conclusion: SDR-CIR通过源头降噪与显式语义去偏，有效缓解零样本CIR中的语义偏差问题，显著提升检索准确率与鲁棒性。

Abstract: Composed Image Retrieval (CIR) aims to retrieve a target image from a query composed of a reference image and modification text. Recent training-free zero-shot methods often employ Multimodal Large Language Models (MLLMs) with Chain-of-Thought (CoT) to compose a target image description for retrieval. However, due to the fuzzy matching nature of ZS-CIR, the generated description is prone to semantic bias relative to the target image. We propose SDR-CIR, a training-free Semantic Debias Ranking method based on CoT reasoning. First, Selective CoT guides the MLLM to extract visual content relevant to the modification text during image understanding, thereby reducing visual noise at the source. We then introduce a Semantic Debias Ranking with two steps, Anchor and Debias, to mitigate semantic bias. In the Anchor step, we fuse reference image features with target description features to reinforce useful semantics and supplement omitted cues. In the Debias step, we explicitly model the visual semantic contribution of the reference image to the description and incorporate it into the similarity score as a penalty term. By supplementing omitted cues while suppressing redundancy, SDR-CIR mitigates semantic bias and improves retrieval performance. Experiments on three standard CIR benchmarks show that SDR-CIR achieves state-of-the-art results among one-stage methods while maintaining high efficiency. The code is publicly available at https://github.com/suny105/SDR-CIR.

</details>


### [168] [DOS: Dual-Flow Orthogonal Semantic IDs for Recommendation in Meituan](https://arxiv.org/abs/2602.04460)
*Junwei Yin,Senjie Kou,Changhao Li,Shuli Wang,Xue Wei,Yinqiu Huang,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.IR

TL;DR: 本文提出Dual-Flow Orthogonal Semantic IDs (DOS)方法，通过用户-物品双流框架对齐语义ID码本空间与生成空间，并引入正交残差量化提升语义保留，显著改善生成式推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有语义ID方法存在上下文感知不足导致码本空间与生成空间不一致、以及量化方式次优加剧语义损失两大问题。

Method: 提出DOS方法：1）用户-物品双流框架，利用协同信号对齐语义ID码本空间与生成空间；2）正交残差量化方案，旋转语义空间以最大化语义保留。

Result: 离线实验和在线A/B测试验证了DOS有效性，已在美团App部署，服务数亿用户。

Conclusion: DOS有效缓解了语义ID在生成式推荐中的空间错配与语义损失问题，提升了推荐性能与实用性。

Abstract: Semantic IDs serve as a key component in generative recommendation systems. They not only incorporate open-world knowledge from large language models (LLMs) but also compress the semantic space to reduce generation difficulty. However, existing methods suffer from two major limitations: (1) the lack of contextual awareness in generation tasks leads to a gap between the Semantic ID codebook space and the generation space, resulting in suboptimal recommendations; and (2) suboptimal quantization methods exacerbate semantic loss in LLMs. To address these issues, we propose Dual-Flow Orthogonal Semantic IDs (DOS) method. Specifically, DOS employs a user-item dual flow-framework that leverages collaborative signals to align the Semantic ID codebook space with the generation space. Furthermore, we introduce an orthogonal residual quantization scheme that rotates the semantic space to an appropriate orientation, thereby maximizing semantic preservation. Extensive offline experiments and online A/B testing demonstrate the effectiveness of DOS. The proposed method has been successfully deployed in Meituan's mobile application, serving hundreds of millions of users.

</details>


### [169] [VK-LSVD: A Large-Scale Industrial Dataset for Short-Video Recommendation](https://arxiv.org/abs/2602.04567)
*Aleksandr Poslavsky,Alexander D'yakonov,Yuriy Dorn,Andrey Zimovnov*

Main category: cs.IR

TL;DR: 本文介绍了VK-LSVD，一个大规模开源短视频推荐数据集，包含400亿用户交互、1000万用户和近2000万视频，旨在推动序列推荐、冷启动等方向的研究。


<details>
  <summary>Details</summary>
Motivation: 现有短视频推荐研究受限于缺乏反映真实平台动态的大规模开放数据集，难以建模用户兴趣的快速变化。

Method: 构建并发布VK Large Short-Video Dataset（VK-LSVD），涵盖6个月内超400亿交互、丰富的内容嵌入、多类型反馈信号与上下文元数据，并进行质量与多样性分析。

Result: VK-LSVD成为VK RecSys Challenge 2025的核心数据集，验证了其实际影响力；分析表明该数据集具备高质量与高多样性。

Conclusion: VK-LSVD为短视频推荐研究提供了关键的开放基准资源，有助于加速序列推荐、冷启动及新一代推荐系统的发展。

Abstract: Short-video recommendation presents unique challenges, such as modeling rapid user interest shifts from implicit feedback, but progress is constrained by a lack of large-scale open datasets that reflect real-world platform dynamics. To bridge this gap, we introduce the VK Large Short-Video Dataset (VK-LSVD), the largest publicly available industrial dataset of its kind. VK-LSVD offers an unprecedented scale of over 40 billion interactions from 10 million users and almost 20 million videos over six months, alongside rich features including content embeddings, diverse feedback signals, and contextual metadata. Our analysis supports the dataset's quality and diversity. The dataset's immediate impact is confirmed by its central role in the live VK RecSys Challenge 2025. VK-LSVD provides a vital, open dataset to use in building realistic benchmarks to accelerate research in sequential recommendation, cold-start scenarios, and next-generation recommender systems.

</details>


### [170] [AIANO: Enhancing Information Retrieval with AI-Augmented Annotation](https://arxiv.org/abs/2602.04579)
*Sameh Khattab,Marie Bauer,Lukas Heine,Till Rostalski,Jens Kleesiek,Julian Friedrich*

Main category: cs.IR

TL;DR: 本文介绍了AIANO，一个专为信息检索数据集标注设计的AI增强型标注工具，通过整合人类专家与大语言模型（LLM）的协作，显著提升了标注速度、易用性和检索准确性。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索数据集依赖通用标注工具，导致标注过程复杂低效，亟需更高效、高质量的专用标注方案。

Method: 开发了AIANO工具，采用AI增强型标注流程，将人类判断与LLM建议紧密结合；并通过n=15的被试内用户研究，对比其与基线工具在标注速度、易用性和检索准确率上的表现。

Result: AIANO使标注速度接近翻倍，同时提升易用性与检索准确率。

Conclusion: AIANO验证了AI增强人工标注范式在信息检索数据集构建中的有效性，可推动检索密集型领域的标注能力进步。

Abstract: The rise of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) has rapidly increased the need for high-quality, curated information retrieval datasets. These datasets, however, are currently created with off-the-shelf annotation tools that make the annotation process complex and inefficient. To streamline this process, we developed a specialized annotation tool - AIANO. By adopting an AI-augmented annotation workflow that tightly integrates human expertise with LLM assistance, AIANO enables annotators to leverage AI suggestions while retaining full control over annotation decisions. In a within-subject user study ($n = 15$), participants created question-answering datasets using both a baseline tool and AIANO. AIANO nearly doubled annotation speed compared to the baseline while being easier to use and improving retrieval accuracy. These results demonstrate that AIANO's AI-augmented approach accelerates and enhances dataset creation for information retrieval tasks, advancing annotation capabilities in retrieval-intensive domains.

</details>


### [171] [Multi-Source Retrieval and Reasoning for Legal Sentencing Prediction](https://arxiv.org/abs/2602.04690)
*Junjie Chen,Haitao Li,Qilei Zhang,Zhenghua Li,Ya Zhang,Quan Zhou,Cheng Luo,Yiqun Liu,Dongsheng Guo,Qingyao Ai*

Main category: cs.IR

TL;DR: 本文提出MSR²框架，结合多源检索、大模型推理与强化学习，提升法律量刑预测（LSP）的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在法律条文和罪名预测上表现良好，但量刑预测因需细粒度客观知识与灵活主观推理而仍具挑战。

Method: 提出MSR²框架，融合多源检索、大语言模型（LLM）的推理能力及面向过程的强化学习奖励机制，以引导中间推理步骤。

Result: 在两个真实数据集上的实验表明，MSR²显著提升量刑预测的准确率与可解释性。

Conclusion: MSR²为实用化法律AI提供了新思路，推动法律判决预测向更可靠、可解释方向发展。

Abstract: Legal judgment prediction (LJP) aims to predict judicial outcomes from case facts and typically includes law article, charge, and sentencing prediction. While recent methods perform well on the first two subtasks, legal sentencing prediction (LSP) remains difficult due to its need for fine-grained objective knowledge and flexible subjective reasoning. To address these limitations, we propose $MSR^2$, a framework that integrates multi-source retrieval and reasoning in LLMs with reinforcement learning. $MSR^2$ enables LLMs to perform multi-source retrieval based on reasoning needs and applies a process-level reward to guide intermediate subjective reasoning steps. Experiments on two real-world datasets show that $MSR^2$ improves both accuracy and interpretability in LSP, providing a promising step toward practical legal AI. Our code is available at https://anonymous.4open.science/r/MSR2-FC3B.

</details>


### [172] [Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention](https://arxiv.org/abs/2602.04711)
*Sagie Dekel,Moshe Tennenholtz,Oren Kurland*

Main category: cs.IR

TL;DR: 本文提出了一种名为SDAG的新型RAG防御方法，通过引入块稀疏注意力机制禁止检索文档间的交叉注意力，以抵御语料知识投毒攻击，且无需微调或架构修改，在多种攻击策略下显著降低攻击成功率，并能与现有SOTA防御方法有效结合提升性能。


<details>
  <summary>Details</summary>
Motivation: RAG虽能提升LLM响应的时效性和减少幻觉，但易受语料知识投毒攻击——攻击者向检索语料注入误导性文档以操纵LLM输出；标准因果注意力机制会引发有害的跨文档交互，加剧该漏洞。

Method: 提出Sparse Document Attention RAG（SDAG），一种块稀疏注意力机制，禁止不同检索文档之间的交叉注意力；仅需在推理时修改注意力掩码，无需微调或模型结构改动。

Result: 在基于LLM的问答任务中，SDAG显著降低了各类知识投毒攻击的成功率；与当前最优RAG防御方法结合后，性能在统计上显著优于单独使用这些方法。

Conclusion: SDAG是一种轻量、即插即用的RAG防御机制，能有效缓解跨文档干扰导致的知识投毒风险，且具备良好的兼容性和实用性。

Abstract: Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to steer an LLMs' output to an undesired response. We argue that the standard causal attention mechanism in LLMs enables harmful cross-document interactions, specifically in cases of attacks. Accordingly, we introduce a novel defense approach for RAG: Sparse Document Attention RAG (SDAG). This is a block-sparse attention mechanism that disallows cross-attention between retrieved documents. SDAG requires a minimal inference-time change to the attention mask; furthermore, no fine-tuning or additional architectural changes are needed. We present an empirical evaluation of LLM-based question answering (QA) with a variety of attack strategies on RAG. We show that our SDAG method substantially outperforms the standard causal attention mechanism in terms of attack success rate. We further demonstrate the clear merits of integrating SDAG with state-of-the-art RAG defense methods. Specifically, the integration results in performance that is statistically significantly better than the state-of-the-art.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [173] [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900)
*Erik Goh,John Kos,Ashok Goel*

Main category: cs.AI

TL;DR: 本文提出将认知科学中的Task-Method-Knowledge（TMK）框架用于提升大语言模型（LLM）的推理与规划能力，尤其在符号化、结构化任务（如Blocksworld）中显著提升性能（从31.5%提升至97.3%），表明TMK不仅提供上下文，还能引导模型切换至形式化、可执行的推理路径。


<details>
  <summary>Details</summary>
Motivation: LLM在推理与规划任务中表现不足，现有提示方法（如CoT）的有效性受到质疑；受认知与教育科学启发，探索TMK框架是否能更本质地增强LLM的因果、目的与层级推理能力。

Method: 将TMK框架融入提示设计，强调任务分解、方法选择与知识依据（含‘为何做’），并在PlanBench基准（特别是Blocksworld领域）上进行实证评估。

Result: TMK提示使推理模型在难解的符号任务（PlanBench随机Blocksworld）中准确率从31.5%跃升至97.3%，并观察到显著的性能反转现象，表明其能激活模型的形式化与代码执行式推理路径。

Conclusion: TMK不仅是辅助上下文，更是一种引导LLM脱离默认语言模式、转向结构化、可验证推理机制的有效框架，为提升LLM符号推理能力提供了新范式。

Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.

</details>


### [174] [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950)
*Aditya Basarkar,Benyamin Tabarsi,Tiffany Barnes,Dongkuan,Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Iteratively Improved Program Construction (IIPC)的新方法，通过迭代优化程序化推理链，并结合执行反馈与大语言模型的思维链能力，以提升数学问题求解的准确性和可修正性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体的大语言模型系统在数学推理中缺乏可可靠修订的推理过程表示，且易受程序上下文干扰，导致错误难以识别和修正。

Method: 提出IIPC方法，迭代地改进程序化推理链，将执行反馈与基础大语言模型的Chain-of-thought能力相结合，保持高层语义聚焦。

Result: IIPC在多个基础大语言模型上的多数数学推理基准测试中超越了现有方法。

Conclusion: IIPC有效提升了数学问题求解的可靠性与可修正性，为需要符号推理的教育、科学与工程应用提供了更稳健的AI推理框架。

Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.

</details>


### [175] [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)
*Yinyi Luo,Yiqiao Jin,Weichen Yu,Mengqi Zhang,Srijan Kumar,Xiaoxiao Li,Weijie Xu,Xin Chen,Jindong Wang*

Main category: cs.AI

TL;DR: 本文提出AgentArk框架，通过分层知识蒸馏将多智能体系统的推理能力压缩到单个大语言模型中，在保持高效推理的同时获得多智能体的强推理与自纠错能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型多智能体系统虽推理性能优越，但存在计算开销高和错误传播问题，限制了实际部署。

Method: 提出三种分层蒸馏策略：推理增强微调、轨迹增强数据增广、过程感知蒸馏，将多智能体动态（如辩论过程）蒸馏至单模型权重中，将测试时显式交互转为隐式模型能力。

Result: 蒸馏后的单模型在保持单智能体推理效率的同时，展现出接近多智能体的推理、自我修正能力，并在多种推理任务上表现出更强鲁棒性与泛化性。

Conclusion: AgentArk为构建高效、鲁棒的多智能体系统提供了新范式，推动多智能体能力向单模型高效迁移。

Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.

</details>


### [176] [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Active Epistemic Control (AEC)的新方法，用于在部分可观测交互环境中进行高效、可靠的规划。AEC通过分离‘已确证事实库’与‘信念库’，结合主动查询与模拟预测，并引入严格可行性验证机制，显著减少重规划次数，同时保持高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测的交互环境中，关键前提条件（如物体位置或容器状态）往往未知，而盲目交互成本高；虽可借助学习的世界模型预测缺失信息，但预测错误可能导致不可行的决策承诺。

Method: 提出Active Epistemic Control（AEC）框架：维护两个独立存储——仅用于最终承诺的‘已确证事实库’和仅用于剪枝的‘信念库’；根据不确定性程度动态选择环境查询或信念模拟；最终承诺需满足已确证前提全覆盖及SQ-BCP兼容性检查。

Result: 在ALFWorld和ScienceWorld基准上，AEC在任务成功率上媲美强LLM智能体基线，同时显著减少重规划轮次。

Conclusion: AEC通过严格区分信念与承诺、引入主动感知与形式化可行性保障，在不牺牲可靠性前提下提升了部分可观测规划的效率与鲁棒性。

Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \emph{grounded fact store} used for commitment and a \emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.

</details>


### [177] [Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure](https://arxiv.org/abs/2602.03975)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 本文提出了一种面向验证成本受限场景的推理中状态级选择性验证框架，通过可行性门控、预验证排序与基于局部不确定性的自适应验证分配，在减少44%验证调用的同时，在MATH基准上超越了best-of-N、多数投票和束搜索等方法。


<details>
  <summary>Details</summary>
Motivation: 测试时计算已成为大语言模型推理进步的主要驱动力，但昂贵的验证过程正成为瓶颈；大量验证调用被浪费在冗余或无前景的中间假设上。

Method: 提出状态级选择性验证框架，包含三部分：(i) 基于结构化动作接口的确定性可行性门控；(ii) 结合学习到的状态距离与残差打分的预验证排序；(iii) 基于局部不确定性的验证调用自适应分配。

Result: 在MATH基准上，相比best-of-N、多数投票和束搜索，该方法在使用44%更少验证调用的情况下取得更高准确率。

Conclusion: 验证资源应分配在最具信息量的中间状态上，而非均匀或仅在最终解层面进行；所提框架实现了更高效、更精准的推理验证。

Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\% fewer verifier calls.

</details>


### [178] [Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning](https://arxiv.org/abs/2602.03978)
*Zidi Xiong,Shan Chen,Himabindu Lakkaraju*

Main category: cs.AI

TL;DR: 本文系统评估了大推理模型（LRMs）在强化学习与可验证奖励（RLVR）训练中链式思维（CoT）可监控性（monitorability）的出现机制，发现其提升高度依赖数据多样性与指令遵循数据，且与模型能力无必然关联；机制上主要源于响应分布锐化和对提示的关注增强，而非对推理路径的更强因果依赖。


<details>
  <summary>Details</summary>
Motivation: 随着大推理模型（LRMs）部署增多，审计其链式思维（CoT）以保障安全变得关键；而近期观察到的‘可监控性作为免费赠礼’现象缺乏系统验证与机理阐释。

Method: 通过跨模型家族与训练领域的系统性实验评估，结合控制变量（如数据多样性、指令遵循数据、训练/评估难度），并开展机制分析（响应熵、注意力分布、因果依赖性检验）。

Result: 可监控性提升并非普遍现象，而是强数据依赖；数据多样性与指令遵循数据起关键作用；可监控性与模型推理能力正交；机制上主因是响应分布锐化和提示注意力增强，而非对CoT的更强因果依赖；其动态变化随训练与评估难度可控变化。

Conclusion: 可监控性在RLVR中并非自动涌现，其出现有明确前提条件与内在机制；需针对性设计训练数据与目标，不能默认其随能力提升而提升；该发现为安全驱动的LRM可解释性工程提供了实证基础与实践指导。

Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a "free gift" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.

</details>


### [179] [When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making](https://arxiv.org/abs/2602.04003)
*Shutong Fan,Lan Zhang,Xiaoyong Yuan*

Main category: cs.AI

TL;DR: 本文提出对抗性解释攻击（AEAs），通过操纵大语言模型生成的解释来影响人类对错误AI输出的信任，揭示了AI与用户之间认知层的新攻击面。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统越来越多地嵌入人类决策环路中，而大语言模型生成的自然语言解释会影响用户对AI输出的信任，因此存在一个尚未被系统研究的认知层攻击面。

Method: 定义了信任误校准差距作为衡量指标，并通过控制实验（n=205）系统改变解释框架的四个维度（推理模式、证据类型、沟通风格、呈现格式）来评估AEAs的影响。

Result: 实验表明，用户对对抗性与良性解释的信任度几乎相同；最易受攻击的情形是AEAs模仿专家沟通风格（权威证据、中性语气、领域适配推理），且在困难任务、事实驱动领域及教育程度较低、较年轻或更信任AI的用户中尤为显著。

Conclusion: 这是首个将解释视为对抗性认知通道并量化其对AI辅助决策中人类信任影响的安全研究，揭示了AI可解释性在安全层面的重要风险。

Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.

</details>


### [180] [Axiomatic Foundations of Counterfactual Explanations](https://arxiv.org/abs/2602.04028)
*Leila Amgoud,Martin Cooper*

Main category: cs.AI

TL;DR: 本文提出了一种基于公理化框架的反事实解释方法，系统性地定义并分类了五种根本不同的反事实解释类型（含局部与全局），证明了若干不可能性定理，并建立了公理子集与解释器家族之间的一一对应关系，同时对现有解释器进行了形式化定位与复杂度分析。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释器大多局限于单一类型和局部解释，缺乏对反事实类型多样性和全局解释的系统研究。

Method: 构建一套具有可取性质的公理化框架，通过证明不可能性定理和表示定理，刻画满足不同公理组合的解释器家族，并据此分类反事实解释类型。

Result: 发现了五种本质上不同的反事实解释类型（部分为局部、部分为全局）；建立了公理子集与解释器家族的一一对应；对现有解释器进行了形式化归类与计算复杂度分析。

Conclusion: 单一解释器无法满足所有理想公理，必须在不同类型间权衡；该框架为反事实解释提供了统一、可扩展且理论严谨的分类与设计基础。

Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.
  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.

</details>


### [181] [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)
*Xiaofeng Lin,Sirou Zhu,Yilei Chen,Mingyu Chen,Hejian Sang,Ioannis Paschalidis,Zhipeng Wang,Aldo Pacchiano,Xuezhou Zhang*

Main category: cs.AI

TL;DR: 本文提出ORBIT框架，通过多任务、多回合的元强化学习训练大语言模型（LLM），使其能在推理时从上下文中高效进行在线学习，在未见过的动态环境中显著提升性能，甚至媲美GPT-5.2。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在需交互获取信息、延迟反馈和权衡探索与利用的在线决策任务中表现不佳，难以可靠利用上下文中的交互经验。

Method: 提出ORBIT——一种多任务、多回合的元强化学习框架，用于训练LLM在上下文中学习交互经验；以Qwen3-14B等开源模型为基座开展元训练。

Result: 经ORBIT训练后，Qwen3-14B在全新在线环境中实现显著提升，性能匹敌GPT-5.2，大幅超越标准RL微调；扩展实验表明性能随模型规模持续提升。

Conclusion: 通过专门训练可有效增强LLM在推理时的在线学习能力，为构建具备实时适应能力的决策智能体提供了可行路径与明显提升空间。

Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.

</details>


### [182] [Interfaze: The Future of AI is built on Task-Specific Small Models](https://arxiv.org/abs/2602.04101)
*Harsha Vardhan Khurdula,Vineet Agarwal,Yoeven D Khemlani*

Main category: cs.AI

TL;DR: Interfaze是一种新型LLM应用架构，通过分层设计（感知模块、上下文构建层、动作层）将任务分解为小模型与工具协同处理，大幅降低对大模型的依赖，在多项基准测试中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM应用过度依赖单一巨型模型，导致计算成本高、灵活性差；而真实场景需处理多模态输入（PDF、图表、语音）、动态外部信息和复杂动作，亟需更高效、模块化的系统设计。

Method: 提出Interfaze系统：（i）异构DNN+小型语言模型作为感知模块处理OCR、图表理解、多语种ASR；（ii）上下文构建层爬取、索引并结构化外部数据；（iii）动作层支持网页浏览、代码执行、头less浏览器操作；顶层轻量控制器调度各组件，并将蒸馏后的上下文交由用户选定的LLM生成最终响应。

Result: Interfaze-Beta在MMLU-Pro（83.6%）、MMLU（91.4%）、GPQA-Diamond（81.3%）、LiveCodeBench v5（57.8%）、AIME-2025（90.0%）及多模态任务MMMU（77.3%）、AI2D（91.5%）、ChartQA（90.9%）、Common Voice v16（90.8%）上均取得高性能；多数查询由小模型与工具栈主导完成，大模型仅处理蒸馏后上下文。

Conclusion: Interfaze验证了‘以上下文为中心’而非‘以模型为中心’的设计范式可行性，显著降低计算开销，提升系统可扩展性与实用性，为下一代LLM应用提供新架构方向。

Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.
  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.

</details>


### [183] [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)
*SeungWon Seo,SooBin Lim,SeongRae Noh,Haneul Kim,HyeongYeop Kang*

Main category: cs.AI

TL;DR: 本文提出PCE框架，将大语言模型（LLM）推理过程中的隐含假设转化为结构化决策树，以在多智能体、部分可观测环境中实现低通信依赖的不确定性感知规划。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的具身智能体主要依赖频繁通信来缓解不确定性，带来高token开销、时间成本及对人类协作的干扰，亟需更高效的不确定性建模方法。

Method: 提出Planner-Composer-Evaluator（PCE）框架：Planner生成推理轨迹，Composer将其转化为带环境假设的决策树（内部节点为假设，叶节点为动作），Evaluator沿各路径综合评估场景似然性、目标收益与执行成本以选择最优动作。

Result: 在C-WAH和TDW-MAT两个多智能体基准上，PCE在成功率与任务效率上持续超越通信密集型基线，且token用量相当；消融实验表明其增益与模型容量和推理深度正交且可叠加；用户研究显示其通信模式更高效、可信。

Conclusion: PCE为将LLM隐含假设转化为不确定性感知的可靠规划策略提供了原则性路径，显著降低对高频通信的依赖，提升多智能体协作效能与人机协同体验。

Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.

</details>


### [184] [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144)
*Ruiting Dai,Zheyu Wang,Haoyu Yang,Yihan Liu,Chengzhi Wang,Zekun Zhang,Zishan Huang,Jiaman Cen,Lisi Mo*

Main category: cs.AI

TL;DR: 本文提出OMG-Agent框架，通过动态粗到细的代理工作流解决多模态数据不完整问题，显著提升系统鲁棒性与保真度。


<details>
  <summary>Details</summary>
Motivation: 数据不完整性严重损害多模态系统的可靠性；现有重建方法存在幻觉、检索僵化及语义-细节纠缠等瓶颈。

Method: 提出OMG-Agent框架，包含三阶段协同流程：(1) MLLM驱动的语义规划器进行渐进式上下文推理；(2) 非参数化证据检索器从外部知识中锚定语义；(3) 检索注入型执行器利用证据作为灵活特征提示合成高保真细节。

Result: 在多个基准测试中持续超越SOTA方法，在极端缺失（如CMU-MOSI 70%缺失率）下仍保持鲁棒性，提升2.6分。

Conclusion: OMG-Agent通过解耦逻辑推理与信号合成，有效缓解语义-细节纠缠，为多模态重建提供新范式。

Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \textbf{\underline{O}}mni-\textbf{\underline{M}}odality \textbf{\underline{G}}eneration Agent (\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\% missing rates.

</details>


### [185] [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)
*Zelai Xu,Zhexuan Xu,Ruize Zhang,Chunyang Zhu,Shi Yu,Weilin Liu,Quanlu Zhang,Wenbo Ding,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 本文提出WideSeek-R1多智能体框架，通过多智能体强化学习训练主-子智能体协同系统，实现信息检索任务中的宽度扩展（并行子智能体），在性能上以更小模型（4B）达到接近超大单智能体（671B）的效果。


<details>
  <summary>Details</summary>
Motivation: 随着任务广度增加，单智能体深度扩展面临瓶颈，组织能力（即多智能体协同）成为关键；现有多智能体系统因手工编排和串行交互而并行效率低。

Method: 提出lead-agent-subagent架构，基于共享LLM但隔离上下文与专用工具，采用多智能体强化学习（MARL）在20k广域信息检索任务上联合优化主智能体与并行子智能体。

Result: WideSeek-R1-4B在WideSearch基准上达到40.0% item F1，媲美DeepSeek-R1-671B；且子智能体数量增加时性能持续提升，验证宽度扩展有效性。

Conclusion: 宽度扩展（多智能体并行）是提升广域信息检索能力的有效新范式，WideSeek-R1证明了轻量级模型通过协同组织可匹敌巨型单智能体。

Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.

</details>


### [186] [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210)
*Enyu Zhou,Zhiheng Xi,Long Ma,Zhihao Zhang,Shihan Dou,Zhikai Lei,Guoteng Wang,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.AI

TL;DR: 本文提出可扩展的交互式监督框架，通过将复杂意图分解为递归决策树，降低人类监督负担，并在网页开发任务中验证了其有效性，显著提升非专家用户生成高质量需求文档的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在执行长周期复杂任务时，用户因缺乏领域知识、难以准确表达意图及验证复杂输出，导致监督困难，形成监督鸿沟。

Method: 提出可扩展交互式监督框架，将复杂意图递归分解为可管理的决策节点，每个节点收集低负担人类反馈，并递归聚合为全局精准指导；并通过仅依赖在线用户反馈的强化学习进行优化。

Result: 在网页开发任务中，非专家用户使用该框架生成的产品需求文档对齐度提升54%；并验证了仅用在线用户反馈即可通过强化学习优化该框架。

Conclusion: 该框架有效弥合了AI能力与人类监督能力之间的鸿沟，为AI规模化发展过程中维持人类可控性提供了实用路径。

Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.

</details>


### [187] [InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons](https://arxiv.org/abs/2602.04213)
*Feiyu Gavin Zhu,Jean Oh,Reid Simmons*

Main category: cs.AI

TL;DR: 本文提出了一种名为InterPReT的交互式策略重构与训练方法，使非专业用户能通过自然语言指令和示范来持续更新AI代理的策略结构和参数，从而降低教AI新技能的门槛。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法依赖大量专家示范和密集训练监控，对缺乏技术背景的普通用户不友好，难以应用于日常教学场景。

Method: 提出Interactive Policy Restructuring and Training (InterPReT)，支持用户以自然语言指令和少量示范交互式地重构策略结构并优化参数，并提供性能监控与决策策略审查功能。

Result: 在赛车游戏驾驶任务的用户研究（N=34）中，InterPReT相比通用模仿学习基线，在非专业用户主导示范与终止决策时，生成更鲁棒的策略且未损害系统可用性。

Conclusion: InterPReT显著提升了非技术背景终端用户训练可靠AI策略的能力与体验，是面向大众化AI教学的可行方案。

Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy

</details>


### [188] [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248)
*Hao Lu,Haoyuan Huang,Yulin Zhou,Chen Li,Ningxin Zhu*

Main category: cs.AI

TL;DR: 本文提出Empirical-MCTS，一种双循环框架，将无状态的蒙特卡洛树搜索（MCTS）转变为持续的、非参数化学习过程，通过本地探索与全局记忆优化结合，显著提升大语言模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有MCTS方法多为无状态，无法像人类一样积累和复用成功推理经验，限制了模型在复杂推理任务中的持续提升能力。

Method: 提出Empirical-MCTS框架，包含两个核心机制：1）Pairwise-Experience-Evolutionary Meta-Prompting（PE-EMP），在局部搜索中利用成对反馈实时演化元提示；2）Memory Optimization Agent，在全局记忆库中以原子操作提炼高质量推理经验作为动态策略先验。

Result: 在AIME25、ARC-AGI-2和MathArena Apex等复杂推理基准上，Empirical-MCTS显著优于传统无状态MCTS及独立经验驱动代理。

Conclusion: 结构化搜索必须与经验积累耦合，才能有效应对开放、复杂的推理任务；Empirical-MCTS为LLMs实现类人经验式推理提供了新范式。

Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.

</details>


### [189] [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)
*Yansong Ning,Jun Fang,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: 本文提出Agent-Omit框架，通过定量分析发现不同交互轮次中思考与观察的必要性不同，进而设计冷启动数据微调与省略感知的强化学习方法，使LLM代理能自适应省略冗余思考和观察，在保持性能的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究将多轮交互轨迹同等对待，忽视了不同轮次中思考必要性和观察能力的差异，导致效率低下。

Method: 提出Agent-Omit统一训练框架：1）合成冷启动数据（含单轮与多轮省略场景）进行微调；2）引入省略感知的代理强化学习，含双重采样机制与定制化省略奖励；3）理论证明省略策略偏差受KL散度上界约束。

Result: 在五个代理基准测试中，Agent-Omit-8B性能媲美七个前沿LLM代理，且在有效性-效率权衡上优于七个高效代理方法。

Conclusion: 自适应省略冗余思考与观察是提升LLM代理效率的关键路径，Agent-Omit为构建高效智能代理提供了可扩展、可证明的新范式。

Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.

</details>


### [190] [Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications](https://arxiv.org/abs/2602.04385)
*Marco Picone,Fabio Turazza,Matteo Martinelli,Marco Mamei*

Main category: cs.AI

TL;DR: 本文提出了一种零配置（ZeroConf）AI流水线方法，通过数字孪生（DT）技术实现AI与工业信息物理系统（CPS）的模块化、松耦合集成，提升可扩展性与复用性，并在MicroFactory场景中验证了其支持并发模型与动态数据处理的能力。


<details>
  <summary>Details</summary>
Motivation: 工业CPS日益复杂，AI/ML集成面临IoT/IIoT碎片化（协议、格式、设备异构）导致的物理层与智能层脱节问题；现有数字孪生方案多为封闭、紧耦合，限制AI功能的可扩展与复用。

Method: 提出模块化、互操作的零配置AI流水线架构，由数字孪生统一协调数据管理与智能增强，解耦DT与AI组件，降低配置依赖。

Result: 在MicroFactory场景中成功验证该方法，支持多ML模型并发运行和动态数据处理，显著加速复杂工业环境中智能服务部署。

Conclusion: 零配置AI流水线通过DT驱动的数据与智能协同机制，有效弥合CPS中物理与智能层鸿沟，为工业AI提供可扩展、易复用的集成范式。

Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.

</details>


### [191] [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)
*Zhentao Tang,Yuqi Cui,Shixiong Kai,Wenqian Zhao,Ke Ye,Xing Li,Anxin Tian,Zehua Pei,Hui-Ling Zhen,Shoubo Hu,Xiaoguang Li,Yunhe Wang,Mingxuan Yuan*

Main category: cs.AI

TL;DR: 本文提出ReThinker框架，通过动态计算分配和多阶段代理架构提升大模型在专家级科学推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在专家级科学推理（如HLE基准）上表现受限，主要由于刚性工具流程、脆弱的多智能体协作及低效的测试时扩展。

Method: 提出基于置信度感知的ReThinker框架，采用分阶段Solver-Critic-Selector架构，结合动态工具调用、多维引导反思与置信加权选择；并设计反向数据合成与自适应轨迹复用策略以实现无标注可扩展训练。

Result: 在HLE、GAIA和XBench上显著超越现有最优基础模型+工具方法及深度研究系统，达成专家级推理任务SOTA结果。

Conclusion: ReThinker通过置信驱动的动态计算与高效自监督训练，为大模型科学推理提供了更鲁棒、可扩展的新范式。

Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.

</details>


### [192] [From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums](https://arxiv.org/abs/2602.04572)
*Niv Fono,Yftah Ziser,Omer Ben-Porat*

Main category: cs.AI

TL;DR: 本文提出了一种生成式AI与问答论坛之间序贯互动的协作框架，以解决AI依赖论坛数据却分流用户这一悖论；通过基于Stack Exchange真实数据和主流大模型的仿真，验证了激励错位问题，并表明即使在信息不对称下，双方仍可获得约一半理想情况下的效用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统既依赖问答论坛产生的数据来提升性能，又因提供便捷服务而分流用户，形成‘依赖-替代’悖论，亟需设计可持续的协作机制。

Method: 提出一个包含非货币交换、信息不对称和激励错位的序贯互动框架，并基于真实Stack Exchange数据与常用大语言模型开展数据驱动的仿真实验。

Result: 实证发现显著的激励错位现象，但在所提框架下，参与方仍能实现约50%的理想完全信息场景下的效用。

Conclusion: 该框架揭示了AI系统与人类知识平台之间可持续协作的可行性，有助于维持高效的知识共享生态。

Abstract: While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.

</details>


### [193] [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575)
*Jiaheng Liu,Yuanxing Zhang,Shihao Li,Xinping Lei*

Main category: cs.AI

TL;DR: 本文提出Vibe AIGC新范式，通过多智能体协同编排实现从用户高层意图（Vibe）到可执行、可验证、自适应工作流的转化，以解决当前生成式AI中‘意图-执行鸿沟’问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI受限于单次黑箱推理，存在‘意图-执行鸿沟’，即用户高层意图难以被准确、可靠地转化为结果，形成‘可用性天花板’。

Method: 受Vibe Coding启发，构建以Meta-Planner为中心的多智能体协同架构：用户作为Commander输入‘Vibe’（含美学偏好、功能逻辑等），Meta-Planner将其分解为可执行、可验证、自适应的分层智能体工作流。

Result: 实现了从随机推断到逻辑编排的范式转变，显著提升生成过程的可控性、可解释性与鲁棒性，支持复杂、长周期数字资产的民主化创作。

Conclusion: Vibe AIGC将AI从脆弱的推理引擎升级为系统级工程伙伴，有望重塑人机协作经济形态。

Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.
  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.

</details>


### [194] [Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813)
*Shubham Vatsal,Harsh Dubey,Aditi Singh*

Main category: cs.AI

TL;DR: 本文提出一个七维分类法，系统评估了49项基于大语言模型的医疗智能体研究，揭示了当前能力分布的显著不对称性：知识集成普遍实现，而事件触发激活、漂移检测与缓解等关键能力严重缺失；多智能体架构占主导，但编排层和治疗规划等行动导向任务仍存在明显缺口。


<details>
  <summary>Details</summary>
Motivation: 现有文献多为宽泛综述或单一能力聚焦，缺乏统一框架来系统评估LLM医疗智能体的能力全景，导致医疗实践缺乏可比性和指导性分析。

Method: 构建包含认知能力、知识管理、交互模式、适应与学习、安全与伦理、框架类型及核心任务七个维度、共29个操作子维度的分类体系；依据明确纳入/排除标准和三级实现标签（完全实现/部分实现/未实现），对49篇研究进行编码与定量统计分析。

Result: 发现多项能力分布严重不均：外部知识集成（76%完全实现）高频，事件触发激活（92%未实现）和漂移检测与缓解（98%未实现）极低；多智能体设计（82%完全实现）为主流，但编排层多为部分实现；信息类任务（如医学问答）成熟，而治疗规划与处方（59%未实现）等行动类任务缺口显著。

Conclusion: 当前LLM医疗智能体研究呈现结构性失衡，亟需在交互动态性、持续适应性及临床行动闭环等薄弱维度加强方法创新与实证验证，以推动从信息辅助向真正临床代理演进。

Abstract: Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).

</details>


### [195] [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836)
*Haosen Ge,Hamsa Bastani,Osbert Bastani*

Main category: cs.AI

TL;DR: 本文质疑METR报告中关于AI能力呈指数增长的观点，通过重新拟合S型曲线发现拐点已过，并提出一个将AI能力分解为基础与推理能力的复合模型，证明AI能力将在近期出现拐点，强调现有指数增长预测的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 质疑METR报告中AI能力呈指数增长的结论，指出其数据支撑不足，并揭示当前预测方法的不稳健性。

Method: 重新拟合METR数据的S型（logistic）曲线；提出一个将AI能力分解为‘基础能力’和‘推理能力’的双组件增长模型，并进行理论分析与验证。

Result: S型曲线拟合显示AI能力增长的拐点已提前发生；新提出的双组件模型支持AI能力将在近期出现增长放缓（拐点）的判断。

Conclusion: AI能力增长并非持续指数式，现有指数预测过于乐观且脆弱；应谨慎对待长期AI能力外推预测，重视增长动态的阶段性变化。

Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

</details>


### [196] [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837)
*Zhaotian Weng,Antonis Antoniades,Deepak Nathani,Zhen Zhang,Xiao Pu,Xin Eric Wang*

Main category: cs.AI

TL;DR: 本文提出了Group-Evolving Agents（GEA）范式，将代理组作为进化基本单元，支持组内经验共享与复用，克服了树状进化中探索多样性利用低效的问题，在编程基准测试中显著超越现有自演化方法，并展现出更强的鲁棒性与可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有开放端自演化代理多采用树状结构，导致各分支孤立、探索多样性利用效率低，且依赖人工干预；亟需一种能高效复用经验、提升长期进化效能的新范式。

Method: 提出GEA范式，以代理组为基本进化单元，通过显式经验共享与复用机制实现群体协同演化，区别于传统树状隔离演化路径。

Result: 在SWE-bench Verified和Polyglot上分别达71.0%和88.3%，显著优于SOTA自演化方法；性能媲美甚至超越顶尖人工设计框架；平均仅需1.4次迭代即可修复框架级bug，鲁棒性与跨模型迁移性更强。

Conclusion: GEA通过群体协同演化有效提升探索多样性向长期性能增益的转化效率，为开放端自改进代理提供了更高效、鲁棒且可扩展的新范式。

Abstract: Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.

</details>


### [197] [Fluid Representations in Reasoning Models](https://arxiv.org/abs/2602.04843)
*Dmitrii Kharlapenko,Alessandro Stolfo,Arthur Conmy,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: 本文对QwQ-32B模型在抽象推理任务（如Mystery Blocksworld）中的内部机制进行了机制性分析，发现其通过推理过程中动态优化token表征（即'流式推理表征'）来提升结构化抽象能力，并通过干预实验证明该机制对性能提升具有因果作用。


<details>
  <summary>Details</summary>
Motivation: 尽管推理型语言模型在抽象问题上表现优异，但其内部工作机制尚不清楚，本文旨在揭示其如何处理抽象结构信息。

Method: 对QwQ-32B模型在Mystery Blocksworld任务中进行机制性分析，包括表征演化追踪与 steering 干预实验（注入成功轨迹的表征、替换符号表征等）。

Result: 发现模型在推理过程中逐步优化动作与概念的抽象编码，聚焦结构而非具体名称；‘流式推理表征’是提升性能的关键因素；干预实验提供了因果证据。

Conclusion: 推理模型的优越性能部分源于上下文内对token表征的动态精炼，即Fluid Reasoning Representations，这为理解与改进推理机制提供了新视角。

Abstract: Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [198] [Multi-threaded Recast-Based A* Pathfinding for Scalable Navigation in Dynamic Game Environments](https://arxiv.org/abs/2602.04130)
*Tiroshan Madushanka,Sakuna Madushanka*

Main category: cs.GR

TL;DR: 本文提出了一种多线程框架，通过Recast网格生成、贝塞尔曲线轨迹平滑和密度分析来增强A*算法，以提升动态3D环境中大规模群体路径规划的性能与真实性。


<details>
  <summary>Details</summary>
Motivation: A*算法在动态3D游戏环境中面临计算性能与视觉真实感之间的权衡问题。

Method: 结合Recast网格生成、贝塞尔曲线轨迹平滑和密度分析的多线程A*增强框架，并在十个渐进式场景（从2D迷宫到多层动态世界）中进行评估。

Result: 系统在1000个智能体同时运行时仍保持350+ FPS，并实现基于密度感知的无碰撞群体导航。

Conclusion: 该框架有效平衡了路径规划的效率与真实感，适用于复杂动态3D环境中的大规模实时群体行为模拟。

Abstract: While the A* algorithm remains the industry standard for game pathfinding, its integration into dynamic 3D environments faces trade-offs between computational performance and visual realism. This paper proposes a multi-threaded framework that enhances standard A* through Recast-based mesh generation, Bezier-curve trajectory smoothing, and density analysis for crowd coordination. We evaluate our system across ten incremental phases, from 2D mazes to complex multi-level dynamic worlds. Experimental results demonstrate that the framework maintains 350+ FPS with 1000 simultaneous agents and achieves collision-free crowd navigation through density-aware path coordination.

</details>


### [199] [Event-T2M: Event-level Conditioning for Complex Text-to-Motion Synthesis](https://arxiv.org/abs/2602.04292)
*Seong-Eun Hong,JaeYoung Seon,JuYeong Hwang,JongHwan Shin,HyeongYeop Kang*

Main category: cs.GR

TL;DR: 本文提出Event-T2M框架，通过将文本提示分解为语义自包含的‘事件’单元，并在扩散模型中进行事件级条件建模，显著提升多动作文本到运动生成的质量与顺序保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成方法常将复杂多动作提示压缩为单一嵌入，导致动作遗漏、顺序错乱或过渡不自然；缺乏针对多事件场景的评估基准。

Method: 定义‘事件’为文本中最小语义自包含的动作或状态变化单元；构建Event-T2M：基于Conformer的扩散框架，结合事件分解、运动感知检索编码与事件级交叉注意力机制；新建按事件数量分层的基准HumanML3D-E。

Result: 在HumanML3D、KIT-ML及新基准HumanML3D-E上，Event-T2M在标准指标上媲美SOTA，且随事件复杂度增加性能优势更显著；人类评估证实其生成的多事件运动在顺序性与自然性上更接近真值。

Conclusion: 事件级条件建模是一种可推广的原则，能有效推动文本到运动生成从单动作向复杂多动作场景拓展。

Abstract: Text-to-motion generation has advanced with diffusion models, yet existing systems often collapse complex multi-action prompts into a single embedding, leading to omissions, reordering, or unnatural transitions. In this work, we shift perspective by introducing a principled definition of an event as the smallest semantically self-contained action or state change in a text prompt that can be temporally aligned with a motion segment. Building on this definition, we propose Event-T2M, a diffusion-based framework that decomposes prompts into events, encodes each with a motion-aware retrieval model, and integrates them through event-based cross-attention in Conformer blocks. Existing benchmarks mix simple and multi-event prompts, making it unclear whether models that succeed on single actions generalize to multi-action cases. To address this, we construct HumanML3D-E, the first benchmark stratified by event count. Experiments on HumanML3D, KIT-ML, and HumanML3D-E show that Event-T2M matches state-of-the-art baselines on standard tests while outperforming them as event complexity increases. Human studies validate the plausibility of our event definition, the reliability of HumanML3D-E, and the superiority of Event-T2M in generating multi-event motions that preserve order and naturalness close to ground-truth. These results establish event-level conditioning as a generalizable principle for advancing text-to-motion generation beyond single-action prompts.

</details>


### [200] [Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging](https://arxiv.org/abs/2602.04805)
*Jia-peng Zhang,Cheng-Feng Pu,Meng-Hao Guo,Yan-Pei Cao,Shi-Min Hu*

Main category: cs.GR

TL;DR: 本文提出SkinTokens——一种学习到的紧凑离散皮肤权重表示，并构建了统一的自回归框架TokenRig，将骨架生成与皮肤绑定建模为单一序列预测问题，结合强化学习优化，显著提升绑定精度与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动化绑定方法将皮肤权重估计视为高维不适定回归问题，效率低且与骨架生成解耦，导致性能瓶颈。

Method: 提出SkinTokens表示，利用FSQ-CVAE建模皮肤权重的内在稀疏性，将连续回归转为离散token序列预测；构建TokenRig统一自回归模型，联合建模骨架参数与SkinTokens；引入面向几何与语义的强化学习优化阶段。

Result: SkinTokens使皮肤绑定精度较SOTA提升98%–133%；完整TokenRig（含RL优化）使骨骼预测精度提升17%–22%。

Conclusion: SkinTokens与TokenRig提供了一种统一、生成式、高保真且鲁棒的自动绑定方案，可扩展地解决3D内容创作中的长期挑战。

Abstract: The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights. By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [201] [GenMRP: A Generative Multi-Route Planning Framework for Efficient and Personalized Real-Time Industrial Navigation](https://arxiv.org/abs/2602.04174)
*Chengzhang Wang,Chao Chen,Jun Tao,Tengfei Liu,He Bai,Song Wang,Longfei Xu,Kaikui Liu,Xiangxiang Chu*

Main category: cs.RO

TL;DR: 本文提出GenMRP，一种面向大规模实时导航的生成式多路径规划框架，通过骨架到毛细血管子网构建与修正增强策略，在保证效率的同时兼顾路径质量与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有工业级导航系统中，预计算方法缺乏个性化和多样性，而生成式方法难以满足大规模实时场景的效率需求。

Method: GenMRP采用骨架到毛细血管的动态子网构建策略，并在子网内迭代生成路径：首轮用Dijkstra求最优路径，后续轮次结合路网特征、用户历史及已生成路径更新链路代价模型，再用Dijkstra生成兼顾质量与多样性的替代路径。

Result: 实验表明GenMRP在离线与在线环境下均达到SOTA性能且高效；已在真实导航App中全面部署，并开源了训练与评测数据集。

Conclusion: GenMRP有效平衡了生成式路径规划的质量、多样性与实时性，具备实际工业落地价值。

Abstract: Existing industrial-scale navigation applications contend with massive road networks, typically employing two main categories of approaches for route planning. The first relies on precomputed road costs for optimal routing and heuristic algorithms for generating alternatives, while the second, generative methods, has recently gained significant attention. However, the former struggles with personalization and route diversity, while the latter fails to meet the efficiency requirements of large-scale real-time scenarios. To address these limitations, we propose GenMRP, a generative framework for multi-route planning. To ensure generation efficiency, GenMRP first introduces a skeleton-to-capillary approach that dynamically constructs a relevant sub-network significantly smaller than the full road network. Within this sub-network, routes are generated iteratively. The first iteration identifies the optimal route, while the subsequent ones generate alternatives that balance quality and diversity using the newly proposed correctional boosting approach. Each iteration incorporates road features, user historical sequences, and previously generated routes into a Link Cost Model to update road costs, followed by route generation using the Dijkstra algorithm. Extensive experiments show that GenMRP achieves state-of-the-art performance with high efficiency in both offline and online environments. To facilitate further research, we have publicly released the training and evaluation dataset. GenMRP has been fully deployed in a real-world navigation app, demonstrating its effectiveness and benefits.

</details>


### [202] [Beyond the Vehicle: Cooperative Localization by Fusing Point Clouds for GPS-Challenged Urban Scenarios](https://arxiv.org/abs/2602.03908)
*Kuo-Yi Chao,Ralph Rasshofer,Alois Christian Knoll*

Main category: cs.RO

TL;DR: 本文提出了一种融合车车通信（V2V）和车路协同（V2I）的多传感器、多模态协同定位方法，结合点云配准SLAM算法，提升城市复杂环境中车辆定位的精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: GPS在城市环境中信号不可靠，导致车辆精确定位困难。

Method: 融合V2V和V2I协同数据，结合基于点云配准的SLAM算法，处理来自车载LiDAR、双目相机及路口基础设施传感器的多源点云数据。

Result: 在GPS干扰严重的城市复杂场景中，显著提升了定位精度和系统鲁棒性。

Conclusion: 多模态协同感知与点云SLAM融合是提升城市车辆定位性能的有效途径。

Abstract: Accurate vehicle localization is a critical challenge in urban environments where GPS signals are often unreliable. This paper presents a cooperative multi-sensor and multi-modal localization approach to address this issue by fusing data from vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) systems. Our approach integrates cooperative data with a point cloud registration-based simultaneous localization and mapping (SLAM) algorithm. The system processes point clouds generated from diverse sensor modalities, including vehicle-mounted LiDAR and stereo cameras, as well as sensors deployed at intersections. By leveraging shared data from infrastructure, our method significantly improves localization accuracy and robustness in complex, GPS-noisy urban scenarios.

</details>


### [203] [How Users Understand Robot Foundation Model Performance through Task Success Rates and Beyond](https://arxiv.org/abs/2602.03920)
*Isaac Sheidlower,Jindan Huang,James Staley,Bingyu Wu,Qicong Chen,Reuben Aronson,Elaine Short*

Main category: cs.RO

TL;DR: 本文研究了非机器人专家如何理解机器人基础模型（RFM）的评估结果，发现尽管任务成功率（TSR）对专家直观，但普通用户更重视失败案例等补充信息，并希望同时获得历史评估数据与机器人对新任务的实时性能预估。


<details>
  <summary>Details</summary>
Motivation: RFM在实际家庭应用中将面临大量未训练过的新型任务，用户需准确理解其能力边界与失败风险；而现有评估仅依赖任务成功率（TSR），其对非专家是否有效尚不明确。

Method: 开展用户研究，向非机器人专家展示多个已发表RFM的真实评估数据（含TSR、失败案例描述及视频），观察其对性能信息的理解与使用偏好。

Result: 非专家能按专家预期使用TSR，但更重视未被常规报告的失败案例信息；用户强烈期望同时获取历史评估数据和机器人对新任务的实时性能估计。

Conclusion: RFM评估应超越单一TSR指标，系统性纳入失败分析与可解释性内容，并支持面向终端用户的动态能力预测机制。

Abstract: Robot Foundation Models (RFMs) represent a promising approach to developing general-purpose home robots. Given the broad capabilities of RFMs, users will inevitably ask an RFM-based robot to perform tasks that the RFM was not trained or evaluated on. In these cases, it is crucial that users understand the risks associated with attempting novel tasks due to the relatively high cost of failure. Furthermore, an informed user who understands an RFM's capabilities will know what situations and tasks the robot can handle. In this paper, we study how non-roboticists interpret performance information from RFM evaluations. These evaluations typically report task success rate (TSR) as the primary performance metric. While TSR is intuitive to experts, it is necessary to validate whether novices also use this information as intended. Toward this end, we conducted a study in which users saw real evaluation data, including TSR, failure case descriptions, and videos from multiple published RFM research projects. The results highlight that non-experts not only use TSR in a manner consistent with expert expectations but also highly value other information types, such as failure cases that are not often reported in RFM evaluations. Furthermore, we find that users want access to both real data from previous evaluations of the RFM and estimates from the robot about how well it will do on a novel task.

</details>


### [204] [VLS: Steering Pretrained Robot Policies via Vision-Language Models](https://arxiv.org/abs/2602.03973)
*Shuo Liu,Ishneet Sukhvinder Singh,Yiqing Xu,Jiafei Duan,Ranjay Krishna*

Main category: cs.RO

TL;DR: 本文提出Vision-Language Steering (VLS)框架，无需重新训练即可在推理时自适应调整预训练扩散或流匹配机器人策略，以应对测试时的空间与任务分布偏移。


<details>
  <summary>Details</summary>
Motivation: 预训练的扩散或流匹配策略在面对障碍物、支撑面偏移或轻微杂乱等测试分布偏移时表现不佳，根源在于模仿学习中动作生成过度依赖训练时特定空间配置，而重训练成本高且不必要。

Method: VLS将适应视为推理时控制问题，利用视觉-语言模型合成轨迹可微奖励函数，在不修改策略参数的前提下，实时引导去噪过程生成满足测试时空间与任务要求的动作轨迹。

Result: 在CALVIN和LIBERO-PRO基准上分别提升31%和13%，并在Franka真实机器人上验证了对空间与语义偏移的鲁棒推理时适应能力。

Conclusion: VLS是一种高效、通用、免训练的推理时策略适配方法，显著提升了生成式机器人策略在分布外场景下的泛化性与实用性。

Abstract: Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/

</details>


### [205] [FDA Flocking: Future Direction-Aware Flocking via Velocity Prediction](https://arxiv.org/abs/2602.04012)
*Hossein B. Jond,Martin Saska*

Main category: cs.RO

TL;DR: 本文提出了一种受鸟类行为启发的未来方向感知（FDA）编队控制方法，通过融合反应式对齐与基于邻居未来速度短时预测的前馈项，提升了集群的速度一致性、凝聚力-分离平衡性，并增强了对传感/通信延迟和测量噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受鸟类姿态与拍翅等前兆信号及多旋翼无人机姿态倾斜预示转向行为的启发，弥补现有反应式集群模型缺乏前瞻性信息利用的不足。

Method: 提出Future Direction-Aware (FDA)编队框架，将反应式对齐与基于邻居未来速度短时估计的预测项加权融合，引入可调混合参数实现反应与前馈行为的连续插值。

Result: 仿真表明FDA相比纯反应式模型具有更快更高的速度对齐度、更强的群体平移运动能力，以及对延迟和噪声更优的鲁棒性。

Conclusion: FDA是一种原理清晰、生物启发的前馈增强型编队策略，有效缓解了传统反应式模型在真实系统中因延迟与噪声导致的失稳问题，为后续自适应混合策略与无人机实验验证奠定基础。

Abstract: Understanding self-organization in natural collectives such as bird flocks inspires swarm robotics, yet most flocking models remain reactive, overlooking anticipatory cues that enhance coordination. Motivated by avian postural and wingbeat signals, as well as multirotor attitude tilts that precede directional changes, this work introduces a principled, bio-inspired anticipatory augmentation of reactive flocking termed Future Direction-Aware (FDA) flocking. In the proposed framework, agents blend reactive alignment with a predictive term based on short-term estimates of neighbors' future velocities, regulated by a tunable blending parameter that interpolates between reactive and anticipatory behaviors. This predictive structure enhances velocity consensus and cohesion-separation balance while mitigating the adverse effects of sensing and communication delays and measurement noise that destabilize reactive baselines. Simulation results demonstrate that FDA achieves faster and higher alignment, enhanced translational displacement of the flock, and improved robustness to delays and noise compared to a purely reactive model. Future work will investigate adaptive blending strategies, weighted prediction schemes, and experimental validation on multirotor drone swarms.

</details>


### [206] [Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement](https://arxiv.org/abs/2602.03983)
*Weikang Qiu,Tinglin Huang,Aosong Feng,Rex Ying*

Main category: cs.RO

TL;DR: 本文提出SD-VLA框架，通过将视觉输入解耦为静态与动态令牌，减少上下文长度并重用KV缓存，显著提升VLA模型在长时序任务中的效率与性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型面临长时序建模能力弱和推理效率低（因注意力复杂度高、参数量大）两大挑战；而机器人轨迹中大量视觉信息（如背景）具有跨帧静态性，可被利用优化建模。

Method: 提出SD-VLA框架：1）将视觉输入分解为多级静态与动态token；2）跨帧复用静态token以压缩上下文；3）设计轻量recache门控机制，仅在必要时更新静态token的KV缓存。同时构建新基准评估长时序依赖建模能力。

Result: 在新基准上成功率达绝对提升39.8%，SimplerEnv基准提升3.9%；推理速度达基线VLA的2.26倍。

Conclusion: SD-VLA通过静态-动态解耦与KV缓存重用，在保持甚至提升任务性能的同时大幅提高推理效率，推动VLA向实际机器人部署迈进。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a promising paradigm for generalist robotic control. Built upon vision-language model (VLM) architectures, VLAs predict actions conditioned on visual observations and language instructions, achieving strong performance and generalization across tasks. However, VLAs face two major challenges: limited long-horizon context and inefficient inference due to the quadratic attention complexity and large parameter counts. Our work is motivated by the observation that much of the visual information in a trajectory remains static across timesteps (e.g., the background). Leveraging this property, we propose SD-VLA, a framework that disentangles visual inputs into multi-level static and dynamic tokens, which enables (1) retaining a single copy of static tokens across frames to significantly reduce context length, and (2) reusing the key-value (KV) cache of static tokens through a lightweight recache gate that updates only when necessary. This design enables efficient multi-frame integration and efficient inference. In addition, we introduce a new benchmark that more effectively evaluates the long-horizon temporal dependency modeling ability of VLAs. Experimental results show that our approach outperforms baselines on this benchmark by 39.8% absolute improvement in success rate, and achieves a 3.9% gain on the SimplerEnv benchmark. Moreover, SD-VLA delivers a 2.26x inference speedup over the base VLA model on the same benchmark, enabling faster and more practical real-world deployment.

</details>


### [207] [KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning](https://arxiv.org/abs/2602.04129)
*Chak Lam Shek,Faizan M. Tariq,Sangjae Bae,David Isele,Piyush Gupta*

Main category: cs.RO

TL;DR: 本文提出KGLAMP框架，利用知识图谱引导大语言模型生成准确的PDDL问题描述，以解决异构多机器人系统在动态环境中符号表示不准与计划不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有规划方法难以在动态环境中为异构多机器人系统构建准确的符号表示并保持计划一致性：经典PDDL规划器依赖人工建模，而大语言模型（LLM）规划器常忽略机器人异构性与环境不确定性。

Method: 提出KGLAMP——一种知识图谱引导的大语言模型规划框架；该框架构建并动态更新一个结构化知识图谱，编码物体关系、空间可达性与机器人能力，用以指导LLM生成PDDL问题描述，并在检测到不一致时触发重规划。

Result: 在MAT-THOR基准测试中，KGLAMP相较纯LLM和纯PDDL规划器变体，性能提升至少25.5%。

Conclusion: KGLAMP通过将知识图谱作为持久化、可更新的记忆机制，有效融合符号推理与感知反馈，显著提升了异构多机器人在长周期动态任务中的规划鲁棒性与适应性。

Abstract: Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and maintain plan consistency in dynamic environments. Classical PDDL planners require manually crafted symbolic models, while LLM-based planners often ignore agent heterogeneity and environmental uncertainty. We introduce KGLAMP, a knowledge-graph-guided LLM planning framework for heterogeneous multi-robot teams. The framework maintains a structured knowledge graph encoding object relations, spatial reachability, and robot capabilities, which guides the LLM in generating accurate PDDL problem specifications. The knowledge graph serves as a persistent, dynamically updated memory that incorporates new observations and triggers replanning upon detecting inconsistencies, enabling symbolic plans to adapt to evolving world states. Experiments on the MAT-THOR benchmark show that KGLAMP improves performance by at least 25.5% over both LLM-only and PDDL-based variants.

</details>


### [208] [An Anatomy-specific Guidewire Shaping Robot for Improved Vascular Navigation](https://arxiv.org/abs/2602.04050)
*Aabha Tamhankar,Jay Patil,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 本文提出了一种用于神经介入手术的导丝自动塑形机器人系统，通过建模将目标导丝形状映射为机器人动作，并在2D/3D中验证了其对常见临床尖端构型（C、S、Angled、Hook）的高精度复现能力（RMS误差0.56mm）及复杂血管路径导航能力。


<details>
  <summary>Details</summary>
Motivation: 传统神经介入导丝塑形依赖术者经验与手动弯折，在复杂解剖结构中难度大、标准化程度低，亟需自主、可重复的自动化塑形方案。

Method: 设计并实现了一个台式导丝塑形机器人系统；构建了将目标导丝形状映射为机器人动作的模型，并利用实验数据进行校准；在2D和3D条件下验证形状复现精度与血管内导航能力。

Result: 机器人可稳定生成C、S、Angled、Hook等临床常用尖端构型，2D形状预测RMS误差为0.56mm；成功实现3D塑形及从岩部颈内动脉至后交通动脉的复杂腔内导航。

Conclusion: 该机器人系统为神经介入导丝塑形提供了标准化、可重复、高精度的自动化解决方案，有望降低术者依赖、提升手术安全性和可推广性。

Abstract: Neuroendovascular access often relies on passive microwires that are hand-shaped at the back table and then used to track a microcatheter to the target. Neuroendovascular surgeons determine the shape of the wire by examining the patient pre-operative images and using their experience to identify anatomy specific shapes of the wire that would facilitate reaching the target. This procedure is particularly complex in convoluted anatomical structures and is heavily dependent on the level of expertise of the surgeon. Towards enabling standardized autonomous shaping, we present a bench-top guidewire shaping robot capable of producing navigation-specific desired wire configurations. We present a model that can map the desired wire shape into robot actions, calibrated using experimental data. We show that the robot can produce clinically common tip geometries (C, S, Angled, Hook) and validate them with respect to the model-predicted shapes in 2D. Our model predicts the shape with a Root Mean Square (RMS) error of 0.56mm across all shapes when compared to the experimental results. We also demonstrate 3D tip shaping capabilities and the ability to traverse complex endoluminal navigation from the petrous Internal Carotid Artery (ICA) to the Posterior Communicating Artery (PComm).

</details>


### [209] [Control and State Estimation of Vehicle-Mounted Aerial Systems in GPS-Denied, Non-Inertial Environments](https://arxiv.org/abs/2602.04057)
*Riming Xu,Obadah Wali,Yasmine Marani,Eric Feron*

Main category: cs.RO

TL;DR: 本文提出了一种面向GNSS拒止、非惯性环境下的四旋翼鲁棒控制与估计算法，仅依赖外部位置测量和扩展卡尔曼滤波器（EKF-UI）估计平台运动，结合级联PID控制器实现三维轨迹跟踪，实验验证其在移动平台上的稳定性和跟踪性能优于标准EKF。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止且平台加速导致IMU不可靠的非惯性环境中，传统估计器无法区分加速度来源，造成漂移和控制退化。

Method: 采用仅依赖外部位置测量的扩展卡尔曼滤波器（EKF-UI）建模并补偿平台运动，并与级联PID控制器结合实现全3D轨迹跟踪；所有实验使用高精度动捕系统以排除定位误差影响。

Result: 在移动小车实验平台上验证了方法在X轴和Y轴平移失配下的有效性，相比标准EKF显著提升了稳定性与轨迹跟踪精度，且无需惯性反馈。

Conclusion: 所提框架可在无GNSS、IMU不可靠的移动平台（如卡车、电梯）上实用部署，为非惯性环境下的四旋翼自主飞行提供了新思路。

Abstract: We present a robust control and estimation framework for quadrotors operating in Global Navigation Satellite System(GNSS)-denied, non-inertial environments where inertial sensors such as Inertial Measurement Units (IMUs) become unreliable due to platform-induced accelerations. In such settings, conventional estimators fail to distinguish whether the measured accelerations arise from the quadrotor itself or from the non-inertial platform, leading to drift and control degradation. Unlike conventional approaches that depend heavily on IMU and GNSS, our method relies exclusively on external position measurements combined with a Extended Kalman Filter with Unknown Inputs (EKF-UI) to account for platform motion. The estimator is paired with a cascaded PID controller for full 3D tracking. To isolate estimator performance from localization errors, all tests are conducted using high-precision motion capture systems. Experimental results in a moving-cart testbed validate our approach under both translational in X-axis and Y-axis dissonance. Compared to standard EKF, the proposed method significantly improves stability and trajectory tracking without requiring inertial feedback, enabling practical deployment on moving platforms such as trucks or elevators.

</details>


### [210] [Comparative Analysis of Autonomous Robotic and Manual Techniques for Ultrasonic Sacral Osteotomy: A Preliminary Study](https://arxiv.org/abs/2602.04076)
*Daniyal Maroufi,Yash Kulkarni,Justin E. Bird,Jeffrey H. Siewerdsen,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 本文介绍了一种自主超声骶骨截骨（USO）机器人系统，结合超声骨刀、七自由度机械臂和光学跟踪系统，在Sawbones模型上验证其轨迹与深度控制精度显著优于手动操作。


<details>
  <summary>Details</summary>
Motivation: 解决手动骶骨截骨中轨迹偏差大、深度控制差等关键局限性，提升手术安全性与精确性。

Method: 开发集成超声骨刀、七自由度机械臂及光学跟踪系统的自主USO机器人系统，并在Sawbones仿体上与手动USO进行定量对比实验，评估表面轨迹与切割深度的控制性能。

Result: RUSO系统实现0.11 mm RMSE轨迹精度（较MUSO的1.10 mm RMSE提升一个数量级），且深度控制达8.1 mm（目标8.0 mm），而MUSO出现严重过切（16.0 mm）。

Conclusion: 该机器人系统可有效克服手动截骨的关键限制，为更安全、精准的骶骨切除术奠定基础。

Abstract: In this paper, we introduce an autonomous Ultrasonic Sacral Osteotomy (USO) robotic system that integrates an ultrasonic osteotome with a seven-degree-of-freedom (DoF) robotic manipulator guided by an optical tracking system. To assess multi-directional control along both the surface trajectory and cutting depth of this system, we conducted quantitative comparisons between manual USO (MUSO) and robotic USO (RUSO) in Sawbones phantoms under identical osteotomy conditions. The RUSO system achieved sub-millimeter trajectory accuracy (0.11 mm RMSE), an order of magnitude improvement over MUSO (1.10 mm RMSE). Moreover, MUSO trials showed substantial over-penetration (16.0 mm achieved vs. 8.0 mm target), whereas the RUSO system maintained precise depth control (8.1 mm). These results demonstrate that robotic procedures can effectively overcome the critical limitations of manual osteotomy, establishing a foundation for safer and more precise sacral resections.

</details>


### [211] [Shaping Expressiveness in Robotics: The Role of Design Tools in Crafting Embodied Robot Movements](https://arxiv.org/abs/2602.04137)
*Elisabetta Zibetti,Alexandra Mercader,Hélène Duval,Florent Levillain,Audrey Rochette,David St-Onge*

Main category: cs.RO

TL;DR: 本文提出了一种以运动为中心的设计教学法，帮助工程师设计富有表现力的机械臂运动，融合舞蹈分析框架与定制化软硬件工具，提升了人机交互的直观性与参与感。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地进入人类共享空间，其运动需超越基础功能，融入表现力以增强互动与沟通效果。

Method: 通过融合跨学科方法的动手工作坊，结合舞蹈领域的动态与具身化分析框架，使用自定义手动遥控器和专用动画软件进行实时交互与精细运动控制。

Result: 定性分析表明，该‘工具箱’有效弥合了人类意图与机器人表现力之间的鸿沟，生成更直观、更具吸引力的机械臂表现性运动。

Conclusion: 以运动为中心的设计教学法及其配套工具可显著提升工程师在机器人表现性运动设计方面的能力与产出质量。

Abstract: As robots increasingly become part of shared human spaces, their movements must transcend basic functionality by incorporating expressive qualities to enhance engagement and communication. This paper introduces a movement-centered design pedagogy designed to support engineers in creating expressive robotic arm movements. Through a hands-on interactive workshop informed by interdisciplinary methodologies, participants explored various creative possibilities, generating valuable insights into expressive motion design. The iterative approach proposed integrates analytical frameworks from dance, enabling designers to examine motion through dynamic and embodied dimensions. A custom manual remote controller facilitates interactive, real-time manipulation of the robotic arm, while dedicated animation software supports visualization, detailed motion sequencing, and precise parameter control. Qualitative analysis of this interactive design process reveals that the proposed "toolbox" effectively bridges the gap between human intent and robotic expressiveness resulting in more intuitive and engaging expressive robotic arm movements.

</details>


### [212] [MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments](https://arxiv.org/abs/2602.04152)
*Yirum Kim,Jaewoo Kim,Ue-Hwan Kim*

Main category: cs.RO

TL;DR: 本文提出了多智能体3D场景图生成（MA3DSG）框架，通过无训练的图对齐算法将多个智能体的局部查询图融合为全局场景图，无需可学习参数，并构建了支持多种配置的基准测试集MA3DSG-Bench，以推动可扩展的多智能体3DSGG研究。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图生成方法依赖单智能体假设和小规模环境，难以扩展到真实场景。

Method: 提出多智能体3D场景图生成（MA3DSG）框架，设计一种无需训练的图对齐算法，将各智能体生成的局部查询图高效融合为统一的全局场景图；所有模块均无须可学习参数。

Result: 实现了单智能体系统在多智能体协作下的无缝扩展；构建了支持多样化配置的新型基准MA3DSG-Bench，验证了方法的通用性与可扩展性。

Conclusion: 该工作首次系统性地拓展了3DSGG至多智能体、大规模场景设定，为后续可扩展的多智能体3DSGG研究奠定了基础。

Abstract: Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3DSG) model, the first framework designed to tackle this scalability challenge using multiple agents. We develop a training-free graph alignment algorithm that efficiently merges partial query graphs from individual agents into a unified global scene graph. Leveraging extensive analysis and empirical insights, our approach enables conventional single-agent systems to operate collaboratively without requiring any learnable parameters. To rigorously evaluate 3DSGG performance, we propose MA3DSG-Bench-a benchmark that supports diverse agent configurations, domain sizes, and environmental conditions-providing a more general and extensible evaluation framework. This work lays a solid foundation for scalable, multi-agent 3DSGG research.

</details>


### [213] [A Modern System Recipe for Situated Embodied Human-Robot Conversation with Real-Time Multimodal LLMs and Tool-Calling](https://arxiv.org/abs/2602.04157)
*Dong Won Lee,Sarah Gillet,Louis-Philippe Morency,Cynthia Breazeal,Hae Won Park*

Main category: cs.RO

TL;DR: 本文提出了一种结合实时多模态大语言模型与少量注意力和主动感知工具接口的简单系统方案，用于实现具身对话中的实时交互与主动感知。


<details>
  <summary>Details</summary>
Motivation: 具身对话需要机器人在严格延迟约束下实时交替进行对话与主动感知（如决定看什么、何时看、说什么），现有方法难以兼顾实时性与感知灵活性。

Method: 设计一个轻量级系统，将实时多模态大语言模型与一组专用工具接口（用于注意力控制和主动感知）耦合，并在六种家庭场景中评估其表现。

Result: 在四个系统变体上，工具决策正确率（对比人工标注）和主观交互质量评分均显示良好性能，验证了该方向的可行性与潜力。

Conclusion: 实时多模态大语言模型配合主动感知工具是实现实用化具身对话的一条有前景的技术路径。

Abstract: Situated embodied conversation requires robots to interleave real-time dialogue with active perception: deciding what to look at, when to look, and what to say under tight latency constraints. We present a simple, minimal system recipe that pairs a real-time multimodal language model with a small set of tool interfaces for attention and active perception. We study six home-style scenarios that require frequent attention shifts and increasing perceptual scope. Across four system variants, we evaluate turn-level tool-decision correctness against human annotations and collect subjective ratings of interaction quality. Results indicate that real-time multimodal large language models and tool use for active perception is a promising direction for practical situated embodied conversation.

</details>


### [214] [SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models](https://arxiv.org/abs/2602.04208)
*Hyeonbeom Choi,Daechul Ahn,Youhan Lee,Taewook Kang,Seongwon Cho,Jonghyun Choi*

Main category: cs.RO

TL;DR: 本文提出SCALE，一种无需额外训练、无需验证器、仅需单次前向传播的VLA模型推理策略，通过自不确定性联合调节视觉感知与动作决策，提升在感知模糊场景下的鲁棒性与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的测试时扩展（TTS）方法需额外训练、验证器或多步前向传播，且仅调整动作解码而忽略视觉表征的可变性，在感知模糊时表现不足。

Method: 基于Active Inference理论中的不确定性驱动探索思想，提出SCALE策略，利用模型自身输出的不确定性信号，在单次前向传播中联合调制视觉感知与动作生成：高不确定性时拓宽感知与动作探索，低不确定性时聚焦利用。

Result: 在仿真与真实世界基准上，SCALE显著提升当前最优VLA模型性能，超越现有TTS方法，同时保持单次前向传播的高效性。

Conclusion: SCALE是一种轻量、通用、即插即用的推理策略，证明了在VLA中联合优化感知与动作对提升鲁棒性和适应性至关重要。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity, where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on 'self-uncertainty', inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency.

</details>


### [215] [ALORE: Autonomous Large-Object Rearrangement with a Legged Manipulator](https://arxiv.org/abs/2602.04214)
*Zhihai Bi,Yushan Zhang,Kai Chen,Guoyang Zhao,Yulin Li,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出ALORE系统，一种用于四足机械臂的自主大型物体重排系统，通过分层强化学习、统一交互配置表示和物体速度估计器，以及任务与运动规划框架，实现了对多种大型物体的高效、稳定、无碰撞重排。


<details>
  <summary>Details</summary>
Motivation: 赋予机器人重排大型重物（如家具）的能力可显著减轻人类工作负担，但该任务因需与多样物体交互、在复杂环境中高效重排多物体并确保无碰撞的运动-操作协同而极具挑战性。

Method: 提出ALORE系统，包含：(i) 分层强化学习训练流程，结合高层物体速度控制器与低层全身控制器；(ii) 统一交互配置表示与物体速度估计器，实现单一策略对多样物体平面速度的精准调控；(iii) 联合优化物体访问顺序与目标分配的任务-运动规划框架，支持在线重规划。

Result: 在策略泛化性、物体速度跟踪精度及多物体重排效率上均优于强基线；仿真与真实实验验证系统鲁棒性：连续8轮完成32把椅子重排（近40分钟无失败），并在约40米路径上实现长距离自主重排。

Conclusion: ALORE系统有效解决了大型物体重排中的多样性、稳定性与效率难题，为腿足式操作机器人在真实场景中部署提供了可行方案。

Abstract: Endowing robots with the ability to rearrange various large and heavy objects, such as furniture, can substantially alleviate human workload. However, this task is extremely challenging due to the need to interact with diverse objects and efficiently rearrange multiple objects in complex environments while ensuring collision-free loco-manipulation. In this work, we present ALORE, an autonomous large-object rearrangement system for a legged manipulator that can rearrange various large objects across diverse scenarios. The proposed system is characterized by three main features: (i) a hierarchical reinforcement learning training pipeline for multi-object environment learning, where a high-level object velocity controller is trained on top of a low-level whole-body controller to achieve efficient and stable joint learning across multiple objects; (ii) two key modules, a unified interaction configuration representation and an object velocity estimator, that allow a single policy to regulate planar velocity of diverse objects accurately; and (iii) a task-and-motion planning framework that jointly optimizes object visitation order and object-to-target assignment, improving task efficiency while enabling online replanning. Comparisons against strong baselines show consistent superiority in policy generalization, object-velocity tracking accuracy, and multi-object rearrangement efficiency. Key modules are systematically evaluated, and extensive simulations and real-world experiments are conducted to validate the robustness and effectiveness of the entire system, which successfully completes 8 continuous loops to rearrange 32 chairs over nearly 40 minutes without a single failure, and executes long-distance autonomous rearrangement over an approximately 40 m route. The open-source packages are available at https://zhihaibi.github.io/Alore/.

</details>


### [216] [OAT: Ordered Action Tokenization](https://arxiv.org/abs/2602.04215)
*Chaoqi Liu,Xiaoshen Han,Jiawei Gao,Yue Zhao,Haonan Chen,Yilun Du*

Main category: cs.RO

TL;DR: 本文提出了一种名为Ordered Action Tokenization (OAT)的新型动作标记化方法，用于提升自回归策略在机器人连续动作学习中的性能。OAT通过带寄存器的Transformer、有限标量量化和排序诱导训练机制，实现高压缩率、完全可解码性及因果有序的标记空间，显著优于现有标记化与扩散模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有动作标记化方法存在两大问题：解析式离散化导致标记序列过长；学习型潜在标记器缺乏结构，难以适配自回归建模。需满足高压缩、完全可解码、左到右因果有序三个关键需求。

Method: 提出Ordered Action Tokenization (OAT)，采用带寄存器的Transformer架构、有限标量量化（finite scalar quantization）和排序诱导训练机制，将动作块离散为有序标记序列，并支持前缀式去标记化（prefix-based detokenization）。

Result: 在超20个任务（涵盖4个仿真基准与真实世界场景）上，采用OAT的自回归策略一致优于先前标记化方案和扩散基线，同时提供更灵活的推理时精度-成本权衡。

Conclusion: OAT是一种满足三大核心需求的高效、结构化、可学习的动作标记化方法，为自回归机器人策略提供了更优、更实用的连续动作抽象基础。

Abstract: Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time.

</details>


### [217] [Reshaping Action Error Distributions for Reliable Vision-Language-Action Models](https://arxiv.org/abs/2602.04228)
*Shuanghao Bai,Dakai Wang,Cheng Chi,Wanqi Zhou,Jing Lyu,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Lei Xing,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于最小误差熵（MEE）的连续动作视觉-语言-动作（VLA）模型训练方法，替代或补充传统MSE损失，提升了模型在标准、少样本和噪声环境下的成功率与鲁棒性，且几乎不增加训练开销。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型多采用MSE等点对点监督目标，难以应对连续动作分布的复杂性与数据不平衡、噪声等问题，缺乏对误差分布的整体建模能力。

Method: 将信息论中的最小误差熵（MEE）引入VLA训练，设计轨迹级MEE损失及其两种加权变体，并与MSE联合优化；在LIBERO、SimplerEnv仿真及真实机器人任务上验证。

Result: 在标准、少样本和含噪设置下，多个VLA架构的成功率和鲁棒性均显著提升；在数据不平衡时仍保持稳定增益，训练开销可忽略，推理效率不受影响。

Conclusion: MEE作为一种分布感知的监督准则，能有效提升连续动作VLA模型的泛化性与鲁棒性，理论分析进一步揭示了其有效性边界与适用条件。

Abstract: In robotic manipulation, vision-language-action (VLA) models have emerged as a promising paradigm for learning generalizable and scalable robot policies. Most existing VLA frameworks rely on standard supervised objectives, typically cross-entropy for discrete actions and mean squared error (MSE) for continuous action regression, which impose strong pointwise constraints on individual predictions. In this work, we focus on continuous-action VLA models and move beyond conventional MSE-based regression by reshaping action error distributions during training. Drawing on information-theoretic principles, we introduce Minimum Error Entropy (MEE) into modern VLA architectures and propose a trajectory-level MEE objective, together with two weighted variants, combined with MSE for continuous-action VLA training. We evaluate our approaches across standard, few-shot, and noisy settings on multiple representative VLA architectures, using simulation benchmarks such as LIBERO and SimplerEnv as well as real-world robotic manipulation tasks. Experimental results demonstrate consistent improvements in success rates and robustness across these settings. Under imbalanced data regimes, the gains persist within a well-characterized operating range, while incurring negligible additional training cost and no impact on inference efficiency. We further provide theoretical analyses that explain why MEE-based supervision is effective and characterize its practical range. Project Page: https://cognition2actionlab.github.io/VLA-TMEE.github.io/

</details>


### [218] [GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning](https://arxiv.org/abs/2602.04231)
*Rui Tang,Guankun Wang,Long Bai,Huxin Gao,Jiewen Lai,Chi Kit Ng,Jiazheng Wang,Fan Zhang,Hongliang Ren*

Main category: cs.RO

TL;DR: 本文提出GeoLanG，一种基于CLIP的端到端多任务框架，通过深度引导几何模块（DGGM）和自适应密集通道集成，提升语言引导抓取在遮挡、低纹理等复杂场景下的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为多阶段流水线，视觉与语言模态融合不足，在遮挡、杂乱或低纹理场景中泛化差、计算冗余。

Method: 基于CLIP构建端到端框架；引入Depth-guided Geometric Module（DGGM）将深度信息转化为几何先验并融入注意力机制；提出Adaptive Dense Channel Integration自适应融合多层特征。

Result: 在OCID-VLG数据集、仿真及真实硬件实验中，GeoLanG显著提升了语言引导抓取的精度与鲁棒性，尤其在复杂杂乱环境中表现优异。

Conclusion: GeoLanG实现了更紧密的跨模态对齐与更强的场景泛化能力，为真实人机共融环境中的多模态机器人操作提供了可靠新路径。

Abstract: Language-guided grasping has emerged as a promising paradigm for enabling robots to identify and manipulate target objects through natural language instructions, yet it remains highly challenging in cluttered or occluded scenes. Existing methods often rely on multi-stage pipelines that separate object perception and grasping, which leads to limited cross-modal fusion, redundant computation, and poor generalization in cluttered, occluded, or low-texture scenes. To address these limitations, we propose GeoLanG, an end-to-end multi-task framework built upon the CLIP architecture that unifies visual and linguistic inputs into a shared representation space for robust semantic alignment and improved generalization. To enhance target discrimination under occlusion and low-texture conditions, we explore a more effective use of depth information through the Depth-guided Geometric Module (DGGM), which converts depth into explicit geometric priors and injects them into the attention mechanism without additional computational overhead. In addition, we propose Adaptive Dense Channel Integration, which adaptively balances the contributions of multi-layer features to produce more discriminative and generalizable visual representations. Extensive experiments on the OCID-VLG dataset, as well as in both simulation and real-world hardware, demonstrate that GeoLanG enables precise and robust language-guided grasping in complex, cluttered environments, paving the way toward more reliable multimodal robotic manipulation in real-world human-centric settings.

</details>


### [219] [Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation](https://arxiv.org/abs/2602.04243)
*Pengfei Yi,Yifan Han,Junyan Li,Litao Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: 本文提出MAE-Select框架，利用预训练多视角掩码自编码器表示，在单摄像头机器人系统中实现无需标签的动态主动视角选择，提升操作性能，甚至在某些情况下超越多摄像头设置。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法依赖固定相机设置，限制了系统的适应性和视野覆盖；受人类主动感知启发，需动态调整视角以获取最相关、噪声最少的信息。

Method: 提出MAE-Select框架，充分利用预训练多视角掩码自编码器（MAE）的表征能力，在每个时间片段动态选择最具信息量的下一视角，且无需标注视角数据。

Result: 大量实验表明，MAE-Select显著提升了单摄像头系统的操作能力，在部分任务中性能超过多摄像头配置。

Conclusion: MAE-Select为单摄像头机器人系统提供了高效、自适应的主动视角选择新范式，降低了对硬件部署的依赖，增强了模仿学习的实用性与泛化性。

Abstract: Robotic manipulation continues to be a challenge, and imitation learning (IL) enables robots to learn tasks from expert demonstrations. Current IL methods typically rely on fixed camera setups, where cameras are manually positioned in static locations, imposing significant limitations on adaptability and coverage. Inspired by human active perception, where humans dynamically adjust their viewpoint to capture the most relevant and least noisy information, we propose MAE-Select, a novel framework for active viewpoint selection in single-camera robotic systems. MAE-Select fully leverages pre-trained multi-view masked autoencoder representations and dynamically selects the next most informative viewpoint at each time chunk without requiring labeled viewpoints. Extensive experiments demonstrate that MAE-Select improves the capabilities of single-camera systems and, in some cases, even surpasses multi-camera setups. The project will be available at https://mae-select.github.io.

</details>


### [220] [Towards Next-Generation SLAM: A Survey on 3DGS-SLAM Focusing on Performance, Robustness, and Future Directions](https://arxiv.org/abs/2602.04251)
*Li Wang,Ruixuan Gong,Yumo Han,Lei Yang,Lu Yang,Ying Li,Bin Xu,Huaping Liu,Rong Fu*

Main category: cs.RO

TL;DR: 本文综述了将3D高斯泼溅（3DGS）与SLAM系统结合的最新技术进展，重点分析其在渲染质量、跟踪精度、重建速度和内存消耗四个维度的性能优化，并探讨其在动态环境等复杂场景下的鲁棒性增强方法及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统存在渲染质量粗糙、场景细节恢复不足、动态环境下鲁棒性差等问题，而3DGS具备高效显式表征与高质量渲染能力，为SLAM提供了新范式。

Method: 系统性综述3DGS-SLAM的关键技术路径，从四个核心维度（渲染质量、跟踪精度、重建速度、内存消耗）分析代表性方法的设计原理与突破；同时梳理针对运动模糊、动态环境等复杂场景的鲁棒性增强策略。

Result: 总结了当前3DGS-SLAM在多维度性能上的优化成果与鲁棒性改进方法，明确了技术优势与现存局限。

Conclusion: 该综述为研究人员提供了技术参考，推动构建高保真、高效率、高鲁棒性的下一代SLAM系统。

Abstract: Traditional Simultaneous Localization and Mapping (SLAM) systems often face limitations including coarse rendering quality, insufficient recovery of scene details, and poor robustness in dynamic environments. 3D Gaussian Splatting (3DGS), with its efficient explicit representation and high-quality rendering capabilities, offers a new reconstruction paradigm for SLAM. This survey comprehensively reviews key technical approaches for integrating 3DGS with SLAM. We analyze performance optimization of representative methods across four critical dimensions: rendering quality, tracking accuracy, reconstruction speed, and memory consumption, delving into their design principles and breakthroughs. Furthermore, we examine methods for enhancing the robustness of 3DGS-SLAM in complex environments such as motion blur and dynamic environments. Finally, we discuss future challenges and development trends in this area. This survey aims to provide a technical reference for researchers and foster the development of next-generation SLAM systems characterized by high fidelity, efficiency, and robustness.

</details>


### [221] [AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models](https://arxiv.org/abs/2602.04256)
*Yuxuan Han,Kunyuan Wu,Qianyi Shao,Renxiang Xiao,Zilu Wang,Cansen Jiang,Yi Xiao,Liang Hu,Yunjiang Lou*

Main category: cs.RO

TL;DR: 本文提出AppleVLM，一种融合视觉、语言与规划模态的端到端自动驾驶模型，通过改进的视觉编码器、专用规划编码器和分层思维链解码器，显著提升在多样场景与真实环境中的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的端到端驾驶方法存在车道感知不足、语言理解偏差及难处理边缘案例等问题，亟需更鲁棒、可扩展且少依赖语言指令的感知-规划联合建模方法。

Method: 提出AppleVLM：1）采用可变形Transformer融合多视角、多时序图像的空间-时间信息；2）引入显式的鸟瞰图（BEV）规划模态编码器，解耦语言指令依赖；3）设计分层Chain-of-Thought微调的VLM解码器，联合输出驾驶航点。

Result: 在CARLA两个闭环基准上达到SOTA性能，并成功部署于AGV平台，在复杂室外真实环境中实现端到端自主驾驶。

Conclusion: AppleVLM通过多模态协同建模与结构化规划表征，有效缓解了VLM在自动驾驶中固有的语言偏差与感知局限，为鲁棒、可部署的端到端驾驶提供了新范式。

Abstract: End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of end-to-end driving models in diverse and unseen scenarios. However, existing VLM-based approaches still face challenges, including suboptimal lane perception, language understanding biases, and difficulties in handling corner cases. To address these issues, we propose AppleVLM, an advanced perception and planning-enhanced VLM model for robust end-to-end driving. AppleVLM introduces a novel vision encoder and a planning strategy encoder to improve perception and decision-making. Firstly, the vision encoder fuses spatial-temporal information from multi-view images across multiple timesteps using a deformable transformer mechanism, enhancing robustness to camera variations and facilitating scalable deployment across different vehicle platforms. Secondly, unlike traditional VLM-based approaches, AppleVLM introduces a dedicated planning modality that encodes explicit Bird's-Eye-View spatial information, mitigating language biases in navigation instructions. Finally, a VLM decoder fine-tuned by a hierarchical Chain-of-Thought integrates vision, language, and planning features to output robust driving waypoints. We evaluate AppleVLM in closed-loop experiments on two CARLA benchmarks, achieving state-of-the-art driving performance. Furthermore, we deploy AppleVLM on an AGV platform and successfully showcase real-world end-to-end autonomous driving in complex outdoor environments.

</details>


### [222] [GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning](https://arxiv.org/abs/2602.04315)
*Guoqing Ma,Siheng Wang,Zeyu Zhang,Shan Yu,Hao Tang*

Main category: cs.RO

TL;DR: 本文提出GeneralVLA，一种分层式视觉-语言-动作模型，通过知识引导的轨迹规划实现机器人零样本操作，并自动生成高质量训练数据，无需真实机器人交互或人类示范。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型在视觉和语言领域展现出强泛化能力，但在机器人领域尚未实现类似效果，主要受限于其零样本能力不足。

Method: 提出分层VLA模型GeneralVLA：高层ASM模块微调以感知图像关键点功能；中层3DAgent进行任务理解、技能知识建模与3D轨迹规划；底层3D感知控制策略执行精准操作。全程无需真实机器人数据或人类演示。

Result: 在14个任务上成功生成轨迹，性能显著优于VoxPoser等SOTA方法；其生成的数据训练出的行为克隆策略比人类示范及其他方法（如VoxPoser、Scaling-up、Code-As-Policies）更鲁棒。

Conclusion: GeneralVLA为机器人领域提供了一种可扩展的零样本任务求解与数据生成新范式。

Abstract: Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is that the models exhibit limited zero-shot capability, which hampers their ability to generalize effectively to unseen scenarios. In this work, we propose GeneralVLA (Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning), a hierarchical vision-language-action (VLA) model that can be more effective in utilizing the generalization of foundation models, enabling zero-shot manipulation and automatically generating data for robotics. In particular, we study a class of hierarchical VLA model where the high-level ASM (Affordance Segmentation Module) is finetuned to perceive image keypoint affordances of the scene; the mid-level 3DAgent carries out task understanding, skill knowledge, and trajectory planning to produce a 3D path indicating the desired robot end-effector trajectory. The intermediate 3D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Compared to alternative approaches, our method requires no real-world robotic data collection or human demonstration, making it much more scalable to diverse tasks and viewpoints. Empirically, GeneralVLA successfully generates trajectories for 14 tasks, significantly outperforming state-of-the-art methods such as VoxPoser. The generated demonstrations can train more robust behavior cloning policies than training with human demonstrations or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. We believe GeneralVLA can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting. Code: https://github.com/AIGeeksGroup/GeneralVLA. Website: https://aigeeksgroup.github.io/GeneralVLA.

</details>


### [223] [Safe and Stylized Trajectory Planning for Autonomous Driving via Diffusion Model](https://arxiv.org/abs/2602.04329)
*Shuo Pei,Yong Wang,Yuanchen Zhu,Chen Sun,Qin Li,Yanan Zhao,Huachun Tan*

Main category: cs.RO

TL;DR: 本文提出SDD Planner，一种基于扩散模型的实时轨迹规划框架，兼顾安全性与驾驶风格，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂真实场景中实现安全且具风格化的轨迹规划仍是自动驾驶系统的关键挑战。

Method: 提出SDD Planner框架，包含多源风格感知编码器（采用距离敏感注意力融合动态智能体与环境信息）和风格引导动态轨迹生成器（在扩散去噪过程中自适应调节优先权重）。

Result: 在StyleDrive上SM-PDMS指标提升3.9%；NuPlan Test14/Test14-hard分别取得91.76/80.32分，排名第一；实车闭环测试验证其安全性与风格一致性。

Conclusion: SDD Planner有效协调安全约束与驾驶风格，具备实际部署价值。

Abstract: Achieving safe and stylized trajectory planning in complex real-world scenarios remains a critical challenge for autonomous driving systems. This paper proposes the SDD Planner, a diffusion-based framework designed to effectively reconcile safety constraints with driving styles in real time. The framework integrates two core modules: a Multi-Source Style-Aware Encoder, which employs distance-sensitive attention to fuse dynamic agent data and environmental contexts for heterogeneous safety-style perception; and a Style-Guided Dynamic Trajectory Generator, which adaptively modulates priority weights within the diffusion denoising process to generate user-preferred yet safe trajectories. Extensive experiments demonstrate that SDD Planner achieves state-of-the-art performance. On the StyleDrive benchmark, it improves the SM-PDMS metric by 3.9% over WoTE, the strongest baseline. Furthermore, on the NuPlan Test14 and Test14-hard benchmarks, SDD Planner ranks first with overall scores of 91.76 and 80.32, respectively, outperforming leading methods such as PLUTO. Real-vehicle closed-loop tests further confirm that SDD Planner maintains high safety standards while aligning with preset driving styles, validating its practical applicability for real-world deployment.

</details>


### [224] [Quantile Transfer for Reliable Operating Point Selection in Visual Place Recognition](https://arxiv.org/abs/2602.04401)
*Dhyey Manish Rajani,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 本文提出一种自动选择视觉地点识别（VPR）系统匹配阈值的方法，在满足用户指定精度要求的前提下最大化召回率，通过校准遍历与分位数归一化实现跨环境鲁棒自适应，显著提升高精度场景下的召回率。


<details>
  <summary>Details</summary>
Motivation: 传统VPR系统依赖人工离线调参设定固定匹配阈值，难以应对环境变化，导致性能下降。

Method: 利用带有已知对应关系的小规模校准遍历数据，通过相似度分数分布的分位数归一化，将校准得到的阈值迁移到部署阶段。

Result: 在多个SOTA VPR方法和数据集上实验表明，该方法在高精度运行区间内召回率最高可提升25%，且对采样变化鲁棒，无需人工调参。

Conclusion: 所提方法能自动适配新环境、泛化至不同运行条件，有效解决VPR中阈值设定的鲁棒性与适应性难题。

Abstract: Visual Place Recognition (VPR) is a key component for localisation in GNSS-denied environments, but its performance critically depends on selecting an image matching threshold (operating point) that balances precision and recall. Thresholds are typically hand-tuned offline for a specific environment and fixed during deployment, leading to degraded performance under environmental change. We propose a method that, given a user-defined precision requirement, automatically selects the operating point of a VPR system to maximise recall. The method uses a small calibration traversal with known correspondences and transfers thresholds to deployment via quantile normalisation of similarity score distributions. This quantile transfer ensures that thresholds remain stable across calibration sizes and query subsets, making the method robust to sampling variability. Experiments with multiple state-of-the-art VPR techniques and datasets show that the proposed approach consistently outperforms the state-of-the-art, delivering up to 25% higher recall in high-precision operating regimes. The method eliminates manual tuning by adapting to new environments and generalising across operating conditions. Our code will be released upon acceptance.

</details>


### [225] [HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation](https://arxiv.org/abs/2602.04412)
*Puyue Wang,Jiawei Hu,Yan Gao,Junyan Wang,Yu Zhang,Gillian Dobbie,Tao Gu,Wafa Johal,Ting Dang,Hong Jia*

Main category: cs.RO

TL;DR: HoRD是一种两阶段学习框架，通过历史条件强化学习和在线知识蒸馏，使类人机器人在面对动力学、任务或环境变化时具备零样本适应能力。


<details>
  <summary>Details</summary>
Motivation: 类人机器人在动力学、任务规范或环境设置发生微小变化时性能显著下降，亟需提升其跨域鲁棒性与泛化能力。

Method: 提出HoRD框架：第一阶段用历史状态-动作轨迹推断潜在动力学上下文，训练高性能量化教师策略；第二阶段通过在线知识蒸馏将能力迁移到基于稀疏根坐标系3D关节点轨迹的Transformer学生策略。

Result: HoRD在未见域和外部扰动下显著优于强基线，在鲁棒性和跨域迁移能力上表现突出。

Conclusion: HoRD实现了单一策略对未知域的零样本自适应，无需针对每个域重新训练，为类人机器人鲁棒控制提供了新范式。

Abstract: Humanoid robots can suffer significant performance drops under small changes in dynamics, task specifications, or environment setup. We propose HoRD, a two-stage learning framework for robust humanoid control under domain shift. First, we train a high-performance teacher policy via history-conditioned reinforcement learning, where the policy infers latent dynamics context from recent state--action trajectories to adapt online to diverse randomized dynamics. Second, we perform online distillation to transfer the teacher's robust control capabilities into a transformer-based student policy that operates on sparse root-relative 3D joint keypoint trajectories. By combining history-conditioned adaptation with online distillation, HoRD enables a single policy to adapt zero-shot to unseen domains without per-domain retraining. Extensive experiments show HoRD outperforms strong baselines in robustness and transfer, especially under unseen domains and external perturbations. Code and project page are available at \href{https://tonywang-0517.github.io/hord/}{https://tonywang-0517.github.io/hord/}.

</details>


### [226] [Integrated Exploration and Sequential Manipulation on Scene Graph with LLM-based Situated Replanning](https://arxiv.org/abs/2602.04419)
*Heqing Yang,Ziyuan Jiao,Shu Wang,Yida Niu,Si Liu,Hangxin Liu*

Main category: cs.RO

TL;DR: 本文提出EPoG框架，结合图规划与大语言模型（LLM）进行部分已知环境下的探索式顺序操作规划，在46个家庭场景中实现91.3%任务成功率，并降低36.1%移动距离。


<details>
  <summary>Details</summary>
Motivation: 在部分已知环境中，机器人需同时兼顾探索以获取信息和任务规划以高效执行，现有方法难以无缝融合二者。

Method: EPoG构建基于场景图的全局图规划器与LLM驱动的具身局部规划器，通过观测和LLM预测持续更新表征已知/未知物体的信念图；动作序列由目标图与信念图间的图编辑操作生成，并依时序依赖与运动代价排序。

Result: 在46个真实家庭场景及5个长视野日常物体搬运任务的消融实验中，EPoG达到91.3%成功率，平均减少36.1%行驶距离；物理移动操作机器人在未知动态环境中成功执行复杂任务。

Conclusion: EPoG能有效协同探索与顺序操作规划，具备强实用性与现实部署潜力。

Abstract: In partially known environments, robots must combine exploration to gather information with task planning for efficient execution. To address this challenge, we propose EPoG, an Exploration-based sequential manipulation Planning framework on Scene Graphs. EPoG integrates a graph-based global planner with a Large Language Model (LLM)-based situated local planner, continuously updating a belief graph using observations and LLM predictions to represent known and unknown objects. Action sequences are generated by computing graph edit operations between the goal and belief graphs, ordered by temporal dependencies and movement costs. This approach seamlessly combines exploration and sequential manipulation planning. In ablation studies across 46 realistic household scenes and 5 long-horizon daily object transportation tasks, EPoG achieved a success rate of 91.3%, reducing travel distance by 36.1% on average. Furthermore, a physical mobile manipulator successfully executed complex tasks in unknown and dynamic environments, demonstrating EPoG's potential for real-world applications.

</details>


### [227] [Gust Estimation and Rejection with a Disturbance Observer for Proprioceptive Underwater Soft Morphing Wings](https://arxiv.org/abs/2602.04438)
*Tobias Cook,Leo Micklem,Huazhi Dong,Yunjie Yang,Michael Mistry,Francesco Giorgio Serchi*

Main category: cs.RO

TL;DR: 本文受海洋生物启发，提出一种具有本体感知能力的软质可变形机翼，通过实时感知机翼曲率变化来估计来流扰动，并结合扰动观测器与控制器实现升力响应的扰动抑制，从而提升水下无人航行器在浅水复杂流场中的稳定性与机动性。


<details>
  <summary>Details</summary>
Motivation: 浅水环境中波浪、水流和湍流等水动力扰动严重影响水下无人航行器的稳定性和操纵性；而海洋生物通过本体感知与柔性鳍尾协同有效抵抗扰动，这为工程设计提供了生物学启示。

Method: 设计并实验验证一种液压驱动、可控弯度的软质机翼动态模型；利用机翼连续形变产生的曲率变化作为本体感知信号，构建扰动观测器以实时重构来流参数（特别是攻角扰动）；进一步设计基于该感知估计的控制器，实现对升力响应的扰动抑制。

Result: 实验证明曲率感知可准确估计攻角扰动，且所提控制器能有效抑制软翼升力响应中的环境扰动。

Conclusion: 将本体感知与扰动观测器相结合的策略，模仿了生物抗扰机制，为软体水下航行器在危险浅水环境中的稳定运行提供了可行技术路径。

Abstract: Unmanned underwater vehicles are increasingly employed for maintenance and surveying tasks at sea, but their operation in shallow waters is often hindered by hydrodynamic disturbances such as waves, currents, and turbulence. These unsteady flows can induce rapid changes in direction and speed, compromising vehicle stability and manoeuvrability. Marine organisms contend with such conditions by combining proprioceptive feedback with flexible fins and tails to reject disturbances. Inspired by this strategy, we propose soft morphing wings endowed with proprioceptive sensing to mitigate environmental perturbations. The wing's continuous deformation provides a natural means to infer dynamic disturbances: sudden changes in camber directly reflect variations in the oncoming flow. By interpreting this proprioceptive signal, a disturbance observer can reconstruct flow parameters in real time. To enable this, we develop and experimentally validate a dynamic model of a hydraulically actuated soft wing with controllable camber. We then show that curvature-based sensing allows accurate estimation of disturbances in the angle of attack. Finally, we demonstrate that a controller leveraging these proprioceptive estimates can reject disturbances in the lift response of the soft wing. By combining proprioceptive sensing with a disturbance observer, this technique mirrors biological strategies and provides a pathway for soft underwater vehicles to maintain stability in hazardous environments.

</details>


### [228] [EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models](https://arxiv.org/abs/2602.04515)
*Yu Bai,MingMing Yu,Chaojie Li,Ziyi Bai,Xinlong Wang,Börje F. Karlsson*

Main category: cs.RO

TL;DR: 本文提出EgoActing任务和EgoActor模型，通过统一的视觉语言模型实现人形机器人对高层指令的实时、空间感知的动作执行，支持多类型动作预测并在真实与仿真环境中展现出强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 部署人形机器人于真实场景面临感知、运动与操作紧密耦合、部分可观测及动态环境等根本挑战，尤其需在不同类型子任务间稳健切换。

Method: 提出EgoActing任务，并构建统一可扩展的视觉语言模型EgoActor；利用真实世界第一视角RGB数据、空间推理问答及仿真演示进行多源监督训练；支持8B和4B参数模型，实现实时（<1s）动作推断。

Result: 在仿真与真实环境中广泛评估表明，EgoActor能有效连接抽象任务规划与具体运动执行，并在多样化任务和未见环境中具备良好泛化性。

Conclusion: EgoActor为真实场景下人形机器人实现端到端、空间感知、多模态协同的具身智能提供了可行框架。

Abstract: Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.

</details>


### [229] [TACO: Temporal Consensus Optimization for Continual Neural Mapping](https://arxiv.org/abs/2602.04516)
*Xunlan Zhou,Hongrui Zhao,Negar Mehr*

Main category: cs.RO

TL;DR: 本文提出TACO（时间一致性优化）框架，用于无需回放的持续神经隐式建图，在内存与计算受限下实现对动态环境的高效自适应更新。


<details>
  <summary>Details</summary>
Motivation: 现有神经隐式建图方法依赖历史数据回放且假设场景静态，难以满足真实机器人在动态环境中持续学习、内存和计算受限的需求。

Method: 将建图建模为时间一致性优化问题，将历史模型快照视为时间邻域，通过加权共识机制融合过去表征以更新当前地图，无需存储或回放历史观测。

Result: 在仿真与真实场景实验中，TACO在不牺牲内存效率的前提下，稳健适应场景变化，持续优于其他持续学习基线方法。

Conclusion: TACO提供了一种兼顾记忆效率与环境适应性的新范式，推动神经隐式建图向实际机器人部署迈进。

Abstract: Neural implicit mapping has emerged as a powerful paradigm for robotic navigation and scene understanding. However, real-world robotic deployment requires continual adaptation to changing environments under strict memory and computation constraints, which existing mapping systems fail to support. Most prior methods rely on replaying historical observations to preserve consistency and assume static scenes. As a result, they cannot adapt to continual learning in dynamic robotic settings. To address these challenges, we propose TACO (TemporAl Consensus Optimization), a replay-free framework for continual neural mapping. We reformulate mapping as a temporal consensus optimization problem, where we treat past model snapshots as temporal neighbors. Intuitively, our approach resembles a model consulting its own past knowledge. We update the current map by enforcing weighted consensus with historical representations. Our method allows reliable past geometry to constrain optimization while permitting unreliable or outdated regions to be revised in response to new observations. TACO achieves a balance between memory efficiency and adaptability without storing or replaying previous data. Through extensive simulated and real-world experiments, we show that TACO robustly adapts to scene changes, and consistently outperforms other continual learning baselines.

</details>


### [230] [A Unified Complementarity-based Approach for Rigid-Body Manipulation and Motion Prediction](https://arxiv.org/abs/2602.04522)
*Bingkun Huang,Xin Ma,Nilanjan Chakraborty,Riddhiman Laha*

Main category: cs.RO

TL;DR: 本文提出了一种名为Unicomp的统一离散时间建模框架，将自由运动与摩擦接触统一建模为耦合的线性与非线性互补问题，并基于最大功率耗散原理构建了适用于非凸/分布式接触斑的椭球形极限曲面摩擦模型，支持实时优化规划与稳定物理一致的接触丰富操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作规划与仿真框架通常将自由空间运动与接触动力学分离，或采用简化的接触表示（尤其对非凸/分布式接触斑），导致接触模式切换保真度低、难以实时鲁棒执行接触丰富的任务。

Method: 基于互补性刚体动力学，构建统一离散时间模型（Unicomp），将自由运动与摩擦接触统一表述为耦合的线性与非线性互补问题；针对平面接触斑，从最大功率耗散原理导出椭球形极限曲面摩擦模型，显式刻画力-力矩耦合效应（含扭转摩擦），且不依赖具体压力分布；最终形成含二次约束的广义速度-接触力矩关系模型，适配实时优化规划。

Result: 实验验证该方法在平面推挤到全身接触丰富操作等任务中，能在交互速度下实现稳定、物理一致的行为。

Conclusion: Unicomp框架通过统一建模与物理合理的椭球摩擦表示，显著提升了接触模式切换的准确性与实时规划能力，为复杂环境中鲁棒的接触丰富操作提供了新范式。

Abstract: Robotic manipulation in unstructured environments requires planners to reason jointly about free-space motion and sustained, frictional contact with the environment. Existing (local) planning and simulation frameworks typically separate these regimes or rely on simplified contact representations, particularly when modeling non-convex or distributed contact patches. Such approximations limit the fidelity of contact-mode transitions and hinder the robust execution of contact-rich behaviors in real time. This paper presents a unified discrete-time modeling framework for robotic manipulation that consistently captures both free motion and frictional contact within a single mathematical formalism (Unicomp). Building on complementarity-based rigid-body dynamics, we formulate free-space motion and contact interactions as coupled linear and nonlinear complementarity problems, enabling principled transitions between contact modes without enforcing fixed-contact assumptions. For planar patch contact, we derive a frictional contact model from the maximum power dissipation principle in which the set of admissible contact wrenches is represented by an ellipsoidal limit surface. This representation captures coupled force-moment effects, including torsional friction, while remaining agnostic to the underlying pressure distribution across the contact patch. The resulting formulation yields a discrete-time predictive model that relates generalized velocities and contact wrenches through quadratic constraints and is suitable for real-time optimization-based planning. Experimental results show that the proposed approach enables stable, physically consistent behavior at interactive speeds across tasks, from planar pushing to contact-rich whole-body maneuvers.

</details>


### [231] [Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data](https://arxiv.org/abs/2602.04600)
*Jialiang Li,Yi Qiao,Yunhan Guo,Changwen Chen,Wenzhao Lian*

Main category: cs.RO

TL;DR: 本文提出CoMe-VLA框架，将主动感知建模为非马尔可夫的信息增益驱动过程，结合认知辅助头与双轨记忆系统，利用人类第一人称数据学习探索与操作先验，在轮式人形机器人上验证了其在多场景长时程任务中的鲁棒性与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法受限于感知行为类型单一，难以应对无约束复杂环境中的信息不确定性问题。

Method: 将主动感知形式化为非马尔可夫过程，提出CoMe-VLA框架：包含认知辅助头实现子任务自主切换、双轨记忆系统融合本体与视觉时序上下文，并在统一的自我中心动作空间中对齐人机手眼协调行为，分三阶段渐进训练。

Result: 在轮式人形机器人上实验表明，该方法在多种主动感知场景下的长时程任务中展现出强鲁棒性与适应性。

Conclusion: CoMe-VLA通过认知建模与记忆增强，显著提升了机器人在开放环境中主动感知与操作的通用性与灵活性。

Abstract: Achieving generalizable manipulation in unconstrained environments requires the robot to proactively resolve information uncertainty, i.e., the capability of active perception. However, existing methods are often confined in limited types of sensing behaviors, restricting their applicability to complex environments. In this work, we formalize active perception as a non-Markovian process driven by information gain and decision branching, providing a structured categorization of visual active perception paradigms. Building on this perspective, we introduce CoMe-VLA, a cognitive and memory-aware vision-language-action (VLA) framework that leverages large-scale human egocentric data to learn versatile exploration and manipulation priors. Our framework integrates a cognitive auxiliary head for autonomous sub-task transitions and a dual-track memory system to maintain consistent self and environmental awareness by fusing proprioceptive and visual temporal contexts. By aligning human and robot hand-eye coordination behaviors in a unified egocentric action space, we train the model progressively in three stages. Extensive experiments on a wheel-based humanoid have demonstrated strong robustness and adaptability of our proposed method across diverse long-horizon tasks spanning multiple active perception scenarios.

</details>


### [232] [Can We Redesign a Shoulder Exosuit to Enhance Comfort and Usability Without Losing Assistance?](https://arxiv.org/abs/2602.04625)
*Roberto Ferroni,Daniele Filippo Mauceri,Jacopo Carpaneto,Alessandra Pedrocchi,Tommaso Proietti*

Main category: cs.RO

TL;DR: 本研究改进了软性肩部外骨骼（Soft Shoulder v2），重点提升穿戴舒适性与功能性交互，同时保持辅助性能；实验表明v2在前臂定位、横向平面活动度（+30°）及用户主观舒适度、易用性等方面显著优于v1，且不增加肌肉负荷。


<details>
  <summary>Details</summary>
Motivation: 现有软性肩部外骨骼虽具辅助潜力，但舒适性常被忽视，而舒适性直接影响长期真实场景使用；同时原设计在功能相关动作（如前向手臂定位）支持不足。

Method: 基于v1的不足，重新设计软性肩部外骨骼（v2），将辅助平面由冠状面转向矢状面以更好支持功能性手部定位；在8名健康受试者中开展对照实验，评估静态持重、动态提举和拾取放置任务下的肌电、运动学及主观反馈。

Result: v2显著提升前向手臂定位能力与横断面活动度（最高+30°），未增加肌肉激活；主观评价显示压力感显著降低，有效性、易用性与舒适性评分均明显提高；两代在耐力提升与三角肌减负方面效果相当。

Conclusion: 以用户为中心的针对性结构优化可在不牺牲辅助性能的前提下显著提升软性外骨骼的舒适性与功能性适用性，推动其向日常长期穿戴应用迈进。

Abstract: Reduced shoulder mobility limits upper-limb function and the performance of activities of daily living across a wide range of conditions. Wearable exosuits have shown promise in assisting arm elevation, reducing muscle effort, and supporting functional movements; however, comfort is rarely prioritized as an explicit design objective, despite it strongly affects real-life, long-term usage. This study presents a redesigned soft shoulder exosuit (Soft Shoulder v2) developed to address comfort-related limitations identified in our previous version, while preserving assistive performance. In parallel, assistance was also improved, shifting from the coronal plane to the sagittal plane to better support functionally relevant hand positioning. A controlled comparison between the previous (v1) and redesigned (v2) modules was conducted in eight healthy participants, who performed static holding, dynamic lifting, and a functional pick and place task. Muscle activity, kinematics, and user-reported outcomes were assessed. Both versions increased endurance time, reduced deltoid activation, and preserved transparency during unpowered shoulder elevation. However, the difference between them emerged most clearly during functional tasks and comfort evaluation. The redesigned module facilitated forward arm positioning and increased transverse plane mobility by up to 30 deg, without increasing muscular demand. User-reported outcomes further indicated a substantial improvement in wearability, with markedly lower perceived pressure and higher ratings in effectiveness, ease of use, and comfort compared to the previous design. Taken together, these findings show that targeted, user-centered design refinements can improve comfort and functional interaction without compromising assistive performance, advancing the development of soft exosuits suitable for prolonged and daily use.

</details>


### [233] [Radar-Inertial Odometry For Computationally Constrained Aerial Navigation](https://arxiv.org/abs/2602.04631)
*Jan Michalczyk*

Main category: cs.RO

TL;DR: 本文提出了一种雷达-惯性里程计（RIO）算法，通过融合低成本FMCW雷达与IMU数据，在资源受限嵌入式平台上实现实时无人机导航状态估计，并引入深度学习提升稀疏噪声雷达点云的3D点匹配性能。


<details>
  <summary>Details</summary>
Motivation: 传统外感受传感器（如LiDAR、相机、GNSS）在极端环境（如强光、烟雾、雾气）下性能受限，而雷达对这些干扰具有鲁棒性，因此亟需发展适用于低成本、嵌入式平台的雷达-惯性融合导航方法。

Method: 提出基于多状态紧耦合扩展卡尔曼滤波（EKF）和因子图（FG）的RIO算法，融合FMCW雷达提供的瞬时速度与3D点距离信息及IMU数据；并创新性地利用深度学习从稀疏噪声雷达点云中提取3D点对应关系。

Result: 实现了可在便携式资源受限嵌入式计算机上实时运行的RIO系统，仅使用廉价消费级雷达与IMU，验证了其在无人机导航中的有效性与鲁棒性。

Conclusion: 雷达-惯性融合是实现极端环境下自主机器人高精度实时导航的可行且有前景的技术路径，所提出的RIO框架兼顾算法精度、计算效率与硬件成本，为实际部署提供了新思路。

Abstract: Recently, the progress in the radar sensing technology consisting in the miniaturization of the packages and increase in measuring precision has drawn the interest of the robotics research community. Indeed, a crucial task enabling autonomy in robotics is to precisely determine the pose of the robot in space. To fulfill this task sensor fusion algorithms are often used, in which data from one or several exteroceptive sensors like, for example, LiDAR, camera, laser ranging sensor or GNSS are fused together with the Inertial Measurement Unit (IMU) measurements to obtain an estimate of the navigation states of the robot. Nonetheless, owing to their particular sensing principles, some exteroceptive sensors are often incapacitated in extreme environmental conditions, like extreme illumination or presence of fine particles in the environment like smoke or fog. Radars are largely immune to aforementioned factors thanks to the characteristics of electromagnetic waves they use. In this thesis, we present Radar-Inertial Odometry (RIO) algorithms to fuse the information from IMU and radar in order to estimate the navigation states of a (Uncrewed Aerial Vehicle) UAV capable of running on a portable resource-constrained embedded computer in real-time and making use of inexpensive, consumer-grade sensors. We present novel RIO approaches relying on the multi-state tightly-coupled Extended Kalman Filter (EKF) and Factor Graphs (FG) fusing instantaneous velocities of and distances to 3D points delivered by a lightweight, low-cost, off-the-shelf Frequency Modulated Continuous Wave (FMCW) radar with IMU readings. We also show a novel way to exploit advances in deep learning to retrieve 3D point correspondences in sparse and noisy radar point clouds.

</details>


### [234] [Relational Scene Graphs for Object Grounding of Natural Language Commands](https://arxiv.org/abs/2602.04635)
*Julia Kuhn,Francesco Verdoja,Tsvetomila Mihaylova,Ville Kyrki*

Main category: cs.RO

TL;DR: 本文研究了在3D场景图（3DSG）中加入显式空间关系（开词汇或闭词汇）是否能提升大语言模型（LLM）对自然语言指令中目标物体的定位能力；提出了基于LLM的目标物体定位流程和基于视觉语言模型（VLM）从机器人采集图像中生成开放词汇空间边以增强3DSG的方法；实验表明显式空间关系确实提升了LLM的定位性能，但开词汇关系相较闭词汇关系的优势有限。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图常缺乏显式空间关系，而人类描述环境时高度依赖此类关系；需提升LLM在自然语言指令理解中对环境（尤其是物体间空间关系）的语义接地能力。

Method: 提出一个基于LLM的目标物体定位流程，并设计一个基于视觉语言模型（VLM）的流程，从机器人建图时采集的图像中自动添加开词汇空间关系边到3D场景图中。

Result: 实验证明，引入显式空间关系显著提升了LLM在目标物体定位任务上的性能；开词汇空间关系可通过VLM从机器人图像中可靠生成，但其相对于闭词汇关系的增益有限。

Conclusion: 显式建模空间关系是提升语言-机器人交互中语义接地能力的有效途径；VLM支持的开词汇关系扩展可行，但在当前设定下尚未展现出明显优于闭词汇方法的优势，提示需进一步优化关系表示与LLM协同机制。

Abstract: Robots are finding wider adoption in human environments, increasing the need for natural human-robot interaction. However, understanding a natural language command requires the robot to infer the intended task and how to decompose it into executable actions, and to ground those actions in the robot's knowledge of the environment, including relevant objects, agents, and locations. This challenge can be addressed by combining the capabilities of Large language models (LLMs) to understand natural language with 3D scene graphs (3DSGs) for grounding inferred actions in a semantic representation of the environment. However, many 3DSGs lack explicit spatial relations between objects, even though humans often rely on these relations to describe an environment. This paper investigates whether incorporating open- or closed-vocabulary spatial relations into 3DSGs can improve the ability of LLMs to interpret natural language commands. To address this, we propose an LLM-based pipeline for target object grounding from open-vocabulary language commands and a vision language model (VLM)-based pipeline to add open-vocabulary spatial edges to 3DSGs from images captured while mapping. Finally, two LLMs are evaluated in a study assessing their performance on the downstream task of target object grounding. Our study demonstrates that explicit spatial relations improve the ability of LLMs to ground objects. Moreover, open-vocabulary relation generation with VLMs proves feasible from robot-captured images, but their advantage over closed-vocabulary relations is found to be limited.

</details>


### [235] [From Vision to Assistance: Gaze and Vision-Enabled Adaptive Control for a Back-Support Exoskeleton](https://arxiv.org/abs/2602.04648)
*Alessandro Leanza,Paolo Franceschi,Blerina Spahiu,Loris Roveda*

Main category: cs.RO

TL;DR: 本文提出了一种基于第一人称视觉与眼动追踪的视觉门控控制框架，用于主动式腰部职业外骨骼，通过实时抓取检测、任务状态机和可变导纳控制器提升辅助时机与适应性，并在15人用户实验中验证其显著降低主观体力负荷、提升流畅性、信任感与舒适度。


<details>
  <summary>Details</summary>
Motivation: 现有背部支撑外骨骼依赖肌电信号或惯性测量单元进行负载估计，或使用无法直接驱动控制的视觉系统，导致辅助不及时、缺乏情境感知，影响实际效果与用户接受度。

Method: 构建基于第一人称视觉（YOLO抓取检测）与可穿戴眼动追踪的视觉门控控制框架，融合有限状态机（FSM）表征任务进展，结合可变导纳控制器动态调节扭矩输出，适配姿态与物体状态。

Result: 用户实验显示：相比无外骨骼和无视觉辅助模式，视觉门控模式显著降低RPE（主观体力需求），提升动作流畅性、信任感与舒适度；定量分析表明辅助启动更早、峰值扭矩更大；问卷结果一致偏好视觉门控模式。

Conclusion: 第一人称视觉可有效提升外骨骼的响应性、工效性、安全性与用户接受度，为智能、情境感知的工业外骨骼控制提供了新范式。

Abstract: Back-support exoskeletons have been proposed to mitigate spinal loading in industrial handling, yet their effectiveness critically depends on timely and context-aware assistance. Most existing approaches rely either on load-estimation techniques (e.g., EMG, IMU) or on vision systems that do not directly inform control. In this work, we present a vision-gated control framework for an active lumbar occupational exoskeleton that leverages egocentric vision with wearable gaze tracking. The proposed system integrates real-time grasp detection from a first-person YOLO-based perception system, a finite-state machine (FSM) for task progression, and a variable admittance controller to adapt torque delivery to both posture and object state. A user study with 15 participants performing stooping load lifting trials under three conditions (no exoskeleton, exoskeleton without vision, exoskeleton with vision) shows that vision-gated assistance significantly reduces perceived physical demand and improves fluency, trust, and comfort. Quantitative analysis reveals earlier and stronger assistance when vision is enabled, while questionnaire results confirm user preference for the vision-gated mode. These findings highlight the potential of egocentric vision to enhance the responsiveness, ergonomics, safety, and acceptance of back-support exoskeletons.

</details>


### [236] [Dull, Dirty, Dangerous: Understanding the Past, Present, and Future of a Key Motivation for Robotics](https://arxiv.org/abs/2602.04746)
*Nozomi Nakajima,Pedro Reynolds-Cuéllar,Caitrin Lynch,Kate Darling*

Main category: cs.RO

TL;DR: 本文对机器人学文献中关于'DDD（枯燥、肮脏、危险）工作'的使用进行了实证分析，发现定义和具体示例严重不足；继而借鉴社会科学文献厘清概念，并提出一个帮助机器人社区更审慎评估技术对人类劳动影响的框架。


<details>
  <summary>Details</summary>
Motivation: 机器人领域长期用'DDD'作为技术应用正当性的依据，但该概念缺乏明确定义和实证基础，易导致对技术社会影响的误判。

Method: 1）统计分析1980–2024年提及DDD的机器人论文中定义与实例的出现频率；2）系统综述社会科学中关于'dull'、'dirty'、'dangerous'工作的理论与实证研究；3）基于上述分析构建面向机器人技术的社会情境化评估框架。

Result: 仅2.7%的论文明确定义DDD，仅8.7%提供具体任务或职业示例；社会科学文献揭示DDD具有历史、文化与制度依赖性，不能简单技术化套用。

Conclusion: DDD不应被当作不言自明的技术前提，而需在具体社会劳动语境中审慎重构；所提框架旨在推动机器人研究者关注技术部署的真实工作场景与劳工后果。

Abstract: In robotics, the concept of "dull, dirty, and dangerous" (DDD) work has been used to motivate where robots might be useful. In this paper, we conduct an empirical analysis of robotics publications between 1980 and 2024 that mention DDD, and find that only 2.7% of publications define DDD and 8.7% of publications provide concrete examples of tasks or jobs that are DDD. We then review the social science literature on "dull," "dirty," and "dangerous" work to provide definitions and guidance on how to conceptualize DDD for robotics. Finally, we propose a framework that helps the robotics community consider the job context for our technology, encouraging a more informed perspective on how robotics may impact human labor.

</details>


### [237] [PDF-HR: Pose Distance Fields for Humanoid Robots](https://arxiv.org/abs/2602.04851)
*Yi Gu,Yukang Gao,Yangchen Zhou,Xingyu Chen,Yixiao Feng,Mingle Zhao,Yunyang Mo,Zhaorui Wang,Lixin Xu,Renjing Xu*

Main category: cs.RO

TL;DR: 本文提出了一种面向人形机器人的轻量级姿态先验方法PDF-HR，通过姿态距离场建模机器人姿态分布，提供连续可微的姿态合理性度量，并在多种运动任务中显著提升基线性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人中缺乏高质量运动数据，导致人类运动恢复（HMR）领域成熟的姿态与运动先验难以直接迁移应用。

Method: 提出Pose Distance Fields for Humanoid Robots（PDF-HR），将机器人姿态分布建模为连续可微的流形；对任意输入姿态，预测其到大规模重定向机器人姿态语料库的距离，输出平滑的姿态合理性分数；支持作为奖励塑形项、正则项或独立置信度评分器嵌入各类控制与优化流程。

Result: 在单轨迹运动跟踪、通用运动跟踪、风格化动作模仿和通用运动重定向等任务上，PDF-HR作为即插即用先验 consistently and substantially strengthens strong baselines。

Conclusion: PDF-HR是一种高效、通用且易于集成的姿态先验，有效弥补了人形机器人领域高质量运动先验缺失的问题，提升了多种下游任务的性能。

Abstract: Pose and motion priors play a crucial role in humanoid robotics. Although such priors have been widely studied in human motion recovery (HMR) domain with a range of models, their adoption for humanoid robots remains limited, largely due to the scarcity of high-quality humanoid motion data. In this work, we introduce Pose Distance Fields for Humanoid Robots (PDF-HR), a lightweight prior that represents the robot pose distribution as a continuous and differentiable manifold. Given an arbitrary pose, PDF-HR predicts its distance to a large corpus of retargeted robot poses, yielding a smooth measure of pose plausibility that is well suited for optimization and control. PDF-HR can be integrated as a reward shaping term, a regularizer, or a standalone plausibility scorer across diverse pipelines. We evaluate PDF-HR on various humanoid tasks, including single-trajectory motion tracking, general motion tracking, style-based motion mimicry, and general motion retargeting. Experiments show that this plug-and-play prior consistently and substantially strengthens strong baselines. Code and models will be released.

</details>


### [238] [Capturing Visual Environment Structure Correlates with Control Performance](https://arxiv.org/abs/2602.04880)
*Jiahua Dong,Yunze Man,Pavel Tokmakov,Yu-Xiong Wang*

Main category: cs.RO

TL;DR: 本文提出了一种通过探测预训练视觉编码器对环境状态（如几何、物体结构和物理属性）解码能力来评估其表征质量的新方法，该方法在仿真环境中验证了探测准确率与下游策略性能高度相关，优于现有代理指标，并为通用机器人策略的视觉表征选择提供了高效途径。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表征评估方法依赖昂贵的策略 rollout 或仅关注视觉世界狭窄方面（如物体形状），难以支持跨环境泛化。

Method: 在具备真实状态（ground-truth state）的仿真环境中，探测预训练视觉编码器对环境状态（几何、物体结构、物理属性）的解码能力，并分析其与下游策略性能的相关性。

Result: 探测准确率与下游策略性能在多种环境和学习设置下呈强相关，显著优于先前代理指标，可实现高效表征选择。

Conclusion: 编码环境潜在物理状态是提升机器人操作泛化能力的关键表征目标，所提探测方法为通用机器人策略的视觉表征评估与选择提供了新范式。

Abstract: The choice of visual representation is key to scaling generalist robot policies. However, direct evaluation via policy rollouts is expensive, even in simulation. Existing proxy metrics focus on the representation's capacity to capture narrow aspects of the visual world, like object shape, limiting generalization across environments. In this paper, we take an analytical perspective: we probe pretrained visual encoders by measuring how well they support decoding of environment state -- including geometry, object structure, and physical attributes -- from images. Leveraging simulation environments with access to ground-truth state, we show that this probing accuracy strongly correlates with downstream policy performance across diverse environments and learning settings, significantly outperforming prior metrics and enabling efficient representation selection. More broadly, our study provides insight into the representational properties that support generalizable manipulation, suggesting that learning to encode the latent physical state of the environment is a promising objective for control.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [239] [Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data](https://arxiv.org/abs/2602.03872)
*Jiaming Zhang,Huanyi Xie,Meng Ding,Shaopeng Fu,Jinyan Liu,Di Wang*

Main category: cs.LG

TL;DR: 本文提出首个从特征学习角度分析DP-SGD在长尾数据上泛化性能下降的理论框架，揭示其因梯度裁剪与噪声注入联合削弱对稀有样本记忆能力而导致子群体误差显著升高。


<details>
  <summary>Details</summary>
Motivation: DP-SGD在长尾数据上泛化性能差且缺乏理论解释，现有隐私分析难以适用于实际中非凸非光滑神经网络。

Method: 构建基于特征学习视角的DP-SGD理论分析框架，刻画其在长尾数据上的训练动态，特别分析梯度裁剪和噪声注入对稀有样本学习的影响。

Result: 证明DP-SGD在长尾子群体上的测试误差显著高于整体测试误差，并通过合成与真实数据实验验证理论发现。

Conclusion: DP-SGD因抑制对信息丰富但样本稀少的特征的记忆，导致长尾子群体性能严重下降；该理论为设计更公平、鲁棒的差分隐私训练方法提供基础。

Abstract: Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private training algorithms such as DP-SGD. However, a growing body of empirical work shows that DP-SGD often leads to suboptimal generalization performance, particularly on long-tailed data that contain a large number of rare or atypical samples. Despite these observations, a theoretical understanding of this phenomenon remains largely unexplored, and existing differential privacy analysis are difficult to extend to the nonconvex and nonsmooth neural networks commonly used in practice. In this work, we develop the first theoretical framework for analyzing DP-SGD on long-tailed data from a feature learning perspective. We show that the test error of DP-SGD-trained models on the long-tailed subpopulation is significantly larger than the overall test error over the entire dataset. Our analysis further characterizes the training dynamics of DP-SGD, demonstrating how gradient clipping and noise injection jointly adversely affect the model's ability to memorize informative but underrepresented samples. Finally, we validate our theoretical findings through extensive experiments on both synthetic and real-world datasets.

</details>


### [240] [Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra](https://arxiv.org/abs/2602.03875)
*Stefan Kuhn,Vandana Dwarka,Przemyslaw Karol Grenda,Eero Vainikko*

Main category: cs.LG

TL;DR: 本文提出了一种基于可逆深度学习的13C NMR谱-结构双向建模方法，使用单一条件可逆神经网络（i-RevNet结构）实现分子结构到谱图及反向的映射，在统一框架下同时支持谱图预测与不确定性感知的结构生成。


<details>
  <summary>Details</summary>
Motivation: 解决13C NMR谱图到分子结构映射的一对多问题，以及传统模型难以同时支持正向预测与反向生成的局限。

Method: 采用i-RevNet风格的双射模块构建条件可逆神经网络，以图编码表示分子结构，输出128位二值化谱图编码，其余隐变量建模残差变异；训练时学习结构→谱码映射，推理时直接逆向生成结构候选。

Result: 在过滤数据子集上，模型对训练样本数值可逆，谱码预测显著优于随机水平，且对验证集谱图逆向生成的结果虽较粗糙但呈现有意义的结构信号。

Conclusion: 可逆架构能在一个端到端模型中统一谱图预测与不确定性感知的结构候选生成，为NMR解析提供了新范式。

Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.

</details>


### [241] [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876)
*Kyuseong Choi,Dwaipayan Saha,Woojeong Kim,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: 本文提出Group Ordinal Policy Optimization (GOPO)，一种仅依赖奖励排序而非绝对数值的策略优化方法，以解决标准RLHF中奖励模型相对偏好与策略优化绝对奖励之间的不匹配问题，在非可验证奖励任务（如摘要生成、指令遵循和聊天补全）中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准RLHF中奖励模型优化目标是相对偏好，但策略优化却依赖绝对奖励值，导致在非可验证奖励场景下性能不佳。

Method: 提出GOPO方法，对奖励进行基于排序的变换，仅利用奖励的序数信息进行策略优化，摒弃其绝对数值。

Result: 相比GRPO，GOPO在训练/验证奖励轨迹、LLM-as-judge评估表现以及收敛速度上均取得一致提升。

Conclusion: GOPO能有效缓解RLHF中奖励建模与策略优化间的不匹配问题，在多种任务和模型规模上展现出更强的鲁棒性与效率。

Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.

</details>


### [242] [NeuroPareto: Calibrated Acquisition for Costly Many-Goal Search in Vast Parameter Spaces](https://arxiv.org/abs/2602.03901)
*Rong Fu,Wenxin Zhang,Chunlei Meng,Youjin Wang,Haoyu Zhao,Jiaxuan Lu,Kun Liu,JiaBao Dou,Simon James Fong*

Main category: cs.LG

TL;DR: NeuroPareto是一种面向高维多目标优化的高效框架，融合排序过滤、不确定性解耦与历史感知采集策略，在低计算开销下生成高质量Pareto解集。


<details>
  <summary>Details</summary>
Motivation: 在严格计算约束下，高维搜索空间中的多目标优化面临收敛性与多样性难以兼顾、评估代价高昂的根本挑战。

Method: 提出NeuroPareto架构：1）基于校准贝叶斯分类器的层级非支配排序与认知不确定性估计；2）深度高斯过程分离可约/不可约预测不确定性；3）轻量级在线训练采集网络，依据历史超体积改进指导评估；4）分层筛选与摊销式代理模型更新。

Result: 在DTLZ、ZDT基准及地下能源开采任务上，NeuroPareto在Pareto接近度和超体积指标上持续优于分类器增强型和代理辅助型基线方法。

Conclusion: NeuroPareto通过协同建模不确定性与历史信息，实现了高精度与低开销的统一，为资源受限下的多目标优化提供了新范式。

Abstract: The pursuit of optimal trade-offs in high-dimensional search spaces under stringent computational constraints poses a fundamental challenge for contemporary multi-objective optimization. We develop NeuroPareto, a cohesive architecture that integrates rank-centric filtering, uncertainty disentanglement, and history-conditioned acquisition strategies to navigate complex objective landscapes. A calibrated Bayesian classifier estimates epistemic uncertainty across non-domination tiers, enabling rapid generation of high-quality candidates with minimal evaluation cost. Deep Gaussian Process surrogates further separate predictive uncertainty into reducible and irreducible components, providing refined predictive means and risk-aware signals for downstream selection. A lightweight acquisition network, trained online from historical hypervolume improvements, guides expensive evaluations toward regions balancing convergence and diversity. With hierarchical screening and amortized surrogate updates, the method maintains accuracy while keeping computational overhead low. Experiments on DTLZ and ZDT suites and a subsurface energy extraction task show that NeuroPareto consistently outperforms classifier-enhanced and surrogate-assisted baselines in Pareto proximity and hypervolume.

</details>


### [243] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息几何的新型信息瓶颈方法GeoIB，避免了传统IB中互信息估计的偏差与不稳定性，通过Fisher-Rao距离和Jacobian-Frobenius项联合控制压缩与预测，提升了信息平面权衡、不变性与优化稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习中的信息瓶颈（IB）依赖于互信息（MI）的代理估计（如变分界或神经估计器），存在估计偏差、松散界和优化脆弱性问题，难以真正控制I(X;Z)。

Method: 基于信息几何视角，将I(X;Z)和I(Z;Y)表示为到独立流形的KL距离；提出GeoIB框架：（i）分布层使用Fisher-Rao（FR）差异近似KL距离（二阶匹配、重参数不变）；（ii）几何层引入Jacobian-Frobenius（JF）项，通过惩罚编码器拉回体积膨胀来局部上界约束I(Z;X)；并设计与FR度量一致的自然梯度优化器。

Result: 在多个主流数据集上，GeoIB在信息平面中实现了优于现有IB基线的预测精度-压缩比权衡；增强了模型不变性与训练稳定性；统一了分布正则化与几何正则化于单一瓶颈系数下。

Conclusion: GeoIB提供了一种无需互信息估计、几何原理清晰、优化鲁棒的信息瓶颈新范式，为深度表示学习中的信息控制提供了更可靠、可解释的理论与实践路径。

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


### [244] [Disentangling Causal Importance from Emergent Structure in Multi-Expert Orchestration](https://arxiv.org/abs/2602.04291)
*Sudipto Ghosh,Sujoy Nath,Sunny Manchanda,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 本文提出INFORM可解释性分析框架，将多专家系统中的调度策略视为可分析的显式计算，揭示了专家间关系重要性与内在重要性的差异，并发现频繁被选中的专家常为交互枢纽但因果影响有限，而稀疏路由的专家可能具有结构性关键作用。


<details>
  <summary>Details</summary>
Motivation: 多专家系统中专家协作的调度策略缺乏透明度，现有方法难以解耦专家交互结构、执行顺序和因果归因。

Method: 提出INFORM可解释性分析框架，通过显式建模调度过程，结合路由质量、交互拓扑与基于梯度的因果归因，在GSM8K、HumanEval和MMLU数据集上评估同构与异构专家联盟。

Result: 发现路由主导性不能反映功能必要性；关系重要性（路由质量与拓扑）与内在重要性（因果归因）存在显著分歧；专家中心化先于路由置信度稳定，排序非确定；屏蔽内在重要专家比屏蔽高频专家更易导致交互结构崩溃。

Conclusion: INFORM能有效揭示多专家系统中超越准确率的因果与结构依赖关系，为理解与优化调度策略提供新视角。

Abstract: Multi-expert systems, where multiple Large Language Models (LLMs) collaborate to solve complex tasks, are increasingly adopted for high-performance reasoning and generation. However, the orchestration policies governing expert interaction and sequencing remain largely opaque. We introduce INFORM, an interpretability analysis that treats orchestration as an explicit, analyzable computation, enabling the decoupling of expert interaction structure, execution order, and causal attribution. We use INFORM to evaluate an orchestrator on GSM8K, HumanEval, and MMLU using a homogeneous consortium of ten instruction-tuned experts drawn from LLaMA-3.1 8B, Qwen-3 8B, and DeepSeek-R1 8B, with controlled decoding-temperature variation, and a secondary heterogeneous consortium spanning 1B-7B parameter models. Across tasks, routing dominance is a poor proxy for functional necessity. We reveal a divergence between relational importance, captured by routing mass and interaction topology, and intrinsic importance, measured via gradient-based causal attribution: frequently selected experts often act as interaction hubs with limited causal influence, while sparsely routed experts can be structurally critical. Orchestration behaviors emerge asynchronously, with expert centralization preceding stable routing confidence and expert ordering remaining non-deterministic. Targeted ablations show that masking intrinsically important experts induces disproportionate collapse in interaction structure compared to masking frequent peers, confirming that INFORM exposes causal and structural dependencies beyond accuracy metrics alone.

</details>


### [245] [The Role of Target Update Frequencies in Q-Learning](https://arxiv.org/abs/2602.03911)
*Simon Weissmann,Tilman Aach,Benedikt Wille,Sebastian Kassing,Leif Döring*

Main category: cs.LG

TL;DR: 本文通过近似动态规划的视角，理论分析了表格型Q学习中目标网络更新频率（TUF）的作用，提出了一种嵌套优化框架，并给出了有限时间收敛性分析；揭示了TUF带来的偏差-方差权衡，证明固定更新周期次优，而几何增长的自适应更新频率最优。


<details>
  <summary>Details</summary>
Motivation: 目标网络更新频率（TUF）是Q学习中关键但理解不足的稳定机制，其选择常被当作经验调参而非原理性设计，亟需理论指导。

Method: 将周期性目标更新建模为嵌套优化：外层应用不精确贝尔曼最优算子，内层由通用优化器（如SGD）近似；在异步采样设定下进行严格有限时间收敛分析。

Result: 得到了TUF引起的偏差-方差权衡的显式刻画；证明固定更新周期会带来可避免的对数级样本复杂度开销；发现最优更新频率应随学习进程呈几何增长。

Conclusion: TUF不应被简单视为超参数，而应依据理论指导采用自适应（几何增长）更新策略，以实现更优收敛性能。

Abstract: The target network update frequency (TUF) is a central stabilization mechanism in (deep) Q-learning. However, their selection remains poorly understood and is often treated merely as another tunable hyperparameter rather than as a principled design decision. This work provides a theoretical analysis of target fixing in tabular Q-learning through the lens of approximate dynamic programming. We formulate periodic target updates as a nested optimization scheme in which each outer iteration applies an inexact Bellman optimality operator, approximated by a generic inner loop optimizer. Rigorous theory yields a finite-time convergence analysis for the asynchronous sampling setting, specializing to stochastic gradient descent in the inner loop. Our results deliver an explicit characterization of the bias-variance trade-off induced by the target update period, showing how to optimally set this critical hyperparameter. We prove that constant target update schedules are suboptimal, incurring a logarithmic overhead in sample complexity that is entirely avoidable with adaptive schedules. Our analysis shows that the optimal target update frequency increases geometrically over the course of the learning process.

</details>


### [246] [Echo State Networks for Time Series Forecasting: Hyperparameter Sweep and Benchmarking](https://arxiv.org/abs/2602.03912)
*Alexander Häußer*

Main category: cs.LG

TL;DR: 本文研究了回声状态网络（ESN）在M4数据集子集上的单变量时间序列预测性能，发现其在月度和季度数据上可与ARIMA、TBATS等统计方法媲美，甚至在季度数据上MASE最低，且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 探索一种全自动、纯反馈驱动的ESN能否作为主流统计预测方法（如ARIMA、ETS）的有力替代方案，尤其针对中短期月度/季度时间序列。

Method: 采用两阶段严格评估：第一阶段在参数数据集上对泄漏率、谱半径、储备池大小和正则化信息准则进行超参数遍历（超四百万次模型拟合）；第二阶段在独立预测数据集上进行样本外精度评估，使用MASE和sMAPE指标，并与漂移法、季节性朴素法及ARIMA、ETS、TBATS等基准模型对比。

Result: 超参数分析揭示清晰模式：月度序列偏好中等持久性储备池，季度序列偏好更强收缩动力学；高频泄漏率普遍最优，谱半径与储备池大小随时间分辨率变化；样本外评估显示ESN在月度数据上性能与ARIMA/TBATS相当，在季度数据上取得最低平均MASE，且计算开销更小。

Conclusion: ESN在预测精度、鲁棒性和计算效率之间取得了良好平衡，是一种适用于自动化时间序列预测的实用方法。

Abstract: This paper investigates the forecasting performance of Echo State Networks (ESNs) for univariate time series forecasting using a subset of the M4 Forecasting Competition dataset. Focusing on monthly and quarterly time series with at most 20 years of historical data, we evaluate whether a fully automatic, purely feedback-driven ESN can serve as a competitive alternative to widely used statistical forecasting methods. The study adopts a rigorous two-stage evaluation approach: a Parameter dataset is used to conduct an extensive hyperparameter sweep covering leakage rate, spectral radius, reservoir size, and information criteria for regularization, resulting in over four million ESN model fits; a disjoint Forecast dataset is then used for out-of-sample accuracy assessment. Forecast accuracy is measured using MASE and sMAPE and benchmarked against simple benchmarks like drift and seasonal naive and statistical models like ARIMA, ETS, and TBATS. The hyperparameter analysis reveals consistent and interpretable patterns, with monthly series favoring moderately persistent reservoirs and quarterly series favoring more contractive dynamics. Across both frequencies, high leakage rates are preferred, while optimal spectral radii and reservoir sizes vary with temporal resolution. In the out-of-sample evaluation, the ESN performs on par with ARIMA and TBATS for monthly data and achieves the lowest mean MASE for quarterly data, while requiring lower computational cost than the more complex statistical models. Overall, the results demonstrate that ESNs offer a compelling balance between predictive accuracy, robustness, and computational efficiency, positioning them as a practical option for automated time series forecasting.

</details>


### [247] [Causal Discovery for Cross-Sectional Data Based on Super-Structure and Divide-and-Conquer](https://arxiv.org/abs/2602.03914)
*Wenyu Wang,Yaping Wan*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级框架，通过放宽超结构（Super-Structure）构建的严格要求，在保持分而治之优势的同时显著降低条件独立性（CI）检验开销，实现在无先验知识场景下的高效、准确因果发现。


<details>
  <summary>Details</summary>
Motivation: 解决基于超结构的分而治之因果发现方法中，超结构构建计算成本高（尤其当CI检验昂贵且缺乏领域知识时）的关键瓶颈。

Method: 提出一种轻量级框架，融合弱约束超结构、高效图划分与合并策略；实例化为具体算法，并在合成数据上进行组件级严格评估。

Result: 在Gaussian贝叶斯网络（magic-NIAB、ECOLI70、magic-IRRI）和真实CHARLS数据集上，结构准确性媲美或接近PC/FCI，同时大幅减少CI检验次数。

Conclusion: 即使初始超结构假设极弱，仍可实现准确且可扩展的因果发现，为生物医学与社会科学等大规模、知识匮乏领域提供了新路径。

Abstract: This paper tackles a critical bottleneck in Super-Structure-based divide-and-conquer causal discovery: the high computational cost of constructing accurate Super-Structures--particularly when conditional independence (CI) tests are expensive and domain knowledge is unavailable. We propose a novel, lightweight framework that relaxes the strict requirements on Super-Structure construction while preserving the algorithmic benefits of divide-and-conquer. By integrating weakly constrained Super-Structures with efficient graph partitioning and merging strategies, our approach substantially lowers CI test overhead without sacrificing accuracy. We instantiate the framework in a concrete causal discovery algorithm and rigorously evaluate its components on synthetic data. Comprehensive experiments on Gaussian Bayesian networks, including magic-NIAB, ECOLI70, and magic-IRRI, demonstrate that our method matches or closely approximates the structural accuracy of PC and FCI while drastically reducing the number of CI tests. Further validation on the real-world China Health and Retirement Longitudinal Study (CHARLS) dataset confirms its practical applicability. Our results establish that accurate, scalable causal discovery is achievable even under minimal assumptions about the initial Super-Structure, opening new avenues for applying divide-and-conquer methods to large-scale, knowledge-scarce domains such as biomedical and social science research.

</details>


### [248] [From Data to Behavior: Predicting Unintended Model Behaviors Before Training](https://arxiv.org/abs/2602.04735)
*Mengru Wang,Zhenqian Xu,Junfeng Fang,Yunzhi Yao,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.LG

TL;DR: 本文提出Data2Behavior任务和Manipulating Data Features (MDF)方法，用于在模型微调前预测大语言模型可能产生的无意偏见与安全风险，无需参数更新，仅需约20%微调所需的GPU资源。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在微调前检测训练数据中隐含的无意偏见，导致事后评估成本高、效率低。

Method: 提出Data2Behavior新任务，并设计轻量级MDF方法：通过候选数据的均值表征注入基础模型前向传播，利用数据的潜在统计信号影响模型激活，从而揭示偏见与安全风险，不更新任何参数。

Result: 在Qwen3-14B、Qwen2.5-32B-Instruct和Gemma-3-12b-it上的实验表明，MDF能可靠预测非预期行为，并揭示预训练阶段的脆弱性，资源消耗仅为微调的约20%。

Conclusion: MDF是一种高效、低开销的前置风险评估方法，为大模型安全与对齐提供了新思路。

Abstract: Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior, a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities.

</details>


### [249] [SpecMD: A Comprehensive Study On Speculative Expert Prefetching](https://arxiv.org/abs/2602.03921)
*Duc Hoang,Ajay Jaiswal,Mohammad Samragh,Minsik Cho*

Main category: cs.LG

TL;DR: 本文提出SpecMD框架用于标准化评估MoE模型的专家缓存策略，并发现传统基于时间局部性的缓存策略（如LRU、LFU）不适用于MoE；为此，作者提出新型驱逐策略Least-Stale，在低缓存容量下显著提升缓存命中率并降低首token延迟。


<details>
  <summary>Details</summary>
Motivation: 现有硬件中心化MoE缓存策略缺乏系统性评估，不同策略与硬件配置间的交互关系尚不明确，且其隐含的时序局部性假设是否适用于MoE专家访问模式未被验证。

Method: 构建标准化基准框架SpecMD，对多种MoE缓存策略在真实约束和多硬件配置下进行可控复现实验；分析专家访问模式，提出基于访问新鲜度的Least-Stale驱逐策略。

Result: 实验证明MoE专家访问不符合LRU/LFU等时序局部性假设；Least-Stale相较LRU可减少高达85倍的冲突缺失；在仅5%（0.6GB）VRAM缓存下，OLMoE模型缓存命中率达88%以上，首token时间（TTFT）降低34.7%。

Conclusion: MoE缓存设计需摒弃通用局部性假设，转向利用其固有可预测访问模式；Least-Stale策略及SpecMD框架为高效MoE推理提供了新方法论与实用工具。

Abstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric caching policies, but how these various caching policies interact with each other and different hardware specification remains poorly understood. To address this gap, we develop \textbf{SpecMD}, a standardized framework for benchmarking ad-hoc cache policies on various hardware configurations. Using SpecMD, we perform an exhaustive benchmarking of several MoE caching strategies, reproducing and extending prior approaches in controlled settings with realistic constraints. Our experiments reveal that MoE expert access is not consistent with temporal locality assumptions (e.g LRU, LFU). Motivated by this observation, we propose \textbf{Least-Stale}, a novel eviction policy that exploits MoE's predictable expert access patterns to reduce collision misses by up to $85\times$ over LRU. With such gains, we achieve over $88\%$ hit rates with up to $34.7\%$ Time-to-first-token (TTFT) reduction on OLMoE at only $5\%$ or $0.6GB$ of VRAM cache capacity.

</details>


### [250] [Robust Generalizable Heterogeneous Legal Link Prediction](https://arxiv.org/abs/2602.04812)
*Lorenz Wendlinger,Simon Alexander Nonn,Abdullah Al Zubaer,Michael Granitzer*

Main category: cs.LG

TL;DR: 本文通过引入边丢弃和特征拼接，提升了法律引用网络中的链接预测性能，并提出基于多语言节点特征和改进的非对称解码器的方法，以增强跨地理与语言隔离法律系统的泛化与迁移能力。


<details>
  <summary>Details</summary>
Motivation: 提升大型异构法律引用网络中链接预测的鲁棒性与跨法律系统的泛化能力。

Method: 引入边丢弃（edge dropout）和特征拼接（feature concatenation）以学习更鲁棒的表示；提出基于多语言节点特征与改进的非对称解码器的方法。

Result: 错误率降低高达45%；成功将模型推广至新西兰等地理与语言上隔离的法律数据；增强了不同法律系统间的归纳迁移能力。

Conclusion: 所提方法显著提升了法律引用链接预测的准确性与跨域适应性，为多司法管辖区法律知识图谱构建提供了新思路。

Abstract: Recent work has applied link prediction to large heterogeneous legal citation networks \new{with rich meta-features}. We find that this approach can be improved by including edge dropout and feature concatenation for the learning of more robust representations, which reduces error rates by up to 45%. We also propose an approach based on multilingual node features with an improved asymmetric decoder for compatibility, which allows us to generalize and extend the prediction to more, geographically and linguistically disjoint, data from New Zealand. Our adaptations also improve inductive transferability between these disjoint legal systems.

</details>


### [251] [Online Vector Quantized Attention](https://arxiv.org/abs/2602.03922)
*Nick Alonso,Tomas Figliolia,Beren Millidge*

Main category: cs.LG

TL;DR: 本文提出了一种新型序列混合层OVQ-attention，兼顾线性计算复杂度与常数内存消耗，并通过稀疏记忆更新提升记忆容量，在长上下文任务中性能接近自注意力，但内存占用显著降低。


<details>
  <summary>Details</summary>
Motivation: 标准序列混合层（如自注意力、线性注意力、SSMs）难以在计算效率与长上下文建模性能之间取得良好平衡：自注意力性能好但计算/内存开销高；线性注意力和SSMs效率高但长程建模能力弱。

Method: 提出在线向量量化（OVQ）注意力机制，基于高斯混合回归构建理论基础，采用稀疏记忆更新以扩大记忆状态规模，实现线性计算与常数内存消耗。

Result: 在合成长上下文任务和长上下文语言建模中，OVQ-attention显著优于线性注意力和原始VQ-attention，在长达64k序列长度上性能媲美强自注意力基线，但仅需其一小部分内存。

Conclusion: OVQ-attention为长上下文建模提供了一种高效且高性能的折中方案，验证了稀疏记忆更新对提升线性复杂度模型记忆容量的有效性。

Abstract: Standard sequence mixing layers used in language models struggle to balance efficiency and performance. Self-attention performs well on long context tasks but has expensive quadratic compute and linear memory costs, while linear attention and SSMs use only linear compute and constant memory but struggle with long context processing. In this paper, we develop a sequence mixing layer that aims to find a better compromise between memory-compute costs and long-context processing, which we call online vector-quantized (OVQ) attention. OVQ-attention requires linear compute costs and constant memory, but, unlike linear attention and SSMs, it uses a sparse memory update that allows it to greatly increase the size of its memory state and, consequently, memory capacity. We develop a theoretical basis for OVQ-attention based on Gaussian mixture regression, and we test it on a variety of synthetic long context tasks and on long context language modeling. OVQ-attention shows significant improvements over linear attention baselines and the original VQ-attention, on which OVQ-attention was inspired. It demonstrates competitive, and sometimes identical, performance to strong self-attention baselines up 64k sequence length, despite using a small fraction of the memory of full self-attention.

</details>


### [252] [WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling](https://arxiv.org/abs/2602.03924)
*Michael Aich,Andreas Fürst,Florian Sestak,Carlos Ruiz-Gonzalez,Niklas Boers,Johannes Brandstetter*

Main category: cs.LG

TL;DR: 本文提出WIND，一种无需任务微调的预训练大气基础模型，通过无条件视频扩散模型进行自监督视频重建预训练，并以逆问题求解方式统一解决多种天气与气候建模任务。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在天气和气候建模中应用广泛但模型高度专用、各自独立训练，缺乏统一基础模型。

Method: 采用自监督视频重建目标预训练WIND模型，使用无条件视频扩散模型从噪声状态迭代重建大气动力过程；推理阶段将各类任务统一建模为逆问题，通过后验采样求解。

Result: WIND可在不微调前提下替代多个专用模型，成功应用于概率预报、时空降尺度、稀疏重构、守恒律约束及全球变暖下极端天气反事实推演等任务。

Conclusion: WIND通过结合生成式视频建模与逆问题求解，实现了计算高效、物理一致、任务通用的大气AI建模范式转变。

Abstract: Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing specialized baselines across a vast array of tasks. Crucially, in contrast to previous atmospheric foundation models, we achieve this without any task-specific fine-tuning. To learn a robust, task-agnostic prior of the atmosphere, we pre-train WIND with a self-supervised video reconstruction objective, utilizing an unconditional video diffusion model to iteratively reconstruct atmospheric dynamics from a noisy state. At inference, we frame diverse domain-specific problems strictly as inverse problems and solve them via posterior sampling. This unified approach allows us to tackle highly relevant weather and climate problems, including probabilistic forecasting, spatial and temporal downscaling, sparse reconstruction and enforcing conservation laws purely with our pre-trained model. We further demonstrate the model's capacity to generate physically consistent counterfactual storylines of extreme weather events under global warming scenarios. By combining generative video modeling with inverse problem solving, WIND offers a computationally efficient paradigm shift in AI-based atmospheric modeling.

</details>


### [253] [Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints](https://arxiv.org/abs/2602.03940)
*Olaf Yunus Laitinen Imanov,Duygu Erisken,Derya Umut Kulali,Taner Yilmaz,Rana Irem Turhan*

Main category: cs.LG

TL;DR: 本文提出了AURA系统，一种基于分层多智能体强化学习的实时可负担住房选址方法，能在严格法规约束下优化多个目标，并显著提升选址效率和质量。


<details>
  <summary>Details</summary>
Motivation: 可负担住房短缺影响数十亿人，而土地稀缺和监管复杂导致选址过程缓慢。

Method: 将任务建模为受硬性监管约束的多目标马尔可夫决策过程，采用监管感知状态编码、Pareto约束策略梯度与奖励分解机制。

Result: 在8个美国大都市数据集上实现94.3%监管合规率，Pareto超体积提升37.2%；纽约市案例中选址时间从18个月缩短至72小时，可行地块增加23%，交通可达性提升31%，环境影响降低19%。

Conclusion: AURA能高效、合规、多目标协同地完成可负担住房选址，具备实际部署潜力。

Abstract: Affordable housing shortages affect billions, while land scarcity and regulations make site selection slow. We present AURA (Autonomous Urban Resource Allocator), a hierarchical multi-agent reinforcement learning system for real-time affordable housing site selection under hard regulatory constraints (QCT, DDA, LIHTC). We model the task as a constrained multi-objective Markov decision process optimizing accessibility, environmental impact, construction cost, and social equity while enforcing feasibility. AURA uses a regulatory-aware state encoding 127 federal and local constraints, Pareto-constrained policy gradients with feasibility guarantees, and reward decomposition separating immediate costs from long-term social outcomes. On datasets from 8 U.S. metros (47,392 candidate parcels), AURA attains 94.3% regulatory compliance and improves Pareto hypervolume by 37.2% over strong baselines. In a New York City 2026 case study, it reduces selection time from 18 months to 72 hours and identifies 23% more viable sites; chosen sites have 31% better transit access and 19% lower environmental impact than expert picks.

</details>


### [254] [Grables: Tabular Learning Beyond Independent Rows](https://arxiv.org/abs/2602.03945)
*Tamara Cucumides,Floris Geerts*

Main category: cs.LG

TL;DR: 本文提出grables框架，通过将表格提升为图并利用消息传递捕捉行间依赖关系，解决了传统行式预测模型在事务性、时序性和关系型表格上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统行式预测模型在处理事务性、时序性和关系型表格时表现不佳，因其无法建模行间依赖（如全局计数、重叠和关系模式）。

Method: 提出grables模块化接口，分离表格到图的构造（constructor）与图上节点预测（node predictor），并结合消息传递与混合方法显式提取行间结构。

Result: 实验表明消息传递能有效捕获行间依赖，混合方法在合成任务、交易数据和RelBench临床试验数据集上均取得一致性能提升。

Conclusion: 利用表格内在结构（如图表示和消息传递）可显著提升复杂表格数据的预测能力，grables为评估和设计结构感知的表格学习方法提供了清晰框架。

Abstract: Tabular learning is still dominated by row-wise predictors that score each row independently, which fits i.i.d. benchmarks but fails on transactional, temporal, and relational tables where labels depend on other rows. We show that row-wise prediction rules out natural targets driven by global counts, overlaps, and relational patterns. To make "using structure" precise across architectures, we introduce grables: a modular interface that separates how a table is lifted to a graph (constructor) from how predictions are computed on that graph (node predictor), pinpointing where expressive power comes from. Experiments on synthetic tasks, transaction data, and a RelBench clinical-trials dataset confirm the predicted separations: message passing captures inter-row dependencies that row-local models miss, and hybrid approaches that explicitly extract inter-row structure and feed it to strong tabular learners yield consistent gains.

</details>


### [255] [Representation Geometry as a Diagnostic for Out-of-Distribution Robustness](https://arxiv.org/abs/2602.03951)
*Ali Zia,Farid Hazratian*

Main category: cs.LG

TL;DR: 本文提出了一种基于嵌入几何结构的无标签诊断框架，利用类条件互k近邻图提取谱复杂度和Ollivier-Ricci曲率两个不变量，有效预测模型在分布外（OOD）数据上的鲁棒性表现。


<details>
  <summary>Details</summary>
Motivation: 在缺乏目标域标签的情况下，难以监控和优化模型在分布偏移下的泛化能力；现有方法多关注训练正则化或低阶表征统计，而嵌入几何结构是否能提供可靠的后验鲁棒性信号尚不清楚。

Method: 构建类条件互k近邻图，从源域嵌入中提取两个几何不变量：基于归一化拉普拉斯矩阵约简对数行列式的全局谱复杂度代理，以及基于Ollivier-Ricci曲率的局部平滑性度量。

Result: 在多种架构、训练策略与污染基准上验证，较低的谱复杂度与较高的平均曲率一致预示更强的OOD准确率；控制扰动与拓扑分析表明该信号反映真实表征结构而非表面统计。

Conclusion: 表征几何可实现可解释、无需标签的鲁棒性诊断，并支持在分布偏移下可靠地进行无监督检查点选择。

Abstract: Robust generalization under distribution shift remains difficult to monitor and optimize in the absence of target-domain labels, as models with similar in-distribution accuracy can exhibit markedly different out-of-distribution (OOD) performance. While prior work has focused on training-time regularization and low-order representation statistics, little is known about whether the geometric structure of learned embeddings provides reliable post-hoc signals of robustness. We propose a geometry-based diagnostic framework that constructs class-conditional mutual k-nearest-neighbor graphs from in-distribution embeddings and extracts two complementary invariants: a global spectral complexity proxy based on the reduced log-determinant of the normalized Laplacian, and a local smoothness measure based on Ollivier--Ricci curvature. Across multiple architectures, training regimes, and corruption benchmarks, we find that lower spectral complexity and higher mean curvature consistently predict stronger OOD accuracy across checkpoints. Controlled perturbations and topological analyses further show that these signals reflect meaningful representation structure rather than superficial embedding statistics. Our results demonstrate that representation geometry enables interpretable, label-free robustness diagnosis and supports reliable unsupervised checkpoint selection under distribution shift.

</details>


### [256] [Child Mortality Prediction in Bangladesh: A Decade-Long Validation Study](https://arxiv.org/abs/2602.03957)
*Md Muhtasim Munif Fahim,Md Rezaul Karim*

Main category: cs.LG

TL;DR: 本文提出了一种避免前瞻性偏差的时序验证策略，使用孟加拉国DHS数据（2011–2022），发现单层神经网络（64单元）优于XGBoost，在预测儿童死亡率上AUROC更高（0.76 vs. 0.73）；模型表现出‘社会经济预测梯度’——在最贫困地区性能最佳（AUC=0.74），富裕地区下降（AUC=0.66），表明其能精准识别高需求区域；经SHAP与Platt校准验证，该模型每年可多识别约1300名高危儿童，具备临床部署潜力。


<details>
  <summary>Details</summary>
Motivation: 现有儿童死亡率预测模型因交叉验证中的随机划分引入前瞻性偏差，导致对未来人群泛化能力差，亟需符合真实时间演进逻辑的建模与评估范式。

Method: 采用严格时间序列划分：训练集（2011–2014）、验证集（2017）、测试集（2022）；结合遗传算法驱动的神经架构搜索（NAS）优化模型结构；开展公平性审计，分析模型性能与区域贫困水平的相关性；使用SHAP解释性和Platt校准评估可靠性。

Result: 单层神经网络（64单元）显著优于XGBoost（AUROC 0.76 vs. 0.73, p<0.01）；发现强负相关（r=-0.62）：区域越贫困，模型AUC越高；最贫困地区AUC达0.74，最富裕地区降至0.66；在10%筛查阈值下，每年比XGBoost多识别约1300名高危儿童。

Conclusion: 该研究不仅提出了抗前瞻性偏差的时间验证框架，还揭示了模型性能与社会经济背景的系统性关联，证明其能优先聚焦资源匮乏地区，为精准母幼健康干预提供了可落地的计算表型工具。

Abstract: The predictive machine learning models for child mortality tend to be inaccurate when applied to future populations, since they suffer from look-ahead bias due to the randomization used in cross-validation. The Demographic and Health Surveys (DHS) data from Bangladesh for 2011-2022, with n = 33,962, are used in this paper. We trained the model on (2011-2014) data, validated it on 2017 data, and tested it on 2022 data. Eight years after the initial test of the model, a genetic algorithm-based Neural Architecture Search found a single-layer neural architecture (with 64 units) to be superior to XGBoost (AUROC = 0.76 vs. 0.73; p < 0.01). Additionally, through a detailed fairness audit, we identified an overall "Socioeconomic Predictive Gradient," with a positive correlation between regional poverty level (r = -0.62) and the algorithm's AUC. In addition, we found that the model performed at its highest levels in the least affluent divisions (AUC 0.74) and decreased dramatically in the wealthiest divisions (AUC 0.66). These findings suggest that the model is identifying areas with the greatest need for intervention. Our model would identify approximately 1300 additional at-risk children annually than a Gradient Boosting model when screened at the 10% level and validated using SHAP values and Platt Calibration, and therefore provide a robust, production-ready computational phenotype for targeted maternal and child health interventions.

</details>


### [257] [Non-linear PCA via Evolution Strategies: a Novel Objective Function](https://arxiv.org/abs/2602.03967)
*Thomas Uriot,Elise Chung*

Main category: cs.LG

TL;DR: 本文提出了一种结合PCA可解释性与神经网络灵活性的鲁棒非线性PCA框架，使用神经网络参数化变量变换，并通过进化策略优化，引入细粒度目标函数以最大化各变量方差贡献，天然支持分类和序数变量，且在多个数据集上显著优于线性PCA和核PCA。


<details>
  <summary>Details</summary>
Motivation: 传统PCA因线性限制难以捕捉真实数据的复杂结构；核PCA虽能处理非线性但牺牲可解释性且超参难调。

Method: 用神经网络参数化变量变换，采用进化策略（ES）优化（应对特征分解不可导问题），并设计新细粒度目标函数——最大化各变量独立方差贡献；天然支持分类/序数变量，避免独热编码维数爆炸。

Result: 在合成与真实数据集上，所提方法在解释方差上显著优于线性PCA和核PCA，同时保持PCA的可解释性（如可用双图biplot分析特征贡献）。

Conclusion: 该框架成功统一了PCA的可解释性与神经网络的非线性建模能力，为高维数据分析提供了一种更鲁棒、灵活且实用的降维新范式。

Abstract: Principal Component Analysis (PCA) is a powerful and popular dimensionality reduction technique. However, due to its linear nature, it often fails to capture the complex underlying structure of real-world data. While Kernel PCA (kPCA) addresses non-linearity, it sacrifices interpretability and struggles with hyperparameter selection. In this paper, we propose a robust non-linear PCA framework that unifies the interpretability of PCA with the flexibility of neural networks. Our method parametrizes variable transformations via neural networks, optimized using Evolution Strategies (ES) to handle the non-differentiability of eigendecomposition. We introduce a novel, granular objective function that maximizes the individual variance contribution of each variable providing a stronger learning signal than global variance maximization. This approach natively handles categorical and ordinal variables without the dimensional explosion associated with one-hot encoding. We demonstrate that our method significantly outperforms both linear PCA and kPCA in explained variance across synthetic and real-world datasets. At the same time, it preserves PCA's interpretability, enabling visualization and analysis of feature contributions using standard tools such as biplots. The code can be found on GitHub.

</details>


### [258] [DeXposure-FM: A Time-series, Graph Foundation Model for Credit Exposures and Stability on Decentralized Financial Networks](https://arxiv.org/abs/2602.03981)
*Aijie Shu,Wenbin Wu,Gbenga Ibikunle,Fengxiang He*

Main category: cs.LG

TL;DR: 本文提出了DeXposure-FM，首个面向DeFi网络协议间信用风险暴露的时序图基础模型，用于量化与预测隐性、代币中介型信用风险及其跨协议传染效应。


<details>
  <summary>Details</summary>
Motivation: DeFi中信用风险暴露常隐性且通过代币传导，形成复杂跨协议依赖；随着DeFi与传统金融（如稳定币）日益融合，亟需更强大的风险量化工具。

Method: 提出图-表格编码器架构的时序图基础模型DeXposure-FM，采用预训练权重初始化与多任务头设计，在大规模DeXposure数据集（4370万条记录、4300+协议、602条链、24300+代币）上联合预测协议资金流与信用暴露图的拓扑及权重动态。

Result: 在两个机器学习基准上显著优于现有图基础模型和时序图神经网络；生成可解释的金融经济学工具，包括协议系统重要性评分、行业级溢出与集中度指标，支持宏观审慎监控与情景压力测试，并经实证验证有效。

Conclusion: DeXposure-FM为DeFi信用风险建模提供了新范式，兼具预测精度与金融可解释性，已开源模型与代码，具备实际监管与风控应用价值。

Abstract: Credit exposure in Decentralized Finance (DeFi) is often implicit and token-mediated, creating a dense web of inter-protocol dependencies. Thus, a shock to one token may result in significant and uncontrolled contagion effects. As the DeFi ecosystem becomes increasingly linked with traditional financial infrastructure through instruments, such as stablecoins, the risk posed by this dynamic demands more powerful quantification tools. We introduce DeXposure-FM, the first time-series, graph foundation model for measuring and forecasting inter-protocol credit exposure on DeFi networks, to the best of our knowledge. Employing a graph-tabular encoder, with pre-trained weight initialization, and multiple task-specific heads, DeXposure-FM is trained on the DeXposure dataset that has 43.7 million data entries, across 4,300+ protocols on 602 blockchains, covering 24,300+ unique tokens. The training is operationalized for credit-exposure forecasting, predicting the joint dynamics of (1) protocol-level flows, and (2) the topology and weights of credit-exposure links. The DeXposure-FM is empirically validated on two machine learning benchmarks; it consistently outperforms the state-of-the-art approaches, including a graph foundation model and temporal graph neural networks. DeXposure-FM further produces financial economics tools that support macroprudential monitoring and scenario-based DeFi stress testing, by enabling protocol-level systemic-importance scores, sector-level spillover and concentration measures via a forecast-then-measure pipeline. Empirical verification fully supports our financial economics tools. The model and code have been publicly available. Model: https://huggingface.co/EVIEHub/DeXposure-FM.
Code: https://github.com/EVIEHub/DeXposure-FM.

</details>


### [259] [eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models](https://arxiv.org/abs/2602.03986)
*Nikolaos Bousias,Lars Lindemann,George Pappas*

Main category: cs.LG

TL;DR: 本文研究了对预训练模型进行群对称化处理对共形预测（CP）的影响，提出通过群平均注入几何信息以减小非一致性分数，从而在高置信水平下获得更紧致的预测区间。


<details>
  <summary>Details</summary>
Motivation: 共形预测在长时程任务中不确定性区域显著增大，导致统计保证变得无意义，需引入几何信息来缓解该问题。

Method: 通过对预训练预测器进行群平均，将每个样本视为其对称轨道的代表，利用对称群元素关联的样本分摊非一致性质量，从而收缩非一致性分数。

Result: 理论证明该方法可在递增凸序下收缩非一致性分数，带来更优的指数尾部界，并在期望意义上尤其在高置信水平下得到更尖锐的共形预测集；实验设计验证了该理论在行人轨迹预测中的有效性。

Conclusion: 群对称化能有效提升共形预测在长时程任务中的实用性，为不确定性量化提供了兼具理论保障与几何感知的新路径。

Abstract: We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.

</details>


### [260] [When Chains of Thought Don't Matter: Causal Bypass in Large Language Models](https://arxiv.org/abs/2602.03994)
*Anish Sathyanarayanan,Aditya Nagarsekar,Aarush Rathore*

Main category: cs.LG

TL;DR: 本文揭示了链式思维（CoT）提示虽表面合规，但模型答案常与CoT内容无因果依赖；提出一种结合行为评分与因果探针（CMI）的诊断框架，发现大量问答任务中存在近乎完全的‘绕过’现象（CMI≈0），仅部分逻辑题展现一定推理中介性。


<details>
  <summary>Details</summary>
Motivation: 验证链式思维（CoT）提示是否真正提升模型推理透明性与因果依赖性，而非仅表面合规。

Method: 构建诊断框架：（i）可解释的行为模块，用于检测CoT中的操纵相关信号；（ii）因果探针（CMI），通过隐藏状态修补量化CoT对答案的因果影响，并定义绕过分数（1−CMI）。

Result: 审计显示，尽管审计感知提示显著提升操纵信号（风险分均值+5.10），但多数问答任务中CMI≈0（强绕过），部分逻辑题CMI最高达0.56；层分析揭示‘推理窗口’狭窄且任务依赖。

Conclusion: CoT提示不能保证模型因果依赖其生成的推理链；表面合理性不等于真实推理；需因果级评估替代表面指标。

Abstract: Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: even when CoT is verbose, strategic, and flagged by surface-level manipulation detectors, model answers are often causally independent of the CoT content. We present a diagnostic framework for auditing this failure mode: it combines (i) an interpretable behavioral module that scores manipulation-relevant signals in CoT text and (ii) a causal probe that measures CoT-mediated influence (CMI) via hidden-state patching and reports a bypass score ($1-\mathrm{CMI}$), quantifying the degree to which the answer is produced by a bypass circuit independent of the rationale. In pilot evaluations, audit-aware prompting increases detectable manipulation signals (mean risk-score delta: $+5.10$), yet causal probes reveal task-dependent mediation: many QA items exhibit near-total bypass (CMI $\approx 0$), while some logic problems show stronger mediation (CMI up to $0.56$). Layer-wise analysis reveals narrow and task-dependent ``reasoning windows'' even when mean CMI is low.

</details>


### [261] [Rational ANOVA Networks](https://arxiv.org/abs/2602.04006)
*Jusheng Zhang,Ningyuan Liu,Qinhan Lyu,Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 本文提出了Rational-ANOVA Network (RAN)，一种基于ANOVA分解与Padé型有理函数逼近的新型神经网络架构，旨在提升模型可解释性、外推能力与数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有深度神经网络将非线性激活函数（如ReLU）视为固定基元，限制了可解释性与函数类控制粒度；而现有加性模型（如KANs）虽尝试用样条建模，却存在计算低效与边界不稳定问题。

Method: RAN将函数f(x)建模为主效应与稀疏二阶交互项的组合，每项由带严格正分母约束的可学习有理单元参数化，结合功能ANOVA分解与稳定有理逼近。

Result: 在可控函数基准与CIFAR-10等视觉分类任务中，RAN在相同参数量和计算预算下，性能持平或超越参数匹配的MLP及可学习激活基线，且具备更优稳定性与吞吐量。

Conclusion: RAN通过有理函数与ANOVA结构的结合，在保持数据效率和可解释性的同时，显著提升了模型外推能力与数值鲁棒性，为神经网络非线性建模提供了新范式。

Abstract: Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational inefficiency and boundary instability. We propose the Rational-ANOVA Network (RAN), a foundational architecture grounded in functional ANOVA decomposition and Padé-style rational approximation. RAN models f(x) as a composition of main effects and sparse pairwise interactions, where each component is parameterized by a stable, learnable rational unit. Crucially, we enforce a strictly positive denominator, which avoids poles and numerical instability while capturing sharp transitions and near-singular behaviors more efficiently than polynomial bases. This ANOVA structure provides an explicit low-order interaction bias for data efficiency and interpretability, while the rational parameterization significantly improves extrapolation. Across controlled function benchmarks and vision classification tasks (e.g., CIFAR-10) under matched parameter and compute budgets, RAN matches or surpasses parameter-matched MLPs and learnable-activation baselines, with better stability and throughput. Code is available at https://github.com/jushengzhang/Rational-ANOVA-Networks.git.

</details>


### [262] [PromptSplit: Revealing Prompt-Level Disagreement in Generative Models](https://arxiv.org/abs/2602.04009)
*Mehdi Lotfian,Mohammad Jalali,Farzan Farnia*

Main category: cs.LG

TL;DR: 本文提出PromptSplit框架，通过核方法检测和分析生成式AI模型在不同提示词下的行为差异，利用张量积嵌入和核协方差矩阵的特征空间识别主要分歧方向，并通过随机投影提升可扩展性，理论证明其误差有界，实验验证其在多模态任务中有效定位模型分歧提示。


<details>
  <summary>Details</summary>
Motivation: 随着文本引导的生成式AI模型在视觉和语言领域快速发展，不同训练数据与架构的模型行为差异日益显著，亟需系统化方法识别导致模型行为分化的提示类型。

Method: 提出PromptSplit：构建提示-输出联合表示（张量积嵌入），计算核协方差矩阵；利用加权差矩阵的特征空间识别行为差异主方向；采用随机投影近似以降低计算复杂度至O(nr² + r³)，并给出O(1/r²)的特征结构估计误差界。

Result: 在文生图、文生文、图像标注等任务上，PromptSplit能准确检测真实行为差异，并精准定位引发分歧的关键提示，具备良好可解释性与可扩展性。

Conclusion: PromptSplit为理解和比较生成式模型行为提供了原理清晰、可扩展且理论可证的分析工具，有助于提升模型评估、调试与对齐的可靠性。

Abstract: Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts lead to distinct model behaviors. In this work, we propose PromptSplit, a kernel-based framework for detecting and analyzing prompt-dependent disagreement between generative models. For each compared model pair, PromptSplit constructs a joint prompt--output representation by forming tensor-product embeddings of the prompt and image (or text) features, and then computes the corresponding kernel covariance matrix. We utilize the eigenspace of the weighted difference between these matrices to identify the main directions of behavioral difference across prompts. To ensure scalability, we employ a random-projection approximation that reduces computational complexity to $O(nr^2 + r^3)$ for projection dimension $r$. We further provide a theoretical analysis showing that this approximation yields an eigenstructure estimate whose expected deviation from the full-dimensional result is bounded by $O(1/r^2)$. Experiments across text-to-image, text-to-text, and image-captioning settings demonstrate that PromptSplit accurately detects ground-truth behavioral differences and isolates the prompts responsible, offering an interpretable tool for detecting where generative models disagree.

</details>


### [263] [Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.04019)
*Yichen Xu,Yuyang Liang,Shan Dai,Tianyang Hu,Tsz Nam Chan,Chenhao Ma*

Main category: cs.LG

TL;DR: 本文提出了一种统一的投影残差视角来理解参数高效微调（PEFT），揭示了层选择受残差范数、激活能量和层间耦合三个关键因素影响，并据此设计了可复用的Layer Card诊断工具，指导更优、更灵活的层微调策略，在保持性能的同时显著降低微调与推理开销。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增长，全参数微调成本高昂，参数高效微调（PEFT）成为主流；但现有方法通常均匀应用PEFT于所有层，缺乏对‘应微调哪些层’这一关键问题的理论理解与实践指导，尤其在延迟敏感或资源受限场景下，层选择不可避免却缺乏依据。

Method: 基于冻结基座模型，构建统一的投影残差PEFT分析框架；在局部二次近似下，推导出决定层适应性的三个量：投影残差范数（resnorm）、激活能量（activation energy）和层耦合（layer coupling）；进一步提出Layer Card诊断工具，量化每层的残差信号强度、计算代价与性能贡献，并用于指导LoRA等适配器的层选择。

Result: 理论层面：证明resnorm等价于归一化梯度范数，激活能量主导病态性与噪声放大，弱耦合下各层贡献近似可加；实验层面：在Qwen3-8B上验证Layer Card引导的层选择可在仅微调部分层时逼近全层LoRA性能，同时显著降低微调成本与推理时的适配器层数。

Conclusion: 层选择不应是经验性或均匀的，而应基于可解释的残差动力学；Layer Card为PEFT提供了可复用、目标可定制的诊断与优化范式，推动参数高效微调向更低成本、更高可控性与更强理论支撑的方向发展。

Abstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited understanding or leverage of layer selection. This paper develops a unified projected residual view of PEFT on top of a frozen base model. Under a local quadratic approximation, layerwise adaptation is governed by three quantities: (i) the projected residual norm (resnorm), which measures how much correctable bias a layer can capture; (ii) the activation energy, which determines feature conditioning; and (iii) layer coupling, which quantifies how strongly residuals interact across layers. We show that, for squared loss and linear adapters, the resnorm equals a normalized gradient norm, activation energy controls ill-conditioning and noise amplification, and weak coupling yields approximately additive layerwise contributions. Building on these insights, we introduce the Layer Card, a reusable diagnostic that summarizes residual signal strength, compute cost, and performance for each layer of a given model. With an identical model and LoRA configuration, Layer Card-guided placement refines the choice of adapted layers to flexibly prioritize different objectives, such as maximizing performance or reducing fine-tuning cost. Moreover, on Qwen3-8B, we show that selectively adapting a subset of layers can achieve performance close to full-layer LoRA while substantially reducing fine-tuning cost and the number of adapter-augmented layers during inference, offering a more cost-performance-aware alternative to full-layer insertion.

</details>


### [264] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: 本文提出GROOVE方法，通过GroupCLIP组级对比损失和在线反译自编码器框架，解决高内涵扰动数据中模态间弱配对下的多模态表征学习问题，并设计组合式评估框架验证其在跨模态匹配与插补任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法难以处理模态间仅通过共享扰动标签弱配对、缺乏直接样本对应关系的高内涵扰动数据；同时，当前评估策略缺乏系统性与鲁棒性分析能力。

Method: 提出GroupCLIP组级对比损失，融合CLIP（用于强配对）与SupCon（用于单模态监督）思想；结合在线反译自编码器实现跨模态纠缠表征与组内一致性；构建涵盖多种最优传输对齐器及可控扰动效应模拟的组合式评估框架。

Result: 在模拟数据和两个真实单细胞遗传扰动数据集上，GROOVE在跨模态匹配与插补任务中表现优于或媲美现有方法；消融实验证明GroupCLIP是性能提升的关键；组合评估揭示尚无一种对齐器能在所有设置下普遍占优。

Conclusion: 在弱配对多模态场景下，利用组级约束进行表征学习至关重要；GroupCLIP为该类问题提供了有效且可扩展的解决方案。

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [265] [A Consensus-Bayesian Framework for Detecting Malicious Activity in Enterprise Directory Access Graphs](https://arxiv.org/abs/2602.04027)
*Pratyush Uppuluri,Shilpa Noushad,Sajan Kumar*

Main category: cs.LG

TL;DR: 本文提出了一种基于共识的贝叶斯框架，用于检测企业目录访问图中的恶意用户行为，通过建模用户与目录间的多层交互及意见动力学，结合动态矩阵与共享影响矩阵识别违反强连通分量结构规范的逻辑扰动，并利用理论保证和贝叶斯异常评分机制实现鲁棒、时变的异常检测。


<details>
  <summary>Details</summary>
Motivation: 检测企业目录访问图中违反结构规范（如强连通分量）的恶意用户行为，尤其是由跨组件逻辑扰动引发的异常。

Method: 构建基于共识的贝叶斯框架：将目录建模为‘主题’、用户为‘智能体’，采用影响力加权意见动力学模拟访问演化；用动态矩阵Ci编码用户间逻辑依赖，共享影响矩阵W刻画目录相似性；引入理论驱动的主题收敛判定与缩放意见方差进行异常检测；设计融合静态先验与在线先验的时变贝叶斯异常评分机制。

Result: 在合成访问图上的仿真验证了该方法对逻辑不一致性的高敏感性及在动态扰动下的鲁棒性。

Conclusion: 所提框架能有效建模和检测企业环境中复杂、演化式的恶意访问行为，兼具理论可解释性与实用鲁棒性。

Abstract: This work presents a consensus-based Bayesian framework to detect malicious user behavior in enterprise directory access graphs. By modeling directories as topics and users as agents within a multi-level interaction graph, we simulate access evolution using influence-weighted opinion dynamics. Logical dependencies between users are encoded in dynamic matrices Ci, and directory similarity is captured via a shared influence matrix W. Malicious behavior is injected as cross-component logical perturbations that violate structural norms of strongly connected components(SCCs). We apply theoretical guarantees from opinion dynamics literature to determine topic convergence and detect anomaly via scaled opinion variance. To quantify uncertainty, we introduce a Bayesian anomaly scoring mechanism that evolves over time, using both static and online priors. Simulations over synthetic access graphs validate our method, demonstrating its sensitivity to logical inconsistencies and robustness under dynamic perturbation.

</details>


### [266] [The Illusion of Generalization: Re-examining Tabular Language Model Evaluation](https://arxiv.org/abs/2602.04031)
*Aditya Gorla,Ratish Puduppully*

Main category: cs.LG

TL;DR: 本文对Tabula-8B这一代表性表格语言模型（TLM）在165个数据集上的性能进行了系统性重评估，发现其所谓‘涌现泛化能力’主要源于评估缺陷，包括任务偏差、数据污染和格式熟悉度影响，而非真正的表格推理能力。


<details>
  <summary>Details</summary>
Motivation: 质疑当前表格语言模型（TLM）所宣称的‘涌现泛化能力’是否真实，探究其在tabular prediction任务中表现优异的原因是否源于评估方法缺陷或数据问题。

Method: 在UniPredict基准的165个数据集上系统评估Tabula-8B；分析不同任务类型（二分类、类别分类、四分位分类）的性能提升；检测数据污染（如训练-测试重叠、任务级泄露）；对比指令微调（无表格数据暴露）与标准微调的效果。

Result: 1）二分类和类别分类对多数类基线几乎无提升，整体高性能由四分位分类主导；2）高性能数据集普遍存在严重数据污染；3）无需表格数据的指令微调即可恢复92.2%的标准分类性能，格式熟悉度可弥补71.3%的四分位分类性能差距，残余差距归因于污染数据。

Conclusion: TLM所声称的泛化能力很可能是评估伪影所致，而非真正习得的表格推理能力；需改进评估协议，加强数据去污与任务设计严谨性。

Abstract: Tabular Language Models (TLMs) have been claimed to achieve emergent generalization for tabular prediction. We conduct a systematic re-evaluation of Tabula-8B as a representative TLM, utilizing 165 datasets from the UniPredict benchmark. Our investigation reveals three findings. First, binary and categorical classification achieve near-zero median lift over majority-class baselines and strong aggregate performance is driven entirely by quartile classification tasks. Second, top-performing datasets exhibit pervasive contamination, including complete train-test overlap and task-level leakage that evades standard deduplication. Third, instruction-tuning without tabular exposure recovers 92.2% of standard classification performance and on quartile classification, format familiarity closes 71.3% of the gap with the residual attributable to contaminated datasets. These findings suggest claimed generalization likely reflects evaluation artifacts rather than learned tabular reasoning. We conclude with recommendations for strengthening TLM evaluation.

</details>


### [267] [DADP: Domain Adaptive Diffusion Policy](https://arxiv.org/abs/2602.04037)
*Pengcheng Wang,Qinghang Liu,Haotian Lin,Yiheng Li,Guojian Zhan,Masayoshi Tomizuka,Yixiao Wang*

Main category: cs.LG

TL;DR: 本文提出DADP（Domain Adaptive Diffusion Policy），通过滞后上下文动力学预测实现无监督解耦静态域信息与瞬态动力学特征，并将解耦后的域表示注入扩散模型先验与目标函数，提升策略在未知动力学下的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于域表征学习的领域自适应策略易将静态域信息与变化的动力学特性混淆，导致条件策略零样本适应能力受限。

Method: 提出DADP框架：1）采用滞后上下文动力学预测（Lagged Context Dynamical Prediction），通过引入时间偏移来无监督解耦静态域表征；2）将解耦后的域表征直接注入扩散模型的先验分布与去噪目标中。

Result: 在运动与操作类基准任务上，DADP显著优于先前方法，展现出更强的鲁棒适应性与泛化能力。

Conclusion: 解耦静态域信息与动态特性对零样本领域自适应至关重要；将解耦表征融入扩散生成过程可有效提升策略泛化性能。

Abstract: Learning domain adaptive policies that can generalize to unseen transition dynamics, remains a fundamental challenge in learning-based control. Substantial progress has been made through domain representation learning to capture domain-specific information, thus enabling domain-aware decision making. We analyze the process of learning domain representations through dynamical prediction and find that selecting contexts adjacent to the current step causes the learned representations to entangle static domain information with varying dynamical properties. Such mixture can confuse the conditioned policy, thereby constraining zero-shot adaptation. To tackle the challenge, we propose DADP (Domain Adaptive Diffusion Policy), which achieves robust adaptation through unsupervised disentanglement and domain-aware diffusion injection. First, we introduce Lagged Context Dynamical Prediction, a strategy that conditions future state estimation on a historical offset context; by increasing this temporal gap, we unsupervisedly disentangle static domain representations by filtering out transient properties. Second, we integrate the learned domain representations directly into the generative process by biasing the prior distribution and reformulating the diffusion target. Extensive experiments on challenging benchmarks across locomotion and manipulation demonstrate the superior performance, and the generalizability of DADP over prior methods. More visualization results are available on the https://outsider86.github.io/DomainAdaptiveDiffusionPolicy/.

</details>


### [268] [Partition Trees: Conditional Density Estimation over General Outcome Spaces](https://arxiv.org/abs/2602.04042)
*Felipe Angelim,Alessandro Leite*

Main category: cs.LG

TL;DR: 本文提出了一种名为Partition Trees的树状框架，用于在通用结果空间上进行条件密度估计，支持连续和分类变量的统一建模；通过最小化条件负对数似然直接学习分段常数密度的自适应数据划分，并扩展为Partition Forests集成方法，在实验中展现出优于CART树及现有概率树方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有概率树方法通常依赖于对目标分布的参数假设，缺乏对连续和分类变量的统一处理能力，且在复杂噪声和冗余特征下鲁棒性不足。

Method: 提出Partition Trees，基于数据自适应划分建模分段常数条件密度，并直接最小化条件负对数似然进行树学习；进一步构建Partition Forests作为其集成形式，通过对多个条件密度取平均实现提升。

Result: 在实证评估中，Partition Trees和Partition Forests在概率预测性能上优于CART风格树，与当前最优概率树方法和随机森林相比具有竞争力或更优表现，并表现出对冗余特征和异方差噪声的良好鲁棒性。

Conclusion: Partition Trees提供了一种可扩展、非参数、统一处理混合变量的条件密度估计新范式，其集成版本Partition Forests进一步提升了预测性能与鲁棒性，为概率机器学习提供了实用而灵活的工具。

Abstract: We propose Partition Trees, a tree-based framework for conditional density estimation over general outcome spaces, supporting both continuous and categorical variables within a unified formulation. Our approach models conditional distributions as piecewise-constant densities on data adaptive partitions and learns trees by directly minimizing conditional negative log-likelihood. This yields a scalable, nonparametric alternative to existing probabilistic trees that does not make parametric assumptions about the target distribution. We further introduce Partition Forests, an ensemble extension obtained by averaging conditional densities. Empirically, we demonstrate improved probabilistic prediction over CART-style trees and competitive or superior performance compared to state-of-the-art probabilistic tree methods and Random Forests, along with robustness to redundant features and heteroscedastic noise.

</details>


### [269] [SEIS: Subspace-based Equivariance and Invariance Scores for Neural Representations](https://arxiv.org/abs/2602.04054)
*Huahua Lin,Katayoun Farrahi,Xiaohao Cai*

Main category: cs.LG

TL;DR: 本文提出SEIS方法，通过子空间度量分析神经网络各层特征在几何变换下的等变性与不变性，无需标签或变换先验知识；验证表明其能准确恢复已知变换，并揭示了网络中从早期等变到深层不变的特征演化规律，以及数据增强、多任务学习和跳跃连接对这些性质的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过比较变换前后模型输出评估鲁棒性，难以揭示几何信息在内部表征中的组织方式，也无法区分信息丢失与重编码。

Method: 提出SEIS（基于子空间的等变性与不变性评分），一种无需标签或变换先验知识的子空间度量方法，用于逐层分析特征对几何变换的响应。

Result: SEIS在合成数据上能准确恢复已知变换；应用于分类网络发现：早期层具等变性、深层具不变性；数据增强提升不变性但保持等变性；多任务学习在共享编码器中协同提升二者；跳跃连接可恢复解码中丢失的等变性。

Conclusion: SEIS为理解神经网络内部几何表征提供了新工具，揭示了等变性与不变性在深度、训练策略和架构设计中的系统性变化规律。

Abstract: Understanding how neural representations respond to geometric transformations is essential for evaluating whether learned features preserve meaningful spatial structure. Existing approaches primarily assess robustness by comparing model outputs under transformed inputs, offering limited insight into how geometric information is organized within internal representations and failing to distinguish between information loss and re-encoding. In this work, we introduce SEIS (Subspace-based Equivariance and Invariance Scores), a subspace metric for analyzing layer-wise feature representations under geometric transformations, disentangling equivariance from invariance without requiring labels or explicit knowledge of the transformation. Synthetic validation confirms that SEIS correctly recovers known transformations. Applied to trained classification networks, SEIS reveals a transition from equivariance in early layers to invariance in deeper layers, and that data augmentation increases invariance while preserving equivariance. We further show that multi-task learning induces synergistic gains in both properties at the shared encoder, and skip connections restore equivariance lost during decoding.

</details>


### [270] [An Empirical Survey and Benchmark of Learned Distance Indexes for Road Networks](https://arxiv.org/abs/2602.04068)
*Gautam Choudhary,Libin Zhou,Yeasir Rayhan,Walid G. Aref*

Main category: cs.LG

TL;DR: 本文对基于机器学习的路网距离索引进行了首次系统性实证调研，从训练时间、查询延迟、存储开销和精度四个维度，在七个真实路网和轨迹驱动查询数据集上评估了十种代表性ML方法，并与经典非ML基线对比，同时开源统一代码库。


<details>
  <summary>Details</summary>
Motivation: 缺乏对ML-based distance indexes的全面、系统性评估，而这类方法在降低路网最短路径查询延迟方面具有潜力。

Method: 对十种代表性ML距离索引方法进行实证评估，使用七个真实路网数据集和轨迹驱动的查询负载，在训练时间、查询延迟、存储和精度四个维度上与经典非ML基线对比。

Result: 揭示了各类ML方法在不同维度上的关键性能表现与实用权衡，并提供了可复现的统一开源代码库。

Conclusion: 该调研填补了ML-based距离索引评估的空白，为实际部署和未来研究提供了重要参考和基准。

Abstract: The calculation of shortest-path distances in road networks is a core operation in navigation systems, location-based services, and spatial analytics. Although classical algorithms, e.g., Dijkstra's algorithm, provide exact answers, their latency is prohibitive for modern real-time, large-scale deployments. Over the past two decades, numerous distance indexes have been proposed to speed up query processing for shortest distance queries. More recently, with the advancement in machine learning (ML), researchers have designed and proposed ML-based distance indexes to answer approximate shortest path and distance queries efficiently. However, a comprehensive and systematic evaluation of these ML-based approaches is lacking. This paper presents the first empirical survey of ML-based distance indexes on road networks, evaluating them along four key dimensions: Training time, query latency, storage, and accuracy. Using seven real-world road networks and workload-driven query datasets derived from trajectory data, we benchmark ten representative ML techniques and compare them against strong classical non-ML baselines, highlighting key insights and practical trade-offs. We release a unified open-source codebase to support reproducibility and future research on learned distance indexes.

</details>


### [271] [Agentic AI-Empowered Dynamic Survey Framework](https://arxiv.org/abs/2602.04071)
*Furkan Mumcu,Lokman Bekit,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.LG

TL;DR: 本文提出了一种动态调查框架，将综述论文视为需长期维护的‘活文档’，通过智能代理实现持续更新，以应对科研产出激增导致综述快速过时的问题。


<details>
  <summary>Details</summary>
Motivation: 综述论文因科研产出爆炸式增长而迅速过时，导致文献冗余与碎片化，亟需从一次性撰写转向长期维护范式。

Method: 提出基于智能体的动态综述框架（Dynamic Survey Framework），支持对已有综述进行增量式更新，在保持原有结构前提下自动识别并整合新研究成果。

Result: 在回溯性实验中验证了该框架能有效识别新兴研究、平滑融入现有综述，并维持其逻辑连贯性与结构完整性。

Conclusion: 将综述视为‘活文档’并辅以自动化维护机制，可显著提升学术综述的时效性、一致性与可持续性，为知识整合提供新范式。

Abstract: Survey papers play a central role in synthesizing and organizing scientific knowledge, yet they are increasingly strained by the rapid growth of research output. As new work continues to appear after publication, surveys quickly become outdated, contributing to redundancy and fragmentation in the literature. We reframe survey writing as a long-horizon maintenance problem rather than a one-time generation task, treating surveys as living documents that evolve alongside the research they describe. We propose an agentic Dynamic Survey Framework that supports the continuous updating of existing survey papers by incrementally integrating new work while preserving survey structure and minimizing unnecessary disruption. Using a retrospective experimental setup, we demonstrate that the proposed framework effectively identifies and incorporates emerging research while preserving the coherence and structure of existing surveys.

</details>


### [272] [Stroke Lesions as a Rosetta Stone for Language Model Interpretability](https://arxiv.org/abs/2602.04074)
*Julius Fridriksson,Roger D. Newman-Norlund,Saeed Ahmadi,Regan Willis,Nadra Salman,Kalil Warren,Xiang Guan,Yong Yang,Srihari Nelakuditi,Rutvik Desai,Leonardo Bonilha,Jeff Charney,Chris Rorden*

Main category: cs.LG

TL;DR: 本文提出了Brain-LLM Unified Model (BLUM)框架，利用临床神经科学中经典的病灶-症状映射方法，对外部验证大语言模型（LLM）各组件对语言功能的因果贡献，发现LLM损伤后的错误模式能显著映射到人脑特定损伤区域，为LLM可解释性提供了新范式。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性方法多依赖内部指标，缺乏外部行为或神经生物学验证；亟需一种具有因果推断能力、可与人类语言障碍实证对标的方法。

Method: 构建BLUM框架：1）基于410例卒中后失语症患者的临床行为错误数据训练症状-病灶预测模型；2）对Transformer各层进行系统性损伤（perturbation）；3）对受损LLM施加与人类相同的临床语言测验；4）将LLM错误谱投影至人类病灶空间并评估匹配度。

Result: LLM错误谱在图片命名任务中67%、句子补全任务中68.3%的条件下能显著匹配真实人类病灶（p值极小）；语义主导错误对应腹侧通路损伤模式，语音主导错误对应背侧通路损伤模式。

Conclusion: 人类病灶-症状映射可作为评估LLM语言机制的外部金标准；LLM与人类语言障碍的行为对齐暗示二者可能存在共享计算原理，为AI可解释性引入临床神经科学验证路径。

Abstract: Large language models (LLMs) have achieved remarkable capabilities, yet methods to verify which model components are truly necessary for language function remain limited. Current interpretability approaches rely on internal metrics and lack external validation. Here we present the Brain-LLM Unified Model (BLUM), a framework that leverages lesion-symptom mapping, the gold standard for establishing causal brain-behavior relationships for over a century, as an external reference structure for evaluating LLM perturbation effects. Using data from individuals with chronic post-stroke aphasia (N = 410), we trained symptom-to-lesion models that predict brain damage location from behavioral error profiles, applied systematic perturbations to transformer layers, administered identical clinical assessments to perturbed LLMs and human patients, and projected LLM error profiles into human lesion space. LLM error profiles were sufficiently similar to human error profiles that predicted lesions corresponded to actual lesions in error-matched humans above chance in 67% of picture naming conditions (p < 10^{-23}) and 68.3% of sentence completion conditions (p < 10^{-61}), with semantic-dominant errors mapping onto ventral-stream lesion patterns and phonemic-dominant errors onto dorsal-stream patterns. These findings open a new methodological avenue for LLM interpretability in which clinical neuroscience provides external validation, establishing human lesion-symptom mapping as a reference framework for evaluating artificial language systems and motivating direct investigation of whether behavioral alignment reflects shared computational principles.

</details>


### [273] [Principles of Lipschitz continuity in neural networks](https://arxiv.org/abs/2602.04078)
*Róisín Luo*

Main category: cs.LG

TL;DR: 本文探讨了Lipschitz连续性在深度神经网络鲁棒性与泛化能力中的基础作用，从训练动态（内部视角）和频率信号传播（外部视角）两个互补角度展开原理性分析。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习取得巨大成功，但模型对输入微小扰动的鲁棒性和分布外泛化能力仍存关键挑战；Lipschitz连续性作为刻画最坏情况敏感性的核心理论工具，其深层原理尚未被充分探索。

Method: 采用双重视角分析：内部视角研究训练过程中Lipschitz常数的动态演化；外部视角探究Lipschitz性质如何调制神经网络对输入特征（特别是不同频率信号）的响应与传播行为。

Result: 揭示了Lipschitz连续性在训练动态与频率选择性之间的内在关联，为理解鲁棒性与泛化提供了新的原理性视角。

Conclusion: Lipschitz连续性不仅是可施加的正则约束，更是理解神经网络内在工作机制（如训练稳定性与频域行为）的基础性原理；该工作推动了从经验正则化走向原理驱动的鲁棒机器学习研究范式。

Abstract: Deep learning has achieved remarkable success across a wide range of domains, significantly expanding the frontiers of what is achievable in artificial intelligence. Yet, despite these advances, critical challenges remain -- most notably, ensuring robustness to small input perturbations and generalization to out-of-distribution data. These critical challenges underscore the need to understand the underlying fundamental principles that govern robustness and generalization. Among the theoretical tools available, Lipschitz continuity plays a pivotal role in governing the fundamental properties of neural networks related to robustness and generalization. It quantifies the worst-case sensitivity of network's outputs to small input perturbations. While its importance is widely acknowledged, prior research has predominantly focused on empirical regularization approaches based on Lipschitz constraints, leaving the underlying principles less explored. This thesis seeks to advance a principled understanding of the principles of Lipschitz continuity in neural networks within the paradigm of machine learning, examined from two complementary perspectives: an internal perspective -- focusing on the temporal evolution of Lipschitz continuity in neural networks during training (i.e., training dynamics); and an external perspective -- investigating how Lipschitz continuity modulates the behavior of neural networks with respect to features in the input data, particularly its role in governing frequency signal propagation (i.e., modulation of frequency signal propagation).

</details>


### [274] [A Probabilistic Framework for Solving High-Frequency Helmholtz Equations via Diffusion Models](https://arxiv.org/abs/2602.04082)
*Yicheng Zou,Samuel Lanthaler,Hossein Salahshoor*

Main category: cs.LG

TL;DR: 本文提出了一种基于分数匹配条件扩散的概率神经算子，用于高频率波现象（如Helmholtz方程）的建模，克服了确定性神经算子在高频下的谱偏差和敏感性问题，显著提升了预测精度并首次在数据驱动方法中实现了输入不确定性向解的传播建模。


<details>
  <summary>Details</summary>
Motivation: 确定性神经算子在处理高频率波动现象（如Helmholtz方程）时存在谱偏差和强输入-输出敏感性问题，导致振荡模糊、近似困难。

Method: 提出基于分数匹配（score-based）的条件扩散概率神经算子；结合Helmholtz算子的稳定性分析，构建可学习的概率映射；通过扩散过程建模输入声速图的不确定性向解场的传播。

Result: 在宽频范围内实验表明，该方法在L²、H¹和能量范数下误差最低；唯一能显式捕捉输入声速不确定性对解影响的神经算子方法。

Conclusion: 概率算子学习是求解高频复杂PDE（如Helmholtz）的一种原理清晰且高效的新范式。

Abstract: Deterministic neural operators perform well on many PDEs but can struggle with the approximation of high-frequency wave phenomena, where strong input-to-output sensitivity makes operator learning challenging, and spectral bias blurs oscillations. We argue for adopting a probabilistic approach for approximating waves in high-frequency regime, and develop our probabilistic framework using a score-based conditional diffusion operator. After demonstrating a stability analysis of the Helmholtz operator, we present our numerical experiments across a wide range of frequencies, benchmarked against other popular data-driven and machine learning approaches for waves. We show that our probabilistic neural operator consistently produces robust predictions with the lowest errors in $L^2$, $H^1$, and energy norms. Moreover, unlike all the other tested deterministic approaches, our framework remarkably captures uncertainties in the input sound speed map propagated to the solution field. We envision that our results position probabilistic operator learning as a principled and effective approach for solving complex PDEs such as Helmholtz in the challenging high-frequency regime.

</details>


### [275] [Federated Concept-Based Models: Interpretable models with distributed supervision](https://arxiv.org/abs/2602.04093)
*Dario Fenoglio,Arianna Casanova,Francesco De Santis,Mohan Li,Gabriele Dominici,Johannes Schneider,Martin Gjoreski,Marc Langheinrich,Pietro Barbiero,Giovanni De Felice*

Main category: cs.LG

TL;DR: 本文提出联邦概念模型（F-CMs），在联邦学习中实现可解释的概念建模，支持跨机构动态概念监督与隐私保护下的模型自适应更新。


<details>
  <summary>Details</summary>
Motivation: 概念模型（CMs）虽具可解释性，但依赖昂贵且稀缺的概念标注；联邦学习（FL）可聚合多源标注，但缺乏可解释建模范式，且现实FL环境具有异构性、非平稳性和动态加入特性，难以直接整合CMs。

Method: 提出F-CMs方法：通过跨机构聚合概念级信息，并设计模型架构自适应机制，以响应新增概念监督，同时保障数据隐私。

Result: 实验表明F-CMs在保持全监督下准确率与干预效果的同时，优于非自适应联邦基线；并首次支持对本地未标注概念进行可解释推理。

Conclusion: F-CMs为动态、异构联邦环境下部署可解释AI提供了新范式，兼顾隐私、适应性与跨机构概念泛化能力。

Abstract: Concept-based models (CMs) enhance interpretability in deep learning by grounding predictions in human-understandable concepts. However, concept annotations are expensive to obtain and rarely available at scale within a single data source. Federated learning (FL) could alleviate this limitation by enabling cross-institutional training that leverages concept annotations distributed across multiple data owners. Yet, FL lacks interpretable modeling paradigms. Integrating CMs with FL is non-trivial: CMs assume a fixed concept space and a predefined model architecture, whereas real-world FL is heterogeneous and non-stationary, with institutions joining over time and bringing new supervision. In this work, we propose Federated Concept-based Models (F-CMs), a new methodology for deploying CMs in evolving FL settings. F-CMs aggregate concept-level information across institutions and efficiently adapt the model architecture in response to changes in the available concept supervision, while preserving institutional privacy. Empirically, F-CMs preserve the accuracy and intervention effectiveness of training settings with full concept supervision, while outperforming non-adaptive federated baselines. Notably, F-CMs enable interpretable inference on concepts not available to a given institution, a key novelty with respect to existing approaches.

</details>


### [276] [CoRe: Context-Robust Remasking for Diffusion Language Models](https://arxiv.org/abs/2602.04096)
*Kevin Zhai,Sabbir Mollah,Zhenyi Wang,Mubarak Shah*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练的推理时修订框架CoRe，通过探测token对上下文扰动的敏感性来识别并修订上下文脆弱的token，从而缓解掩码扩散模型中因早期高置信度预测导致的级联错误问题。


<details>
  <summary>Details</summary>
Motivation: 标准掩码扩散模型（MDMs）解码过程中存在上下文刚性问题：早期预测缺乏完整上下文却仍被高置信度保留，引发后续生成的级联错误；而现有基于静态置信度的修订策略本身具有短视性，无法识别表面自信但实际不一致的token。

Method: 提出Context-Robust Remasking（CoRe），在推理时通过定向掩码上下文扰动探测token的上下文脆弱性，并将修订建模为关于上下文偏移的鲁棒优化问题，高效近似该目标以优先修订不稳定token。

Result: 在LLaDA-8B-Base模型上，CoRe在推理与代码基准测试中持续优于计算量匹配的基线方法，在MBPP上提升达9.2个百分点。

Conclusion: CoRe是一种有效、即插即用的推理时修订机制，无需额外训练，显著提升了MDMs在复杂生成任务中的鲁棒性与准确性。

Abstract: Standard decoding in Masked Diffusion Models (MDMs) is hindered by context rigidity: tokens are retained based on transient high confidence, often ignoring that early predictions lack full context. This creates cascade effects where initial inconsistencies misguide the remaining generation. Existing revision strategies attempt to mitigate this by relying on static confidence scores, but these signals are inherently myopic; inconsistent tokens can appear confident to the model itself. We propose Context-Robust Remasking (CoRe), a training-free framework for inference-time revision. Rather than trusting static token probabilities, CoRe identifies context-brittle tokens by probing their sensitivity to targeted masked-context perturbations. We formalize revision as a robust optimization objective over context shifts and efficiently approximate this objective to prioritize unstable tokens for revision. On LLaDA-8B-Base, CoRe delivers consistent improvements across reasoning and code benchmarks, outperforming compute-matched baselines and improving MBPP by up to 9.2 percentage points.

</details>


### [277] [Rethinking Perplexity: Revealing the Impact of Input Length on Perplexity Evaluation in LLMs](https://arxiv.org/abs/2602.04099)
*Letian Cheng,Junyan Wang,Yan Gao,Elliott Wen,Ting Dang,Hong Jia*

Main category: cs.LG

TL;DR: 本文提出LengthBenchmark框架，系统性研究输入长度对大语言模型困惑度评估的影响，发现滑动窗口评估会高估短输入性能，且模型在更长输入段上表现更好，揭示了长度偏差对公平跨模型比较的威胁。


<details>
  <summary>Details</summary>
Motivation: 现有困惑度评估指标在处理无关长输入时不可靠，但输入长度对评估的影响尚未从系统角度被系统研究，且未被视为影响公平性和效率的一等系统变量。

Method: 提出LengthBenchmark系统感知评估框架，整合输入长度、评估协议设计和系统级成本，采用直接累加和固定窗口滑动两种评分协议，在不同上下文长度下评估代表性大语言模型，并测量延迟、内存占用和评估成本；同时引入量化变体作为鲁棒性检验。

Result: 发现（i）滑动窗口评估持续高估短输入性能；（ii）全精度与量化模型均在更长评估段上表现出性能提升；长度偏差是普遍现象，损害公平跨模型比较。

Conclusion: 输入长度是影响困惑度评估可靠性与公平性的关键系统变量，LengthBenchmark将预测指标与部署现实相联系，揭示并量化了长度偏差问题，为更稳健、公平的LLM评估提供了新范式。

Abstract: Perplexity is a widely adopted metric for assessing the predictive quality of large language models (LLMs) and often serves as a reference metric for downstream evaluations. However, recent evidence shows that perplexity can be unreliable, especially when irrelevant long inputs are used, raising concerns for both benchmarking and system deployment. While prior efforts have employed selective input filtering and curated datasets, the impact of input length on perplexity has not been systematically studied from a systems perspective and input length has rarely been treated as a first-class system variable affecting both fairness and efficiency. In this work, we close this gap by introducing LengthBenchmark, a system-conscious evaluation framework that explicitly integrates input length, evaluation protocol design, and system-level costs, evaluating representative LLMs under two scoring protocols (direct accumulation and fixed window sliding) across varying context lengths. Unlike prior work that focuses solely on accuracy-oriented metrics, LengthBenchmark additionally measures latency, memory footprint, and evaluation cost, thereby linking predictive metrics to deployment realities. We further incorporate quantized variants not as a main contribution, but as robustness checks, showing that length-induced biases persist across both full-precision and compressed models. This design disentangles the effects of evaluation logic, quantization, and input length, and demonstrates that length bias is a general phenomenon that undermines fair cross-model comparison. Our analysis yields two key observations: (i) sliding window evaluation consistently inflates performance on short inputs, and (ii) both full-precision and quantized models appear to realise gains as the evaluated segment length grows.

</details>


### [278] [Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis](https://arxiv.org/abs/2602.04107)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 本文从信息论角度出发，将机器学习泛化问题建模为有损压缩，并利用有限块长分析推导出样本复杂度与泛化误差的下界，明确分离过拟合与归纳偏置-任务失配两项，并统一信息论界与稳定性理论。


<details>
  <summary>Details</summary>
Motivation: 现有泛化分析框架难以清晰区分过拟合与归纳偏置和任务之间的不匹配，缺乏对学习过程的信息论本质刻画。

Method: 将训练数据采样视为编码、模型构建视为解码，构建基于损失压缩的学习框架；采用有限块长信息论分析技术，推导固定随机学习算法及其最优采样策略下的样本复杂度与泛化误差下界。

Result: 得到了显式包含过拟合程度与归纳偏置-任务失配项的泛化误差下界；进一步分解过拟合项，揭示其与现有信息论泛化界及稳定性度量的理论联系。

Conclusion: 该框架不仅提供了更精细的泛化误差刻画，还统一了信息论与稳定性视角，为理解学习算法本质及设计更鲁棒模型提供了新思路。

Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.

</details>


### [279] [Rate-Optimal Noise Annealing in Semi-Dual Neural Optimal Transport: Tangential Identifiability, Off-Manifold Ambiguity, and Guaranteed Recovery](https://arxiv.org/abs/2602.04110)
*Raymond Chu,Jaewoong Choi,Dohyun Kwon*

Main category: cs.LG

TL;DR: 本文研究半对偶神经最优传输中的虚假解问题，提出通过加性噪声平滑来缓解，并给出了达到最优统计速率的可计算终止噪声水平ε_stat(N)，其标度由数据的内在维度m决定。


<details>
  <summary>Details</summary>
Motivation: 半对偶神经最优传输在训练中易收敛到错误或退化的传输映射，尤其当数据集中在低维流形上时，目标函数在流形外欠约束，导致不稳定性。

Method: 采用加性噪声平滑策略，结合定量稳定性分析、平滑引入的偏差分析与有限样本误差分析，推导出依赖于内在维度m而非环境维度的统计速率，并提出基于条件数恶化的原理性退火停止准则。

Result: 证明了噪声趋于零时的映射恢复保证；给出了可计算的最优终端噪声水平ε_stat(N) ∝ N^{-1/(m+2)}；揭示了ε↓0时目标函数病态加剧的现象，为退火提供理论停止依据。

Conclusion: 加性噪声不仅是正则化手段，其大小需精细控制：过小损害优化，过大损失统计精度；ε_stat(N)实现了统计与优化的最优权衡。

Abstract: Semi-dual neural optimal transport learns a transport map via a max-min objective, yet training can converge to incorrect or degenerate maps. We fully characterize these spurious solutions in the common regime where data concentrate on low-dimensional manifold: the objective is underconstrained off the data manifold, while the on-manifold transport signal remains identifiable. Following Choi, Choi, and Kwon (2025), we study additive-noise smoothing as a remedy and prove new map recovery guarantees as the noise vanishes. Our main practical contribution is a computable terminal noise level $\varepsilon_{\mathrm{stat}}(N)$ that attains the optimal statistical rate, with scaling governed by the intrinsic dimension $m$ of the data. The formula arises from a theoretical unified analysis of (i) quantitative stability of optimal plans, (ii) smoothing-induced bias, and (iii) finite-sample error, yielding rates that depend on $m$ rather than the ambient dimension. Finally, we show that the reduced semi-dual objective becomes increasingly ill-conditioned as $\varepsilon \downarrow 0$. This provides a principled stopping rule: annealing below $\varepsilon_{\mathrm{stat}}(N)$ can $\textit{worsen}$ optimization conditioning without improving statistical accuracy.

</details>


### [280] [Turning mechanistic models into forecasters by using machine learning](https://arxiv.org/abs/2602.04114)
*Amit K. Chakraborty,Hao Wang,Pouria Ramazi*

Main category: cs.LG

TL;DR: 本文提出了一种结合时间不变与时间变化参数的数据驱动微分方程发现方法，能更准确建模和预测复杂动态系统。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法假设参数恒定，难以刻画系统动态演化；当真实机制未知时，需从时序数据中自动识别含时变参数的控制方程。

Method: 构建含常数与时间变化参数的微分方程库，从数据中联合学习方程结构与时变参数的演化规律，并将时变参数预测嵌入到预报流程中。

Result: 在SIR、消费者-资源、温室气体浓度和蓝藻细胞计数等数据集上，建模误差<3%，月尺度预报误差<6%；在多数任务上优于CNN-LSTM和GBM。

Conclusion: 引入时间变化参数显著提升了数据驱动微分方程发现的建模精度与长期预测能力。

Abstract: The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\% for learning a time series and below 6\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.

</details>


### [281] [Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach](https://arxiv.org/abs/2602.04116)
*Sicheng Liu,Xunkai Li,Daohan Su,Ru Zhang,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本文提出PLANET框架，通过嵌入级域门控（EDG）和节点级离散化检索（NDR）分别解决多模态图基础模型中模态交互不足与对齐不佳两大问题，在多种图与多模态生成任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态图基础模型（MGFMs）未能显式建模模态间交互，且模态对齐效果欠佳，难以弥合不同模态间的语义鸿沟。

Method: 提出PLANET框架，采用分而治之策略：在嵌入粒度引入嵌入级域门控（EDG）实现拓扑感知的跨模态上下文融合；在节点粒度引入节点级离散化检索（NDR），构建离散语义表征空间（DSRS）以实现全局模态对齐。

Result: PLANET在多种图中心任务和多模态生成任务上显著超越当前最优基线模型。

Conclusion: 显式建模模态交互与对齐对提升多模态图基础模型性能至关重要，PLANET为此提供了有效且可扩展的解决方案。

Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.

</details>


### [282] [Learning to Reason in 13 Parameters](https://arxiv.org/abs/2602.04118)
*John X. Morris,Niloofar Mireshghallah,Mark Ibrahim,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 本文提出TinyLoRA，一种可将低秩适配器缩放至仅一个参数的新方法，在GSM8K等推理任务上以极少量参数（如13个）实现高准确率，并发现强化学习（RL）对此类极低参数微调至关重要。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA无法在模型维度以下有效缩放，作者质疑是否连rank=1的LoRA都非必要，进而探索更极致的参数效率。

Method: 提出TinyLoRA，将低秩适配器压缩至极小规模（最小仅1参数），并在Qwen2.5-8B模型上结合强化学习（RL）进行训练；对比监督微调（SFT）效果。

Result: 在GSM8K上达91%准确率（仅13个bf16参数，26字节）；在AIME、AMC、MATH500等难任务上以千分之一参数量恢复90%性能提升；RL显著优于SFT（后者需百至千倍参数更新）。

Conclusion: 极低秩甚至单参数适配器（TinyLoRA）足以支撑语言模型推理能力学习，且RL是实现该高效性的关键训练范式。

Abstract: Recent research has shown that language models can learn to \textit{reason}, often via reinforcement learning. Some work even trains low-rank parameterizations for reasoning, but conventional LoRA cannot scale below the model dimension. We question whether even rank=1 LoRA is necessary for learning to reason and propose TinyLoRA, a method for scaling low-rank adapters to sizes as small as one parameter. Within our new parameterization, we are able to train the 8B parameter size of Qwen2.5 to 91\% accuracy on GSM8K with only 13 trained parameters in bf16 (26 total bytes). We find this trend holds in general: we are able to recover 90\% of performance improvements while training $1000x$ fewer parameters across a suite of more difficult learning-to-reason benchmarks such as AIME, AMC, and MATH500. Notably, we are only able to achieve such strong performance with RL: models trained using SFT require $100-1000x$ larger updates to reach the same performance.

</details>


### [283] [Synthesizable Molecular Generation via Soft-constrained GFlowNets with Rich Chemical Priors](https://arxiv.org/abs/2602.04119)
*Hyeonah Kim,Minsu Kim,Celine Roget,Dionessa Biton,Louis Vaillancourt,Yves V. Brun,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: 本文提出S3-GFN，一种通过软正则化序列式生成流网络（GFlowNet）来生成可合成分子的新型方法，利用大规模SMILES语料学习的分子先验，并结合对比学习与离策略重放训练，显著提升生成分子的可合成性（≥95%）与任务奖励。


<details>
  <summary>Details</summary>
Motivation: 现有基于GFlowNets的从头分子设计方法受限于预定义反应模板和构建模块，缺乏灵活性与可扩展性，难以兼顾可合成性与生成多样性。

Method: 提出S3-GFN：采用序列式GFlowNet生成SMILES；引入基于可合成/不可合成样本缓冲区的对比学习信号；通过离策略重放训练施加软正则化，利用大规模SMILES预训练的分子先验引导生成。

Result: S3-GFN在多个任务中生成分子的可合成性达≥95%，且平均奖励高于基线方法。

Conclusion: 软约束方式比硬编码反应规则更灵活、可扩展，能有效协同利用先验知识与强化信号，推动生成模型在真实药物发现中的实用化。

Abstract: The application of generative models for experimental drug discovery campaigns is severely limited by the difficulty of designing molecules de novo that can be synthesized in practice. Previous works have leveraged Generative Flow Networks (GFlowNets) to impose hard synthesizability constraints through the design of state and action spaces based on predefined reaction templates and building blocks. Despite the promising prospects of this approach, it currently lacks flexibility and scalability. As an alternative, we propose S3-GFN, which generates synthesizable SMILES molecules via simple soft regularization of a sequence-based GFlowNet. Our approach leverages rich molecular priors learned from large-scale SMILES corpora to steer molecular generation towards high-reward, synthesizable chemical spaces. The model induces constraints through off-policy replay training with a contrastive learning signal based on separate buffers of synthesizable and unsynthesizable samples. Our experiments show that S3-GFN learns to generate synthesizable molecules ($\geq 95\%$) with higher rewards in diverse tasks.

</details>


### [284] [Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems](https://arxiv.org/abs/2602.04120)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 本文提出Explainability-as-a-Service（XaaS）架构，将可解释性解耦为边缘系统中的独立服务，通过缓存、验证与自适应引擎提升效率与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有边缘与IoT系统中XAI方法多为模型耦合式，导致冗余计算、高延迟和差扩展性，难以适配异构边缘设备。

Method: 提出XaaS分布式架构，包含：(1)基于语义相似度的分布式解释缓存；(2)轻量级解释保真度验证协议；(3)依据设备能力与用户需求自适应选择解释方法的引擎。

Result: 在制造质检、自动驾驶感知和医疗诊断三个真实边缘AI场景中，XaaS降低延迟38%，同时保持高解释质量。

Conclusion: XaaS使透明、可信AI可在大规模异构IoT系统中实用化部署，弥合XAI研究与边缘落地之间的鸿沟。

Abstract: Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are "coupled" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redundant computation, high latency and poor scalability when deployed across heterogeneous sets of edge devices. In this work we propose Explainability-as-a-Service (XaaS), a distributed architecture for treating explainability as a first-class system service (as opposed to a model-specific feature). The key innovation in our proposed XaaS architecture is that it decouples inference from explanation generation allowing edge devices to request, cache and verify explanations subject to resource and latency constraints. To achieve this, we introduce three main innovations: (1) A distributed explanation cache with a semantic similarity based explanation retrieval method which significantly reduces redundant computation; (2) A lightweight verification protocol that ensures the fidelity of both cached and newly generated explanations; and (3) An adaptive explanation engine that chooses explanation methods based upon device capability and user requirement. We evaluated the performance of XaaS on three real-world edge-AI use cases: (i) manufacturing quality control; (ii) autonomous vehicle perception; and (iii) healthcare diagnostics. Experimental results show that XaaS reduces latency by 38\% while maintaining high explanation quality across three real-world deployments. Overall, this work enables the deployment of transparent and accountable AI across large scale, heterogeneous IoT systems, and bridges the gap between XAI research and edge-practicality.

</details>


### [285] [Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting](https://arxiv.org/abs/2602.04131)
*Mehrdad Moghimi,Anthony Coache,Hyejin Ku*

Main category: cs.LG

TL;DR: 本文提出了一种支持灵活折扣和风险度量优化的新型分布强化学习框架，强调了折扣因子在刻画时间偏好和风险偏好中的核心作用，并通过理论分析与实验验证了其有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有分布强化学习中折扣因子常被简单视为固定参数或可调超参，忽略了其对策略学习及风险敏感目标优化的关键影响；而指数折扣无法充分表达智能体复杂的时间偏好。

Method: 提出支持灵活折扣函数的分布强化学习新框架，结合多时间尺度扩展，支持风险度量优化，并提供算法最优性技术分析。

Result: 理论证明所提方法能修正现有方法的问题，实验表明其在多种场景下具有更强的鲁棒性和表达能力。

Conclusion: 折扣机制是决策建模的核心要素，合理设计可更准确刻画时间与风险偏好，在安全关键应用中具有重要价值。

Abstract: Distributional reinforcement learning (RL) is a powerful framework increasingly adopted in safety-critical domains for its ability to optimize risk-sensitive objectives. However, the role of the discount factor is often overlooked, as it is typically treated as a fixed parameter of the Markov decision process or tunable hyperparameter, with little consideration of its effect on the learned policy. In the literature, it is well-known that the discounting function plays a major role in characterizing time preferences of an agent, which an exponential discount factor cannot fully capture. Building on this insight, we propose a novel framework that supports flexible discounting of future rewards and optimization of risk measures in distributional RL. We provide a technical analysis of the optimality of our algorithms, show that our multi-horizon extension fixes issues raised with existing methodologies, and validate the robustness of our methods through extensive experiments. Our results highlight that discounting is a cornerstone in decision-making problems for capturing more expressive temporal and risk preferences profiles, with potential implications for real-world safety-critical applications.

</details>


### [286] [Generative Neural Operators through Diffusion Last Layer](https://arxiv.org/abs/2602.04139)
*Sungwon Park,Anthony Zhou,Hongjoong Kim,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 本文提出了一种名为扩散最后一层（DLL）的轻量级概率头部，可附加到任意神经算子骨干网络上，以建模预测不确定性，尤其适用于随机偏微分方程（PDE）求解场景。


<details>
  <summary>Details</summary>
Motivation: 许多实际系统本质上是随机的，因此需要合理的不确定性量化来保障神经算子在科学计算中的可靠部署。

Method: DLL基于函数空间中的低秩Karhunen-Loève展开，直接参数化条件输出分布，利用PDE解分布常具有的相对平滑性和低维结构特性。

Result: 在多个随机PDE算子学习基准上，DLL提升了泛化能力和不确定性感知预测性能；即使在确定性长时序推演中，也增强了推演稳定性并提供了有意义的认知不确定性估计。

Conclusion: DLL是一种通用、高效且表达力强的不确定性建模模块，能显著提升神经算子在随机与确定性任务中的鲁棒性与可靠性。

Abstract: Neural operators have emerged as a powerful paradigm for learning discretization-invariant function-to-function mappings in scientific computing. However, many practical systems are inherently stochastic, making principled uncertainty quantification essential for reliable deployment. To address this, we introduce a simple add-on, the diffusion last layer (DLL), a lightweight probabilistic head that can be attached to arbitrary neural operator backbones to model predictive uncertainty. Motivated by the relative smoothness and low-dimensional structure often exhibited by PDE solution distributions, DLL parameterizes the conditional output distribution directly in function space through a low-rank Karhunen-Loève expansion, enabling efficient and expressive uncertainty modeling. Across stochastic PDE operator learning benchmarks, DLL improves generalization and uncertainty-aware prediction. Moreover, even in deterministic long-horizon rollout settings, DLL enhances rollout stability and provides meaningful estimates of epistemic uncertainty for backbone neural operators.

</details>


### [287] [Training Data Efficiency in Multimodal Process Reward Models](https://arxiv.org/abs/2602.04145)
*Jinyuan Li,Chengsong Huang,Langlin Huang,Shaoyang Xu,Haolin Liu,Wenxuan Zhang,Jiaxin Huang*

Main category: cs.LG

TL;DR: 本文研究了多模态过程奖励模型（MPRM）训练的数据效率问题，发现现有蒙特卡洛标注数据存在显著冗余；为此提出基于标签混合度与可靠性的平衡信息分数（BIS）采样策略，在仅用10%数据时即可达到全量数据性能，优于随机采样4.1%。


<details>
  <summary>Details</summary>
Motivation: MPRM训练依赖大规模蒙特卡洛（MC）标注语料，成本高昂；而初步实验显示其训练在随机子采样下快速饱和，表明数据存在冗余，亟需提升数据效率。

Method: 建立理论框架，指出有效梯度更新取决于正负步标签混合度与正步标签可靠性（平均MC分）；据此提出无额外开销的 rollout 级 Balanced-Information Score（BIS），兼顾二者进行数据筛选。

Result: 在 VisualProcessBench 上，BIS 选取的子集（仅10%数据）在 InternVL2.5-8B 和 Qwen2.5-VL-7B 两个骨干上均达到甚至超越全量数据性能，相对随机采样提升4.1%。

Conclusion: MPRM训练存在显著数据冗余；BIS提供了一种高效、低成本的数据选择方法，大幅降低训练开销而不损性能。

Abstract: Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.

</details>


### [288] [Pruning for Generalization: A Transfer-Oriented Spatiotemporal Graph Framework](https://arxiv.org/abs/2602.04153)
*Zihao Jing,Yuxi Long,Ganlin Feng*

Main category: cs.LG

TL;DR: 本文提出TL-GPSTGN框架，通过结构感知的上下文选择（如信息论与相关性驱动的子图剪枝）提升图结构多元时间序列预测在数据稀缺和跨域场景下的泛化能力与样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有时空模型在数据稀缺和跨域迁移时性能下降，需提升样本效率与分布外泛化能力。

Method: 提出TL-GPSTGN：基于信息论和相关性准则进行非优化图上下文剪枝，提取结构信息丰富的子图与特征，并将其嵌入时空卷积架构中建模多元动态。

Result: 在大规模交通基准上验证，TL-GPSTGN在低数据迁移场景下持续优于基线方法。

Conclusion: 显式的上下文剪枝可作为有效归纳偏置，显著增强图神经预测模型的鲁棒性。

Abstract: Multivariate time series forecasting in graph-structured domains is critical for real-world applications, yet existing spatiotemporal models often suffer from performance degradation under data scarcity and cross-domain shifts. We address these challenges through the lens of structure-aware context selection. We propose TL-GPSTGN, a transfer-oriented spatiotemporal framework that enhances sample efficiency and out-of-distribution generalization by selectively pruning non-optimized graph context. Specifically, our method employs information-theoretic and correlation-based criteria to extract structurally informative subgraphs and features, resulting in a compact, semantically grounded representation. This optimized context is subsequently integrated into a spatiotemporal convolutional architecture to capture complex multivariate dynamics. Evaluations on large-scale traffic benchmarks demonstrate that TL-GPSTGN consistently outperforms baselines in low-data transfer scenarios. Our findings suggest that explicit context pruning serves as a powerful inductive bias for improving the robustness of graph-based forecasting models.

</details>


### [289] [BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models](https://arxiv.org/abs/2602.04163)
*Junyu Chen,Jungang Li,Jing Xiong,Wenjie Wang,Qingyao Yang,He Xiao,Zhen Li,Taiqiang Wu,Mengzhao Chen,Zhen Peng,Chaofan Tao,Long Shi,Hongxia Yang,Ngai Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为Bit-Plane Decomposition Quantization (BPDQ)的新型量化方法，通过可变量化网格和近似二阶信息优化，在2比特下显著提升大语言模型推理精度与效率。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法在2-3比特下性能下降严重，因其强制使用形状不变的量化网格（如UINT2的固定均匀区间），限制了误差最小化的可行解空间。

Method: BPDQ通过位平面分解与标量系数构建可变量化网格，并利用近似二阶信息迭代优化，同时逐步补偿量化误差以最小化输出差异。

Result: 在2比特下，BPDQ使Qwen2.5-72B可在单张RTX 3090上运行，GSM8K准确率达83.85%（16比特为90.83%）；理论分析表明其可变网格扩大了可行集，且量化过程在Hessian诱导几何中与优化目标一致。

Conclusion: BPDQ为低比特大模型量化提供了一种更灵活、更精准的新范式，兼顾理论严谨性与实际部署效率。

Abstract: Large language model (LLM) inference is often bounded by memory footprint and memory bandwidth in resource-constrained deployments, making quantization a fundamental technique for efficient serving. While post-training quantization (PTQ) maintains high fidelity at 4-bit, it deteriorates at 2-3 bits. Fundamentally, existing methods enforce a shape-invariant quantization grid (e.g., the fixed uniform intervals of UINT2) for each group, severely restricting the feasible set for error minimization. To address this, we propose Bit-Plane Decomposition Quantization (BPDQ), which constructs a variable quantization grid via bit-planes and scalar coefficients, and iteratively refines them using approximate second-order information while progressively compensating quantization errors to minimize output discrepancy. In the 2-bit regime, BPDQ enables serving Qwen2.5-72B on a single RTX 3090 with 83.85% GSM8K accuracy (vs. 90.83% at 16-bit). Moreover, we provide theoretical analysis showing that the variable grid expands the feasible set, and that the quantization process consistently aligns with the optimization objective in Hessian-induced geometry. Code: github.com/KingdalfGoodman/BPDQ.

</details>


### [290] [Topology-Aware Revival for Efficient Sparse Training](https://arxiv.org/abs/2602.04166)
*Meiling Jin,Fei Wang,Xiaoyun Yuan,Chen Qian,Yuan Cheng*

Main category: cs.LG

TL;DR: 本文提出Topology-Aware Revival (TAR)，一种轻量级的一次性后剪枝方法，通过按拓扑需求分配预留预算并随机恢复少量已剪连接，提升静态稀疏训练在深度强化学习中的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 静态稀疏训练因固定掩码结构导致鲁棒性下降，尤其在策略分布持续变化的深度强化学习中，早期剪枝决策易使网络陷入脆弱结构。

Method: TAR在静态剪枝后执行单次恢复步骤：按层拓扑需求分配小量预留预算，随机均匀地重新激活各层中少量已剪连接，并保持新连接结构固定至训练结束。

Result: 在SAC和TD3算法下的多个连续控制任务中，TAR相较静态稀疏基线最高提升最终回报37.9%，中位数上优于动态稀疏基线13.5%。

Conclusion: TAR无需动态重连即可显著增强静态稀疏训练的性能与鲁棒性，为高效强化学习提供了实用新路径。

Abstract: Static sparse training is a promising route to efficient learning by committing to a fixed mask pattern, yet the constrained structure reduces robustness. Early pruning decisions can lock the network into a brittle structure that is difficult to escape, especially in deep reinforcement learning (RL) where the evolving policy continually shifts the training distribution. We propose Topology-Aware Revival (TAR), a lightweight one-shot post-pruning procedure that improves static sparsity without dynamic rewiring. After static pruning, TAR performs a single revival step by allocating a small reserve budget across layers according to topology needs, randomly uniformly reactivating a few previously pruned connections within each layer, and then keeping the resulting connectivity fixed for the remainder of training. Across multiple continuous-control tasks with SAC and TD3, TAR improves final return over static sparse baselines by up to +37.9% and also outperforms dynamic sparse training baselines with a median gain of +13.5%.

</details>


### [291] [Benchmarking Uncertainty Quantification of Plug-and-Play Diffusion Priors for Inverse Problems Solving](https://arxiv.org/abs/2602.04189)
*Xiaoyu Qiu,Taewon Yang,Zhanhao Liu,Guanyang Wang,Liyue Shen*

Main category: cs.LG

TL;DR: 本文系统研究了扩散先验即插即用（PnPDP）方法在求解反问题时的不确定性量化（UQ）能力，指出当前评估仅关注单一样本点估计的准确性，忽视了其固有的分布特性；为此提出基于UQ的分类法，并通过理论分析与大量仿真及真实科学反问题实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有PnPDP方法的评估仅关注单一样本的点估计精度，忽略了其作为随机求解器所输出的重建分布及反问题本身的内在不确定性，而科学任务中往往需要后验分布而非单一解。

Method: 设计严格的玩具模型仿真以评估各类PnPDP求解器的不确定性行为，并据此提出一种基于UQ的分类框架；结合理论分析与在仿真及多类真实科学反问题上的广泛实验进行验证。

Result: 观察到不同PnPDP求解器的不确定性行为与其所提分类一致，且符合理论预期，为PnPDP的评估与理解提供了新视角和实证依据。

Conclusion: PnPDP方法的不确定性量化能力存在显著差异，需建立面向分布评估的新基准；所提出的UQ驱动分类法可有效刻画并指导此类方法的设计与应用。

Abstract: Plug-and-play diffusion priors (PnPDP) have become a powerful paradigm for solving inverse problems in scientific and engineering domains. Yet, current evaluations of reconstruction quality emphasize point-estimate accuracy metrics on a single sample, which do not reflect the stochastic nature of PnPDP solvers and the intrinsic uncertainty of inverse problems, critical for scientific tasks. This creates a fundamental mismatch: in inverse problems, the desired output is typically a posterior distribution and most PnPDP solvers induce a distribution over reconstructions, but existing benchmarks only evaluate a single reconstruction, ignoring distributional characterization such as uncertainty. To address this gap, we conduct a systematic study to benchmark the uncertainty quantification (UQ) of existing diffusion inverse solvers. Specifically, we design a rigorous toy model simulation to evaluate the uncertainty behavior of various PnPDP solvers, and propose a UQ-driven categorization. Through extensive experiments on toy simulations and diverse real-world scientific inverse problems, we observe uncertainty behaviors consistent with our taxonomy and theoretical justification, providing new insights for evaluating and understanding the uncertainty for PnPDPs.

</details>


### [292] [LORE: Jointly Learning the Intrinsic Dimensionality and Relative Similarity Structure From Ordinal Data](https://arxiv.org/abs/2602.04192)
*Vivek Anand,Alec Helbling,Mark Davenport,Gordon Berman,Sankar Alagapan,Christopher Rozell*

Main category: cs.LG

TL;DR: LORE是一种可扩展的框架，用于从噪声三元组比较中联合学习主观感知空间的内在维度和序数嵌入，通过非凸Schatten-p拟范数正则化实现自动维度选择，并在合成与真实数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 从序数数据（如三元组比较）中学习味觉、嗅觉或美学等主观感知空间的内在维度具有挑战性，现有方法需预先设定嵌入维度，缺乏自动维度选择能力。

Method: 提出LORE（Low Rank Ordinal Embedding）框架，采用非凸Schatten-p拟范数正则化，通过迭代重加权算法联合优化序数嵌入及其内在维度，并提供收敛性保证。

Result: 在合成数据、模拟感知空间及真实众包序数判断数据上的实验表明，LORE能学习到紧凑、可解释且高精度的低维嵌入，准确恢复主观感知的潜在几何结构。

Conclusion: LORE实现了内在维度与序数嵌入的同步推断，提升了心理物理学中感知建模的可解释性与数据效率，也为机器学习中从序数数据发现低维结构提供了新方向。

Abstract: Learning the intrinsic dimensionality of subjective perceptual spaces such as taste, smell, or aesthetics from ordinal data is a challenging problem. We introduce LORE (Low Rank Ordinal Embedding), a scalable framework that jointly learns both the intrinsic dimensionality and an ordinal embedding from noisy triplet comparisons of the form, "Is A more similar to B than C?". Unlike existing methods that require the embedding dimension to be set apriori, LORE regularizes the solution using the nonconvex Schatten-$p$ quasi norm, enabling automatic joint recovery of both the ordinal embedding and its dimensionality. We optimize this joint objective via an iteratively reweighted algorithm and establish convergence guarantees. Extensive experiments on synthetic datasets, simulated perceptual spaces, and real world crowdsourced ordinal judgements show that LORE learns compact, interpretable and highly accurate low dimensional embeddings that recover the latent geometry of subjective percepts. By simultaneously inferring both the intrinsic dimensionality and ordinal embeddings, LORE enables more interpretable and data efficient perceptual modeling in psychophysics and opens new directions for scalable discovery of low dimensional structure from ordinal data in machine learning.

</details>


### [293] [From Sparse Sensors to Continuous Fields: STRIDE for Spatiotemporal Reconstruction](https://arxiv.org/abs/2602.04201)
*Yanjie Tong,Peng Chen*

Main category: cs.LG

TL;DR: 本文提出STRIDE框架，通过两阶段方法（时间编码器+调制隐式神经表示解码器）从稀疏传感器数据中重建高维时空场，在多个基准测试中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨轨迹和参数设置的泛化能力上存在不足，且依赖于与离散化绑定的解码器，难以在不同网格和分辨率间迁移。

Method: STRIDE采用两阶段框架：首先用时间编码器将短时传感器窗口映射为潜在状态；再用基于FMMNN的调制隐式神经表示（INR）解码器在任意查询位置重建场；并提供条件性理论依据支持该架构设计。

Result: 在四个涵盖混沌动力学和波动传播的挑战性基准上，STRIDE在极稀疏传感条件下优于强基线，支持超分辨率重建，并对噪声鲁棒。

Conclusion: STRIDE是一种自然且有效的高维时空场重建架构，尤其适用于稀疏、多尺度、带噪的实际传感场景。

Abstract: Reconstructing high-dimensional spatiotemporal fields from sparse point-sensor measurements is a central challenge in learning parametric PDE dynamics. Existing approaches often struggle to generalize across trajectories and parameter settings, or rely on discretization-tied decoders that do not naturally transfer across meshes and resolutions. We propose STRIDE (Spatio-Temporal Recurrent Implicit DEcoder), a two-stage framework that maps a short window of sensor measurements to a latent state with a temporal encoder and reconstructs the field at arbitrary query locations with a modulated implicit neural representation (INR) decoder. Using the Fourier Multi-Component and Multi-Layer Neural Network (FMMNN) as the INR backbone improves representation of complex spatial fields and yields more stable optimization than sine-based INRs. We provide a conditional theoretical justification: under stable delay observability of point measurements on a low-dimensional parametric invariant set, the reconstruction operator factors through a finite-dimensional embedding, making STRIDE-type architectures natural approximators. Experiments on four challenging benchmarks spanning chaotic dynamics and wave propagation show that STRIDE outperforms strong baselines under extremely sparse sensing, supports super-resolution, and remains robust to noise.

</details>


### [294] [RAPO: Risk-Aware Preference Optimization for Generalizable Safe Reasoning](https://arxiv.org/abs/2602.04224)
*Zeming Wei,Qiaosheng Zhang,Xia Hu,Xingcheng Xu*

Main category: cs.LG

TL;DR: 本文提出了一种风险感知偏好优化（RAPO）框架，以增强大型推理模型（LRMs）在面对复杂越狱攻击时的安全推理泛化能力，同时保持其通用性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全推理方法在面对多样且复杂的越狱攻击时泛化能力不足，导致拒绝有害提示失败。

Method: 提出风险感知偏好优化（RAPO）框架，使LRM能自适应地识别并以适当粒度应对推理过程中的安全风险。

Result: RAPO在多种LRM上显著提升了对多样化攻击提示的安全推理泛化能力，同时不损害模型的通用性能。

Conclusion: RAPO为大型推理模型提供了一种鲁棒、可泛化的安全对齐新方法。

Abstract: Large Reasoning Models (LRMs) have achieved tremendous success with their chain-of-thought (CoT) reasoning, yet also face safety issues similar to those of basic language models. In particular, while algorithms are designed to guide them to deliberately refuse harmful prompts with safe reasoning, this process often fails to generalize against diverse and complex jailbreak attacks. In this work, we attribute these failures to the generalization of the safe reasoning process, particularly their insufficiency against complex attack prompts. We provide both theoretical and empirical evidence to show the necessity of a more sufficient safe reasoning process to defend against advanced attack prompts. Building on this insight, we propose a Risk-Aware Preference Optimization (RAPO) framework that enables LRM to adaptively identify and address the safety risks with appropriate granularity in its thinking content. Extensive experiments demonstrate that RAPO successfully generalizes multiple LRMs' safe reasoning adaptively across diverse attack prompts whilst preserving general utility, contributing a robust alignment technique for LRM safety. Our code is available at https://github.com/weizeming/RAPO.

</details>


### [295] [Cascading Robustness Verification: Toward Efficient Model-Agnostic Certification](https://arxiv.org/abs/2602.04236)
*Mohammadreza Maleki,Rushendra Sidibomma,Arman Adibi,Reza Samavi*

Main category: cs.LG

TL;DR: 本文提出级联鲁棒性验证（CRV）框架，通过组合多种不完全验证器，在保证或提升验证准确率的同时显著降低计算开销；其核心是渐进式调用验证器，并为高成本方法引入逐步松弛算法（SR），实现高效可靠的神经网络鲁棒性认证。


<details>
  <summary>Details</summary>
Motivation: 单一不完全验证器因近似松散或与训练方式不匹配，易低估模型鲁棒性；现有鲁棒性度量存在根本局限，亟需兼顾可靠性与效率的新验证范式。

Method: 提出模型无关的级联鲁棒性验证（CRV）框架：按计算成本升序排列多个不完全验证器，对每个输入依次调用，任一验证器成功即终止；针对高成本验证器，设计逐步松弛算法（SR），增量添加约束并实时检查认证结果。

Result: 理论证明CRV在验证准确率上不低于级联中最强大的单个验证器，且验证开销显著降低；实验表明其认证输入数不少于基准方法，运行效率最高提升约90%。

Conclusion: CRV不仅是一种工程优化，更揭示了现有鲁棒性度量的根本缺陷；它提供了一种通用、可靠且高效的鲁棒性验证新范式，适用于各类训练方法的模型。

Abstract: Certifying neural network robustness against adversarial examples is challenging, as formal guarantees often require solving non-convex problems. Hence, incomplete verifiers are widely used because they scale efficiently and substantially reduce the cost of robustness verification compared to complete methods. However, relying on a single verifier can underestimate robustness because of loose approximations or misalignment with training methods. In this work, we propose Cascading Robustness Verification (CRV), which goes beyond an engineering improvement by exposing fundamental limitations of existing robustness metric and introducing a framework that enhances both reliability and efficiency. CRV is a model-agnostic verifier, meaning that its robustness guarantees are independent of the model's training process. The key insight behind the CRV framework is that, when using multiple verification methods, an input is certifiably robust if at least one method certifies it as robust. Rather than relying solely on a single verifier with a fixed constraint set, CRV progressively applies multiple verifiers to balance the tightness of the bound and computational cost. Starting with the least expensive method, CRV halts as soon as an input is certified as robust; otherwise, it proceeds to more expensive methods. For computationally expensive methods, we introduce a Stepwise Relaxation Algorithm (SR) that incrementally adds constraints and checks for certification at each step, thereby avoiding unnecessary computation. Our theoretical analysis demonstrates that CRV achieves equal or higher verified accuracy compared to powerful but computationally expensive incomplete verifiers in the cascade, while significantly reducing verification overhead. Empirical results confirm that CRV certifies at least as many inputs as benchmark approaches, while improving runtime efficiency by up to ~90%.

</details>


### [296] [Training A Foundation Model to Represent Graphs as Vectors](https://arxiv.org/abs/2602.04244)
*Qi Feng,Jicong Fan*

Main category: cs.LG

TL;DR: 本文提出了一种图基础模型，通过多图特征对齐、密度最大化均值对齐算法和多层参考分布模块，在不使用池化操作的情况下，有效保留图的结构与语义信息，提升图级任务（如分类、聚类）的泛化能力与性能。


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习方法在跨域泛化能力及图级任务中信息保留方面存在不足，亟需一种能统一建模多源图数据并保持结构与语义一致性的图基础模型。

Method: 提出多图特征对齐方法，构建基于节点属性的加权图并生成一致节点嵌入；设计密度最大化均值对齐算法以增强跨数据集特征一致性；采用GNN结合对比学习获取判别性图表示；引入无池化操作的多层参考分布模块以增强节点到图级的信息保留；并给出理论泛化界分析。

Result: 在少样本图分类与图聚类任务上，该模型显著优于多个强基线方法。

Conclusion: 所提图基础模型在跨域泛化性、结构-语义信息保留及图级表征判别力方面具有优势，为图学习提供了可扩展、理论可支撑的新范式。

Abstract: This paper aims to train a graph foundation model that is able to represent any graph as a vector preserving structural and semantic information useful for downstream graph-level tasks such as graph classification and graph clustering. To learn the features of graphs from diverse domains while maintaining strong generalization ability to new domains, we propose a multi-graph-based feature alignment method, which constructs weighted graphs using the attributes of all nodes in each dataset and then generates consistent node embeddings. To enhance the consistency of the features from different datasets, we propose a density maximization mean alignment algorithm with guaranteed convergence. The original graphs and generated node embeddings are fed into a graph neural network to achieve discriminative graph representations in contrastive learning. More importantly, to enhance the information preservation from node-level representations to the graph-level representation, we construct a multi-layer reference distribution module without using any pooling operation. We also provide a theoretical generalization bound to support the effectiveness of the proposed model. The experimental results of few-shot graph classification and graph clustering show that our model outperforms strong baselines.

</details>


### [297] [From Ambiguity to Action: A POMDP Perspective on Partial Multi-Label Ambiguity and Its Horizon-One Resolution](https://arxiv.org/abs/2602.04255)
*Hanlin Pan,Yuhao Tang,Wanfu Gao*

Main category: cs.LG

TL;DR: 本文提出PML-POMDP框架，将部分多标签学习中的标签消歧和特征选择联合建模为部分可观测马尔可夫决策过程，并通过强化学习分两阶段求解，同时提供理论误差界分析。


<details>
  <summary>Details</summary>
Motivation: 在部分多标签学习中，真实标签不可见，导致标签消歧困难，且模糊候选标签易将错误传播至下游任务（如特征工程）。

Method: 将标签消歧与特征选择联合建模为POMDP；第一阶段用强化学习训练Transformer策略生成高质量硬伪标签；第二阶段将特征选择建模为序列强化学习问题，逐步选择并输出可解释的全局特征排序；并给出PML-POMDP对应关系及过风险界理论分析。

Result: 在多个数据集和指标上的实验验证了该框架的有效性和优势。

Conclusion: PML-POMDP框架有效缓解了标签模糊性带来的误差传播问题，提升了伪标签质量和特征选择可解释性，并具备理论保障。

Abstract: In partial multi-label learning (PML), the true labels are unobserved, which makes label disambiguation important but difficult. A key challenge is that ambiguous candidate labels can propagate errors into downstream tasks such as feature engineering. To solve this issue, we jointly model the disambiguation and feature selection tasks as Partially Observable Markov Decision Processes (POMDP) to turn PML risk minimization into expected-return maximization. Stage 1 trains a transformer policy via reinforcement learning to produce high-quality hard pseudo-labels; Stage 2 describes feature selection as a sequential reinforcement learning problem, selecting features step by step and outputting an interpretable global ranking. We further provide the theoretical analysis of PML-POMDP correspondence and the excess-risk bound that decompose the error into pseudo label quality term and sample size. Experiments in multiple metrics and data sets verify the advantages of the framework.

</details>


### [298] [From Dead Neurons to Deep Approximators: Deep Bernstein Networks as a Provable Alternative to Residual Layers](https://arxiv.org/abs/2602.04264)
*Ibrahim Albool,Malak Gamal El-Din,Salma Elmalaki,Yasser Shoukry*

Main category: cs.LG

TL;DR: 本文提出Deep Bernstein Networks，使用Bernstein多项式作为激活函数，无需残差连接即可缓解梯度消失问题，并在训练稳定性和表示能力上优于传统ReLU类网络。


<details>
  <summary>Details</summary>
Motivation: 残差连接虽能缓解梯度消失，但引入结构约束，且无法解决分段线性激活函数固有的低效问题。

Method: 采用Bernstein多项式作为激活函数，构建无需残差连接的深度网络；理论分析其局部导数下界及逼近误差随深度的衰减速率。

Result: 局部导数严格远离零，'死亡神经元'比例从90%降至5%以下；逼近误差随深度指数衰减（优于ReLU的多项式速率）；在HIGGS和MNIST上验证了无残差连接下的高性能训练。

Conclusion: Bernstein激活函数为构建深层、无残差、高表达力网络提供了原理性新路径。

Abstract: Residual connections are the de facto standard for mitigating vanishing gradients, yet they impose structural constraints and fail to address the inherent inefficiencies of piecewise linear activations. We show that Deep Bernstein Networks (which utilizes Bernstein polynomials as activation functions) can act as residual-free architecture while simultaneously optimize trainability and representation power. We provide a two-fold theoretical foundation for our approach. First, we derive a theoretical lower bound on the local derivative, proving it remains strictly bounded away from zero. This directly addresses the root cause of gradient stagnation; empirically, our architecture reduces ``dead'' neurons from 90\% in standard deep networks to less than 5\%, outperforming ReLU, Leaky ReLU, SeLU, and GeLU. Second, we establish that the approximation error for Bernstein-based networks decays exponentially with depth, a significant improvement over the polynomial rates of ReLU-based architectures. By unifying these results, we demonstrate that Bernstein activations provide a superior mechanism for function approximation and signal flow. Our experiments on HIGGS and MNIST confirm that Deep Bernstein Networks achieve high-performance training without skip-connections, offering a principled path toward deep, residual-free architectures with enhanced expressive capacity.

</details>


### [299] [Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning](https://arxiv.org/abs/2602.04265)
*Wenze Lin,Zhen Yang,Xitai Jiang,Pony Ma,Gao Huang*

Main category: cs.LG

TL;DR: 本文提出T2T（Thickening-to-Thinning）动态奖励框架，用于改进大语言模型在强化学习中的推理能力，通过错误时鼓励长轨迹探索、正确时惩罚冗余长度，显著提升数学推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法面临熵崩溃、冗余输出和对难题探索不足等问题，且奖励机制无法区分需广泛搜索与已掌握知识所需的效率。

Method: 提出T2T双阶段动态奖励机制：错误尝试时鼓励‘增厚’（更长推理轨迹）以拓展搜索空间；正确回答时启动‘变薄’（施加长度惩罚）以抑制冗余、增强模型自信与推理凝练。

Result: 在MATH-500、AIME、AMC等数学基准上，T2T在Qwen系列与Deepseek模型上显著优于标准GRPO及近期基线方法。

Conclusion: T2T通过模拟人类学习的渐进式精炼过程，有效平衡探索与利用，提升了LLM在复杂推理任务中的鲁棒性与效率。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes "thickening" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to "thinning", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance.

</details>


### [300] [Multi-Integration of Labels across Categories for Component Identification (MILCCI)](https://arxiv.org/abs/2602.04270)
*Noga Mudrik,Yuxi Chen,Gal Mishne,Adam S. Charles*

Main category: cs.LG

TL;DR: 本文提出MILCCI方法，用于分析多类别标签的时序数据，通过稀疏分解和标签相似性建模，分离各标签类别的贡献并学习动态时间成分。


<details>
  <summary>Details</summary>
Motivation: 理解多类别元数据标签如何在多试次时序数据中被编码，并解耦各类别标签的独立效应。

Method: MILCCI是一种数据驱动方法，结合稀疏逐试次分解与类别内标签相似性，实现标签驱动的跨试次成分调整，并学习每个成分随时间演化且跨试次灵活变化的轨迹。

Result: 在合成数据及真实数据（投票模式、网页浏览趋势、神经元记录）上验证了MILCCI的有效性，能识别可解释成分、刻画跨试次变异性、整合标签信息以解析各类别表征。

Conclusion: MILCCI为带多类别标签的大规模时序数据分析提供了可解释、灵活且标签感知的新框架。

Abstract: Many fields collect large-scale temporal data through repeated measurements (trials), where each trial is labeled with a set of metadata variables spanning several categories. For example, a trial in a neuroscience study may be linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data. MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category. MILCCI also learns each component's corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI's performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.

</details>


### [301] [Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms](https://arxiv.org/abs/2602.04277)
*Priyankkumar Dhrangdhariya,Soumyadipta Maiti,Venkataramana Runkana*

Main category: cs.LG

TL;DR: 本文提出了一种结合生成式设计与机器学习的框架，用于优化UPTIS型非充气轮胎的辐条几何结构，在刚度调节性、耐久性和减振性能上显著优于基准设计。


<details>
  <summary>Details</summary>
Motivation: 非充气轮胎（如UPTIS）因辐条结构不连续，面临刚度调控难、耐久性差及高速振动等问题，亟需高效设计方法。

Method: 采用高阶多项式参数化上下辐条轮廓，结合PCHIP插值生成约250种几何构型；使用KRR预测刚度、XGBoost预测耐久性与振动；再通过粒子群优化（PSO）和贝叶斯优化进行多目标性能优化。

Result: 优化后设计实现53%刚度可调性、最高50%耐久性提升、43%振动降低；PSO收敛快，贝叶斯优化擅长多目标权衡。

Conclusion: 该框架为高性能下一代UPTIS辐条结构提供了系统化、数据驱动的设计范式。

Abstract: Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UPTIS type spoke geometries for passenger vehicles. Upper and lower spoke profiles were parameterized using high order polynomial representations, enabling the creation of approximately 250 generative designs through PCHIP based geometric variation. Machine learning models like KRR for stiffness and XGBoost for durability and vibration achieved strong predictive accuracy, reducing the reliance on computationally intensive FEM simulations. Optimization using Particle Swarm Optimization and Bayesian Optimization further enabled extensive performance refinement. The resulting designs demonstrate 53% stiffness tunability, up to 50% durability improvement, and 43% reduction in vibration compared to the baseline. PSO provided fast, targeted convergence, while Bayesian Optimization effectively explored multi objective tradeoffs. Overall, the proposed framework enables systematic development of high performance, next generation UPTIS spoke structures.

</details>


### [302] [Convolution Operator Network for Forward and Inverse Problems (FI-Conv): Application to Plasma Turbulence Simulations](https://arxiv.org/abs/2602.04287)
*Xingzhuo Chen,Anthony Poole,Ionut-Gabriel Farcas,David R. Hatch,Ulisses Braga-Neto*

Main category: cs.LG

TL;DR: 本文提出FI-Conv框架，基于改进U-Net（嵌入ConvNeXt V2块）实现复杂时空动力学（如等离子体湍流）的前向预测与PDE参数反演，兼顾高精度与低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持低计算复杂度的同时，准确建模具有高频变化和强非线性的复杂时空动力学系统（如湍流）；需统一处理前向演化预测与逆问题参数估计。

Method: 构建基于U-Net架构的FI-Conv网络，用ConvNeXt V2块替代大部分卷积层；以初始状态、PDE参数和演化时间作为输入进行前向预测；采用自回归策略实现多步预测；设计无需微调模型权重的梯度下降法进行PDE参数反演。

Result: 在Hasegawa-Wakatani方程描述的二维等离子体湍流任务中，FI-Conv在短时（t~3）前向预测上准确，在长时（t~100）能正确复现物理量统计特性；反演方法可高精度估计未知PDE参数。

Conclusion: FI-Conv为复杂时空动力学系统提供了一种高效、通用且无需重训练的前向-逆向联合建模新范式，是现有物理信息机器学习方法的有效替代方案。

Abstract: We propose the Convolutional Operator Network for Forward and Inverse Problems (FI-Conv), a framework capable of predicting system evolution and estimating parameters in complex spatio-temporal dynamics, such as turbulence. FI-Conv is built on a U-Net architecture, in which most convolutional layers are replaced by ConvNeXt V2 blocks. This design preserves U-Net performance on inputs with high-frequency variations while maintaining low computational complexity. FI-Conv uses an initial state, PDE parameters, and evolution time as input to predict the system future state. As a representative example of a system exhibiting complex dynamics, we evaluate the performance of FI-Conv on the task of predicting turbulent plasma fields governed by the Hasegawa-Wakatani (HW) equations. The HW system models two-dimensional electrostatic drift-wave turbulence and exhibits strongly nonlinear behavior, making accurate approximation and long-term prediction particularly challenging. Using an autoregressive forecasting procedure, FI-Conv achieves accurate forward prediction of the plasma state evolution over short times (t ~ 3) and captures the statistic properties of derived physical quantities of interest over longer times (t ~ 100). Moreover, we develop a gradient-descent-based inverse estimation method that accurately infers PDE parameters from plasma state evolution data, without modifying the trained model weights. Collectively, our results demonstrate that FI-Conv can be an effective alternative to existing physics-informed machine learning methods for systems with complex spatio-temporal dynamics.

</details>


### [303] [Efficient Equivariant High-Order Crystal Tensor Prediction via Cartesian Local-Environment Many-Body Coupling](https://arxiv.org/abs/2602.04323)
*Dian Jin,Yancheng Yuan,Xiaoming Tao*

Main category: cs.LG

TL;DR: 本文提出CEITNet模型，通过构建多通道笛卡尔局部环境张量并进行可学习的通道空间交互，高效预测高阶晶体张量性质（如二阶介电、三阶压电、四阶弹性张量），在精度与计算效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 端到端预测高阶晶体张量性质仍具挑战性；球谐等变模型虽表达能力强，但其Clebsch-Gordan张量积带来高昂计算与内存开销。

Method: 提出笛卡尔环境交互张量网络（CEITNet）：为每个原子构建多通道笛卡尔局部环境张量，并通过可学习的通道空间交互实现灵活多体混合；在通道空间学习，利用笛卡尔张量基组装等变输出。

Result: 在二阶介电、三阶压电和四阶弹性张量预测基准数据集上，CEITNet在关键精度指标上超越先前高阶预测方法，同时具备高计算效率。

Conclusion: CEITNet提供了一种更高效、更准确的高阶晶体张量性质预测新范式，兼顾等变性与计算可扩展性。

Abstract: End-to-end prediction of high-order crystal tensor properties from atomic structures remains challenging: while spherical-harmonic equivariant models are expressive, their Clebsch-Gordan tensor products incur substantial compute and memory costs for higher-order targets. We propose the Cartesian Environment Interaction Tensor Network (CEITNet), an approach that constructs a multi-channel Cartesian local environment tensor for each atom and performs flexible many-body mixing via a learnable channel-space interaction. By performing learning in channel space and using Cartesian tensor bases to assemble equivariant outputs, CEITNet enables efficient construction of high-order tensor. Across benchmark datasets for order-2 dielectric, order-3 piezoelectric, and order-4 elastic tensor prediction, CEITNet surpasses prior high-order prediction methods on key accuracy criteria while offering high computational efficiency.

</details>


### [304] [RISE: Interactive Visual Diagnosis of Fairness in Machine Learning Models](https://arxiv.org/abs/2602.04339)
*Ray Chen,Christan Grant*

Main category: cs.LG

TL;DR: 本文提出了RISE（通过排序评估进行残差检查）可视化工具，用于在域偏移下诊断模型公平性问题，通过分析排序后的残差曲线结构，实现局部差异诊断、跨环境子群比较及隐藏公平性问题的发现。


<details>
  <summary>Details</summary>
Motivation: 标量公平性指标在域偏移场景下难以揭示差异发生的具体位置和方式，亟需可解释、细粒度的诊断方法。

Method: 提出RISE工具，将排序后的预测残差转化为可视化曲线，并建立曲线结构与形式化公平性定义之间的映射关系，支持交互式、局部化的公平性分析。

Result: RISE能实现局部公平性差异诊断、跨环境子群对比，并发现聚合统计忽略的准确率-公平性权衡及隐藏公平问题。

Conclusion: RISE为域偏移下的公平性评估提供了可解释、交互式、细粒度的分析框架，提升了模型选择与公平性调试的可靠性。

Abstract: Evaluating fairness under domain shift is challenging because scalar metrics often obscure exactly where and how disparities arise. We introduce \textit{RISE} (Residual Inspection through Sorted Evaluation), an interactive visualization tool that converts sorted residuals into interpretable patterns. By connecting residual curve structures to formal fairness notions, RISE enables localized disparity diagnosis, subgroup comparison across environments, and the detection of hidden fairness issues. Through post-hoc analysis, RISE exposes accuracy-fairness trade-offs that aggregate statistics miss, supporting more informed model selection.

</details>


### [305] [UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching](https://arxiv.org/abs/2602.04344)
*Kou Misaki,Takuya Akiba*

Main category: cs.LG

TL;DR: 本文提出UnMaskFork（UMF）框架，利用蒙特卡洛树搜索优化掩码扩散语言模型（MDLMs）的非自回归迭代解码路径，在编程与数学推理任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放策略主要针对自回归大语言模型，而掩码扩散语言模型（MDLMs）因其迭代、非自回归特性，尚未被充分挖掘其适配先进搜索策略的潜力。

Method: 将MDLM的解码过程建模为搜索树，提出UnMaskFork（UMF）框架，采用蒙特卡洛树搜索（MCTS）指导确定性部分解掩码动作，并由多个MDLM协同执行。

Result: UMF在复杂编程基准上持续超越现有测试时缩放基线，并在数学推理任务中展现出强可扩展性。

Conclusion: MDLMs天然适合高级搜索策略；UMF通过结构化搜索替代随机采样，有效提升了MDLM在推理密集型任务上的性能。

Abstract: Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their iterative and non-autoregressive generation process. To leverage this, we propose UnMaskFork (UMF), a framework that formulates the unmasking trajectory as a search tree and employs Monte Carlo Tree Search to optimize the generation path. In contrast to standard scaling methods relying on stochastic sampling, UMF explores the search space through deterministic partial unmasking actions performed by multiple MDLMs. Our empirical evaluation demonstrates that UMF consistently outperforms existing test-time scaling baselines on complex coding benchmarks, while also exhibiting strong scalability on mathematical reasoning tasks.

</details>


### [306] [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)
*Weikang Meng,Liangyu Huo,Yadan Luo,Yaowei Wang,Yingjian Li,Zheng Zhang*

Main category: cs.LG

TL;DR: 本文提出MirrorLA，一种通过可学习的Householder反射替代传统非负约束的线性注意力机制，以提升线性注意力的表征能力，在保持线性复杂度的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 线性注意力虽降低计算复杂度，但因核特征映射的非负约束（如ReLU）导致语义信息丢失，性能落后于softmax注意力。

Method: 提出MirrorLA框架，用可学习Householder反射实现特征空间的主动重定向，结合分块等距变换、方差感知调制和跨头反射，实现局部判别性优化、长程动态稳定与全局协方差混合。

Result: 在标准基准上达到SOTA性能，验证了线性复杂度与高表征保真度可兼得。

Conclusion: 非负约束是线性注意力性能下降的主因，主动几何重定向（而非被动截断）能有效恢复表征密度，提升模型性能。

Abstract: Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standard projections like ReLU act as "passive truncation" operators, indiscriminately discarding semantic information residing in the negative domain. We propose MirrorLA, a geometric framework that substitutes passive truncation with active reorientation. By leveraging learnable Householder reflections, MirrorLA rotates the feature geometry into the non-negative orthant to maximize information retention. Our approach restores representational density through a cohesive, multi-scale design: it first optimizes local discriminability via block-wise isometries, stabilizes long-context dynamics using variance-aware modulation to diversify activations, and finally, integrates dispersed subspaces via cross-head reflections to induce global covariance mixing. MirrorLA achieves state-of-the-art performance across standard benchmarks, demonstrating that strictly linear efficiency can be achieved without compromising representational fidelity.

</details>


### [307] [Mosaic Learning: A Framework for Decentralized Learning with Model Fragmentation](https://arxiv.org/abs/2602.04352)
*Sayan Biswas,Davide Frey,Romaric Gaudel,Nirupam Gupta,Anne-Marie Kermarrec,Dimitri Lerévérend,Rafael Pires,Rishi Sharma,François Taïani,Martijn de Vos*

Main category: cs.LG

TL;DR: Mosaic Learning是一种去中心化学习框架，通过将模型分解为独立片段并在网络中分发，减少冗余通信、利用参数相关性提升收敛速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化学习中通信冗余和信息传播多样性不足的问题，同时不增加通信开销。

Method: 提出Mosaic Learning框架，将模型分解为多个独立片段进行分布式传播，并从理论角度分析其收敛性及对参数相关性的利用。

Result: 理论证明达到最优最坏情况收敛速率，并通过降低简化系统最大特征值提升收缩性；实验显示在四个任务上节点级测试准确率比流行病式学习（EL）最高提升12个百分点。

Conclusion: Mosaic Learning在不牺牲实用性与效率的前提下显著提升去中心化学习性能，有望成为新的DL标准。

Abstract: Decentralized learning (DL) enables collaborative machine learning (ML) without a central server, making it suitable for settings where training data cannot be centrally hosted. We introduce Mosaic Learning, a DL framework that decomposes models into fragments and disseminates them independently across the network. Fragmentation reduces redundant communication across correlated parameters and enables more diverse information propagation without increasing communication cost. We theoretically show that Mosaic Learning (i) shows state-of-the-art worst-case convergence rate, and (ii) leverages parameter correlation in an ML model, improving contraction by reducing the highest eigenvalue of a simplified system. We empirically evaluate Mosaic Learning on four learning tasks and observe up to 12 percentage points higher node-level test accuracy compared to epidemic learning (EL), a state-of-the-art baseline. In summary, Mosaic Learning improves DL performance without sacrificing its utility or efficiency, and positions itself as a new DL standard.

</details>


### [308] [Counterfactual Explanations for Hypergraph Neural Networks](https://arxiv.org/abs/2602.04360)
*Fabiano Veglianti,Lorenzo Antonelli,Gabriele Tolomei*

Main category: cs.LG

TL;DR: 本文提出CF-HyperGNNExplainer，一种面向超图神经网络（HGNN）的反事实解释方法，通过最小化结构修改（如删边或删节点-超边关联）来改变模型预测，从而提供简洁、可操作、结构有意义的解释。


<details>
  <summary>Details</summary>
Motivation: 超图神经网络（HGNNs）虽能有效建模高阶交互，但缺乏可解释性，阻碍其在高风险场景中的应用。

Method: 提出CF-HyperGNNExplainer，基于反事实推理，仅允许删除节点-超边关联或整条超边等可操作编辑，生成最小改动的反事实超图。

Result: 在三个基准数据集上的实验表明，该方法能生成有效且简洁的反事实解释，准确识别对HGNN决策最关键的高阶关系。

Conclusion: CF-HyperGNNExplainer为HGNN提供了可解释性新路径，兼顾解释的合理性、简洁性与结构意义，有助于提升模型可信度与实际部署潜力。

Abstract: Hypergraph neural networks (HGNNs) effectively model higher-order interactions in many real-world systems but remain difficult to interpret, limiting their deployment in high-stakes settings.
  We introduce CF-HyperGNNExplainer, a counterfactual explanation method for HGNNs that identifies the minimal structural changes required to alter a model's prediction. The method generates counterfactual hypergraphs using actionable edits limited to removing node-hyperedge incidences or deleting hyperedges, producing concise and structurally meaningful explanations. Experiments on three benchmark datasets show that CF-HyperGNNExplainer generates valid and concise counterfactuals, highlighting the higher-order relations most critical to HGNN decisions.

</details>


### [309] [EXaMCaP: Subset Selection with Entropy Gain Maximization for Probing Capability Gains of Large Chart Understanding Training Sets](https://arxiv.org/abs/2602.04365)
*Jiapeng Liu,Liang Li,Bing Li,Peng Fu,Xiyan Gao,Chengyang Fang,Xiaoshuai Hao,Can Ma*

Main category: cs.LG

TL;DR: 本文提出EXaMCaP方法，通过最大化熵增来选择高多样性子集，以高效评估ChartU数据集对多模态大语言模型（MLLMs）能力提升的效果，避免全量微调的高时间成本。


<details>
  <summary>Details</summary>
Motivation: 全量微调MLLMs以评估ChartU数据集效果耗时过长，阻碍数据集迭代优化；需一种高效、可扩展的子集选择方法来近似全量微调的能力增益。

Method: 提出EXaMCaP方法，基于熵衡量数据多样性，采用贪心策略迭代选取使当前集合熵增最大的样本，逼近全集的最大熵子集。

Result: EXaMCaP在探测ChartU训练集能力增益方面优于基线方法，且在不同子集大小和多种MLLM架构下均表现鲁棒有效。

Conclusion: 熵增最大化是一种高效、通用且可扩展的ChartU数据子集选择策略，能显著加速ChartU数据集的开发与验证闭环。

Abstract: Recent works focus on synthesizing Chart Understanding (ChartU) training sets to inject advanced chart knowledge into Multimodal Large Language Models (MLLMs), where the sufficiency of the knowledge is typically verified by quantifying capability gains via the fine-tune-then-evaluate paradigm. However, full-set fine-tuning MLLMs to assess such gains incurs significant time costs, hindering the iterative refinement cycles of the ChartU dataset. Reviewing the ChartU dataset synthesis and data selection domains, we find that subsets can potentially probe the MLLMs' capability gains from full-set fine-tuning. Given that data diversity is vital for boosting MLLMs' performance and entropy reflects this feature, we propose EXaMCaP, which uses entropy gain maximization to select a subset. To obtain a high-diversity subset, EXaMCaP chooses the maximum-entropy subset from the large ChartU dataset. As enumerating all possible subsets is impractical, EXaMCaP iteratively selects samples to maximize the gain in set entropy relative to the current set, approximating the maximum-entropy subset of the full dataset. Experiments show that EXaMCaP outperforms baselines in probing the capability gains of the ChartU training set, along with its strong effectiveness across diverse subset sizes and compatibility with various MLLM architectures.

</details>


### [310] [Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis](https://arxiv.org/abs/2602.04369)
*Zongjiang Shang,Dongliang Cui,Binqing Wu,Ling Chen*

Main category: cs.LG

TL;DR: 本文提出MSH-LLM，一种基于多尺度超图的大型语言模型对齐方法，用于时间序列分析，通过超边机制、跨模态对齐模块和混合提示机制提升LLM对多尺度时间模式的理解能力，并在27个真实数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有利用预训练大语言模型（LLMs）进行时间序列分析的方法未充分考虑自然语言与时间序列在多尺度结构上的差异，导致LLM能力利用不足。

Method: 提出MSH-LLM：1）设计超边机制增强时间序列语义空间的多尺度信息；2）引入跨模态对齐（CMA）模块实现不同尺度下语言与时间序列的模态对齐；3）采用混合提示（MoP）机制提供上下文并增强LLM对多尺度时序模式的理解。

Result: 在涵盖5类应用的27个真实世界数据集上实验表明，MSH-LLM达到当前最优（state-of-the-art）性能。

Conclusion: 多尺度建模与跨模态对齐对提升LLM在时间序列任务中的表现至关重要，MSH-LLM为LLM赋能时序分析提供了新范式。

Abstract: Recently, there has been great success in leveraging pre-trained large language models (LLMs) for time series analysis. The core idea lies in effectively aligning the modality between natural language and time series. However, the multi-scale structures of natural language and time series have not been fully considered, resulting in insufficient utilization of LLMs capabilities. To this end, we propose MSH-LLM, a Multi-Scale Hypergraph method that aligns Large Language Models for time series analysis. Specifically, a hyperedging mechanism is designed to enhance the multi-scale semantic information of time series semantic space. Then, a cross-modality alignment (CMA) module is introduced to align the modality between natural language and time series at different scales. In addition, a mixture of prompts (MoP) mechanism is introduced to provide contextual information and enhance the ability of LLMs to understand the multi-scale temporal patterns of time series. Experimental results on 27 real-world datasets across 5 different applications demonstrate that MSH-LLM achieves the state-of-the-art results.

</details>


### [311] [Reducing the labeling burden in time-series mapping using Common Ground: a semi-automated approach to tracking changes in land cover and species over time](https://arxiv.org/abs/2602.04373)
*Geethen Singh,Jasper A Slingsby,Tamara B Robinson,Glenn Moncrieff*

Main category: cs.LG

TL;DR: 本文提出了一种名为'Common Ground'的半监督方法，利用时间上稳定的区域作为隐式监督信号，使仅用初始时刻t0标签训练的模型能在未来时刻t1保持高性能，从而减少对多时相人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据分类依赖高质量、及时更新的参考标签，但在动态或偏远生态系统中，持续采集新标签成本高、难度大。

Method: 提出'Common Ground'方法，结合变化检测与半监督学习（SSL），利用时间上光谱/语义稳定的区域为动态区域提供隐式监督，并在多种分类器、传感器和生态场景下验证。

Result: 在入侵树种制图任务中，相比朴素时序迁移提升21-40%，优于金标准方法10-16%；在欧洲广义土地覆被分类中，较两者均提升约2%。

Conclusion: 利用稳定区域筛选结合SSL可实现高效、可扩展的多时相遥感分类，显著降低对多时相标注的依赖。

Abstract: Reliable classification of Earth Observation data depends on consistent, up-to-date reference labels. However, collecting new labelled data at each time step remains expensive and logistically difficult, especially in dynamic or remote ecological systems. As a response to this challenge, we demonstrate that a model with access to reference data solely from time step t0 can perform competitively on both t0 and a future time step t1, outperforming models trained separately on time-specific reference data (the gold standard). This finding suggests that effective temporal generalization can be achieved without requiring manual updates to reference labels beyond the initial time step t0. Drawing on concepts from change detection and semi-supervised learning (SSL), the most performant approach, "Common Ground", uses a semi-supervised framework that leverages temporally stable regions-areas with little to no change in spectral or semantic characteristics between time steps-as a source of implicit supervision for dynamic regions. We evaluate this strategy across multiple classifiers, sensors (Landsat-8, Sentinel-2 satellite multispectral and airborne imaging spectroscopy), and ecological use cases. For invasive tree species mapping, we observed a 21-40% improvement in classification accuracy using Common Ground compared to naive temporal transfer, where models trained at a single time step are directly applied to a future time step. We also observe a 10 -16% higher accuracy for the introduced approach compared to a gold-standard approach. In contrast, when broad land cover categories were mapped across Europe, we observed a more modest 2% increase in accuracy compared to both the naive and gold-standard approaches. These results underscore the effectiveness of combining stable reference screening with SSL for scalable and label-efficient multi-temporal remote sensing classification.

</details>


### [312] [Beyond KL Divergence: Policy Optimization with Flexible Bregman Divergences for LLM Reasoning](https://arxiv.org/abs/2602.04380)
*Rui Yuan,Mykola Khandoga,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: 本文提出了Group-Based Mirror Policy Optimization (GBMPO)框架，将基于组的策略优化扩展到灵活的Bregman散度（包括手工设计和神经网络学习的镜像映射），在数学推理和代码生成任务上显著提升了性能，并表明散度选择是组策略优化中一个关键且此前未被探索的设计维度。


<details>
  <summary>Details</summary>
Motivation: 现有基于组的策略优化方法（如GRPO）均仅使用KL散度进行策略正则化，而散度函数的选择尚未被系统探索。

Method: 提出GBMPO框架，支持多种Bregman散度（如概率空间中的L2散度）及可学习的神经镜像映射；在GSM8K和MBPP数据集上评估手工设计与学习型镜像映射的效果，并分析进化策略元学习对性能与方差的影响。

Result: ProbL2-GRPO在GSM8K上达86.7%准确率（+5.5点）；神经镜像映射在MBPP上达60.1–60.8% pass@1；随机初始化已获大部分收益；进化策略主要降低方差（±0.2 vs ±0.6）并缩短响应长度（15%）。

Conclusion: 散度函数的选择是组策略优化中一个关键且此前被忽视的设计维度，GBMPO为LLM推理任务提供了更灵活、高效的新范式。

Abstract: Policy optimization methods like Group Relative Policy Optimization (GRPO) and its variants have achieved strong results on mathematical reasoning and code generation tasks. Despite extensive exploration of reward processing strategies and training dynamics, all existing group-based methods exclusively use KL divergence for policy regularization, leaving the choice of divergence function unexplored. We introduce Group-Based Mirror Policy Optimization (GBMPO), a framework that extends group-based policy optimization to flexible Bregman divergences, including hand-designed alternatives (L2 in probability space) and learned neural mirror maps. On GSM8K mathematical reasoning, hand-designed ProbL2-GRPO achieves 86.7% accuracy, improving +5.5 points over the Dr. GRPO baseline. On MBPP code generation, neural mirror maps reach 60.1-60.8% pass@1, with random initialization already capturing most of the benefit. While evolutionary strategies meta-learning provides marginal accuracy improvements, its primary value lies in variance reduction ($\pm$0.2 versus $\pm$0.6) and efficiency gains (15% shorter responses on MBPP), suggesting that random initialization of neural mirror maps is sufficient for most practical applications. These results establish divergence choice as a critical, previously unexplored design dimension in group-based policy optimization for LLM reasoning.

</details>


### [313] [Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting](https://arxiv.org/abs/2602.04384)
*Fabio Turazza,Alessandro Neri,Marcello Pietri,Maria Angela Butturi,Marco Picone,Marco Mamei*

Main category: cs.LG

TL;DR: 本文探讨了联邦学习（FL）在可持续供应链管理（SSCM）中的应用，特别是在生鲜食品零售领域的需求预测与浪费评估中；提出了一种基于区块链的FL模型，实现多零售商在不共享原始数据前提下的协同建模，实验表明其性能接近数据集中式训练，显著优于单点建模，可有效减少浪费、提升效率。


<details>
  <summary>Details</summary>
Motivation: 数据隐私问题阻碍零售商间协作，限制需求预测准确率提升，进而加剧食品浪费；亟需一种兼顾隐私保护与模型性能的协同建模方法。

Method: 构建孤立零售商的基线预测模型；设计并实现基于区块链的联邦学习框架，支持多零售商在不共享原始数据前提下协同训练需求与浪费预测模型。

Result: 联邦学习模型性能接近数据完全共享的理想情况，明显优于各零售商独立建模的结果，能有效降低食品浪费、提高运营效率。

Conclusion: 联邦学习（尤其结合区块链）是解决零售业数据孤岛与隐私约束下协同需求预测问题的有效范式，对可持续供应链具有实际应用价值。

Abstract: Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Management (SSCM), with a focus on the grocery retail sector dealing with perishable goods. We develop a baseline predictive model for demand forecasting and waste assessment in an isolated retailer scenario. Subsequently, we introduce a Blockchain-based FL model, trained collaboratively across multiple retailers without direct data sharing. Our preliminary results show that FL models have performance almost equivalent to the ideal setting in which parties share data with each other, and are notably superior to models built by individual parties without sharing data, cutting waste and boosting efficiency.

</details>


### [314] [On the use of LLMs to generate a dataset of Neural Networks](https://arxiv.org/abs/2602.04388)
*Nadia Daoudi,Jordi Cabot*

Main category: cs.LG

TL;DR: 本文提出利用大语言模型（LLMs）自动生成多样化神经网络数据集，用于验证神经网络可靠性与可适应性相关工具的有效性，并通过静态分析和符号追踪验证其正确性，最终开源该含608个样本的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证、重构与迁移工具缺乏公开、多样化的神经网络数据集，难以系统评估其有效性。

Method: 利用大语言模型（LLMs）自动生成覆盖多种架构组件、输入数据类型和任务的神经网络；对生成的608个网络样本进行静态分析和符号追踪以验证其正确性。

Result: 构建了一个包含608个高质量、多样化神经网络样本的公开基准数据集，所有样本均满足预设设计规范并经形式化验证。

Conclusion: 该数据集填补了神经网络工具评估中基准缺失的空白，为提升神经网络的可靠性、可维护性与可复用性研究提供了重要支撑。

Abstract: Neural networks are increasingly used to support decision-making. To verify their reliability and adaptability, researchers and practitioners have proposed a variety of tools and methods for tasks such as NN code verification, refactoring, and migration. These tools play a crucial role in guaranteeing both the correctness and maintainability of neural network architectures, helping to prevent implementation errors, simplify model updates, and ensure that complex networks can be reliably extended and reused. Yet, assessing their effectiveness remains challenging due to the lack of publicly diverse datasets of neural networks that would allow systematic evaluation. To address this gap, we leverage large language models (LLMs) to automatically generate a dataset of neural networks that can serve as a benchmark for validation. The dataset is designed to cover diverse architectural components and to handle multiple input data types and tasks. In total, 608 samples are generated, each conforming to a set of precise design choices. To further ensure their consistency, we validate the correctness of the generated networks using static analysis and symbolic tracing. We make the dataset publicly available to support the community in advancing research on neural network reliability and adaptability.

</details>


### [315] [LoRDO: Distributed Low-Rank Optimization with Infrequent Communication](https://arxiv.org/abs/2602.04396)
*Andrej Jovanović,Alex Iacob,Mher Safaryan,Ionut-Vlad Modoranu,Lorenzo Sani,William F. Shen,Xinchi Qiu,Dan Alistarh,Nicholas D. Lane*

Main category: cs.LG

TL;DR: 本文提出LoRDO框架，将低秩优化与不频繁同步相结合，解决了分布式训练中通信带宽和内存受限的问题，在保持性能的同时大幅降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 分布式训练中DDP受限于互连带宽，而现有不频繁通信策略仍受优化器状态的内存和通信需求制约；低秩优化虽有潜力，但在本地更新场景下因缺乏全批量梯度而难以有效计算低秩投影，导致性能下降。

Method: 提出LoRDO框架：首先分析基于伪梯度的全局投影的理论优势与子空间限制问题；进而引入全秩拟双曲更新以恢复子空间探索能力。

Result: LoRDO在125M–720M规模语言模型上实现与低秩DDP近似相当的语言建模及下游任务性能，通信量减少约10倍；在极低内存、小秩/小批量设置下性能进一步提升。

Conclusion: LoRDO为大规模分布式训练提供了一种兼顾通信效率、内存节约与优化灵活性的新范式，尤其适用于资源受限场景。

Abstract: Distributed training of foundation models via $\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\texttt{LoRDO}$ achieves near-parity with low-rank $\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\approx 10 \times$. Finally, we show that $\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.

</details>


### [316] [Theory of Speciation Transitions in Diffusion Models with General Class Structure](https://arxiv.org/abs/2602.04404)
*Beatrice Achilli,Marco Benedetti,Giulio Biroli,Marc Mézard*

Main category: cs.LG

TL;DR: 本文提出了一个关于扩散模型中'物种形成'（speciation）现象的通用理论框架，适用于任意具有明确定义类结构的目标分布，而不仅限于均值可分的高斯混合模型；该理论基于贝叶斯分类定义类结构，并以类间自由熵差刻画物种形成时间，能处理多类、高阶特征差异及细粒度逐级承诺现象，并在Ising模型与协方差不同的零均值高斯混合上得到解析验证。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型中物种形成（speciation）的理论分析局限于仅靠一阶矩（如均值）可区分的简单分布（如均值分离的高斯混合），无法解释更一般情形下（如靠高阶统计量或集体特征区分的类别）的动态类承诺现象。

Method: 通过贝叶斯分类形式化类结构，引入自由熵差作为关键判据来刻画物种形成时间；将问题映射为随机场Ising模型并用复本法求解；推广至多类情形并推导逐级细粒度的连续speciation时间。

Result: 建立了适用于任意目标分布的speciation通用理论；恢复了已有高斯混合结果；成功应用于两类新模型（温度不同的1D Ising混合、协方差不同的零均值高斯混合），并在Ising情形下获得speciation时间的显式解析表达；预测并解释了多阶段、逐级细化的类承诺现象。

Conclusion: 本文提供了一个统一、普适且可解析的理论框架，深刻揭示了扩散模型反向过程中类结构涌现的动力学机制，显著拓展了对生成模型内部表示演化的理解边界。

Abstract: Diffusion Models generate data by reversing a stochastic diffusion process, progressively transforming noise into structured samples drawn from a target distribution. Recent theoretical work has shown that this backward dynamics can undergo sharp qualitative transitions, known as speciation transitions, during which trajectories become dynamically committed to data classes. Existing theoretical analyses, however, are limited to settings where classes are identifiable through first moments, such as mixtures of Gaussians with well-separated means. In this work, we develop a general theory of speciation in diffusion models that applies to arbitrary target distributions admitting well-defined classes. We formalize the notion of class structure through Bayes classification and characterize speciation times in terms of free-entropy difference between classes. This criterion recovers known results in previously studied Gaussian-mixture models, while extending to situations in which classes are not distinguishable by first moments and may instead differ through higher-order or collective features. Our framework also accommodates multiple classes and predicts the existence of successive speciation times associated with increasingly fine-grained class commitment. We illustrate the theory on two analytically tractable examples: mixtures of one-dimensional Ising models at different temperatures and mixtures of zero-mean Gaussians with distinct covariance structures. In the Ising case, we obtain explicit expressions for speciation times by mapping the problem onto a random-field Ising model and solving it via the replica method. Our results provide a unified and broadly applicable description of speciation transitions in diffusion-based generative models.

</details>


### [317] [Separation-Utility Pareto Frontier: An Information-Theoretic Characterization](https://arxiv.org/abs/2602.04408)
*Shizhou Xu*

Main category: cs.LG

TL;DR: 本文研究了效用与分离性（一种公平性标准）之间的帕累托前沿，通过信息论方法刻画了该前沿的性质，并提出了一种基于条件互信息（CMI）的正则化器，在多个数据集上验证了其在减少分离性违规的同时保持甚至提升模型效用的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习中效用与公平性（特别是分离性）之间的权衡问题，提供理论刻画与实用算法。

Method: 基于信息论对效用-分离帕累托前沿进行理论刻画；提出基于条件互信息（CMI）的可微正则化器，适用于任意梯度优化的深度模型。

Result: 证明了帕累托前沿的凹性及分离成本递增性；给出了严格权衡成立的条件；CMI正则器在COMPAS、UCI Adult、UCI Bank和CelebA数据集上显著降低分离违规，同时保持或超越基线方法的效用。

Conclusion: 本文提供了可证明、稳定且灵活的深度学习公平性实现方法，兼顾理论严谨性与实际可扩展性。

Abstract: We study the Pareto frontier (optimal trade-off) between utility and separation, a fairness criterion requiring predictive independence from sensitive attributes conditional on the true outcome. Through an information-theoretic lens, we prove a characterization of the utility-separation Pareto frontier, establish its concavity, and thereby prove the increasing marginal cost of separation in terms of utility. In addition, we characterize the conditions under which this trade-off becomes strict, providing a guide for trade-off selection in practice. Based on the theoretical characterization, we develop an empirical regularizer based on conditional mutual information (CMI) between predictions and sensitive attributes given the true outcome. The CMI regularizer is compatible with any deep model trained via gradient-based optimization and serves as a scalar monitor of residual separation violations, offering tractable guarantees during training. Finally, numerical experiments support our theoretical findings: across COMPAS, UCI Adult, UCI Bank, and CelebA, the proposed method substantially reduces separation violations while matching or exceeding the utility of established baseline methods. This study thus offers a provable, stable, and flexible approach to enforcing separation in deep learning.

</details>


### [318] [EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL](https://arxiv.org/abs/2602.04417)
*Lunjun Zhang,Jimmy Ba*

Main category: cs.LG

TL;DR: 本文提出EMA-PG方法，通过指数移动平均锚策略和Top-k KL估计器改进LLM的策略梯度算法，在数学推理与智能体RL任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在强化学习中的策略梯度算法稳定性与性能，解决固定锚策略和KL散度估计偏差问题。

Method: 1）用指数移动平均（EMA）替代固定锚策略；2）引入Top-k KL估计器，实现精确KL与采样KL之间的灵活插值；二者结合GRPO形成EMA-PG算法。

Result: 在OlympiadBench上Qwen-1.5B达53.9%（+3.1%）；在7个搜索增强问答数据集上平均提升33.3%，如HotpotQA从29.7%→44.1%。

Conclusion: EMA-PG是一种简洁、有理论依据且可扩展的LLM强化学习优化方法。

Abstract: Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential Moving Average (EMA), similar to a target network in deep Q-learning. Second, we introduce Top-k KL estimator, which allows for flexible interpolation between exact KL and sampled KL. We derive the stability conditions for using EMA anchor; moreover, we show that our Top-k KL estimator yields both unbiased KL values and unbiased gradients at any k, while bringing the benefits of exact KL. When combined with GRPO, the two techniques (EMA-PG) lead to a significant performance boost. On math reasoning, it allows R1-distilled Qwen-1.5B to reach 53.9% on OlympiadBench compared to 50.8% by GRPO. On agentic RL domains, with Qwen-3B base, EMA-PG improves GRPO by an average of 33.3% across 7 datasets of Q&A with search engines, including 29.7% $\rightarrow$ 44.1% on HotpotQA, 27.4% $\rightarrow$ 40.1% on 2WikiMultiHopQA. Overall, we show that EMA-PG is a simple, principled, and powerful approach to scaling RL for LLMs. Code: https://github.com/LunjunZhang/ema-pg

</details>


### [319] [MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems](https://arxiv.org/abs/2602.04431)
*Jonathan Nöther,Adish Singla,Goran Radanovic*

Main category: cs.LG

TL;DR: 本文提出MaMa算法，通过Stackelberg安全博弈建模，利用LLM驱动的对抗搜索自动设计在部分代理被攻破时仍能保持安全的多智能体系统。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统虽能力强，但单个代理失败或恶意行为会带来显著安全风险，亟需设计具备鲁棒安全性的系统。

Method: 将系统设计问题形式化为Meta-Agent（设计者）与Meta-Adversary（攻击者）之间的Stackelberg安全博弈；提出MaMa算法，采用LLM-based对抗搜索：Meta-Agent迭代提出设计方案，Meta-Adversary寻找最强攻击以反馈优化。

Result: MaMa设计的系统在多种环境中持续抵御最坏攻击，任务性能与仅优化任务成功率的系统相当；且泛化性强，可应对更强、目标不同或使用不同LLM的攻击者。

Conclusion: MaMa提供了一种自动化、鲁棒且泛化性好的方法，用于构建即使在部分代理被攻破时仍安全可靠的LLM多智能体系统。

Abstract: LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.

</details>


### [320] [Hand Gesture Recognition from Doppler Radar Signals Using Echo State Networks](https://arxiv.org/abs/2602.04436)
*Towa Sano,Gouhei Tanaka*

Main category: cs.LG

TL;DR: 本文提出了一种基于回声状态网络（ESN）的轻量级雷达手势识别方法，利用FMCW雷达信号生成多域特征图并输入多储层ESN，结合多种读出分类器，在Soli和Dop-NET数据集上实现了高性能与低计算开销的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在雷达手势识别中计算成本高，难以满足车载界面和机器人系统等资源受限场景的需求。

Method: 将FMCW雷达原始信号转换为range-time和Doppler-time等特征图，输入一个或多个基于RNN的ESN储层，再通过岭回归、SVM或随机森林等读出分类器进行分类；采用多储层并行处理不同域的特征图。

Result: 在Soli数据集（11类）和Dop-NET数据集（4类）上均优于现有方法，尤其在计算效率上显著优于深度学习模型。

Conclusion: 多储层ESN能有效建模时-空与时-频域的时序模式，在保证高识别精度的同时大幅降低计算开销，适用于资源受限的人机交互场景。

Abstract: Hand gesture recognition (HGR) is a fundamental technology in human computer interaction (HCI).In particular, HGR based on Doppler radar signals is suited for in-vehicle interfaces and robotic systems, necessitating lightweight and computationally efficient recognition techniques. However, conventional deep learning-based methods still suffer from high computational costs. To address this issue, we propose an Echo State Network (ESN) approach for radar-based HGR, using frequency-modulated-continuous-wave (FMCW) radar signals. Raw radar data is first converted into feature maps, such as range-time and Doppler-time maps, which are then fed into one or more recurrent neural network-based reservoirs. The obtained reservoir states are processed by readout classifiers, including ridge regression, support vector machines, and random forests. Comparative experiments demonstrate that our method outperforms existing approaches on an 11-class HGR task using the Soli dataset and surpasses existing deep learning models on a 4-class HGR task using the Dop-NET dataset. The results indicate that parallel processing using multi-reservoir ESNs are effective for recognizing temporal patterns from the multiple different feature maps in the time-space and time-frequency domains. Our ESN approaches achieve high recognition performance with low computational cost in HGR, showing great potential for more advanced HCI technologies, especially in resource-constrained environments.

</details>


### [321] [Mixture of Masters: Sparse Chess Language Models with Player Routing](https://arxiv.org/abs/2602.04447)
*Giacomo Frisoni,Lorenzo Molfetta,Davide Freddi,Gianluca Moro*

Main category: cs.LG

TL;DR: 本文提出Mixture-of-Masters（MoM）模型，通过多个小型GPT专家模拟不同棋风的特级大师，并用可学习门控网络动态选择最适配当前局面的专家，从而提升下棋多样性、可控性与可解释性，且在对抗Stockfish时优于传统密集模型和GPT基线。


<details>
  <summary>Details</summary>
Motivation: 现代国际象棋语言模型因使用大量混合数据训练而趋于模式平均化，模糊了棋手风格边界并压制罕见但有效的策略，亟需引入风格化与专业化建模。

Method: 构建基于小型GPT专家的混合专家（MoE）模型，每位专家通过自监督学习与面向棋类的强化学习联合训练；引入后验可学习门控网络，依据当前棋局状态动态选择最匹配的‘大师人格’专家。

Result: MoM在未见过的标准对局中击败Stockfish，性能超越单个密集专家网络及聚合数据训练的主流GPT基线，同时保持生成多样性、策略可控性与决策可解释性。

Conclusion: MoM验证了将专家专业化、风格显式建模与动态门控机制结合的有效性，为领域专用大模型提供了兼顾性能与人类可理解性的新范式。

Abstract: Modern chess language models are dense transformers trained on millions of games played by thousands of high-rated individuals. However, these monolithic networks tend to collapse into mode-averaged behavior, where stylistic boundaries are blurred, and rare but effective strategies are suppressed. To counteract homogenization, we introduce Mixture-of-Masters (MoM), the first chess mixture-of-experts model with small-sized GPT experts emulating world-class grandmasters. Each expert is trained with a combination of self-supervised learning and reinforcement learning guided by chess-specific rewards. For each move, a post-hoc learnable gating network selects the most appropriate persona to channel depending on the game state, allowing MoM to switch its style dynamically$--$e.g., Tal's offensive vocation or Petrosian's defensive solidity. When evaluated against Stockfish on unseen standard games, MoM outperforms both dense individual expert networks and popular GPT baselines trained on aggregated data, while ensuring generation variety, control, and interpretability.

</details>


### [322] [RASA: Routing-Aware Safety Alignment for Mixture-of-Experts Models](https://arxiv.org/abs/2602.04448)
*Jiacheng Liang,Yuhui Wang,Tanqiu Jiang,Ting Wang*

Main category: cs.LG

TL;DR: 本文提出RASA框架，针对MoE语言模型的安全对齐问题，通过识别并修复安全关键专家（Safety-Critical Experts），同时防止路由绕过，显著提升对抗 jailbreak 攻击的鲁棒性与泛化能力，且不损害模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 标准全参数安全微调在MoE模型上易引发路由或专家主导等退化优化行为，无法真正修复安全关键专家，导致虚假的安全提升。

Method: RASA框架分三步：1）识别在成功越狱攻击下被异常激活的安全关键专家；2）在固定路由下仅微调这些专家；3）强制路由在安全对齐上下文中保持一致性。

Result: RASA在两类典型MoE架构和多种jailbreak攻击下实现近似完美的鲁棒性、强跨攻击泛化能力、大幅降低过度拒绝率，同时在MMLU、GSM8K、TruthfulQA等基准上保持原有能力。

Conclusion: MoE模型的安全对齐应聚焦于目标专家修复而非全局参数更新，RASA提供了一种实用且架构保持的安全对齐新范式。

Abstract: Mixture-of-Experts (MoE) language models introduce unique challenges for safety alignment due to their sparse routing mechanisms, which can enable degenerate optimization behaviors under standard full-parameter fine-tuning. In our preliminary experiments, we observe that naively applying full-parameter safety fine-tuning to MoE models can reduce attack success rates through routing or expert dominance effects, rather than by directly repairing Safety-Critical Experts. To address this challenge, we propose RASA, a routing-aware expert-level alignment framework that explicitly repairs Safety-Critical Experts while preventing routing-based bypasses. RASA identifies experts disproportionately activated by successful jailbreaks, selectively fine-tunes only these experts under fixed routing, and subsequently enforces routing consistency with safety-aligned contexts. Across two representative MoE architectures and a diverse set of jailbreak attacks, RASA achieves near-perfect robustness, strong cross-attack generalization, and substantially reduced over-refusal, while preserving general capabilities on benchmarks such as MMLU, GSM8K, and TruthfulQA. Our results suggest that robust MoE safety alignment benefits from targeted expert repair rather than global parameter updates, offering a practical and architecture-preserving alternative to prior approaches.

</details>


### [323] [Delving into Muon and Beyond: Deep Analysis and Extensions](https://arxiv.org/abs/2602.04669)
*Xianbiao Qi,Marco Chen,Jiaquan Ye,Yelin He,Rong Xiao*

Main category: cs.LG

TL;DR: 本文从谱视角统一分析Muon优化器，将其视为谱变换族的p=0端点，并探索不同p值变体；发现RMS归一化更新比一阶矩更新更稳定，而Muon（p=0）并不始终优于Adam，表明其本质是有效的谱归一化方法而非普适更优优化器。


<details>
  <summary>Details</summary>
Motivation: Muon优化器虽表现优异且采用矩阵参数正交更新，但其内在机制及与Adam等自适应优化器的关系尚不清晰，亟需理论解释。

Method: 将Muon建模为谱变换族UΣ^pV'在p=0处的特例，并构造p=1/4, 1/2, 1等变体；分别应用于一阶矩更新（如动量SGD）和RMS归一化梯度更新（如Adam）；设计耦合牛顿迭代法避免显式SVD以提升计算效率。

Result: RMS归一化更新比一阶矩更新更稳定；谱压缩对一阶矩更新有显著稳定作用，但Muon（p=0）并未在所有实验中持续超越Adam。

Conclusion: Muon本质上是一种有效的谱归一化方法，而非在所有场景下都优于Adam的通用更优优化器。

Abstract: The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we aim to address these questions through a unified spectral perspective. Specifically, we view Muon as the p = 0 endpoint of a family of spectral transformations of the form U \boldsymbolΣ^{p} V' , and consider additional variants with p = 1/2 , p = 1/4 , and p = 1 . These transformations are applied to both first-moment updates, as in momentum SGD, and to root-mean-square (RMS) normalized gradient updates as in Adam. To enable efficient computation, we develop a coupled Newton iteration that avoids explicit singular value decomposition. Across controlled experiments, we find that RMS-normalized updates yield more stable optimization than first-moment updates. Moreover, while spectral compression provides strong stabilization benefits under first-moment updates, the Muon update (p = 0) does not consistently outperform Adam. These results suggest that Muon is best understood as an effective form of spectral normalization, but not a universally superior optimization method. Our source code will be released at https://github.com/Ocram7/BeyondMuon.

</details>


### [324] [Greedy-Gnorm: A Gradient Matrix Norm-Based Alternative to Attention Entropy for Head Pruning](https://arxiv.org/abs/2602.04491)
*Yuxi Guo,Paul Sheridan*

Main category: cs.LG

TL;DR: 本文提出了一种动态注意力头剪枝算法Greedy-Gnorm，通过在每次剪枝后基于验证集梯度重新计算各头的重要性（Q/K/V梯度块L2范数的逐元素乘积），显著优于静态方法（如注意力熵），在BERT等模型上实现了高精度保持的大规模剪枝。


<details>
  <summary>Details</summary>
Motivation: 现有注意力头剪枝方法多依赖静态重要性评分，无法反映头在迭代剪枝过程中角色的动态变化，导致剪枝效果受限。

Method: 提出Greedy-Gradient norm（Greedy-Gnorm）算法：在每次贪心剪枝步骤后，利用保留验证集估计并更新每个注意力头的Q、K、V参数梯度块的L2范数，以其逐元素乘积作为动态重要性得分。

Result: 在BERT、ALBERT、RoBERTa和XLM-RoBERTa上实验表明，Greedy-Gnorm在大幅剪枝下持续优于注意力熵等基线方法，显著保持下游任务准确率。

Conclusion: Greedy-Gnorm是一种更鲁棒、梯度感知的动态剪枝策略，有助于实现更节能高效的Transformer模型部署，推动Green AI发展。

Abstract: Attention head pruning has emerged as an effective technique for transformer model compression, an increasingly important goal in the era of Green AI. However, existing pruning methods often rely on static importance scores, which fail to capture the evolving role of attention heads during iterative removal. We propose Greedy-Gradient norm (Greedy-Gnorm), a novel head pruning algorithm that dynamically recalculates head importance after each pruning step. Specifically, each head is scored by the elementwise product of the l2-norms of its Q/K/V gradient blocks, as estimated from a hold-out validation set and updated at every greedy iteration. This dynamic approach to scoring mitigates against stale rankings and better reflects gradient-informed importance as pruning progresses. Extensive experiments on BERT, ALBERT, RoBERTa, and XLM-RoBERTa demonstrate that Greedy-Gnorm consistently preserves accuracy under substantial head removal, outperforming attention entropy. By effectively reducing model size while maintaining task performance, Greedy-Gnorm offers a promising step toward more energy-efficient transformer model deployment.

</details>


### [325] [Identifying Intervenable and Interpretable Features via Orthogonality Regularization](https://arxiv.org/abs/2602.04718)
*Moritz Miller,Florent Draye,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 本文提出了一种正交化稀疏自编码器解码矩阵的方法，以减少特征间的干扰和叠加，提升可解释性与因果干预能力，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 提升稀疏自编码器中特征的可解释性与因果可干预性，解决特征间干扰和叠加问题。

Method: 在稀疏自编码器训练中引入正交性惩罚项，使解码矩阵的特征趋于正交，并基于独立因果机制（ICM）原理论证其合理性。

Result: 正交化后特征干扰减少、性能基本不变、特征解释距离增大、支持孤立干预；代码已开源。

Conclusion: 正交化是构建模块化、可解释、可因果干预表征的有效途径。

Abstract: With recent progress on fine-tuning language models around a fixed sparse autoencoder, we disentangle the decoder matrix into almost orthogonal features. This reduces interference and superposition between the features, while keeping performance on the target dataset essentially unchanged. Our orthogonality penalty leads to identifiable features, ensuring the uniqueness of the decomposition. Further, we find that the distance between embedded feature explanations increases with stricter orthogonality penalty, a desirable property for interpretability. Invoking the $\textit{Independent Causal Mechanisms}$ principle, we argue that orthogonality promotes modular representations amenable to causal intervention. We empirically show that these increasingly orthogonalized features allow for isolated interventions. Our code is available under $\texttt{https://github.com/mrtzmllr/sae-icm}$.

</details>


### [326] [Forget to Generalize: Iterative Adaptation for Generalization in Federated Learning](https://arxiv.org/abs/2602.04536)
*Abdulrahman Alotaibi,Irene Tenison,Miriam Kim,Isaac Lee,Lalana Kagal*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦学习训练范式——迭代联邦自适应（IFA），通过在每一代训练结束时选择性地重置部分模型参数（随机或深层参数），实现‘遗忘与进化’策略，以提升非独立同分布（Non-IID）场景下的泛化能力。实验表明其在多个数据集上平均提升全局准确率21.5%。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在真实Web系统中面临严重的非IID数据分布问题，导致性能显著下降，亟需提升模型在异构客户端上的泛化能力。

Method: 提出迭代联邦自适应（IFA）范式：将训练划分为多代，在每代末随机或按层（如后几层）选择部分参数进行重初始化，形成‘迭代式遗忘与进化’机制，帮助模型逃离局部最优并保留全局有效表征。

Result: 在CIFAR-10、MIT-Indoors和Stanford Dogs数据集上验证了IFA的有效性，尤其在Non-IID设置下显著提升全局准确率，平均增益达21.5%；且可即插即用地增强任意现有联邦算法。

Conclusion: IFA是一种通用、高效且易于集成的联邦学习增强方法，推动了面向真实世界异构分布式Web系统的可扩展、隐私保护智能的发展。

Abstract: The Web is naturally heterogeneous with user devices, geographic regions, browsing patterns, and contexts all leading to highly diverse, unique datasets. Federated Learning (FL) is an important paradigm for the Web because it enables privacy-preserving, collaborative machine learning across diverse user devices, web services and clients without needing to centralize sensitive data. However, its performance degrades severely under non-IID client distributions that is prevalent in real-world web systems. In this work, we propose a new training paradigm - Iterative Federated Adaptation (IFA) - that enhances generalization in heterogeneous federated settings through generation-wise forget and evolve strategy. Specifically, we divide training into multiple generations and, at the end of each, select a fraction of model parameters (a) randomly or (b) from the later layers of the model and reinitialize them. This iterative forget and evolve schedule allows the model to escape local minima and preserve globally relevant representations. Extensive experiments on CIFAR-10, MIT-Indoors, and Stanford Dogs datasets show that the proposed approach improves global accuracy, especially when the data cross clients are Non-IID. This method can be implemented on top any federated algorithm to improve its generalization performance. We observe an average of 21.5%improvement across datasets. This work advances the vision of scalable, privacy-preserving intelligence for real-world heterogeneous and distributed web systems.

</details>


### [327] [Continual Learning through Control Minimization](https://arxiv.org/abs/2602.04542)
*Sander de Haan,Yassine Taoudi-Benchekroun,Pau Vilimelis Aceituno,Benjamin F. Grewe*

Main category: cs.LG

TL;DR: 本文将持续学习重新定义为一个控制问题，通过将正则化惩罚转化为保护先前任务表示的‘保持信号’，在神经活动动力学中平衡学习与保持，从而避免灾难性遗忘，且无需显式存储曲率信息。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在顺序学习任务时面临的灾难性遗忘这一根本性挑战。

Method: 将持续学习建模为学习信号与保持信号在神经活动动力学中竞争的控制问题；将正则化项转化为保持先前任务表征的动态信号；通过最小化整合新任务所需的控制努力来实现学习；在平衡态下，神经活动隐式编码全部先前任务的曲率（即‘持续自然梯度’）。

Result: 实验验证该框架能准确恢复先前任务的真实曲率，支持任务判别，并在无回放的标准基准上优于现有方法。

Conclusion: 所提出的控制视角及持续自然梯度机制，为无需显式曲率存储、不依赖回放的持续学习提供了有效且理论一致的新范式。

Abstract: Catastrophic forgetting remains a fundamental challenge for neural networks when tasks are trained sequentially. In this work, we reformulate continual learning as a control problem where learning and preservation signals compete within neural activity dynamics. We convert regularization penalties into preservation signals that protect prior-task representations. Learning then proceeds by minimizing the control effort required to integrate new tasks while competing with the preservation of prior tasks. At equilibrium, the neural activities produce weight updates that implicitly encode the full prior-task curvature, a property we term the continual-natural gradient, requiring no explicit curvature storage. Experiments confirm that our learning framework recovers true prior-task curvature and enables task discrimination, outperforming existing methods on standard benchmarks without replay.

</details>


### [328] [Subliminal Effects in Your Data: A General Mechanism via Log-Linearity](https://arxiv.org/abs/2602.04863)
*Ishaq Aden-Ali,Noah Golowich,Allen Liu,Abhishek Shetty,Ankur Moitra,Nika Haghtalab*

Main category: cs.LG

TL;DR: 本文提出Logit-Linear-Selection（LLS）方法，揭示通用偏好数据集中隐藏子文本的产生机制，并通过子集选择在不同模型上稳定诱发特定行为（如跨语言响应、人格切换等），表明数据集存在非局部、非显式的全局信号效应。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练依赖大量算法与数据组合，但数据如何影响模型性质尚不清晰；近期实验显示数据集可传递单个样本无法体现的隐式信号，挑战了以单一样本为中心的数据理解范式，亟需基础性解释。

Method: 受LLM线性结构启发，提出Logit-Linear-Selection（LLS）方法，用于从通用偏好数据集中系统性选取子集，以激活隐藏行为效应。

Result: LLS成功在真实世界数据集中发现多个子集，使训练模型展现出特定偏好、跨语言响应（即使数据中无该语言）、人格切换等行为；且效果在不同架构模型上具有一致性和鲁棒性。

Conclusion: 数据集存在超越个体样本的全局结构信号，LLS揭示了一种通用机制来解码和利用此类隐藏子文本，为数据集影响建模提供了新理论视角与实用工具。

Abstract: Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.
  We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.

</details>


### [329] [Gradient Flow Through Diagram Expansions: Learning Regimes and Explicit Solutions](https://arxiv.org/abs/2602.04548)
*Dmitry Yarotsky,Eugene Golikov,Yaroslav Gusev*

Main category: cs.LG

TL;DR: 本文提出了一种基于形式幂级数展开（类费曼图编码）的数学框架，用于分析大规模学习问题中梯度流（GF）的缩放行为与相变，并在CP张量分解任务中揭示了多种极限训练机制（如自由演化、NTK、均场等），同时将损失展开式求和归约为可解的一阶PDE。


<details>
  <summary>Details</summary>
Motivation: 理解大规模学习中梯度流的动力学行为，尤其是不同参数缩放下出现的多种学习相（如lazy/rich regimes），缺乏统一的解析理论框架。

Method: 构建损失演化的形式幂级数展开，用类Feynman图编码系数；分析其大尺寸极限；针对CP张量分解建模，推导不同缩放下的GF相；将级数求和转化为一阶偏微分方程（PDE），并用特征线法求解。

Result: 成功解析刻画了CP分解中自由演化、NTK、欠/过参数化均场等多种GF极限相；明确了这些相如何依赖参数缩放、张量阶数与模型对称性；所导出PDE在多场景下可解，且理论预测与实验高度吻合。

Conclusion: 该框架为理解深度学习中的缩放律与训练动力学提供了新的解析工具，揭示了不同学习机制间的精细过渡，并具备向更广模型推广的潜力。

Abstract: We develop a general mathematical framework to analyze scaling regimes and derive explicit analytic solutions for gradient flow (GF) in large learning problems. Our key innovation is a formal power series expansion of the loss evolution, with coefficients encoded by diagrams akin to Feynman diagrams. We show that this expansion has a well-defined large-size limit that can be used to reveal different learning phases and, in some cases, to obtain explicit solutions of the nonlinear GF. We focus on learning Canonical Polyadic (CP) decompositions of high-order tensors, and show that this model has several distinct extreme lazy and rich GF regimes such as free evolution, NTK and under- and over-parameterized mean-field. We show that these regimes depend on the parameter scaling, tensor order, and symmetry of the model in a specific and subtle way. Moreover, we propose a general approach to summing the formal loss expansion by reducing it to a PDE; in a wide range of scenarios, it turns out to be 1st order and solvable by the method of characteristics. We observe a very good agreement of our theoretical predictions with experiment.

</details>


### [330] [Rethinking the Trust Region in LLM Reinforcement Learning](https://arxiv.org/abs/2602.04879)
*Penghui Qi,Xiangxin Zhou,Zichen Liu,Tianyu Pang,Chao Du,Min Lin,Wee Sun Lee*

Main category: cs.LG

TL;DR: 本文提出DPPO算法，通过直接估计策略散度（如总变差或KL散度）替代PPO中的比率裁剪机制，以解决其在大词汇量LLM微调中因单样本估计导致的更新不均衡问题；引入Binary与Top-K近似降低内存开销，并在实验中验证了其更优的训练稳定性与效率。


<details>
  <summary>Details</summary>
Motivation: PPO在LLM微调中广泛使用，但其基于单个采样token概率比的比率裁剪机制在大词汇量下存在结构性缺陷：对低概率token更新过度惩罚，对高概率token的危险偏移约束不足，导致训练低效且不稳定。

Method: 提出Divergence Proximal Policy Optimization（DPPO），用直接估计策略散度（如Total Variation或KL）代替启发式比率裁剪；为控制内存开销，设计Binary和Top-K两种高效近似方法来估算关键散度。

Result: 大量实验证明DPPO相比现有方法具有更优的训练稳定性和效率，提升了RL-based LLM微调的鲁棒性。

Conclusion: DPPO通过更合理的散度约束机制克服了PPO在LLM场景下的根本局限，是一种更适配大语言模型强化学习微调的替代方案。

Abstract: Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.

</details>


### [331] [Finding Structure in Continual Learning](https://arxiv.org/abs/2602.04555)
*Pourya Shamsolmoali,Masoumeh Zareapoor*

Main category: cs.LG

TL;DR: 本文提出使用Douglas-Rachford Splitting（DRS）重新构建持续学习目标，将稳定性与可塑性解耦为两个独立目标，并通过其近端算子迭代达成共识，从而避免灾难性遗忘，无需额外模块或复杂策略。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中可塑性与稳定性之间的固有冲突，避免传统方法中因多损失项叠加导致的梯度冲突和低效策略依赖。

Method: 采用Douglas-Rachford Splitting优化框架，将学习目标分解为分别对应新任务可塑性和旧知识稳定性的两个子问题，并通过迭代应用其近端算子实现协同优化。

Result: 在不引入外部记忆回放或参数正则化等辅助机制的前提下，实现了更稳定、高效且简洁的持续学习性能。

Conclusion: DRS提供了一种更原则性、解耦化的持续学习范式，显著简化系统设计，同时提升稳定性与可塑性的平衡能力。

Abstract: Learning from a stream of tasks usually pits plasticity against stability: acquiring new knowledge often causes catastrophic forgetting of past information. Most methods address this by summing competing loss terms, creating gradient conflicts that are managed with complex and often inefficient strategies such as external memory replay or parameter regularization. We propose a reformulation of the continual learning objective using Douglas-Rachford Splitting (DRS). This reframes the learning process not as a direct trade-off, but as a negotiation between two decoupled objectives: one promoting plasticity for new tasks and the other enforcing stability of old knowledge. By iteratively finding a consensus through their proximal operators, DRS provides a more principled and stable learning dynamic. Our approach achieves an efficient balance between stability and plasticity without the need for auxiliary modules or complex add-ons, providing a simpler yet more powerful paradigm for continual learning systems.

</details>


### [332] [Probabilistic Label Spreading: Efficient and Consistent Estimation of Soft Labels with Epistemic Uncertainty on Graphs](https://arxiv.org/abs/2602.04574)
*Jonathan Klees,Tobias Riedlinger,Peter Stehr,Bennet Böddecker,Daniel Kondermann,Matthias Rottmann*

Main category: cs.LG

TL;DR: 本文提出了一种基于图扩散的概率性标签传播方法，能在仅用单个标注的情况下可靠估计标签的随机性和认知不确定性，显著降低高质量标注所需成本，并在数据为中心的图像分类基准上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 安全AI感知任务面临高质量标注数据缺乏的挑战，而现有标注和评估常忽略标签本身的随机性（aleatoric）和认知性（epistemic）不确定性；大规模众包多标注虽可估计不确定性但成本过高，亟需更高效的方法。

Method: 提出一种基于特征空间标签平滑假设的概率性标签传播方法，采用图扩散（graph-based diffusion）将单个标注在特征图上进行传播；理论上证明即使每样本标注数趋于零，该方法仍能给出一致的概率估计；并设计了可扩展实现。

Result: 实验表明，相比基线方法，该方法大幅减少达成目标标注质量所需的标注预算，在常见图像数据集及Data-Centric Image Classification基准上均取得显著性能提升，达到新SOTA。

Conclusion: 单标注+图扩散标签传播是一种高效、理论可靠且可扩展的不确定性建模方法，为数据高效、安全AI感知系统提供了新范式。

Abstract: Safe artificial intelligence for perception tasks remains a major challenge, partly due to the lack of data with high-quality labels. Annotations themselves are subject to aleatoric and epistemic uncertainty, which is typically ignored during annotation and evaluation. While crowdsourcing enables collecting multiple annotations per image to estimate these uncertainties, this approach is impractical at scale due to the required annotation effort. We introduce a probabilistic label spreading method that provides reliable estimates of aleatoric and epistemic uncertainty of labels. Assuming label smoothness over the feature space, we propagate single annotations using a graph-based diffusion method. We prove that label spreading yields consistent probability estimators even when the number of annotations per data point converges to zero. We present and analyze a scalable implementation of our method. Experimental results indicate that, compared to baselines, our approach substantially reduces the annotation budget required to achieve a desired label quality on common image datasets and achieves a new state of the art on the Data-Centric Image Classification benchmark.

</details>


### [333] [Stochastic Decision Horizons for Constrained Reinforcement Learning](https://arxiv.org/abs/2602.04599)
*Nikola Milosevic,Leonard Franz,Daniel Haeufle,Georg Martius,Nico Scherf,Pavel Kolev*

Main category: cs.LG

TL;DR: 本文提出了一种基于随机决策时限的‘控制即推理’（Control as Inference）新框架，用于求解约束马尔可夫决策过程（CMDPs），通过生存加权目标实现离策略学习兼容性，并设计两种违反语义（吸收终止与虚拟终止），在标准基准和高维肌肉骨骼控制任务中验证了其高效性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有CMDP方法多依赖加性代价约束与对偶变量，难以支持高效的离策略学习与大规模扩展。

Method: 提出基于随机决策时限的Control as Inference框架，引入状态-动作相关的继续概率，使约束违反自动衰减奖励贡献并缩短有效规划步长；定义吸收终止与虚拟终止两种违反语义，分别导出SAC/MPO风格的策略改进形式。

Result: 在标准CMDP基准上取得更优的样本效率与回报-违反权衡；VT-MPO成功扩展至高维musculoskeletal Hyfydy控制任务。

Conclusion: 该生存加权建模方式为CMDPs提供了更自然、可扩展且离策略兼容的新范式，虚拟终止语义尤其适合高维复杂控制场景。

Abstract: Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.

</details>


### [334] [Jacobian Regularization Stabilizes Long-Term Integration of Neural Differential Equations](https://arxiv.org/abs/2602.04608)
*Maya Janvier,Julien Salomon,Etienne Meunier*

Main category: cs.LG

TL;DR: 本文提出了一种通过正则化神经微分方程（NDE）模型雅可比矩阵的方向导数来提升其长期积分稳定性的方法，适用于短训练轨迹场景，并在常微分与偏微分方程系统中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 混合模型和神经微分方程（NDE）在物理系统建模中日益重要，但其长期积分常面临稳定性与精度问题；而基于展开轨迹的训练虽能缓解该问题，却因需迭代计算梯度而开销过大。

Method: 设计两种雅可比方向导数正则化方法：一是针对已知动力学的情形，直接推导动力学的方向导数；二是针对未知动力学的情形，采用有限差分近似方向导数。

Result: 两种方法在训练成本远低于长轨迹展开的前提下，显著提升了多个常微分与偏微分方程系统的长期仿真稳定性。

Conclusion: 所提正则化策略为在短训练数据下实现大规模系统NDE的稳定长期集成提供了可行且高效的新路径。

Abstract: Hybrid models and Neural Differential Equations (NDE) are getting increasingly important for the modeling of physical systems, however they often encounter stability and accuracy issues during long-term integration. Training on unrolled trajectories is known to limit these divergences but quickly becomes too expensive due to the need for computing gradients over an iterative process. In this paper, we demonstrate that regularizing the Jacobian of the NDE model via its directional derivatives during training stabilizes long-term integration in the challenging context of short training rollouts. We design two regularizations, one for the case of known dynamics where we can directly derive the directional derivatives of the dynamic and one for the case of unknown dynamics where they are approximated using finite differences. Both methods, while having a far lower cost compared to long rollouts during training, are successful in improving the stability of long-term simulations for several ordinary and partial differential equations, opening up the door to training NDE methods for long-term integration of large scale systems.

</details>


### [335] [Resilient Load Forecasting under Climate Change: Adaptive Conditional Neural Processes for Few-Shot Extreme Load Forecasting](https://arxiv.org/abs/2602.04609)
*Chenxi Hu,Yue Ma,Yifan Wu,Yunhe Hou*

Main category: cs.LG

TL;DR: 本文提出AdaCNP模型，用于极端天气下电力负荷的少样本概率预测，通过共享嵌入空间学习相似性并动态重加权历史信息，在真实电力数据上显著提升极端时段预测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 极端天气导致负荷曲线剧烈波动，而极端样本稀疏且不规则，使传统预测方法难以可靠建模和校准，易引发供电短缺或过载风险。

Method: AdaCNP是一种面向数据稀缺场景的概率预测模型，它在共享嵌入空间中学习相似性，对每个目标数据动态评估并重加权相关历史片段，支持少样本适配新极端模式，并直接输出预测分布。

Result: 在真实电力负荷数据上，AdaCNP相较最强基线将均方误差相对降低22%，且负对数似然最低，表明其概率预测更可靠、极端时段鲁棒性更强。

Conclusion: AdaCNP能有效缓解突变分布偏移与极端样本稀缺的双重挑战，为极端事件下的电力系统韧性运行提供更可信的负荷预测支持。

Abstract: Extreme weather can substantially change electricity consumption behavior, causing load curves to exhibit sharp spikes and pronounced volatility. If forecasts are inaccurate during those periods, power systems are more likely to face supply shortfalls or localized overloads, forcing emergency actions such as load shedding and increasing the risk of service disruptions and public-safety impacts. This problem is inherently difficult because extreme events can trigger abrupt regime shifts in load patterns, while relevant extreme samples are rare and irregular, making reliable learning and calibration challenging. We propose AdaCNP, a probabilistic forecasting model for data-scarce condition. AdaCNP learns similarity in a shared embedding space. For each target data, it evaluates how relevant each historical context segment is to the current condition and reweights the context information accordingly. This design highlights the most informative historical evidence even when extreme samples are rare. It enables few-shot adaptation to previously unseen extreme patterns. AdaCNP also produces predictive distributions for risk-aware decision-making without expensive fine-tuning on the target domain. We evaluate AdaCNP on real-world power-system load data and compare it against a range of representative baselines. The results show that AdaCNP is more robust during extreme periods, reducing the mean squared error by 22\% relative to the strongest baseline while achieving the lowest negative log-likelihood, indicating more reliable probabilistic outputs. These findings suggest that AdaCNP can effectively mitigate the combined impact of abrupt distribution shifts and scarce extreme samples, providing a more trustworthy forecasting for resilient power system operation under extreme events.

</details>


### [336] [QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning](https://arxiv.org/abs/2602.04620)
*Doyeon Lee,Eunyi Lyou,Hyunsoo Cho,Sookyung Kim,Joonseok Lee,Jaemoo Choi*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于强化学习的LLM微调算法QUATRO，通过精确的信任区域优化来替代启发式近似，从而实现更稳定、可解释且熵可控的训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO风格的RL微调算法依赖启发式信任区域近似，导致优化行为脆弱，难以有效约束重要性比率超出裁剪范围的样本。

Method: 提出Query-Adaptive Trust-Region policy Optimization (QUATRO)，通过原理性的优化直接施加信任区域约束，导出具有明确解释性和熵控制能力的目标函数，并自然引入稳定化项。

Result: 在多个数学推理基准上验证，QUATRO在策略陈旧度升高和学习率激进时仍保持训练稳定，并全程维持良好可控的熵水平。

Conclusion: QUATRO提供了一种更鲁棒、可解释且易于调控的RL-based LLM微调框架，克服了现有方法在信任区域近似上的局限性。

Abstract: GRPO-style reinforcement learning (RL)-based LLM fine-tuning algorithms have recently gained popularity. Relying on heuristic trust-region approximations, however, they can lead to brittle optimization behavior, as global importance-ratio clipping and group-wise normalization fail to regulate samples whose importance ratios fall outside the clipping range. We propose Query-Adaptive Trust-Region policy Optimization (QUATRO), which directly enforces trust-region constraints through a principled optimization. This yields a clear and interpretable objective that enables explicit control over policy updates and stable, entropy-controlled optimization, with a stabilizer terms arising intrinsically from the exact trust-region formulation. Empirically verified on diverse mathematical reasoning benchmarks, QUATRO shows stable training under increased policy staleness and aggressive learning rates, maintaining well-controlled entropy throughout training.

</details>


### [337] [RIGA-Fold: A General Framework for Protein Inverse Folding via Recurrent Interaction and Geometric Awareness](https://arxiv.org/abs/2602.04637)
*Sisi Yuan,Jiehuang Chen,Junchuang Cai,Dong Xu,Xueliang Li,Zexuan Zhu,Junkai Ji*

Main category: cs.LG

TL;DR: 本文提出了RIGA-Fold框架，通过几何注意力更新模块和全局上下文桥接机制解决蛋白质逆折叠中长程依赖建模与误差累积问题；进一步提出RIGA-Fold*，融合可训练几何特征与冻结的ESM进化先验，并采用‘预测-循环-精炼’策略提升序列恢复率与结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的蛋白质逆折叠方法受限于感受野窄（难以建模长程依赖）和单次推理导致误差累积。

Method: 提出RIGA-Fold：微尺度引入SE(3)-不变的几何注意力更新（GAU）模块，宏尺度设计基于注意力的全局上下文桥；进一步提出RIGA-Fold*，结合可训练几何特征与冻结ESM-2/ESM-IF进化表征，并采用双流架构；引入生物启发的‘预测-循环-精炼’迭代去噪策略。

Result: 在CATH 4.2、TS50、TS500基准上，RIGA-Fold表现具竞争力，RIGA-Fold*显著超越SOTA方法，在序列恢复率和结构一致性两方面均取得更优结果。

Conclusion: 几何感知与迭代优化协同设计能有效提升蛋白质逆折叠性能，RIGA-Fold*验证了融合几何先验与进化先验的有效性。

Abstract: Protein inverse folding, the task of predicting amino acid sequences for desired structures, is pivotal for de novo protein design. However, existing GNN-based methods typically suffer from restricted receptive fields that miss long-range dependencies and a "single-pass" inference paradigm that leads to error accumulation. To address these bottlenecks, we propose RIGA-Fold, a framework that synergizes Recurrent Interaction with Geometric Awareness. At the micro-level, we introduce a Geometric Attention Update (GAU) module where edge features explicitly serve as attention keys, ensuring strictly SE(3)-invariant local encoding. At the macro-level, we design an attention-based Global Context Bridge that acts as a soft gating mechanism to dynamically inject global topological information. Furthermore, to bridge the gap between structural and sequence modalities, we introduce an enhanced variant, RIGA-Fold*, which integrates trainable geometric features with frozen evolutionary priors from ESM-2 and ESM-IF via a dual-stream architecture. Finally, a biologically inspired ``predict-recycle-refine'' strategy is implemented to iteratively denoise sequence distributions. Extensive experiments on CATH 4.2, TS50, and TS500 benchmarks demonstrate that our geometric framework is highly competitive, while RIGA-Fold* significantly outperforms state-of-the-art baselines in both sequence recovery and structural consistency.

</details>


### [338] [MTS-JEPA: Multi-Resolution Joint-Embedding Predictive Architecture for Time-Series Anomaly Prediction](https://arxiv.org/abs/2602.04643)
*Yanan He,Yunshi Wen,Xin Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: 本文提出MTS-JEPA，一种面向多变量时间序列异常预测的新型JEPA架构，通过多分辨率预测目标与软码本瓶颈机制，解耦瞬时冲击与长期趋势、建模离散状态转移，并提升训练稳定性与早期预警性能。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA方法在多变量时间序列异常预测中存在表征坍缩和难以捕捉跨时间尺度前兆信号的问题。

Method: 提出MTS-JEPA架构，融合多分辨率预测目标与软码本瓶颈，显式解耦瞬时扰动与长期趋势，并利用码本建模离散系统状态转移；该码本同时起到内在正则化作用以保障优化稳定。

Result: 在标准基准上验证了该方法能有效避免退化解，并在早期预警协议下达到最优性能。

Conclusion: MTS-JEPA通过结构化表征学习与正则化设计，显著提升了多变量时间序列异常的可解释性预测与早期预警能力。

Abstract: Multivariate time series underpin modern critical infrastructure, making the prediction of anomalies a vital necessity for proactive risk mitigation. While Joint-Embedding Predictive Architectures (JEPA) offer a promising framework for modeling the latent evolution of these systems, their application is hindered by representation collapse and an inability to capture precursor signals across varying temporal scales. To address these limitations, we propose MTS-JEPA, a specialized architecture that integrates a multi-resolution predictive objective with a soft codebook bottleneck. This design explicitly decouples transient shocks from long-term trends, and utilizes the codebook to capture discrete regime transitions. Notably, we find this constraint also acts as an intrinsic regularizer to ensure optimization stability. Empirical evaluations on standard benchmarks confirm that our approach effectively prevents degenerate solutions and achieves state-of-the-art performance under the early-warning protocol.

</details>


### [339] [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)
*Dipan Maity*

Main category: cs.LG

TL;DR: 本文提出SAFE（Stable Alignment Finetuning with Entropy-aware control），一种面向大语言模型RLHF任务的新型纯在线策略actor-critic算法，通过双软最小值critic、熵门控KL正则化与PID自适应阈值控制，显著提升训练稳定性与奖励表现，优于PPO。


<details>
  <summary>Details</summary>
Motivation: 现有主流RLHF方法PPO虽经验效果好，但动机启发式、KL约束处理随意，易出现奖励振荡、熵崩溃、价值函数漂移和策略突变等问题，需频繁重启和大量调参。

Method: SAFE结合Double Soft-Min Critic实现悲观价值估计，并构建多层稳定化框架：包括熵门控KL调节（区分高/低熵状态）和PID控制的自适应KL阈值，动态响应奖励变化速度；摒弃PPO对称KL惩罚。

Result: 在3B参数模型上实验显示，SAFE相较PPO提升平均训练奖励5.15%（0.725 vs 0.689），几乎无奖励崩溃，KL控制更优，计算开销小，具备可解释性与生产部署适用性。

Conclusion: SAFE为LM-RLHF提供了一种更稳定、鲁棒、高效且易于部署的替代方案，解决了PPO在实际应用中的关键缺陷。

Abstract: Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collapse, value function drift, and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM-RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation, and PID-controlled adaptive thresholds. Unlike standard PPO's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE

</details>


### [340] [Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design](https://arxiv.org/abs/2602.04663)
*Jaemoo Choi,Yuchen Zhu,Wei Guo,Petr Molodyk,Bo Yuan,Jinbin Bai,Yi Xin,Molei Tao,Yongxin Chen*

Main category: cs.LG

TL;DR: 本文系统分析了强化学习在扩散模型中的设计空间，发现基于ELBO的似然估计器（仅用最终生成样本计算）是实现高效稳定RL优化的关键因素，显著优于策略梯度损失函数的选择；该方法在SD 3.5 Medium上将GenEval分数从0.24提升至0.95，训练效率达SOTA方法的2倍以上。


<details>
  <summary>Details</summary>
Motivation: 扩散模型似然不可解，阻碍主流策略梯度法直接应用；现有工作缺乏对似然估计如何影响整体算法性能的系统性研究。

Method: 解耦分析三个因素：策略梯度目标、似然估计器、rollout采样方案；提出并验证仅基于最终生成样本的ELBO似然估计器的有效性。

Result: 在多个奖励基准上验证一致性效果；GenEval分数从0.24提升至0.95，90 GPU小时内训练效率达FlowGRPO的4.6倍、DiffusionNFT的2倍，且无reward hacking。

Conclusion: ELBO-based似然估计器是扩散模型强化学习中起主导作用的设计要素，其重要性远超策略梯度损失函数的具体形式。

Abstract: Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type methods. Existing approaches primarily focus on crafting new objectives built on already heavily engineered LLM objectives, using ad hoc estimators for likelihood, without a thorough investigation into how such estimation affects overall algorithmic performance. In this work, we provide a systematic analysis of the RL design space by disentangling three factors: i) policy-gradient objectives, ii) likelihood estimators, and iii) rollout sampling schemes. We show that adopting an evidence lower bound (ELBO) based model likelihood estimator, computed only from the final generated sample, is the dominant factor enabling effective, efficient, and stable RL optimization, outweighing the impact of the specific policy-gradient loss functional. We validate our findings across multiple reward benchmarks using SD 3.5 Medium, and observe consistent trends across all tasks. Our method improves the GenEval score from 0.24 to 0.95 in 90 GPU hours, which is $4.6\times$ more efficient than FlowGRPO and $2\times$ more efficient than the SOTA method DiffusionNFT without reward hacking.

</details>


### [341] [Generalized Schrödinger Bridge on Graphs](https://arxiv.org/abs/2602.04675)
*Panagiotis Theodoropoulos,Juno Nam,Evangelos Theodorou,Jaemoo Choi*

Main category: cs.LG

TL;DR: 本文提出了一种名为GSBoG的新框架，用于在任意图上学习可执行的连续时间马尔可夫链策略，以解决图上传输问题中的拓扑与操作约束、泛化性差及可扩展性不足等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图传输方法受限于强假设、难以泛化至稀疏图结构，且随图规模和时间范围增大而性能下降，缺乏对实际应用中拓扑与运行成本约束的建模能力。

Method: 提出广义薛定谔桥图方法（GSBoG），基于似然优化学习轨迹级控制策略，满足端点边缘分布约束，并联合优化状态依赖的中间运行成本；采用可控连续时间马尔可夫链（CTMC）建模，避免稠密全局求解器以提升可扩展性。

Result: 在多个真实复杂图拓扑上的实验表明，GSBoG能稳定学习高精度、符合图结构的策略，并有效优化任务相关的中间状态成本。

Conclusion: GSBoG为通用图上的成本感知动态传输提供了可扩展、数据驱动的新范式，拓展了图运输方法的应用边界。

Abstract: Transportation on graphs is a fundamental challenge across many domains, where decisions must respect topological and operational constraints. Despite the need for actionable policies, existing graph-transport methods lack this expressivity. They rely on restrictive assumptions, fail to generalize across sparse topologies, and scale poorly with graph size and time horizon. To address these issues, we introduce Generalized Schrödinger Bridge on Graphs (GSBoG), a novel scalable data-driven framework for learning executable controlled continuous-time Markov chain (CTMC) policies on arbitrary graphs under state cost augmented dynamics. Notably, GSBoG learns trajectory-level policies, avoiding dense global solvers and thereby enhancing scalability. This is achieved via a likelihood optimization approach, satisfying the endpoint marginals, while simultaneously optimizing intermediate behavior under state-dependent running costs. Extensive experimentation on challenging real-world graph topologies shows that GSBoG reliably learns accurate, topology-respecting policies while optimizing application-specific intermediate state costs, highlighting its broad applicability and paving new avenues for cost-aware dynamical transport on general graphs.

</details>


### [342] [REDistill: Robust Estimator Distillation for Balancing Robustness and Efficiency](https://arxiv.org/abs/2602.04677)
*Ondrej Tybl,Lukas Neumann*

Main category: cs.LG

TL;DR: 本文提出了一种基于鲁棒统计的新型知识蒸馏框架REDistill，通过引入幂散度损失替代传统的KL散度，自适应地抑制教师模型中不可靠的软标签，从而提升学生模型性能，且无需针对特定模型调参。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法假设教师模型预测可靠，但实际中教师预测常存在噪声或过度自信问题；现有校正方法依赖启发式规则和大量超参调优，泛化能力差。

Method: 提出REDistill框架，用幂散度损失（Power Divergence）替代KL散度作为蒸馏目标，该损失能自适应降低不可靠教师输出的权重，同时保留有用logit关系；仅需教师logits，无需额外模块或显著计算开销。

Result: 在CIFAR-100和ImageNet-1k上大量实验表明，REDistill在多种师生架构下均稳定提升学生准确率，且无需模型特异性超参调优。

Conclusion: REDistill是一种简洁、原理清晰、通用性强的知识蒸馏方法，为处理教师噪声提供了统一可解释的鲁棒解决方案，并展现出优异的跨架构泛化能力。

Abstract: Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student by aligning their predictive distributions. However, conventional KD formulations - typically based on Kullback-Leibler divergence - assume that the teacher provides reliable soft targets. In practice, teacher predictions are often noisy or overconfident, and existing correction-based approaches rely on ad-hoc heuristics and extensive hyper-parameter tuning, which hinders generalization. We introduce REDistill (Robust Estimator Distillation), a simple yet principled framework grounded in robust statistics. REDistill replaces the standard KD objective with a power divergence loss, a generalization of KL divergence that adaptively downweights unreliable teacher output while preserving informative logit relationships. This formulation provides a unified and interpretable treatment of teacher noise, requires only logits, integrates seamlessly into existing KD pipelines, and incurs negligible computational overhead. Extensive experiments on CIFAR-100 and ImageNet-1k demonstrate that REDistill consistently improves student accuracy in diverse teacher-student architectures. Remarkably, it achieves these gains without model-specific hyper-parameter tuning, underscoring its robustness and strong generalization to unseen teacher-student pairs.

</details>


### [343] [Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting](https://arxiv.org/abs/2602.04678)
*Zhen Zhou,Zhirui Wang,Qi Hong,Yunyang Shi,Ziyuan Gu,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 本文提出了一种多专家学习分布标签（LDL）框架，通过混合专家架构实现高精度时间序列预测与可解释的不确定性量化，包含Multi-Expert LDL和Pattern-Aware LDL-MoE两种方法，在M5销售数据上验证了其优越性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中时间序列预测既需高精度又需可解释的不确定性量化，而传统点预测缺乏不确定性建模能力，现有概率方法难以兼顾效率与可解释性。

Method: 提出两种基于分布学习的混合专家（MoE）方法：(1) Multi-Expert LDL，利用多个参数各异的专家捕获多样化时序模式；(2) Pattern-Aware LDL-MoE，通过专用子专家显式分解趋势、季节性、变点和波动率等可解释成分；均采用最大均值差异（MMD）进行分布拟合与不确定性量化。

Result: 在M5聚合销售数据上，Continuous Multi-Expert LDL取得最佳整体预测性能，Pattern-Aware LDL-MoE则提供更优的组件级可解释性；二者均显著优于基线方法。

Conclusion: 所提LDL框架成功在预测精度与模型可解释性之间取得平衡，适用于对性能与可操作洞察均有要求的实际预测场景。

Abstract: Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance computational efficiency with interpretability. We propose a novel Multi-Expert Learning Distributional Labels (LDL) framework that addresses these challenges through mixture-of-experts architectures with distributional learning capabilities. Our approach introduces two complementary methods: (1) Multi-Expert LDL, which employs multiple experts with different learned parameters to capture diverse temporal patterns, and (2) Pattern-Aware LDL-MoE, which explicitly decomposes time series into interpretable components (trend, seasonality, changepoints, volatility) through specialized sub-experts. Both frameworks extend traditional point prediction to distributional learning, enabling rich uncertainty quantification through Maximum Mean Discrepancy (MMD). We evaluate our methods on aggregated sales data derived from the M5 dataset, demonstrating superior performance compared to baseline approaches. The continuous Multi-Expert LDL achieves the best overall performance, while the Pattern-Aware LDL-MoE provides enhanced interpretability through component-wise analysis. Our frameworks successfully balance predictive accuracy with interpretability, making them suitable for real-world forecasting applications where both performance and actionable insights are crucial.

</details>


### [344] [Static and auto-regressive neural emulation of phytoplankton biomass dynamics from physical predictors in the global ocean](https://arxiv.org/abs/2602.04689)
*Mahima Lakra,Ronan Fablet,Lucas Drumetz,Etienne Pauthenet,Elodie Martinez*

Main category: cs.LG

TL;DR: 本研究探索了深度学习模型（特别是UNet）在基于卫星和环境数据预测全球海洋浮游植物生物量时空分布中的应用，结果表明UNet优于CNN、ConvLSTM等模型，其自回归版本可实现长达5个月的短期预测。


<details>
  <summary>Details</summary>
Motivation: 准确模拟浮游植物动态对海洋生态和全球生物地球化学循环至关重要，但现有数值模型受限于参数化不足、观测数据稀疏及海洋过程复杂性。

Method: 测试多种深度学习架构（如CNN、ConvLSTM、4CastNet和UNet），评估其基于卫星遥感与环境变量预测浮游植物生物量的能力；进一步构建自回归UNet模型以提升时序预测性能。

Result: UNet在重现浮游植物季节与年际变化方面表现最优；使用1–2个月环境数据输入效果最佳，但低估低频变化振幅；自回归UNet适用于5个月内短期预测，长期预测性能下降。

Conclusion: 结合海洋物理因子与深度学习可有效重建并短期预测浮游植物动态，为海洋健康监测与生态系统管理提供新工具，尤其在气候变化背景下具有重要应用潜力。

Abstract: Phytoplankton is the basis of marine food webs, driving both ecological processes and global biogeochemical cycles. Despite their ecological and climatic significance, accurately simulating phytoplankton dynamics remains a major challenge for biogeochemical numerical models due to limited parameterizations, sparse observational data, and the complexity of oceanic processes. Here, we explore how deep learning models can be used to address these limitations predicting the spatio-temporal distribution of phytoplankton biomass in the global ocean based on satellite observations and environmental conditions. First, we investigate several deep learning architectures. Among the tested models, the UNet architecture stands out for its ability to reproduce the seasonal and interannual patterns of phytoplankton biomass more accurately than other models like CNNs, ConvLSTM, and 4CastNet. When using one to two months of environmental data as input, UNet performs better, although it tends to underestimate the amplitude of low-frequency changes in phytoplankton biomass. Thus, to improve predictions over time, an auto-regressive version of UNet was also tested, where the model uses its own previous predictions to forecast future conditions. This approach works well for short-term forecasts (up to five months), though its performance decreases for longer time scales. Overall, our study shows that combining ocean physical predictors with deep learning allows for reconstruction and short-term prediction of phytoplankton dynamics. These models could become powerful tools for monitoring ocean health and supporting marine ecosystem management, especially in the context of climate change.

</details>


### [345] [Towards Understanding and Avoiding Limitations of Convolutions on Graphs](https://arxiv.org/abs/2602.04709)
*Andreas Roth*

Main category: cs.LG

TL;DR: 本文深入分析了消息传递神经网络（MPNNs）的理论局限，提出共享组件放大（SCA）和组件主导（CD）两个关键性质，并指出其导致节点表征的秩坍缩（推广了过平滑现象）；为解决SCA，提出多关系分裂（MRS）框架和MIMO-GC/LMGC图卷积方法；为缓解CD，基于个性化PageRank设计支持无限迭代且保留初始特征的MPNN变体。


<details>
  <summary>Details</summary>
Motivation: MPNNs在现实应用中效果受限，现有研究对其理论基础理解不足，导致问题识别碎片化，亟需系统性理论分析以统一认识并指导改进。

Method: 通过理论分析识别SCA与CD性质及其引发的秩坍缩；提出MRS框架将单图MPNN扩展至多关系建模；设计MIMO-GC及其局部化版本LMGC实现多计算图卷积；借鉴个性化PageRank构造支持无限迭代且保持初始特征的MPNN变体。

Result: 揭示了MPNNs中SCA与CD现象及其导致的秩坍缩；MRS、MIMO-GC/LMGC有效缓解SCA；基于个性化PageRank的MPNN变体成功克服CD并支持无限消息传递；整体提升了MPNN的理论可解释性与性能。

Conclusion: MPNNs的性能瓶颈源于内在结构性质（SCA与CD），而非单纯架构或训练问题；通过分解过平滑为更细粒度机制并针对性设计新框架，可显著提升模型表达能力与鲁棒性，为图神经网络理论发展提供新范式。

Abstract: While message-passing neural networks (MPNNs) have shown promising results, their real-world impact remains limited. Although various limitations have been identified, their theoretical foundations remain poorly understood, leading to fragmented research efforts. In this thesis, we provide an in-depth theoretical analysis and identify several key properties limiting the performance of MPNNs. Building on these findings, we propose several frameworks that address these shortcomings. We identify two properties exhibited by many MPNNs: shared component amplification (SCA), where each message-passing iteration amplifies the same components across all feature channels, and component dominance (CD), where a single component gets increasingly amplified as more message-passing steps are applied. These properties lead to the observable phenomenon of rank collapse of node representations, which generalizes the established over-smoothing phenomenon. By generalizing and decomposing over-smoothing, we enable a deeper understanding of MPNNs, more targeted solutions, and more precise communication within the field. To avoid SCA, we show that utilizing multiple computational graphs or edge relations is necessary. Our multi-relational split (MRS) framework transforms any existing MPNN into one that leverages multiple edge relations. Additionally, we introduce the spectral graph convolution for multiple feature channels (MIMO-GC), which naturally uses multiple computational graphs. A localized variant, LMGC, approximates the MIMO-GC while inheriting its beneficial properties. To address CD, we demonstrate a close connection between MPNNs and the PageRank algorithm. Based on personalized PageRank, we propose a variant of MPNNs that allows for infinitely many message-passing iterations, while preserving initial node features. Collectively, these results deepen the theoretical understanding of MPNNs.

</details>


### [346] [Bounded-Abstention Multi-horizon Time-series Forecasting](https://arxiv.org/abs/2602.04714)
*Luca Stradiotti,Laurens Devos,Anna Monreale,Jesse Davis,Andrea Pugnana*

Main category: cs.LG

TL;DR: 本文提出了多时间步长预测中的主动拒绝预测（abstention）框架，解决了现有方法无法处理多时间步长预测相关性和结构化特性的问题，并设计了三种自然的拒绝策略，理论推导最优策略并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 多时间步长预测在医疗、金融等领域至关重要，错误预测代价高；现有拒绝预测方法仅适用于单步预测，未考虑多步预测的结构化和相关性。

Method: 形式化定义多时间步长预测下的学习与拒绝问题，提出三种自然的拒绝方式，理论分析每种情形下的最优拒绝策略，并设计可实现算法。

Result: 在24个数据集上的实验表明，所提算法显著优于现有基线方法。

Conclusion: 多时间步长预测中的拒绝机制需考虑其结构特性，本文提出的结构化拒绝框架及对应算法能有效提升预测可靠性与实用性。

Abstract: Multi-horizon time-series forecasting involves simultaneously making predictions for a consecutive sequence of subsequent time steps. This task arises in many application domains, such as healthcare and finance, where mispredictions can have a high cost and reduce trust. The learning with abstention framework tackles these problems by allowing a model to abstain from offering a prediction when it is at an elevated risk of making a misprediction. Unfortunately, existing abstention strategies are ill-suited for the multi-horizon setting: they target problems where a model offers a single prediction for each instance. Hence, they ignore the structured and correlated nature of the predictions offered by a multi-horizon forecaster. We formalize the problem of learning with abstention for multi-horizon forecasting setting and show that its structured nature admits a richer set of abstention problems. Concretely, we propose three natural notions of how a model could abstain for multi-horizon forecasting. We theoretically analyze each problem to derive the optimal abstention strategy and propose an algorithm that implements it. Extensive evaluation on 24 datasets shows that our proposed algorithms significantly outperforms existing baselines.

</details>


### [347] [Generative Modeling via Drifting](https://arxiv.org/abs/2602.04770)
*Mingyang Deng,He Li,Tianhong Li,Yilun Du,Kaiming He*

Main category: cs.LG

TL;DR: 本文提出了一种名为Drifting Models的新生成建模范式，通过引入漂移场在训练过程中动态演化推前分布，实现自然的一次性（one-step）生成，并在ImageNet 256×256上取得SOTA FID结果。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型（如扩散模型、流模型）依赖多步迭代推理，效率低；亟需高质量、高效率的一次性生成方法。

Method: 提出Drifting Models，定义一个漂移场来控制样本运动，使推前分布在训练中逐步演化至与数据分布平衡；优化目标由神经网络优化器驱动分布演化。

Result: 在ImageNet 256×256上，一阶段生成器在潜在空间FID为1.54、像素空间FID为1.61，达当前最优水平。

Conclusion: Drifting Models为高质量、一次性生成提供了新范式，有望推动高效生成建模的发展。

Abstract: Generative modeling can be formulated as learning a mapping f such that its pushforward distribution matches the data distribution. The pushforward behavior can be carried out iteratively at inference time, for example in diffusion and flow-based models. In this paper, we propose a new paradigm called Drifting Models, which evolve the pushforward distribution during training and naturally admit one-step inference. We introduce a drifting field that governs the sample movement and achieves equilibrium when the distributions match. This leads to a training objective that allows the neural network optimizer to evolve the distribution. In experiments, our one-step generator achieves state-of-the-art results on ImageNet at 256 x 256 resolution, with an FID of 1.54 in latent space and 1.61 in pixel space. We hope that our work opens up new opportunities for high-quality one-step generation.

</details>


### [348] [It's not a Lottery, it's a Race: Understanding How Gradient Descent Adapts the Network's Capacity to the Task](https://arxiv.org/abs/2602.04832)
*Hannah Pinson*

Main category: cs.LG

TL;DR: 本文研究了梯度下降如何在训练过程中降低神经网络的理论容量，使其适应具体任务，并提出了三个动态原理（相互对齐、解锁和竞速）来解释这一现象及其与‘彩票假说’的关系。


<details>
  <summary>Details</summary>
Motivation: 神经网络的理论理解落后于其实际成功，特别是训练过程中理论容量如何被降低到适合任务的有效容量尚不清楚。

Method: 通过分析单隐层ReLU网络中单个神经元的学习动力学，识别出三个动态原理：相互对齐、解锁和竞速。

Result: 揭示了梯度下降通过三个动态原理实现容量降低的机制，并解释了‘彩票假说’中某些神经元因初始条件有利而获得更高权重范数的原因。

Conclusion: 梯度下降通过相互对齐、解锁和竞速等动态过程，使神经网络在训练中自发降低有效容量，从而提升泛化能力；该机制也为‘彩票假说’提供了理论支持。

Abstract: Our theoretical understanding of neural networks is lagging behind their empirical success. One of the important unexplained phenomena is why and how, during the process of training with gradient descent, the theoretical capacity of neural networks is reduced to an effective capacity that fits the task. We here investigate the mechanism by which gradient descent achieves this through analyzing the learning dynamics at the level of individual neurons in single hidden layer ReLU networks. We identify three dynamical principles -- mutual alignment, unlocking and racing -- that together explain why we can often successfully reduce capacity after training through the merging of equivalent neurons or the pruning of low norm weights. We specifically explain the mechanism behind the lottery ticket conjecture, or why the specific, beneficial initial conditions of some neurons lead them to obtain higher weight norms.

</details>


### [349] [Benchmarking and Enhancing PPG-Based Cuffless Blood Pressure Estimation Methods](https://arxiv.org/abs/2602.04725)
*Neville Mathew,Yidan Shen,Renjie Hu,Maham Rahimi,George Zouridakis*

Main category: cs.LG

TL;DR: 本文构建了一个标准化的PPG血压评估基准数据集NBPDB，并系统评测了多种PPG血压估计算法，发现其在严格生理控制条件下均未达AAMI/ISO临床标准；通过引入年龄、性别、BMI等人口统计学信息改进模型（如MInception），显著提升精度，使SBP和DBP误差分别降至4.75和2.90 mmHg，接近临床可接受水平。


<details>
  <summary>Details</summary>
Motivation: 现有PPG血压估计算法在临床标准（AAMI/ISO 81060-2）下表现不稳定，且缺乏生理条件受控、高质量、可复现的公开基准数据集，制约公平比较与临床转化。

Method: 构建标准化基准子集NBPDB（源自MIMIC-III和VitalDB，含101,453段高质量PPG信号，来自1,103名健康成人）；系统评测多个SOTA PPG血压模型；在各模型中融合年龄、性别、BMI等人口统计学特征作为额外输入以提升性能。

Result: 所有原始模型均未满足AAMI/ISO标准（MAE<5 mmHg且SD<8 mmHg）；加入人口统计学特征后，MInception模型SBP和DBP的MAE分别降至4.75 mmHg和2.90 mmHg，首次逼近该标准。

Conclusion: 在标准化生理条件下，当前PPG血压估计模型尚不具备临床实用性；融入基本人口统计学信息是提升其准确性与生理合理性的有效且必要策略。

Abstract: Cuffless blood pressure screening based on easily acquired photoplethysmography (PPG) signals offers a practical pathway toward scalable cardiovascular health assessment. Despite rapid progress, existing PPG-based blood pressure estimation models have not consistently achieved the established clinical numerical limits such as AAMI/ISO 81060-2, and prior evaluations often lack the rigorous experimental controls necessary for valid clinical assessment. Moreover, the publicly available datasets commonly used are heterogeneous and lack physiologically controlled conditions for fair benchmarking. To enable fair benchmarking under physiologically controlled conditions, we created a standardized benchmarking subset NBPDB comprising 101,453 high-quality PPG segments from 1,103 healthy adults, derived from MIMIC-III and VitalDB. Using this dataset, we systematically benchmarked several state-of-the-art PPG-based models. The results showed that none of the evaluated models met the AAMI/ISO 81060-2 accuracy requirements (mean error $<$ 5 mmHg and standard deviation $<$ 8 mmHg). To improve model accuracy, we modified these models and added patient demographic data such as age, sex, and body mass index as additional inputs. Our modifications consistently improved performance across all models. In particular, the MInception model reduced error by 23\% after adding the demographic data and yielded mean absolute errors of 4.75 mmHg (SBP) and 2.90 mmHg (DBP), achieves accuracy comparable to the numerical limits defined by AAMI/ISO accuracy standards. Our results show that existing PPG-based BP estimation models lack clinical practicality under standardized conditions, while incorporating demographic information markedly improves their accuracy and physiological validity.

</details>


### [350] [DMFlow: Disordered Materials Generation by Flow Matching](https://arxiv.org/abs/2602.04734)
*Liming Wu,Rui Jiao,Qi Li,Mingze Li,Songyou Li,Shifeng Jin,Wenbing Huang*

Main category: cs.LG

TL;DR: 本文提出了DMFlow，一种专为无序晶体设计的生成框架，通过统一表示有序、取代无序和位置无序晶体，并采用黎曼流匹配与球面重参数化确保物理有效的无序权重，结合具有物理对称性的图神经网络进行向量场学习，最终通过两阶段离散化生成多热原子分配。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型主要集中于完全有序晶体，忽略了重要的无序材料类别，因此需要一种能有效建模无序晶体的生成方法。

Method: 提出DMFlow框架：1）统一表示有序、取代无序（SD）和位置无序（PD）晶体；2）采用黎曼流匹配与球面重参数化保证无序权重在概率单纯形上；3）设计融合物理对称性与专用消息传递机制的图神经网络学习向量场；4）两阶段离散化生成多热原子分配。

Result: 在晶体结构预测（CSP）和从头生成（DNG）任务中，DMFlow显著优于适配自有序晶体生成的最先进基线模型；并发布了包含SD、PD及混合结构的基准数据集。

Conclusion: DMFlow为无序材料的AI驱动发现提供了坚实基础，填补了生成模型在无序材料建模方面的空白。

Abstract: The design of materials with tailored properties is crucial for technological progress. However, most deep generative models focus exclusively on perfectly ordered crystals, neglecting the important class of disordered materials. To address this gap, we introduce DMFlow, a generative framework specifically designed for disordered crystals. Our approach introduces a unified representation for ordered, Substitutionally Disordered (SD), and Positionally Disordered (PD) crystals, and employs a flow matching model to jointly generate all structural components. A key innovation is a Riemannian flow matching framework with spherical reparameterization, which ensures physically valid disorder weights on the probability simplex. The vector field is learned by a novel Graph Neural Network (GNN) that incorporates physical symmetries and a specialized message-passing scheme. Finally, a two-stage discretization procedure converts the continuous weights into multi-hot atomic assignments. To support research in this area, we release a benchmark containing SD, PD, and mixed structures curated from the Crystallography Open Database. Experiments on Crystal Structure Prediction (CSP) and De Novo Generation (DNG) tasks demonstrate that DMFlow significantly outperforms state-of-the-art baselines adapted from ordered crystal generation. We hope our work provides a foundation for the AI-driven discovery of disordered materials.

</details>


### [351] [Rationality Measurement and Theory for Reinforcement Learning Agents](https://arxiv.org/abs/2602.04737)
*Kejiang Qian,Amos Storkey,Fengxiang He*

Main category: cs.LG

TL;DR: 本文提出了一套用于强化学习智能体的理性度量方法与理论，定义了完美理性动作、期望理性风险及其训练与部署间的理性风险差距，并将差距分解为环境迁移导致的外在成分和算法泛化能力不足导致的内在成分，分别用Wasserstein距离和Rademacher复杂度进行上界分析，理论预测被实验验证。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体的理性（rationality）日益重要但缺乏系统研究，亟需可量化、可分析的理性度量框架以理解其行为稳健性与泛化能力。

Method: 定义完美理性动作（最大化真实价值函数梯度方向）、期望理性风险（策略动作与理性动作的价值偏差累积）及理性风险差距（训练与部署间差异），并将其分解为外在（环境迁移）与内在（算法泛化）两部分，分别用1-Wasserstein距离和经验Rademacher复杂度进行理论界定；结合正则化与域随机化等技术进行实证验证。

Result: 理论推导出理性风险差距的两个上界，并据此提出关于正则化（如层归一化、L2正则、权值归一化）和域随机化的益处及环境迁移危害的可检验假设；所有假设均在实验中得到一致验证。

Conclusion: 理性风险差距是刻画强化学习泛化失败的关键指标，其可分解性与可界定性为设计更鲁棒、更理性的智能体提供了理论基础与实用指导。

Abstract: This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.

</details>


### [352] [Decomposing Query-Key Feature Interactions Using Contrastive Covariances](https://arxiv.org/abs/2602.04752)
*Andrew Lee,Yonatan Belinkov,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TL;DR: 本文提出了一种对比协方差方法，用于分解查询-键（QK）空间，以揭示Transformer中注意力机制为何关注特定token，并识别出语义和绑定等可解释的低秩子空间。


<details>
  <summary>Details</summary>
Motivation: 缺乏理解Transformer中注意力头为何关注特定token的有效工具。

Method: 提出对比协方差方法，将查询-键（QK）空间分解为低秩、人类可解释的成分。

Result: 在简化设置中进行了理论与实证分析；在大语言模型中识别出语义类别与绑定等可解释的QK子空间；实现了注意力分数对所识别特征的归因。

Conclusion: QK空间中的特征对齐是产生高注意力分数的关键，该方法为理解注意力机制提供了可解释、可归因的新视角。

Abstract: Despite the central role of attention heads in Transformers, we lack tools to understand why a model attends to a particular token. To address this, we study the query-key (QK) space -- the bilinear joint embedding space between queries and keys. We present a contrastive covariance method to decompose the QK space into low-rank, human-interpretable components. It is when features in keys and queries align in these low-rank subspaces that high attention scores are produced. We first study our method both analytically and empirically in a simplified setting. We then apply our method to large language models to identify human-interpretable QK subspaces for categorical semantic features and binding features. Finally, we demonstrate how attention scores can be attributed to our identified features.

</details>


### [353] [A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates](https://arxiv.org/abs/2602.04757)
*Yuchen Ye,Zixuan Qi,Shixuan Li,Wei Qi,Yanpeng Cai,Chaoxia Yuan*

Main category: cs.LG

TL;DR: 本文提出了一种基于双阶段TransUNet的多源降水融合框架（DDL-MSPMF），通过结合六种多源降水产品与四种ERA5近地表物理变量，提升了中国区域日降水（尤其是极端降水）的估计精度与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有卫星和再分析降水产品存在空间异质性偏差、极端事件刻画能力不足等问题，限制了其水文应用价值。

Method: 构建双阶段深度学习框架：第一阶段用TransUNet分类器预测降水发生概率；第二阶段将该概率与所有输入变量一同输入TransUNet回归器，估算0.25°分辨率日降水总量；引入SHAP进行可解释性分析，并在多个基准数据集上开展对比评估。

Result: 在2001–2020年中国区域评估中，DDL-MSPMF取得最优季节性能（R=0.75，RMSE=2.70 mm/day）；对>25 mm/day强降水的ETS评分普遍提升，并更好复现2021年郑州特大暴雨空间格局；在青藏高原使用TPHiPr独立验证亦表现稳健。

Conclusion: DDL-MSPMF是一种可扩展、可解释的降水融合新范式，显著增强对极端降水事件的监测与诊断能力，适用于数据稀缺区域。

Abstract: Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.

</details>


### [354] [Improved Dimension Dependence for Bandit Convex Optimization with Gradient Variations](https://arxiv.org/abs/2602.04761)
*Hang Yu,Yu-Hu Yan,Peng Zhao*

Main category: cs.LG

TL;DR: 本文研究了带梯度变化的Bandit凸优化（BCO）问题，改进了非连续梯度变化的分析，提升了凸与强凸函数下的维度依赖性，并拓展至单点反馈、动态/通用遗憾及带臂博弈等场景。


<details>
  <summary>Details</summary>
Motivation: 梯度变化在线学习在博弈论和优化中具有重要意义，但在带臂反馈（尤其是BCO）下研究不足，尤其缺乏对非连续梯度变化的精细刻画。

Method: 提出对非连续梯度变化的精细化分析方法，结合两点半径估计与问题依赖性分析，推广至单点线性优化、动态/通用遗憾及带臂博弈设置。

Result: 在两点半径BCO中改善了凸与强凸函数的维度依赖性；首次获得单点线性优化的梯度变化界；实现首个两点半径BCO的动态/通用遗憾界及带臂博弈中的快速收敛率。

Conclusion: 本文通过重构非连续梯度变化的分析框架，显著提升BCO中梯度变化驱动的自适应性能，并拓展其在多种挑战性在线学习任务中的适用性。

Abstract: Gradient-variation online learning has drawn increasing attention due to its deep connections to game theory, optimization, etc. It has been studied extensively in the full-information setting, but is underexplored with bandit feedback. In this work, we focus on gradient variation in Bandit Convex Optimization (BCO) with two-point feedback. By proposing a refined analysis on the non-consecutive gradient variation, a fundamental quantity in gradient variation with bandits, we improve the dimension dependence for both convex and strongly convex functions compared with the best known results (Chiang et al., 2013). Our improved analysis for the non-consecutive gradient variation also implies other favorable problem-dependent guarantees, such as gradient-variance and small-loss regrets. Beyond the two-point setup, we demonstrate the versatility of our technique by achieving the first gradient-variation bound for one-point bandit linear optimization over hyper-rectangular domains. Finally, we validate the effectiveness of our results in more challenging tasks such as dynamic/universal regret minimization and bandit games, establishing the first gradient-variation dynamic and universal regret bounds for two-point BCO and fast convergence rates in bandit games.

</details>


### [355] [Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763)
*Rui Liu,Pratap Tokekar,Ming Lin*

Main category: cs.LG

TL;DR: 本文提出了A2MAML方法，用于多智能体多模态系统中不确定性感知的模态级协同，通过建模模态特征的随机性、主动选择可靠智能体-模态对，并采用贝叶斯逆方差加权融合，在协作事故检测任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作框架通常在智能体层面推理、假设传感器同质化且隐式处理不确定性，难以应对传感器损坏等不确定性场景，鲁棒性不足。

Method: A2MAML将每个模态特征建模为带不确定性预测的随机估计，主动选择可靠的智能体-模态组合，并通过贝叶斯逆方差加权进行信息聚合，实现细粒度、支持异构模态可用性的模态级融合。

Result: 在连接自动驾驶场景下的协作事故检测任务中，A2MAML持续优于单智能体及各类协同基线方法，事故检测率最高提升18.7%。

Conclusion: A2MAML为多智能体多模态系统提供了不确定性感知、模态级协同的新范式，提升了系统在传感器异常下的鲁棒性与性能。

Abstract: Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.

</details>


### [356] [Billion-Scale Graph Foundation Models](https://arxiv.org/abs/2602.04768)
*Maya Bechler-Speicher,Yoel Gottlieb,Andrey Isakov,David Abensur,Ami Tavory,Daniel Haimovich,Ido Guy,Udi Weinsberg*

Main category: cs.LG

TL;DR: 本文提出了GraphBFF，首个面向任意异构、十亿级图数据的图基础模型（GFM）端到端构建方案，包含可扩展的GraphBFF Transformer架构、图神经缩放定律，并在十项真实下游任务中展现出卓越的零样本、少样本和探针性能。


<details>
  <summary>Details</summary>
Motivation: 将大语言/视觉模型的成功范式（大规模预训练+轻量微调）迁移到通用、真实世界的大规模图数据上面临巨大挑战，亟需可扩展、实用的图基础模型框架。

Method: 提出GraphBFF框架，核心是GraphBFF Transformer；建立首个通用图的神经缩放定律；提供面向十亿级图的数据批处理、预训练与微调方法论。

Result: 在10个未见过的真实下游任务（节点/链路分类与回归）上，14亿参数模型实现显著零样本、少样本及探针性能，最高提升31 PRAUC点。

Conclusion: GraphBFF是构建工业级图基础模型的首个可行且系统性方案，揭示了图缩放规律，同时指出了迈向实用化GFM的关键挑战与开放方向。

Abstract: Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.

</details>


### [357] [NeuroCanvas: VLLM-Powered Robust Seizure Detection by Reformulating Multichannel EEG as Image](https://arxiv.org/abs/2602.04769)
*Yan Chen,Jie Peng,Moajjem Hossain Chowdhury,Tianlong Chen,Yunmei Liu*

Main category: cs.LG

TL;DR: 本文提出NeuroCanvas框架，通过Entropy-guided Channel Selector（ECS）选择关键EEG通道，并用Canvas of Neuron Signal（CNS）将其转换为紧凑视觉表征，从而提升癫痫发作检测的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的EEG seizure检测方法面临多通道异质性和计算低效两大挑战：不同通道中癫痫相关信息差异大，且原始信号需编码为大量token导致推理开销高。

Method: 提出NeuroCanvas框架，包含两个模块：(i) Entropy-guided Channel Selector（ECS）基于信息熵筛选关键通道；(ii) Canvas of Neuron Signal（CNS）将选中的多通道EEG信号映射为结构化视觉表示（紧凑视觉token），以适配LLM并降低token数量。

Result: 在多个癫痫检测数据集上验证，F1分数提升20%，推理延迟降低88%。

Conclusion: NeuroCanvas是一种可扩展、高效、适用于临床实时癫痫检测的新范式，兼顾准确性与资源效率。

Abstract: Accurate and timely seizure detection from Electroencephalography (EEG) is critical for clinical intervention, yet manual review of long-term recordings is labor-intensive. Recent efforts to encode EEG signals into large language models (LLMs) show promise in handling neural signals across diverse patients, but two significant challenges remain: (1) multi-channel heterogeneity, as seizure-relevant information varies substantially across EEG channels, and (2) computing inefficiency, as the EEG signals need to be encoded into a massive number of tokens for the prediction. To address these issues, we draw the EEG signal and propose the novel NeuroCanvas framework. Specifically, NeuroCanvas consists of two modules: (i) The Entropy-guided Channel Selector (ECS) selects the seizure-relevant channels input to LLM and (ii) the following Canvas of Neuron Signal (CNS) converts selected multi-channel heterogeneous EEG signals into structured visual representations. The ECS module alleviates the multi-channel heterogeneity issue, and the CNS uses compact visual tokens to represent the EEG signals that improve the computing efficiency. We evaluate NeuroCanvas across multiple seizure detection datasets, demonstrating a significant improvement of $20\%$ in F1 score and reductions of $88\%$ in inference latency. These results highlight NeuroCanvas as a scalable and effective solution for real-time and resource-efficient seizure detection in clinical practice.The code will be released at https://github.com/Yanchen30247/seizure_detect.

</details>


### [358] [Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification](https://arxiv.org/abs/2602.04775)
*Yuqi Li,Matthew M. Engelhard*

Main category: cs.LG

TL;DR: 本文提出了一种面向区间预测的不确定性感知ROC框架，定义了AUC_L和AUC_U两个新指标，支持三区域ROC分解与选择性排序，并在类条件覆盖有效时为其提供理论最优AUC的上下界保证。


<details>
  <summary>Details</summary>
Motivation: 标准ROC和AUC仅适用于点预测，无法评估区间预测中不确定性对排序性能的影响，而高风险场景下需量化不确定性以支撑可靠决策。

Method: 构建不确定性感知ROC框架，引入AUC_L和AUC_U指标，实现ROC平面的三区域分解（正确/错误/不确定排序），支持基于区间重叠的排序拒绝机制，并在类条件覆盖假设下推导其对理论最优AUC的上下界性质。

Result: 理论证明AUC_L和AUC_U分别是理论最优AUC*的严格下界和上界；在多个真实基准数据集（采用Bootstrap区间）上的实验验证了框架的正确性与实用性。

Conclusion: 该框架为区间预测提供了首个形式化、可解释且具理论保障的排序评估工具，兼顾不确定性建模与判别可靠性优化，适用于各类区间构造方法。

Abstract: In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.

</details>


### [359] [Dynamical Regimes of Multimodal Diffusion Models](https://arxiv.org/abs/2602.04780)
*Emil Albrychiewicz,Andrés Franco Valiente,Li-Ching Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于耦合Ornstein-Uhlenbeck过程的耦合扩散模型理论框架，利用非平衡统计物理中的动力学相变理论，揭示多模态生成由特征模态的时间尺度谱系主导，并预测了‘同步间隙’现象；推导了对称与各向异性耦合下的物种形成与坍缩时间解析条件，指出耦合强度作为谱滤波器可调控生成的时间层级；实验验证支持该理论，并启发了面向模态特异性时间尺度的时变耦合调度策略。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型虽在高维数据合成上取得高保真度，但其多模态生成的理论机制尚不清楚。

Method: 构建基于耦合Ornstein-Uhlenbeck过程的理论框架，结合非平衡统计物理中的动力学相变理论，分析特征模态的时间尺度谱系、同步间隙、耦合强度对稳定性的影响，并通过MNIST上的扩散模型训练与精确得分采样器进行实验验证。

Result: 发现多模态生成由谱系化的交互时间尺度主导而非同时解析；预测并解释‘同步间隙’这一常见失同步伪影；给出避免不稳定对称破缺的耦合强度严格界限；证实耦合强度起谱滤波作用，可调控生成时间层级；实验支持理论预测。

Conclusion: 耦合扩散模型的多模态行为可由动力学相变与谱时间层级统一理解；耦合强度是关键可控参数，时变耦合调度有望替代经验式引导调优，提升生成质量与可控性。

Abstract: Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.

</details>


### [360] [Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation](https://arxiv.org/abs/2602.04785)
*Congjing Zhang,Ryan Feng Lin,Ruoxuan Bao,Shuai Huang*

Main category: cs.LG

TL;DR: 本文提出Team-then-Trim（T²）框架，利用多个大语言模型（LLMs）协同生成高质量合成表格数据，并通过三阶段质量控制流程提升数据质量，有效缓解类不平衡、选择偏差和低保真等问题。


<details>
  <summary>Details</summary>
Motivation: 表格数据在现实ML应用中至关重要，但高质量数据获取成本高、样本稀缺，导致类不平衡、选择偏差和低保真等关键缺陷。

Method: 提出T²框架：由领域知识引导的多个专用LLMs协作生成表格数据各组件（团队阶段），再经三阶段插件式数据质量控制（修剪阶段）。

Result: 在模拟与真实数据集上的实验表明，T²在生成高质量表格数据方面优于当前最优方法，能有效支持下游模型训练。

Conclusion: T²为数据稀缺场景下高质量合成表格数据生成提供了新范式，具有实际部署潜力。

Abstract: While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.

</details>


### [361] [Legendre Memory Unit with A Multi-Slice Compensation Model for Short-Term Wind Speed Forecasting Based on Wind Farm Cluster Data](https://arxiv.org/abs/2602.04782)
*Mumin Zhang,Haochen Zhang,Xin Zhi Khoo,Yilin Zhang,Nuo Chen,Ting Zhang,Junjie Tang*

Main category: cs.LG

TL;DR: 本文提出了一种名为WMF-CPK-MSLMU的集成模型，用于风电机群的短期风速预测。该模型结合加权均值滤波（WMF）、基于Kendall秩相关系数的补偿参数（CPK）和多切片Legendre记忆单元（MSLMU），充分利用风电机群数据的空间-时间相关性，实现了高精度、快速且鲁棒的预测。


<details>
  <summary>Details</summary>
Motivation: 随着风电场集群化并网增多，其短期风速预测对电力系统安全稳定运行至关重要；现有方法难以充分挖掘集群数据中的空间-时间相关性，导致预测精度、速度与鲁棒性不足。

Method: 提出WMF-CPK-MSLMU集成模型：1）用加权均值滤波（WMF）进行单风电场级去噪；2）创新性地将Legendre记忆单元（LMU）与基于Kendall秩相关系数的补偿参数（CPK）结合，构建多切片LMU（MSLMU）；3）整体架构包含数据预处理、预测与多切片补偿三大模块。

Result: 在多个风电场集群实测数据上的测试表明，所提WMF-CPK-MSLMU模型在短期风速预测任务中显著优于现有模型，具备更高精度、更快速度与更强鲁棒性。

Conclusion: WMF-CPK-MSLMU通过融合空间-时间建模、自适应补偿与结构化记忆机制，有效提升了风电场集群风速预测性能，为集群化风电并网调度提供了可靠技术支撑。

Abstract: With more wind farms clustered for integration, the short-term wind speed prediction of such wind farm clusters is critical for normal operation of power systems. This paper focuses on achieving accurate, fast, and robust wind speed prediction by full use of cluster data with spatial-temporal correlation. First, weighted mean filtering (WMF) is applied to denoise wind speed data at the single-farm level. The Legendre memory unit (LMU) is then innovatively applied for the wind speed prediction, in combination with the Compensating Parameter based on Kendall rank correlation coefficient (CPK) of wind farm cluster data, to construct the multi-slice LMU (MSLMU). Finally, an innovative ensemble model WMF-CPK-MSLMU is proposed herein, with three key blocks: data pre-processing, forecasting, and multi-slice compensation. Advantages include: 1) LMU jointly models linear and nonlinear dependencies among farms to capture spatial-temporal correlations through backpropagation; 2) MSLMU enhances forecasting by using CPK-derived weights instead of random initialization, allowing spatial correlations to fully activate hidden nodes across clustered wind farms.; 3) CPK adaptively weights the compensation model in MSLMU and complements missing data spatially, to facilitate the whole model highly accurate and robust. Test results on different wind farm clusters indicate the effectiveness and superiority of proposed ensemble model WMF-CPK-MSLMU in the short-term prediction of wind farm clusters compared to the existing models.

</details>


### [362] [From independent patches to coordinated attention: Controlling information flow in vision transformers](https://arxiv.org/abs/2602.04784)
*Kieran A. Murphy*

Main category: cs.LG

TL;DR: 本文通过在视觉Transformer的所有注意力机制写入残差流的路径上插入变分信息瓶颈，使注意力传递的信息成为显式、可测量的量，从而在不改变其他架构的情况下实现对模型内部通信的显式控制和分析。


<details>
  <summary>Details</summary>
Motivation: 希望将注意力机制中传递的信息显式化并量化，以增强视觉Transformer的可解释性和可控性，并探究全局视觉表征如何从局部块处理中涌现。

Method: 在视觉Transformer所有由注意力机制介导的残差流写入操作处插入变分信息瓶颈，引入显式信息成本，从而构建一个从独立块处理到完全全局注意力的可控连续谱。

Result: 在ImageNet-100上刻画了分类行为与信息路由随信息约束程度的变化规律；识别并分析了首批开始传输信息的注意力头，为理解全局表征形成机制提供了初步洞见；所得模型更易于进行机制分析和外部控制。

Conclusion: 引入信息瓶颈不仅实现了对Transformer内部信息流的显式调控，还提升了模型的可解释性与可控性，为理解视觉Transformer工作机制提供了新范式。

Abstract: We make the information transmitted by attention an explicit, measurable quantity in vision transformers. By inserting variational information bottlenecks on all attention-mediated writes to the residual stream -- without other architectural changes -- we train models with an explicit information cost and obtain a controllable spectrum from independent patch processing to fully expressive global attention. On ImageNet-100, we characterize how classification behavior and information routing evolve across this spectrum, and provide initial insights into how global visual representations emerge from local patch processing by analyzing the first attention heads that transmit information. By biasing learning toward solutions with constrained internal communication, our approach yields models that are more tractable for mechanistic analysis and more amenable to control.

</details>


### [363] [Beyond Rewards in Reinforcement Learning for Cyber Defence](https://arxiv.org/abs/2602.04809)
*Elizabeth Bates,Chris Hicks,Vasilios Mavroudis*

Main category: cs.LG

TL;DR: 本文研究了不同奖励函数（稀疏与密集）对基于深度强化学习的自主网络防御智能体训练效果的影响，发现目标对齐且高频可获得的稀疏奖励能提升训练可靠性、降低策略风险，并更自然地契合防御目标。


<details>
  <summary>Details</summary>
Motivation: 密集奖励虽有助于探索复杂环境，但易导致次优甚至高风险策略，这在网络防御中尤为危险；需系统评估奖励结构对策略行为与安全性的影响。

Method: 在两个主流网络攻防仿真平台（cyber gyms）上，结合多种稀疏与密集奖励函数、不同规模网络及策略梯度/值函数类强化学习算法，开展系统性实验；提出一种新颖的‘真实基准’评估方法，实现跨奖励函数的策略直接可比性。

Result: 稀疏奖励（若目标对齐且可高频获取）能带来更可靠的训练过程、更有效的防御策略以及更低风险的行为；且无需显式惩罚即可减少高成本防御动作，策略更符合人类防御者目标。

Conclusion: 稀疏奖励在自主网络防御智能体训练中具有显著优势，挑战了当前普遍依赖密集奖励的范式，为设计安全、可靠、目标对齐的奖励函数提供了新思路。

Abstract: Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.

</details>


### [364] [Maximum-Volume Nonnegative Matrix Factorization](https://arxiv.org/abs/2602.04795)
*Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.LG

TL;DR: 本文提出最大体积非负矩阵分解（MaxVol NMF），通过最大化因子H的体积来提升解的可解释性与唯一性，相比最小体积NMF（MinVol NMF）更鲁棒、更稀疏、不产生秩亏解，并在超光谱解混中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 为获得更可解释、唯一且鲁棒的NMF解，传统方法（如MinVol NMF）最小化W的体积，但易受噪声影响并导致秩亏；本文提出对偶思路——最大化H的体积（MaxVol NMF），以改善稀疏性与稳定性。

Method: 提出最大体积NMF（MaxVol NMF），理论分析其可识别性与几何意义（对应列聚类），设计两种优化算法，并引入归一化变体作为标准NMF与正交NMF之间的连续模型。

Result: MaxVol NMF在噪声下更鲁棒，能提取稀疏分解且避免秩亏；其最大体积解等价于将X的列划分为互斥簇；归一化MaxVol NMF在实验中性能优于MinVol和原始MaxVol NMF。

Conclusion: MaxVol NMF是一种有理论保障、实用性强的新NMF范式，在超光谱解混等任务中展现出优越性，归一化变体进一步拓展了NMF建模的灵活性。

Abstract: Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.

</details>


### [365] [Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning](https://arxiv.org/abs/2602.04807)
*Wolfgang Maass,Sabine Janzen,Prajvi Saxena,Sach Mukherjee*

Main category: cs.LG

TL;DR: 本文提出了Afferent Learning框架，通过进化优化与强化学习结合生成计算性传入痕迹（CATs），作为损伤规避学习的自适应内部风险信号，并在生物力学数字孪生体中验证了其高效性和年龄鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受生物系统启发，旨在解决长期运行的生物力学数字孪生体中的损伤规避学习问题，提升策略学习效率与年龄鲁棒性。

Method: 提出两层架构：外层用进化优化发现有效的传入感知架构，内层用强化学习基于计算性传入痕迹（CATs）训练损伤规避策略；理论分析给出收敛性保证。

Result: 在生物力学数字孪生体长期仿真中，CAT-based演化架构相比人工设计基线显著提升效率与年龄鲁棒性，高风险行为减少23%；消融实验验证CAT信号、进化机制与预测差异的关键作用。

Conclusion: Afferent Learning将传入感知形式化为一种归纳偏置，通过架构选择而非直接优化损伤指标来促进高效学习，为长期自适应智能体建模提供了新范式。

Abstract: We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.

</details>


### [366] [Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821)
*Joydeep Chandra,Satyam Kumar Navneet,Aleksandr Algazinov,Yong Zhang*

Main category: cs.LG

TL;DR: STREAM-RL是一个面向城市交通管理的统一框架，集预测、异常检测与安全决策于一体，首次实现从预测到策略学习的端到端校准不确定性传播与理论保障。


<details>
  <summary>Details</summary>
Motivation: 城市交通管理需要同时具备未来状态预测、异常检测和安全干预能力，并提供可靠性保证。

Method: 提出三个新算法：PU-GAT+（不确定性引导的自适应共形预测器）、CRFN-BY（带Benjamini-Yekutieli FDR控制的共形残差流网络）和LyCon-WRL+（具Lyapunov稳定性证书与不确定性传播想象推演的安全世界模型强化学习智能体）。

Result: 在真实交通轨迹数据上，覆盖效率达91.4%，FDR控制在4.1%，安全率提升至95.2%（对比PPO的69%），奖励更高，端到端推理延迟仅23ms。

Conclusion: STREAM-RL是首个在预测、检测与策略学习全流程中实现校准不确定性传播并具备严格理论保证的框架。

Abstract: Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\% coverage efficiency, controls FDR at 4.1\% under verified dependence, and improves safety rate to 95.2\% compared to 69\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.

</details>


### [367] [From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures](https://arxiv.org/abs/2602.04861)
*Ryan Liu,Eric Qu,Tobias Kreiman,Samuel M. Blau,Aditi S. Krishnapriyan*

Main category: cs.LG

TL;DR: 本文提出了一种新的高效评估方法——键平滑性表征测试（BSCT），用于检测机器学习原子间势（MLIPs）在势能面（PES）上的非物理不光滑性（如间断、虚假极小值和异常力），并验证其与分子动力学（MD）稳定性的强相关性及低成本优势；同时，以无约束Transformer为测试平台，展示了BSCT如何指导模型改进（如可微k近邻和温度控制注意力机制），最终获得高精度、高稳定性和强泛化能力的MLIP。


<details>
  <summary>Details</summary>
Motivation: 现有MLIP评估方法（如微正则系综MD）计算昂贵且主要覆盖平衡态附近区域，难以有效发现势能面的非物理不光滑性，而这类问题会引发下游模拟错误且易被常规能量/力回归误差掩盖。

Method: 提出键平滑性表征测试（BSCT），通过可控键变形系统探测势能面，识别不连续性、人工极小值和虚假力；并以无约束Transformer为基线模型，结合可微k近邻算法和温度控制注意力机制进行迭代优化。

Result: BSCT与MD稳定性高度相关，但计算成本仅为MD的一小部分；经BSCT引导优化后的MLIP在保持低E/F回归误差的同时，实现了稳定的MD模拟和鲁棒的原子性质预测。

Conclusion: BSCT不仅是一种有效的MLIP验证指标，更可作为‘闭环’模型设计代理，及时揭示当前基准无法高效检测的物理建模缺陷，推动MLIP向更高物理保真度发展。

Abstract: Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an "in-the-loop" model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.

</details>


### [368] [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868)
*Yannick Denker,Alexander Gepperth*

Main category: cs.LG

TL;DR: 本文提出了一个名为CRoSS的新型持续强化学习（CRL）基准套件，基于Gazebo仿真器中的高保真机器人模型，涵盖差速驱动小车和七自由度机械臂两类平台，支持多种任务变体与传感器模态，并提供轻量级运动学版本以加速实验，同时配套容器化部署与基线算法性能报告。


<details>
  <summary>Details</summary>
Motivation: 现有CRL基准缺乏高物理真实感与多模态传感器支持，难以反映真实机器人持续学习的挑战；需构建可扩展、可复现、兼顾效率与真实性的新基准。

Method: 设计并实现Continual Robotic Simulation Suite（CRoSS），包含两种机器人平台（差速小车与七轴机械臂）、多任务场景（如循线、推物、目标到达）、结构/视觉参数扰动生成任务序列，并引入仅依赖运动学的加速变体；采用Apptainer容器封装，集成DQN与策略梯度等标准RL算法作为基线。

Result: CRoSS支持高物理真实感的CRL研究，机械臂运动学变体提速百倍；已验证主流RL算法在该基准上的表现，证明其作为可扩展、可复现CRL基准的有效性与实用性。

Conclusion: CRoSS填补了高保真、多传感器、易扩展的CRL机器人基准空白，为持续学习算法在真实机器人场景中的评估与迁移提供了坚实基础。

Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

</details>


### [369] [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)
*Philipp Nazari,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 本文分析了线性注意力模型中状态低秩现象的原因及其影响，并提出了一种硬件感知的结构化剪枝方法，在保持性能的同时显著减少查询和键矩阵的通道数，提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 线性注意力模型在训练后常呈现低秩状态，导致其实际表达能力未被充分利用；同时低秩会放大查询噪声、增加检索误差。

Method: 基于理论分析揭示低秩对检索误差的影响，并提出一种硬件感知的结构化剪枝框架，适配CUDA内核；改进多种剪枝策略，并设计基于秩揭示QR分解的新剪枝方法。

Result: 在多个模型规模和下游任务上验证有效；可移除50%的查询与键通道，仅带来微小困惑度上升。

Conclusion: 线性注意力模型的低秩状态可通过结构化剪枝有效缓解，在几乎不损失性能的前提下实现更快、更省内存的推理。

Abstract: Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.

</details>


### [370] [Contrastive Continual Learning for Model Adaptability in Internet of Things](https://arxiv.org/abs/2602.04881)
*Ajesh Koyatan Chathoth*

Main category: cs.LG

TL;DR: 本文综述了面向物联网（IoT）的对比持续学习（CCL），将算法设计（如回放、正则化、知识蒸馏、提示）与IoT系统实际约束（如TinyML、间歇连接、隐私）相结合，提出了统一问题建模、融合对比与蒸馏损失的目标函数、分层参考架构，并探讨了评估方法及IoT特有挑战（如概念漂移、联邦学习、能效训练等）。


<details>
  <summary>Details</summary>
Motivation: IoT环境具有非平稳性、动态性（如传感器漂移、用户行为演化、异构隐私需求），需模型持续适应且避免灾难性遗忘；同时对比学习可提升表征鲁棒性与样本效率，二者结合具有重要价值。

Method: 综述对比持续学习（CCL）在IoT中的应用，提出统一问题形式化，推导对比损失与蒸馏损失的融合目标，设计面向IoT的端-边-云三层CCL参考架构，并给出评估协议与指标建议。

Result: 建立了CCL与IoT系统约束之间的映射关系；提出统一建模范式与融合损失目标；构建了分层参考架构；明确了IoT场景下特有的开放挑战（如流式/表格数据兼容、概念漂移、联邦设置、能耗感知训练）。

Conclusion: CCL是提升IoT系统长期适应性与鲁棒性的关键范式，但需针对IoT的资源受限、隐私敏感、动态演化等特点进行算法与系统协同设计。

Abstract: Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.

</details>


### [371] [Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883)
*Yanru Qu,Cheng-Yen Hsieh,Zaixiang Zheng,Ge Liu,Quanquan Gu*

Main category: cs.LG

TL;DR: PAR是一种多尺度自回归蛋白质骨架生成框架，通过从粗到细的逐级预测，结合多尺度下采样、自回归Transformer编码器和基于流的骨架解码器，有效缓解暴露偏差，并支持零样本条件生成与模体支架设计。


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归模型在蛋白质骨架生成中因训练与推理不匹配导致的暴露偏差问题，并利用蛋白质结构的层次性实现更真实、可控的生成。

Method: 提出多尺度自回归框架PAR，包含三部分：(i) 多尺度下采样操作；(ii) 编码多尺度信息并生成条件嵌入的自回归Transformer；(iii) 基于流的条件骨架解码器；并引入噪声上下文学习与调度采样缓解暴露偏差。

Result: PAR在无条件生成基准上展现出高质量骨架设计能力与良好可扩展性，同时支持零样本的人类提示条件生成与模体支架设计，无需微调。

Conclusion: PAR是首个面向蛋白质骨架生成的多尺度自回归框架，兼具生成质量、鲁棒性与灵活性，为蛋白质结构生成提供了新范式。

Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

</details>


### [372] [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)
*Chenwei Cui,Rockwell Jackson,Benjamin Joseph Herrera,Ana María Tárano,Hannah Kerner*

Main category: cs.LG

TL;DR: 本文提出Multi-Head LatentMoE架构与Head Parallel（HP）并行策略，解决传统Expert Parallel在稀疏Mixture of Experts训练中的高通信开销、负载不均衡和数据依赖通信等问题，实现O(1)通信成本、完全均衡流量与确定性通信，并在保持性能不变前提下训练速度提升最高达1.61倍。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏MoE模型训练中Expert Parallel（EP）存在通信成本随激活专家数k线性增长、负载不平衡导致延迟和内存使用波动、以及需交换元数据的数据依赖通信三大问题，限制了大模型训练效率与可扩展性。

Method: 提出Multi-Head LatentMoE新架构与Head Parallel（HP）分布式训练方法；引入IO-aware路由与专家计算优化以加速训练；HP设计确保通信复杂度为O(1)、流量完全均衡且通信行为确定，同时兼容EP。

Result: 相比标准MoE+EP，Multi-Head LatentMoE+HP训练速度最高提升1.61×，性能完全一致；在专家粒度加倍时仍快1.11×且整体性能更高。

Conclusion: 该方法显著降低超大规模语言模型训练门槛，使百亿至千亿参数基础模型的研究更易普及和高效。

Abstract: Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [373] [On the Uncertainty of Large Language Model-Based Multi-Agent Systems](https://arxiv.org/abs/2602.04234)
*Yuxuan Zhao,Sijia Chen,Ningxin Su*

Main category: cs.MA

TL;DR: 本文从不确定性视角重新审视多智能体系统（MAS），通过分析熵变化揭示其成功或失败的内在机制，并提出Entropy Judger算法以提升MAS性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于公开大语言模型的多智能体系统（MAS）缺乏对其有效性机制（尤其是成功或失败的根本原因）的深入理解，本文旨在填补这一空白。

Method: 从不确定性角度出发，考察MAS中智能体内部（intra-agent）与智能体间（inter-agent）的熵动态变化，涵盖token级、trajectory级和round级共245个熵特征，在多种拓扑结构和六个基准任务上进行实证分析，并提出Entropy Judger算法用于pass@k结果筛选。

Result: 发现单智能体在约43.3%情况下优于MAS；首轮交互即决定大部分不确定性演化趋势；提出三大观察：确定性偏好、基础不确定性影响、任务感知性差异；Entropy Judger算法在所有MAS配置和任务上均带来一致准确率提升。

Conclusion: MAS性能关键取决于不确定性（熵）的演化规律，尤其受首轮交互与基座模型固有不确定性影响；基于熵的轻量级决策机制可有效提升MAS鲁棒性与准确性。

Abstract: Multi-agent systems (MAS) have emerged as a prominent paradigm for leveraging large language models (LLMs) to tackle complex tasks. However, the mechanisms governing the effectiveness of MAS built upon publicly available LLMs, specifically the underlying rationales for their success or failure, remain largely unexplored. In this paper, we revisit MAS through the perspective of uncertainty, considering both intra- and inter-agent dynamics by investigating entropy transitions during problem-solving across various topologies and six benchmark tasks. By analyzing 245 features spanning token-, trajectory-, and round-level entropy, we counterintuitively find that a single agent outperforms MAS in approximately 43.3% of cases, and that uncertainty dynamics are largely determined during the first round of interaction. Furthermore, we provide three key observations: 1) Certainty Preference: reducing uncertainty at any stage for any agent is critical for guaranteeing correct solutions; 2) Base Uncertainty: base models with lower entropy during problem-solving directly benefit MAS performance; and 3) Task Awareness: entropy dynamics of MAS play varying roles across different tasks. Building on these insights, we introduce a simple yet effective algorithm, the Entropy Judger, to select solutions from MAS's pass@k results, leading to consistent accuracy improvements across all MAS configurations and tasks. Our source code is available at https://github.com/AgenticFinLab/multiagent-entropy.

</details>


### [374] [SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing](https://arxiv.org/abs/2602.04418)
*Arnab Mallick,Indraveni Chebolu,Harmesh Rana*

Main category: cs.MA

TL;DR: SPEAR是一个面向智能合约审计的多智能体协调框架，通过规划、执行和修复三类专业化智能体协同工作，结合风险感知启发式、契约网协议与AGM兼容信念修正机制，在失败场景下展现出更优的协调性、恢复能力与资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有智能合约审计方法在面对复杂失败场景时缺乏鲁棒的协调与自主恢复能力，亟需引入成熟的多智能体系统（MAS）模式提升审计流程的适应性与可靠性。

Method: 提出SPEAR框架，包含规划代理（基于风险启发式优先级排序）、执行代理（采用契约网协议分配任务）和修复代理（基于程序化优先策略自动修复脆弱生成物），所有代理通过AGM兼容信念修正更新本地知识，并借助协商与拍卖协议实现动态协调与计划重规划。

Result: 实证研究表明，相较于集中式和流水线式方案，SPEAR在控制失败场景下显著提升了协调效率、故障恢复行为稳健性及资源利用率。

Conclusion: 将成熟MAS设计模式融入智能合约安全分析流程是可行且有效的，SPEAR为构建自适应、可恢复的自动化审计系统提供了新范式。

Abstract: We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.

</details>
