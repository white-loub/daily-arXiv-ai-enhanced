{"id": "2601.05487", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05487", "abs": "https://arxiv.org/abs/2601.05487", "authors": ["Huanxiang Lin", "Qianyue Wang", "Jinwu Hu", "Bailin Chen", "Qing Du", "Mingkui Tan"], "title": "EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting", "comment": null, "summary": "Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \\textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \\textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \\textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEvidFuse\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u53ef\u89c6\u5316\u5206\u6790\u4e0e\u957f\u6587\u672c\u64b0\u5199\uff0c\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u62a5\u544a\u4e2d\u6587\u5b57\u4e0e\u56fe\u8868\u7684\u5b9e\u65f6\u4ea4\u7ec7\u751f\u6210\uff0c\u63d0\u5347\u56fe\u8868\u8d28\u91cf\u3001\u56fe\u6587\u4e00\u81f4\u6027\u53ca\u62a5\u544a\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709LLM\u7cfb\u7edf\u91c7\u7528\u5206\u9636\u6bb5\u6d41\u6c34\u7ebf\uff08\u6587\u672c\u4f18\u5148\u6216\u56fe\u8868\u4f18\u5148\uff09\u751f\u6210\u6570\u636e\u62a5\u544a\uff0c\u6613\u5bfc\u81f4\u56fe\u6587\u4e0d\u4e00\u81f4\u548c\u2018\u6d1e\u5bdf\u51bb\u7ed3\u2019\u95ee\u9898\uff0c\u9650\u5236\u5206\u6790\u6df1\u5ea6\u3002", "method": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6EvidFuse\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a1\uff09\u57fa\u4e8e\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff08EDA\uff09\u5e76\u53ef\u8bbf\u95ee\u539f\u59cb\u8868\u683c\u7684\u6570\u636e\u589e\u5f3a\u5206\u6790\u4ee3\u7406\uff1b2\uff09\u5b9e\u65f6\u8bc1\u636e\u6784\u5efa\u5199\u624b\uff0c\u8fb9\u89c4\u5212\u5927\u7eb2\u8fb9\u64b0\u5199\uff0c\u5e76\u6309\u9700\u53d1\u8d77\u7ec6\u7c92\u5ea6\u5206\u6790\u8bf7\u6c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEvidFuse\u5728LLM\u81ea\u52a8\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u5747\u5728\u56fe\u8868\u8d28\u91cf\u3001\u56fe\u6587\u5bf9\u9f50\u5ea6\u548c\u62a5\u544a\u5b9e\u7528\u6027\u4e09\u65b9\u9762\u53d6\u5f97\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "EvidFuse\u901a\u8fc7\u5199\u4f5c\u65f6\u52a8\u6001\u751f\u6210\u89c6\u89c9\u8bc1\u636e\uff0c\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u6d41\u6c34\u7ebf\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u62a5\u544a\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u6df1\u5165\u548c\u4e00\u81f4\u7684\u65b0\u8303\u5f0f\u3002"}}
