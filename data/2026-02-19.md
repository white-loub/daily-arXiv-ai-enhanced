<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 46]
- [cs.CL](#cs.CL) [Total: 69]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.RO](#cs.RO) [Total: 46]
- [cs.IR](#cs.IR) [Total: 8]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 90]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Egocentric Bias in Vision-Language Models](https://arxiv.org/abs/2602.15892)
*Maijunxian Wang,Yijiang Li,Bingyang Wang,Tianwei Zhao,Ran Ji,Qingying Gao,Emmy Liu,Hokin Deng,Dezhi Luo*

Main category: cs.CV

TL;DR: 本文提出了FlipSet基准，用于评估视觉-语言模型在Level-2视觉视角采择（L2 VPT）任务中的能力，发现大多数模型存在系统性自我中心偏差，无法将社会意识与空间操作有效结合。


<details>
  <summary>Details</summary>
Motivation: 视觉视角采择是社会认知的基础能力，但现有视觉-语言模型（VLMs）在该能力上的评估缺乏认知基础明确、任务解耦清晰的基准。

Method: 构建FlipSet诊断基准，要求模型对2D字符字符串进行180度视角旋转模拟，以隔离空间变换能力；评估103个VLM，并设计控制实验检验其理论心智与心理旋转能力的组合表现。

Result: 多数VLM在FlipSet上表现低于随机水平，约75%错误源于直接复现相机视角（即自我中心偏差）；控制实验显示模型单独任务表现良好，但在需整合时失败。

Conclusion: 当前VLM缺乏将社会意识绑定到空间操作的机制，揭示其在基于模型的空间推理方面存在根本性局限；FlipSet为多模态系统视角采择能力提供了认知驱动的诊断工具。

Abstract: Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.

</details>


### [2] [Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment](https://arxiv.org/abs/2602.15903)
*Jingwei Li,Jiaxin Tong,Pengfei Wu*

Main category: cs.CV

TL;DR: 本文提出MSBA-CLIP框架，结合CLIP引导的伪造强度估计与多变量软融合增强策略，显著提升深度伪造检测的泛化性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法在面对多种伪造技术导致的数据分布偏移时，准确率和泛化能力不足。

Method: 提出Multivariate and Soft Blending Augmentation（MSBA）策略，融合多种伪造图像；设计CLIP引导的Multivariate Forgery Intensity Estimation（MFIE）模块，显式建模不同伪造模式与强度。

Result: 在域内测试中，准确率和AUC分别提升3.32%和4.02%；跨域五数据集平均AUC提升3.27%；消融实验证明两模块均有效。

Conclusion: MSBA-CLIP显著增强了深度伪造检测模型的泛化性和鲁棒性，是迈向更可靠检测的重要进展，但依赖大模型带来较高计算开销。

Abstract: The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\% and 4.02\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.

</details>


### [3] [A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving](https://arxiv.org/abs/2602.15904)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: 本文首次全面综述了面向自动驾驶的LiDAR超分辨率方法，系统梳理了四类主流技术路线，明确了基本概念与评估体系，并指出实时推理、跨传感器泛化等实际部署趋势及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 高分辨率LiDAR成本高昂，而低成本低分辨率LiDAR产生的稀疏点云缺乏关键细节；亟需通过深度学习提升稀疏点云质量，实现跨传感器兼容与实际部署。

Method: 对现有LiDAR超分辨率方法进行系统性分类与分析，涵盖CNN、模型驱动展开、隐式表示、Transformer/Mamba四大类，并梳理数据表示、问题建模、基准数据集与评估指标。

Result: 建立了LiDAR超分辨率领域的首个完整综述框架，归纳出范围图像表示、极致模型压缩、分辨率自适应架构等当前趋势，并强调实时推理与跨传感器泛化能力。

Conclusion: 指出了该领域在理论建模、算法鲁棒性、硬件协同优化等方面仍存在开放挑战，为后续研究提供了明确方向。

Abstract: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.

</details>


### [4] [MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.15915)
*Xianwei Mao,Kai Ye,Sheng Zhou,Nan Zhang,Haikuan Huang,Bin Li,Jiajun Bu*

Main category: cs.CV

TL;DR: 本文提出MaS-VQA框架，通过Mask-and-Select机制联合过滤视觉区域与外部知识片段，实现显式知识筛选与隐式知识推理的紧密耦合，从而提升KB-VQA任务中的答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有KB-VQA方法受限于检索知识的噪声、不相关性及与视觉内容错位，且模型内部知识难以控制和解释，导致简单融合效果差。

Method: 提出MaS-VQA框架：先检索候选段落，再用Mask-and-Select机制同步剪枝无关图像区域和弱相关知识片段，生成高信噪比的多模态知识；该知识进一步约束大模型内部知识激活空间，实现显隐知识协同建模。

Result: 在Encyclopedic-VQA和InfoSeek数据集上，MaS-VQA在多个MLLM骨干网络上均取得一致性能提升；消融实验证明其选择机制能有效降噪并提升知识利用率。

Conclusion: 显式知识筛选与隐式知识推理的协同建模可显著增强KB-VQA系统的鲁棒性与可解释性，Mask-and-Select机制是关键设计。

Abstract: Knowledge-based Visual Question Answering (KB-VQA) requires models to answer questions by integrating visual information with external knowledge. However, retrieved knowledge is often noisy, partially irrelevant, or misaligned with the visual content, while internal model knowledge is difficult to control and interpret. Naive aggregation of these sources limits reasoning effectiveness and reduces answer accuracy. To address this, we propose MaS-VQA, a selection-driven framework that tightly couples explicit knowledge filtering with implicit knowledge reasoning. MaS-VQA first retrieves candidate passages and applies a Mask-and-Select mechanism to jointly prune irrelevant image regions and weakly relevant knowledge fragments, producing compact, high-signal multimodal knowledge . This filtered knowledge then guides the activation of internal knowledge in a constrained semantic space, enabling complementary co-modeling of explicit and implicit knowledge for robust answer prediction. Experiments on Encyclopedic-VQA and InfoSeek demonstrate consistent performance gains across multiple MLLM backbones, and ablations verify that the selection mechanism effectively reduces noise and enhances knowledge utilization.

</details>


### [5] [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918)
*Zelin Xu,Yupu Zhang,Saugat Adhikari,Saiful Islam,Tingsong Xiao,Zibo Liu,Shigang Chen,Da Yan,Zhe Jiang*

Main category: cs.CV

TL;DR: 本文提出了EarthSpatialBench，一个面向地球影像的多模态大语言模型空间推理评测基准，涵盖定性/定量距离与方向推理、系统性拓扑关系、多种查询类型及多模态对象指代方式，共32.5万问答对，并通过实验揭示了现有MLLM在空间推理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有地球影像空间推理基准局限于2D空间定位、图像描述和粗粒度空间关系，缺乏对定量方向/距离推理、系统性拓扑关系及复杂几何对象（如多边形、折线）的支持，难以满足具身AI对精确物理世界交互的需求。

Method: 构建EarthSpatialBench基准，包含325K+问答对，覆盖四类空间推理任务：（1）定性与定量距离/方向推理；（2）系统性拓扑关系；（3）单对象、对象对及组合聚合组查询；（4）文本描述、视觉叠加和显式几何坐标（边界框、折线、多边形）等多种对象指代方式；并在开源与闭源MLLM上开展系统评测。

Result: 实验揭示了当前MLLM在定量空间推理（如精确距离/角度计算）、复杂拓扑关系理解（如连通性、包含性）及多边形等高阶几何对象处理方面存在显著局限。

Conclusion: EarthSpatialBench填补了地球影像空间推理评测的空白，为推动MLLM在地理空间智能与具身AI中的发展提供了标准化评估工具和明确改进方向。

Abstract: Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

</details>


### [6] [A Study on Real-time Object Detection using Deep Learning](https://arxiv.org/abs/2602.15926)
*Ankita Bose,Jayasravani Bhumireddy,Naveen N*

Main category: cs.CV

TL;DR: 本文综述了深度学习在实时目标检测中的应用，详细介绍了主流算法（如Faster R-CNN、YOLO、SSD等）、公开数据集、多领域应用案例及对比实验，并指出了未来研究挑战与方向。


<details>
  <summary>Details</summary>
Motivation: 目标检测在人机交互、安防监控、交通管理、医疗、AR/VR等多个领域具有重要应用价值，实时性与准确性需求推动深度学习方法的发展与优化。

Method: 系统性综述方法：梳理主流深度学习目标检测模型，分析其原理与特点；总结常用公开基准数据集；归纳各领域实际应用案例；开展控制实验对比不同算法性能。

Result: 明确了各类模型的适用场景与性能差异，揭示了当前方法在速度、精度、鲁棒性等方面的优劣，提供了具有启发性的实验发现。

Conclusion: 深度学习显著提升了实时目标检测的性能，但仍有挑战（如小目标检测、遮挡处理、边缘部署等）需进一步研究；未来应关注模型轻量化、跨域泛化及与AR/VR等新兴技术的融合。

Abstract: Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.

</details>


### [7] [Visual Memory Injection Attacks for Multi-Turn Conversations](https://arxiv.org/abs/2602.15927)
*Christian Schlarmann,Matthias Hein*

Main category: cs.CV

TL;DR: 本文提出了一种针对多轮长上下文视觉语言模型（LVLMs）的隐蔽视觉记忆注入（VMI）攻击，通过上传恶意图像，在特定触发提示下诱导模型输出预定有害信息，且在多轮对话中仍保持有效性。


<details>
  <summary>Details</summary>
Motivation: LVLMs在多轮长上下文场景下的安全性尚未被充分研究，而现实中的图像上传与复用为隐蔽攻击提供了可行渠道。

Method: 设计视觉记忆注入（VMI）攻击：利用精心扰动的图像作为输入，在正常提问时模型行为正常，仅在特定触发提示下才输出预设目标信息；攻击在多轮对话中持续有效。

Result: 在多个开源LVLM上成功验证VMI攻击的有效性，证明其可在长上下文多轮交互中稳定触发恶意响应。

Conclusion: LVLMs在现实多轮交互场景中面临严重安全风险，亟需提升对基于图像的记忆注入类攻击的鲁棒性。

Abstract: Generative large vision-language models (LVLMs) have recently achieved impressive performance gains, and their user base is growing rapidly. However, the security of LVLMs, in particular in a long-context multi-turn setting, is largely underexplored. In this paper, we consider the realistic scenario in which an attacker uploads a manipulated image to the web/social media. A benign user downloads this image and uses it as input to the LVLM. Our novel stealthy Visual Memory Injection (VMI) attack is designed such that on normal prompts the LVLM exhibits nominal behavior, but once the user gives a triggering prompt, the LVLM outputs a specific prescribed target message to manipulate the user, e.g. for adversarial marketing or political persuasion. Compared to previous work that focused on single-turn attacks, VMI is effective even after a long multi-turn conversation with the user. We demonstrate our attack on several recent open-weight LVLMs. This article thereby shows that large-scale manipulation of users is feasible with perturbed images in multi-turn conversation settings, calling for better robustness of LVLMs against these attacks. We release the source code at https://github.com/chs20/visual-memory-injection

</details>


### [8] [Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families](https://arxiv.org/abs/2602.15950)
*Yuval Levental*

Main category: cs.CV

TL;DR: 本文通过实验揭示了视觉-语言模型（VLMs）在定位无文本标识的二值网格中填充单元时存在根本性局限：当使用文本符号（如#和.）渲染时性能良好，而换成无网格线的实心方块时，所有前沿VLMs性能急剧下降，表明其空间推理严重依赖文本识别通路而非纯视觉通路。


<details>
  <summary>Details</summary>
Motivation: 探究VLMs是否真正具备通用视觉空间理解能力，还是过度依赖图像中的文本线索进行空间推理。

Method: 构建15个15×15二值网格（填充密度10.7%-41.8%），分别以文本符号（.和#）和无网格线的实心方块两种图像形式呈现；输入至Claude Opus、ChatGPT 5.2和Gemini 3 Thinking三个前沿VLM，并评估其单元级准确率与F1分数。

Result: 文本符号条件下，Claude和ChatGPT达~91%准确率、84% F1；Gemini为84%准确率、63% F1；实心方块条件下三者均骤降至60–73%准确率、29–39% F1；F1下降幅度达34–54分；各模型表现出不同失败模式（低估、高估、模板幻觉）。

Conclusion: VLMs的空间定位能力高度依赖图像中可识别的文本线索，其原生视觉通路对非文本视觉元素的空间定位能力严重不足，暴露了当前VLM架构在通用视觉理解上的根本缺陷。

Abstract: We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking) to transcribe them. In the text-symbol condition, Claude and ChatGPT achieve approximately 91% cell accuracy and 84% F1, while Gemini achieves 84% accuracy and 63% F1. In the filled-squares condition, all three models collapse to 60-73% accuracy and 29-39% F1. Critically, all conditions pass through the same visual encoder -- the text symbols are images, not tokenized text. The text-vs-squares F1 gap ranges from 34 to 54 points across models, demonstrating that VLMs behave as if they possess a high-fidelity text-recognition pathway for spatial reasoning that dramatically outperforms their native visual pathway. Each model exhibits a distinct failure mode in the squares condition -- systematic under-counting (Claude), massive over-counting (ChatGPT), and template hallucination (Gemini) -- but all share the same underlying deficit: severely degraded spatial localization for non-textual visual elements.

</details>


### [9] [Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration](https://arxiv.org/abs/2602.15959)
*Yiwen Wang,Jiahao Qin*

Main category: cs.CV

TL;DR: 本文提出GPEReg-Net，一种基于场景外观解耦和全局位置编码的光声显微镜图像配准方法，显著提升高速双向扫描下的配准精度与时间一致性。


<details>
  <summary>Details</summary>
Motivation: 高速光学分辨率光声显微镜（OR-PAM）双向扫描引入域偏移与几何错位，现有配准方法受限于亮度恒定假设或缺乏时间建模能力。

Method: 提出GPEReg-Net框架：1）用AdaIN解耦场景结构特征与域特定外观码，实现端到端图像配准；2）设计全局位置编码（GPE）模块，融合可学习位置嵌入、正弦编码与跨帧注意力，增强时序一致性。

Result: 在OR-PAM-Reg-4K数据集上，NCC达0.953，SSIM达0.932（SOTA提升3.8%），PSNR达34.49dB（SOTA提升1.99dB）。

Conclusion: GPEReg-Net通过外观解耦与显式时间建模，有效解决双向扫描中的域偏移与时间不一致问题，为高速OR-PAM提供高精度、高鲁棒性配准方案。

Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at https://github.com/JiahaoQin/GPEReg-Net.

</details>


### [10] [Automated Re-Identification of Holstein-Friesian Cattle in Dense Crowds](https://arxiv.org/abs/2602.15962)
*Phoenix Yu,Tilo Burghardt,Andrew W Dowsey,Neill W Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种新的detect-segment-identify流程，结合Open-Vocabulary Weight-free Localisation和Segment Anything模型，有效解决奶牛密集聚集时的检测与重识别难题，在真实农场CCTV数据上达到98.93%检测准确率和94.82%重识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于YOLO等的目标检测方法在奶牛密集聚集、毛色图案干扰轮廓时性能显著下降，亟需提升密集场景下的检测与重识别鲁棒性与泛化能力。

Method: 构建detect-segment-identify三阶段流程：先用Open-Vocabulary Weight-free Localisation实现无权重开放词汇定位，再用Segment Anything模型（SAM）进行分割预处理，最后接入Re-ID网络；并引入无监督对比学习提升重识别性能。

Result: 在自建的九天真实农场CCTV数据集上，检测准确率达98.93%，较定向边界框和SAM基线分别提升47.52%和27.13%；重识别准确率达94.82%。

Conclusion: 该方法证明了在无需人工干预的真实农场密集场景下，奶牛检测与重识别是可行且可靠的，兼具实用性与高精度，并开源代码与数据集。

Abstract: Holstein-Friesian detection and re-identification (Re-ID) methods capture individuals well when targets are spatially separate. However, existing approaches, including YOLO-based species detection, break down when cows group closely together. This is particularly prevalent for species which have outline-breaking coat patterns. To boost both effectiveness and transferability in this setting, we propose a new detect-segment-identify pipeline that leverages the Open-Vocabulary Weight-free Localisation and the Segment Anything models as pre-processing stages alongside Re-ID networks. To evaluate our approach, we publish a collection of nine days CCTV data filmed on a working dairy farm. Our methodology overcomes detection breakdown in dense animal groupings, resulting in a 98.93% accuracy. This significantly outperforms current oriented bounding box-driven, as well as SAM species detection baselines with accuracy improvements of 47.52% and 27.13%, respectively. We show that unsupervised contrastive learning can build on this to yield 94.82% Re-ID accuracy on our test data. Our work demonstrates that Re-ID in crowded scenarios is both practical as well as reliable in working farm settings with no manual intervention. Code and dataset are provided for reproducibility.

</details>


### [11] [Non-Contact Physiological Monitoring in Pediatric Intensive Care Units via Adaptive Masking and Self-Supervised Learning](https://arxiv.org/abs/2602.15967)
*Mohamed Khalil Ben Salah,Philippe Jouvet,Rita Noumeir*

Main category: cs.CV

TL;DR: 本文提出了一种面向儿科重症监护室（PICU）的自监督rPPG预训练框架，结合VisionMamba架构与自适应掩码机制，在缺乏标注临床数据的情况下，通过渐进式课程学习和师生蒸馏显著提升接触式心率估计精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统接触式传感器在PICU中易致皮肤刺激、感染风险和不适；rPPG虽为无接触替代方案，但受限于运动伪影、遮挡、光照变化及实验室到临床的域偏移，临床落地困难。

Method: 提出基于VisionMamba的自监督预训练框架，引入轻量级Mamba控制器实现时空重要性评分与概率化补丁采样；采用三阶段渐进式课程学习（公开干净视频→合成遮挡→500例患儿无标签视频），并结合教师-学生蒸馏利用公开数据集监督信号指导学生模型。

Result: 相比标准掩码自编码器MAE降低42%，优于PhysFormer 31%，最终MAE达3.2 bpm；无需显式ROI提取即能聚焦脉搏丰富区域，对临床遮挡与噪声具有强鲁棒性。

Conclusion: 该框架有效缓解了rPPG在真实PICU场景下的数据稀缺与干扰挑战，为临床无接触生命体征监测提供了可推广的新范式。

Abstract: Continuous monitoring of vital signs in Pediatric Intensive Care Units (PICUs) is essential for early detection of clinical deterioration and effective clinical decision-making. However, contact-based sensors such as pulse oximeters may cause skin irritation, increase infection risk, and lead to patient discomfort. Remote photoplethysmography (rPPG) offers a contactless alternative to monitor heart rate using facial video, but remains underutilized in PICUs due to motion artifacts, occlusions, variable lighting, and domain shifts between laboratory and clinical data.
  We introduce a self-supervised pretraining framework for rPPG estimation in the PICU setting, based on a progressive curriculum strategy. The approach leverages the VisionMamba architecture and integrates an adaptive masking mechanism, where a lightweight Mamba-based controller assigns spatiotemporal importance scores to guide probabilistic patch sampling. This strategy dynamically increases reconstruction difficulty while preserving physiological relevance.
  To address the lack of labeled clinical data, we adopt a teacher-student distillation setup. A supervised expert model, trained on public datasets, provides latent physiological guidance to the student. The curriculum progresses through three stages: clean public videos, synthetic occlusion scenarios, and unlabeled videos from 500 pediatric patients.
  Our framework achieves a 42% reduction in mean absolute error relative to standard masked autoencoders and outperforms PhysFormer by 31%, reaching a final MAE of 3.2 bpm. Without explicit region-of-interest extraction, the model consistently attends to pulse-rich areas and demonstrates robustness under clinical occlusions and noise.

</details>


### [12] [LAND: A Longitudinal Analysis of Neuromorphic Datasets](https://arxiv.org/abs/2602.15973)
*Gregory Cohen,Alexandre Marcireau*

Main category: cs.CV

TL;DR: 本文综述了神经形态工程领域数据集的现状与挑战，分析了423个现有数据集在规模、标准化、可访问性及任务定义方面的不足，并探讨了合成数据（仿真/视频转事件）的利弊，提出元数据集作为缓解数据需求与偏差的新思路。


<details>
  <summary>Details</summary>
Motivation: 神经形态研究虽数据集数量激增，但仍普遍面临数据稀缺、难发现、难理解、难使用等问题，亟需系统性梳理与改进。

Method: 对超过423个神经形态数据集进行快照式统计与结构化分析，考察其任务类型、数据组织方式、规模演变及获取难度；同时评估合成数据与元数据集的可行性与影响。

Result: 揭示了数据集在规模不一、缺乏标准、访问困难及任务模糊等方面的共性问题；指出合成数据在算法验证中有价值但易导致应用偏差；元数据集可减少重复建设并缓解数据-任务耦合带来的偏见。

Conclusion: 神经形态数据生态需从‘追求数量’转向‘提升质量与互操作性’，应推动标准化、增强可复现性，并审慎使用合成数据，积极发展元数据集范式。

Abstract: Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.

</details>


### [13] [SAM 3D Body: Robust Full-Body Human Mesh Recovery](https://arxiv.org/abs/2602.15989)
*Xitong Yang,Devansh Kukreja,Don Pinkus,Anushka Sagar,Taosha Fan,Jinhyung Park,Soyong Shin,Jinkun Cao,Jiawei Liu,Nicolas Ugrinovic,Matt Feiszli,Jitendra Malik,Piotr Dollar,Kris Kitani*

Main category: cs.CV

TL;DR: 本文提出了SAM 3D Body（3DB），一种可提示的单图像全身3D人体网格恢复模型，采用新型参数化网格表示Momentum Human Rig（MHR），支持多模态提示输入，在真实场景中展现出卓越泛化能力和精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体重建方法在复杂、多变的真实场景下泛化能力不足，缺乏对罕见姿态和成像条件的有效建模；同时缺少统一、高质量且多样化的训练与评估数据。

Method: 提出MHR新参数化表示以解耦骨骼结构与表面形状；构建基于编码器-解码器的可提示3DB模型，支持2D关键点和掩码等辅助提示；设计多阶段数据引擎生成高质量标注，并构建按姿态与外观分类的新基准测试集。

Result: 3DB在定性用户偏好研究和定量指标上均显著超越先前方法，具备强泛化性与鲁棒性；MHR与3DB模型均已开源。

Conclusion: 3DB是首个结合可提示机制与新型人体表示的全身体3D重建框架，推动了HMR在真实场景中的实用化与可控性发展。

Abstract: We introduce SAM 3D Body (3DB), a promptable model for single-image full-body 3D human mesh recovery (HMR) that demonstrates state-of-the-art performance, with strong generalization and consistent accuracy in diverse in-the-wild conditions. 3DB estimates the human pose of the body, feet, and hands. It is the first model to use a new parametric mesh representation, Momentum Human Rig (MHR), which decouples skeletal structure and surface shape. 3DB employs an encoder-decoder architecture and supports auxiliary prompts, including 2D keypoints and masks, enabling user-guided inference similar to the SAM family of models. We derive high-quality annotations from a multi-stage annotation pipeline that uses various combinations of manual keypoint annotation, differentiable optimization, multi-view geometry, and dense keypoint detection. Our data engine efficiently selects and processes data to ensure data diversity, collecting unusual poses and rare imaging conditions. We present a new evaluation dataset organized by pose and appearance categories, enabling nuanced analysis of model behavior. Our experiments demonstrate superior generalization and substantial improvements over prior methods in both qualitative user preference studies and traditional quantitative analysis. Both 3DB and MHR are open-source.

</details>


### [14] [BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features](https://arxiv.org/abs/2602.16006)
*Juampablo E. Heras Rivera,Dickson T. Chen,Tianyi Ren,Daniel K. Low,Asma Ben Abacha,Alberto Santamaria-Pang,Mehmet Kurt*

Main category: cs.CV

TL;DR: 本文提出BTReport框架，通过确定性特征提取与大语言模型结合的方式生成可解释、低幻觉的脑肿瘤放射学报告，并发布配套合成数据集BTReport-BraTS。


<details>
  <summary>Details</summary>
Motivation: 神经肿瘤学领域缺乏公开的配对影像-报告数据集，限制了放射学报告自动生成（RRG）的发展。

Method: BTReport将RRG分为两步：先通过确定性方法从MRI影像中提取临床相关成像特征，再利用大语言模型仅负责语法组织和叙述格式化，不参与图像理解。

Result: 生成的报告更贴近真实临床报告，所用特征可预测生存期和IDH突变状态；配套发布BTReport-BraTS合成数据集。

Conclusion: 分离特征提取与文本生成能提升报告可解释性与可靠性，为小样本医学RRG提供新范式。

Abstract: Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.

</details>


### [15] [MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019)
*Ahmad Elallaf,Yu Zhang,Yuktha Priya Masupalli,Jeong Yang,Young Lee,Zechun Cao,Gongbo Liang*

Main category: cs.CV

TL;DR: MedProbCLIP is a probabilistic vision-language model for chest X-ray and radiology report understanding, using Gaussian embeddings and uncertainty-aware contrastive learning to improve reliability, calibration, and robustness in biomedical retrieval.


<details>
  <summary>Details</summary>
Motivation: Deterministic vision-language models lack reliability and uncertainty quantification needed for high-stakes biomedical applications like radiology.

Method: MedProbCLIP models image and text as Gaussian embeddings via probabilistic contrastive learning; incorporates variational information bottleneck, multi-view radiograph encoding, and multi-section report encoding for fine-grained clinical alignment.

Result: Outperforms deterministic (CLIP, CXR-CLIP) and probabilistic (PCME++) baselines on MIMIC-CXR in bidirectional retrieval and zero-shot classification, with better calibration, risk-coverage, selective retrieval reliability, and robustness to clinical corruptions.

Conclusion: Probabilistic modeling of vision-language representations significantly enhances trustworthiness and safety in radiology AI systems.

Abstract: Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

</details>


### [16] [LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization](https://arxiv.org/abs/2602.16086)
*Idil Bilge Altun,Mert Onur Cakiroglu,Elham Buxton,Mehmet Dalkilic,Hasan Kurban*

Main category: cs.CV

TL;DR: 本文提出了可学习几何量化（LGQ）方法，用于离散图像标记化，通过端到端学习离散化几何结构，在保持稳定优化和均衡码本利用率的同时提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有离散图像标记器在灵活性与稳定性之间存在权衡：向量量化易出现优化偏差、码本利用不足和表征坍缩；标量或隐式量化虽利用稳定但几何固定、容量分配低效。

Method: LGQ采用温度控制的软分配替代硬最近邻查找，以各向同性高斯混合模型后验责任为依据，最小化变分自由能目标，并引入词元级尖锐性正则项与全局使用正则项以平衡置信度与码本利用。

Result: 在ImageNet上基于VQGAN风格主干的实验表明，LGQ在16K码本规模下，相比FSQ提升rFID达11.88%且激活码减少49.96%，相比SimVQ提升rFID 6.06%且有效表征率降低49.45%，同时保持高保真度。

Conclusion: LGQ实现了离散图像标记化中几何灵活性与训练稳定性的统一，显著提升生成性能与码本效率，为视觉生成中的高效tokenization提供了新范式。

Abstract: Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.
  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.
  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ

</details>


### [17] [OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis](https://arxiv.org/abs/2602.16110)
*Tianwei Lin,Zhongwei Qiu,Wenqiao Zhang,Jiang Liu,Yihan Xie,Mingjian Gao,Zhenxuan Fan,Zhaocheng Li,Sijing Li,Zhongle Xie,Peng LU,Yueting Zhuang,Yingda Xia,Ling Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: 本文提出OmniCT，一种统一的切片-体素大视觉语言模型，通过空间一致性增强、器官级语义增强和新构建的大规模CT数据集MedEval-CT，在CT影像理解中实现了细粒度细节感知与宏观空间推理的兼顾，推动医学多模态理解新范式。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在CT影像理解中存在切片级与体素级建模割裂的问题：切片级模型缺乏跨切片空间一致性，体素级模型则分辨率粗糙且难以兼容常规切片输入，阻碍临床落地。

Method: 提出OmniCT模型，包含三项核心技术：（i）空间一致性增强（SCE），融合体素切片组合与三轴位置编码，并采用MoE混合投影实现高效切片-体素适配；（ii）器官级语义增强（OSE），通过分割与ROI定位显式对齐解剖区域；（iii）构建MedEval-CT——首个大规模切片-体素CT数据集与混合评测基准。

Result: OmniCT在多种临床任务上显著超越现有方法，兼具微观细节敏感性与宏观空间推理能力，并确立了跨模态医学影像理解的新范式。

Conclusion: OmniCT成功弥合了CT影像中切片级与体素级理解的鸿沟，为医学大模型的临床转化提供了统一建模范式与可扩展技术路径。

Abstract: Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, lesion boundaries) and volume-driven spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). However, existing Large Vision-Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. We present OmniCT, a powerful unified slice-volume LVLM for CT scenarios, which makes three contributions: (i) Spatial Consistency Enhancement (SCE): volumetric slice composition combined with tri-axial positional embedding that introduces volumetric consistency, and an MoE hybrid projection enables efficient slice-volume adaptation; (ii) Organ-level Semantic Enhancement (OSE): segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; (iii) MedEval-CT: the largest slice-volume CT dataset and hybrid benchmark integrates comprehensive metrics for unified evaluation. OmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks and satisfies both micro-level detail sensitivity and macro-level spatial reasoning. More importantly, it establishes a new paradigm for cross-modal medical imaging understanding.

</details>


### [18] [CHAI: CacHe Attention Inference for text2video](https://arxiv.org/abs/2602.16132)
*Joel Mathew Cherian,Ashutosh Muralidhara Bharadwaj,Vima Gupta,Anand Padmanabha Iyer*

Main category: cs.CV

TL;DR: CHAI提出Cache Attention机制，通过跨推理缓存复用语义相关的潜变量，显著减少去噪步数（低至8步），在保持视频质量的同时实现1.65x–3.35x加速。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成视频扩散模型推理慢，且加速方法或需重训练、或依赖启发式跳步而损害质量。

Method: 提出CHAI框架，核心为Cache Attention机制，支持跨不同提示间缓存与选择性注意力复用语义共享的潜变量。

Result: 仅用8步去噪即可生成高质量视频；相较OpenSora 1.2，整体加速1.65x–3.35x，视频质量无损。

Conclusion: 跨推理缓存结合语义感知注意力是高效高质量文本生成视频的有效路径。

Abstract: Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.

</details>


### [19] [IRIS: Intent Resolution via Inference-time Saccades for Open-Ended VQA in Large Vision-Language Models](https://arxiv.org/abs/2602.16138)
*Parsa Madinei,Srijita Karmakar,Russell Cohen Hoffing,Felix Gervitz,Miguel P. Eckstein*

Main category: cs.CV

TL;DR: IRIS是一种无需训练的新方法，利用实时眼动追踪数据解决开放性视觉问答（VQA）中的歧义问题，在模糊问题上将大视觉语言模型（VLM）回答准确率从35.2%提升至77.2%，同时保持对非模糊问题的性能。


<details>
  <summary>Details</summary>
Motivation: 解决开放性视觉问答中因图像-问题对存在歧义而导致大视觉语言模型（VLM）回答不准确的问题。

Method: 提出IRIS（通过推理时扫视进行意图解析），在推理阶段实时融合眼动数据（尤其是提问起始时刻附近的注视点），无需额外训练。

Result: 在500组独特图像-问题对的用户研究中，IRIS使模糊问题回答准确率从35.2%提升至77.2%，且在多种SOTA VLM上表现稳健；并发布新基准数据集、实时交互协议与评估套件。

Conclusion: 眼动数据（特别是提问初期的注视）是解析用户视觉意图的有效实时信号，IRIS为训练无关、可即插即用的VQA歧义消解提供了新范式。

Abstract: We introduce IRIS (Intent Resolution via Inference-time Saccades), a novel training-free approach that uses eye-tracking data in real-time to resolve ambiguity in open-ended VQA. Through a comprehensive user study with 500 unique image-question pairs, we demonstrate that fixations closest to the time participants start verbally asking their questions are the most informative for disambiguation in Large VLMs, more than doubling the accuracy of responses on ambiguous questions (from 35.2% to 77.2%) while maintaining performance on unambiguous queries. We evaluate our approach across state-of-the-art VLMs, showing consistent improvements when gaze data is incorporated in ambiguous image-question pairs, regardless of architectural differences. We release a new benchmark dataset to use eye movement data for disambiguated VQA, a novel real-time interactive protocol, and an evaluation suite.

</details>


### [20] [Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing](https://arxiv.org/abs/2602.16149)
*Huichan Seo,Minki Hong,Sieun Choi,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 本文研究了图像到图像（I2I）编辑中基于人口统计学特征的偏差问题，提出了两种失败模式：软擦除和刻板印象替换，并构建了一个受控基准来评估多种开源I2I编辑器在种族、性别和年龄条件下的表现；结果表明身份保持失败普遍存在且具有人口统计学差异，而简单的提示级身份约束即可显著缓解少数群体的身份变化。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像（T2I）生成中的群体偏差已被广泛研究，但指令引导的图像到图像（I2I）编辑中与人口统计学相关的失败仍缺乏深入探索。本文旨在揭示I2I编辑中是否存在系统性、依赖于被编辑对象人口统计属性的编辑失败。

Method: 提出并形式化两种失败模式（软擦除、刻板印象替换），构建一个控制变量的基准测试集，涵盖不同种族、性别和年龄的人物肖像及其诊断性编辑提示；采用视觉语言模型（VLM）自动评分与人工评估相结合的方式对多个开源I2I编辑器进行评测；进一步设计提示级身份约束策略以缓解偏差。

Result: 发现身份保持失败在I2I编辑中普遍存在、分布不均，且受隐含社会先验（如职业驱动的性别推断）影响；提示级身份约束可在不修改模型的前提下显著减少少数群体的身份改变，而对多数群体影响甚微，揭示当前编辑器存在不对称的身份先验。

Conclusion: 身份保持是I2I编辑中一个核心且具有人口统计学差异的失败模式；应推动构建对人口统计信息鲁棒的I2I编辑系统。

Abstract: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) editing remain underexplored. We examine whether identical edit instructions yield systematically different outcomes across subject demographics in open-weight I2I editors. We formalize two failure modes: Soft Erasure, where edits are silently weakened or ignored in the output image, and Stereotype Replacement, where edits introduce unrequested, stereotype-consistent attributes. We introduce a controlled benchmark that probes demographic-conditioned behavior by generating and editing portraits conditioned on race, gender, and age using a diagnostic prompt set, and evaluate multiple editors with vision-language model (VLM) scoring and human evaluation. Our analysis shows that identity preservation failures are pervasive, demographically uneven, and shaped by implicit social priors, including occupation-driven gender inference. Finally, we demonstrate that a prompt-level identity constraint, without model updates, can substantially reduce demographic change for minority groups while leaving majority-group portraits largely unchanged, revealing asymmetric identity priors in current editors. Together, our findings establish identity preservation as a central and demographically uneven failure mode in I2I editing and motivate demographic-robust editing systems. Project page: https://seochan99.github.io/i2i-demographic-bias

</details>


### [21] [Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking](https://arxiv.org/abs/2602.16160)
*Patrick Poggi,Divake Kumar,Theja Tulabandhula,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 本文提出UncL-STARK，一种在不修改网络结构或添加额外模块的前提下，实现Transformer跟踪器动态、不确定性感知的深度自适应方法，通过随机深度训练与知识蒸馏提升中间层鲁棒性，并利用热图不确定性估计和反馈策略选择每帧的编码器/解码器深度，在显著降低计算开销（GFLOPs、延迟、能耗）的同时几乎不损失精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的单目标跟踪器采用固定深度推理，对每一帧均执行完整的编码器-解码器流程，导致在长视频中（尤其帧间高度一致时）产生大量冗余计算。

Method: 提出UncL-STARK：1）保持原架构，通过随机深度训练+知识蒸馏使模型在多个中间深度仍具预测鲁棒性；2）从角点定位热图中导出轻量级不确定性估计；3）设计反馈驱动策略，依据当前帧预测置信度与视频时序一致性动态决定下一帧的编码器和解码器深度。

Result: 在GOT-10k和LaSOT数据集上实验表明，相比全深度基线，UncL-STARK可减少最多12% GFLOPs、8.9%延迟、10.8%能耗，且跟踪精度下降不超过0.2%。

Conclusion: UncL-STARK实现了高效、准确、即插即用的动态深度推理，在保持SOTA精度的同时显著提升Transformer跟踪器的实际部署效率。

Abstract: Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences dominated by temporally coherent frames. We propose UncL-STARK, an architecture-preserving approach that enables dynamic, uncertainty-aware depth adaptation in transformer-based trackers without modifying the underlying network or adding auxiliary heads. The model is fine-tuned to retain predictive robustness at multiple intermediate depths using random-depth training with knowledge distillation, thus enabling safe inference-time truncation. At runtime, we derive a lightweight uncertainty estimate directly from the model's corner localization heatmaps and use it in a feedback-driven policy that selects the encoder and decoder depth for the next frame based on the prediction confidence by exploiting temporal coherence in video. Extensive experiments on GOT-10k and LaSOT demonstrate up to 12\% GFLOPs reduction, 8.9\% latency reduction, and 10.8\% energy savings while maintaining tracking accuracy within 0.2\% of the full-depth baseline across both short-term and long-term sequences.

</details>


### [22] [DataCube: A Video Retrieval Platform via Natural Language Semantic Profiling](https://arxiv.org/abs/2602.16231)
*Yiming Ju,Hanyu Zhao,Quanyue Ma,Donglin Hao,Chengwei Wu,Ming Li,Songjing Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: DataCube是一个面向大规模视频库的智能平台，支持自动视频处理、多维语义建模与查询驱动检索，帮助用户高效构建定制化视频子集。


<details>
  <summary>Details</summary>
Motivation: 大规模视频库日益丰富，但将原始视频转化为高质量、任务特定的数据集成本高、效率低。

Method: 提出DataCube平台，通过构建视频片段的结构化语义表示，结合神经重排序与深度语义匹配实现混合检索，并提供交互式Web界面。

Result: 实现了对海量视频库的高效定制子集构建与私有视频集合的可搜索系统，平台已公开上线并提供演示视频。

Conclusion: DataCube显著提升了视频数据集构建的自动化与智能化水平，为视频理解与生成任务提供了实用基础设施。

Abstract: Large-scale video repositories are increasingly available for modern video understanding and generation tasks. However, transforming raw videos into high-quality, task-specific datasets remains costly and inefficient. We present DataCube, an intelligent platform for automatic video processing, multi-dimensional profiling, and query-driven retrieval. DataCube constructs structured semantic representations of video clips and supports hybrid retrieval with neural re-ranking and deep semantic matching. Through an interactive web interface, users can efficiently construct customized video subsets from massive repositories for training, analysis, and evaluation, and build searchable systems over their own private video collections. The system is publicly accessible at https://datacube.baai.ac.cn/. Demo Video: https://baai-data-cube.ks3-cn-beijing.ksyuncs.com/custom/Adobe%20Express%20-%202%E6%9C%8818%E6%97%A5%20%281%29%281%29%20%281%29.mp4

</details>


### [23] [EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection](https://arxiv.org/abs/2602.16238)
*Hiroki Nakamura,Hiroto Iino,Masashi Okada,Tadahiro Taniguchi*

Main category: cs.CV

TL;DR: 本文提出了EasyControlEdge，一种将图像生成基础模型适配到边缘检测任务的新方法，通过边缘导向的目标函数和无条件动态引导机制，实现了高清晰度、数据高效且可调节边缘密度的边缘检测。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的边缘检测（如建筑平面图、卫星图像、医学图像）对边缘的清晰度和数据效率要求很高，但现有方法在有限训练样本下难以生成清晰的原始边缘图。

Method: 提出EasyControlEdge方法，将图像生成基础模型适配到边缘检测；引入边缘导向的像素空间损失函数以增强边缘特化；在推理阶段采用基于无条件动态的引导机制，实现通过引导尺度控制边缘密度。

Result: 在BSDS500、NYUDv2、BIPED和CubiCasa数据集上的实验表明，该方法在无后处理的清晰度评估和小样本设置下均显著优于当前最先进方法。

Conclusion: EasyControlEdge有效挖掘了图像生成基础模型在数据高效迁移与高频细节保持方面的潜力，为边缘检测提供了一种新颖、灵活且高性能的解决方案。

Abstract: We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.

</details>


### [24] [HyPCA-Net: Advancing Multimodal Fusion in Medical Image Analysis](https://arxiv.org/abs/2602.16245)
*J. Dhar,M. K. Pandey,D. Chakladar,M. Haghighat,A. Alavi,S. Mistry,N. Zaidi*

Main category: cs.CV

TL;DR: 本文提出了一种高效、鲁棒的多模态医学图像融合网络HyPCA-Net，通过并行-级联混合注意力机制，在提升多疾病分析性能的同时大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态融合方法存在计算开销大、级联注意力易导致信息损失、难以学习跨模态鲁棒共享表征等问题，限制其在低资源环境和多病种分析中的泛化能力。

Method: 提出HyPCA-Net，包含两个核心模块：(a) 计算高效的残差自适应学习注意力块，用于提取精细的模态特异性表征；(b) 双视图级联注意力块，用于学习跨模态鲁棒共享表征。

Result: 在10个公开数据集上实验表明，HyPCA-Net相较SOTA方法最高提升5.2%性能，计算成本最多降低73.1%。

Conclusion: HyPCA-Net兼顾效率与表征能力，为低资源场景下的多模态医学图像分析提供了新范式。

Abstract: Multimodal fusion frameworks, which integrate diverse medical imaging modalities (e.g., MRI, CT), have shown great potential in applications such as skin cancer detection, dementia diagnosis, and brain tumor prediction. However, existing multimodal fusion methods face significant challenges. First, they often rely on computationally expensive models, limiting their applicability in low-resource environments. Second, they often employ cascaded attention modules, which potentially increase risk of information loss during inter-module transitions and hinder their capacity to effectively capture robust shared representations across modalities. This restricts their generalization in multi-disease analysis tasks. To address these limitations, we propose a Hybrid Parallel-Fusion Cascaded Attention Network (HyPCA-Net), composed of two core novel blocks: (a) a computationally efficient residual adaptive learning attention block for capturing refined modality-specific representations, and (b) a dual-view cascaded attention block aimed at learning robust shared representations across diverse modalities. Extensive experiments on ten publicly available datasets exhibit that HyPCA-Net significantly outperforms existing leading methods, with improvements of up to 5.2% in performance and reductions of up to 73.1% in computational cost. Code: https://github.com/misti1203/HyPCA-Net.

</details>


### [25] [AFFMAE: Scalable and Efficient Vision Pretraining for Desktop Graphics Cards](https://arxiv.org/abs/2602.16249)
*David Smerkous,Zian Wang,Behzad Najafian*

Main category: cs.CV

TL;DR: AFFMAE是一种面向高分辨率图像自监督预训练的新型框架，通过自适应、非网格化token合并与混合精度稀疏注意力机制，在保持性能的同时显著降低计算与内存开销。


<details>
  <summary>Details</summary>
Motivation: 高分辨率自监督预训练通常依赖大规模服务器资源，限制了中小型实验室开发领域基础模型的能力；现有MAE与分层架构结合存在结构不兼容问题。

Method: 提出AFFMAE框架：采用仅对可见token进行动态合并的自适应非网格token合并策略；设计数值稳定的混合精度Flash式聚类注意力核；引入深度监督缓解稀疏阶段表征坍缩。

Result: 在高分辨率电子显微镜分割任务上，AFFMAE在同等参数量下达到ViT-MAE性能，FLOPs降低至1/7，内存减半，并可在单张RTX 5090上更快完成训练。

Conclusion: AFFMAE成功解耦掩码机制与分层架构的结构性冲突，为资源受限场景下的高分辨率视觉基础模型预训练提供了高效可行的新范式。

Abstract: Self-supervised pretraining has transformed computer vision by enabling data-efficient fine-tuning, yet high-resolution training typically requires server-scale infrastructure, limiting in-domain foundation model development for many research laboratories. Masked Autoencoders (MAE) reduce computation by encoding only visible tokens, but combining MAE with hierarchical downsampling architectures remains structurally challenging due to dense grid priors and mask-aware design compromises. We introduce AFFMAE, a masking-friendly hierarchical pretraining framework built on adaptive, off-grid token merging. By discarding masked tokens and performing dynamic merging exclusively over visible tokens, AFFMAE removes dense-grid assumptions while preserving hierarchical scalability. We developed numerically stable mixed-precision Flash-style cluster attention kernels, and mitigate sparse-stage representation collapse via deep supervision. On high-resolution electron microscopy segmentation, AFFMAE matches ViT-MAE performance at equal parameter count while reducing FLOPs by up to 7x, halving memory usage, and achieving faster training on a single RTX 5090. Code available at https://github.com/najafian-lab/affmae.

</details>


### [26] [Breaking the Sub-Millimeter Barrier: Eyeframe Acquisition from Color Images](https://arxiv.org/abs/2602.16281)
*Manel Guzmán,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角人工视觉的新型眼镜框轮廓追踪方法，利用InVision系统采集的彩色图像，结合图像分割、深度估计与多视角融合，实现亚毫米级精度的无接触式测量，无需专用机械设备，简化了验光师工作流程。


<details>
  <summary>Details</summary>
Motivation: 传统机械式眼镜框追踪需精确校准和定位，耗时且依赖额外设备，导致验光工作流低效。

Method: 基于InVision系统采集的多视角彩色图像，构建完整处理流程：图像获取→眼镜框前景分割→深度估计→RGB图像与深度数据的多视角融合，以提取高精度三维轮廓。

Result: 在真实数据上验证了多种配置与变体，所得轮廓测量精度达亚毫米级，媲美现有方案，且仅需静态彩色图像，无需专用追踪硬件。

Conclusion: 该视觉驱动方法有效替代传统机械追踪，显著降低设备依赖与操作复杂度，提升了光学配镜流程的自动化与实用性。

Abstract: Eyeframe lens tracing is an important process in the optical industry that requires sub-millimeter precision to ensure proper lens fitting and optimal vision correction. Traditional frame tracers rely on mechanical tools that need precise positioning and calibration, which are time-consuming and require additional equipment, creating an inefficient workflow for opticians. This work presents a novel approach based on artificial vision that utilizes multi-view information. The proposed algorithm operates on images captured from an InVision system. The full pipeline includes image acquisition, frame segmentation to isolate the eyeframe from background, depth estimation to obtain 3D spatial information, and multi-view processing that integrates segmented RGB images with depth data for precise frame contour measurement. To this end, different configurations and variants are proposed and analyzed on real data, providing competitive measurements from still color images with respect to other solutions, while eliminating the need for specialized tracing equipment and reducing workflow complexity for optical technicians.

</details>


### [27] [A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks](https://arxiv.org/abs/2602.16322)
*Santiago C. Vilabella,Pablo Pérez-Núñez,Beatriz Remeseiro*

Main category: cs.CV

TL;DR: 本文提出了一种基于自监督学习的特征提取器增强方法，能够在少量标注数据下学习更有效的表征，超越ImageNet预训练及专为检测设计的特征提取器，并提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标注数据获取成本高、耗时长，尤其在目标检测等复杂任务中，制约了深度学习模型的开发与应用。

Method: 采用自监督学习策略，在无标签数据上训练特征提取器，以提升其在少量标注数据下的表征能力。

Result: 所提模型在无标签数据上训练后，性能超越ImageNet预训练及专为检测设计的先进特征提取器；且能聚焦物体关键区域，获得更优、更鲁棒的特征表示。

Conclusion: 增强特征提取器（尤其是通过自监督学习）可显著缓解标注数据稀缺问题，提升模型在低资源场景下的有效性与可靠性。

Abstract: In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.

</details>


### [28] [Subtractive Modulative Network with Learnable Periodic Activations](https://arxiv.org/abs/2602.16337)
*Tiou Wang,Zhuoqian Yang,Markus Flierl,Mathieu Salzmann,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 本文提出了一种受减法合成启发的新型隐式神经表示（INR）架构——减法调制网络（SMN），通过可学习周期激活层和调制掩码模块实现高效多频信号建模，在图像重建与NeRF任务中均取得高PSNR和参数效率优势。


<details>
  <summary>Details</summary>
Motivation: 提升隐式神经表示（INR）的参数效率与建模能力，借鉴经典减法合成思想构建更符合信号处理原理的网络结构。

Method: 设计Subtractive Modulative Network（SMN），包含可学习周期激活层（Oscillator）生成多频基，以及一系列调制掩码模块（Filters）生成高阶谐波；结合理论分析与实验验证。

Result: 在两个图像数据集上PSNR达40+ dB，优于当前SOTA方法；在3D NeRF新视角合成任务中也展现出稳定优势。

Conclusion: SMN是一种参数高效、原理清晰的INR新架构，兼具高重建精度与强泛化能力，为隐式表示提供了新的信号处理视角。

Abstract: We propose the Subtractive Modulative Network (SMN), a novel, parameter-efficient Implicit Neural Representation (INR) architecture inspired by classical subtractive synthesis. The SMN is designed as a principled signal processing pipeline, featuring a learnable periodic activation layer (Oscillator) that generates a multi-frequency basis, and a series of modulative mask modules (Filters) that actively generate high-order harmonics. We provide both theoretical analysis and empirical validation for our design. Our SMN achieves a PSNR of $40+$ dB on two image datasets, comparing favorably against state-of-the-art methods in terms of both reconstruction accuracy and parameter efficiency. Furthermore, consistent advantage is observed on the challenging 3D NeRF novel view synthesis task. Supplementary materials are available at https://inrainbws.github.io/smn/.

</details>


### [29] [SCAR: Satellite Imagery-Based Calibration for Aerial Recordings](https://arxiv.org/abs/2602.16349)
*Henry Hölzemann,Michael Schleiss*

Main category: cs.CV

TL;DR: SCAR是一种利用地理参考卫星影像进行空中视觉-惯性系统长期自动校准优化的方法，通过2D-3D匹配实现内、外参估计，无需人工干预，在多种环境条件下显著降低重投影误差和定位误差。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法依赖专用校准动作或人工布设的地面控制点，难以应对野外部署中长期校准参数退化问题；需一种基于外部地理空间数据、无需手动干预的持续自动校准方案。

Method: 提出SCAR方法，利用公开正射影像和数字高程模型生成2D-3D对应关系，将航拍图像与地理参考影像对齐，联合估计相机内参和外参，实现长期在线校准优化。

Result: 在两年间六次大规模空中作业数据上验证，SCAR显著优于Kalibr、COLMAP和VINS-Mono等基线方法，中位重投影误差大幅下降，并带来视觉定位旋转误差降低和位姿精度提升。

Conclusion: SCAR实现了准确、鲁棒且可复现的长期空中系统自动校准，摆脱了对人工操作和特定校准场景的依赖。

Abstract: We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.

</details>


### [30] [Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired](https://arxiv.org/abs/2602.16385)
*Qi He,XiangXiang Wang,Jingtao Zhang,Yongbin Yu,Hongxiang Chu,Manping Fan,JingYe Cai,Zhenglin Yang*

Main category: cs.CV

TL;DR: 本文提出了一种自适应多尺度注意力聚合（AMAA）框架，用于单目3D语义场景补全（SSC），通过可靠性导向的体素特征调节和分层自适应特征门控策略，提升了结构稳定性和语义一致性，并在NYUv2数据集和Jetson嵌入式平台验证了其有效性与可部署性。


<details>
  <summary>Details</summary>
Motivation: 现有单目SSC方法缺乏对体素特征可靠性的显式建模及跨尺度信息传播的规范控制，易受投影扩散和特征纠缠影响，限制结构稳定性，难以满足视障用户室内辅助感知的安全关键需求。

Method: 在MonoScene框架基础上构建AMAA：1）对提升后的体素特征，在语义与空间维度上并行进行通道-空间注意力聚合以联合校准；2）采用分层自适应特征门控策略，调控编码器-解码器多尺度融合中的信息注入。

Result: 在NYUv2基准上，SSC mIoU达27.25%（+0.31），SC IoU达43.10%（+0.59）；完整框架可在NVIDIA Jetson嵌入式平台稳定部署。

Conclusion: AMAA在不显著增加系统复杂度的前提下，提升了单目SSC的质量与鲁棒性，为面向视障用户的室内辅助感知系统提供了可靠、可部署的解决方案。

Abstract: In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural stability.To address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across scales.Experiments on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.

</details>


### [31] [ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding](https://arxiv.org/abs/2602.16412)
*Daichi Yashima,Shuhei Kurita,Yusuke Oda,Komei Sugiura*

Main category: cs.CV

TL;DR: 本文提出ReMoRa，一种基于视频压缩表示的多模态大语言模型，通过保留稀疏RGB关键帧和引入去噪后的细粒度运动表征（作为光流的紧凑代理）来高效理解长视频，显著降低计算复杂度并提升长视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 长视频理解在MLLM中仍具挑战性，因直接处理全部RGB帧计算不可行且冗余，自注意力机制的序列长度二次复杂度加剧了该问题。

Method: 提出ReMoRa模型：1）仅保留稀疏RGB关键帧表征外观；2）用块级运动表示编码时序动态，并通过专用模块去噪并生成细粒度运动表征，替代完整光流；3）特征压缩方式实现线性序列长度扩展。

Result: 在LongVideoBench、NExT-QA和MLVU等多个长视频理解基准上，ReMoRa显著优于基线方法。

Conclusion: 基于压缩表示（关键帧+去噪运动表征）的建模范式可有效缓解长视频理解中的计算与冗余瓶颈，为高效视频MLLM提供新思路。

Abstract: While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.

</details>


### [32] [Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems](https://arxiv.org/abs/2602.16430)
*Ali Faraz,Raja Kolla,Ashish Kulkarni,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文研究了两种基于视觉-语言模型的多语言OCR系统训练策略，发现微调现有OCR模型在准确率与延迟权衡上优于端到端训练；提出的Chitrapathak-2和Parichay系列在印度多语言OCR和政府文档结构化识别任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 印度OCR系统需兼顾语言多样性、文档异质性和部署限制，现有方法在准确率与效率间难以平衡。

Method: 比较两种策略：1）端到端训练通用视觉编码器+多语言语言模型；2）微调未针对目标语言预训练的现有OCR模型；并构建专用模型Parichay用于9类印度政府文档关键字段提取。

Result: Chitrapathak-2在Telugu上达SOTA（6.69 char ANLS），其余语种第二；较前代提速3–6倍；Parichay在政府文档结构化识别中达89.8% Exact Match且推理更快。

Conclusion: 微调OCR模型比端到端多模态训练更适用于印度多语言OCR实际部署；Chitrapathak与Parichay系列为构建生产级OCR系统提供了有效范式与实践指导。

Abstract: Designing Optical Character Recognition (OCR) systems for India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder with a strong multilingual language model and training the system end-to-end for OCR. Alternatively, we explore fine-tuning an existing OCR model, despite not being trained for the target languages. Through extensive evaluation on multilingual Indic OCR benchmarks and deployment-oriented metrics, we find that the second strategy consistently achieves better accuracy-latency trade-offs. Chitrapathak-2 achieves 3-6x speedup over its predecessor with being state-of-the-art (SOTA) in Telugu (6.69 char ANLS) and second best in the rest. In addition, we present Parichay, an independent OCR model series designed specifically for 9 Indian government documents to extract structured key fields, achieving 89.8% Exact Match score with a faster inference. Together, these systems achieve SOTA performance and provide practical guidance for building production-scale OCR pipelines in the Indian context.

</details>


### [33] [Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing](https://arxiv.org/abs/2602.16455)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为Visual Self-Refine（VSR）的新范式，通过像素级定位与视觉反馈机制提升大视觉语言模型在图表解析等视觉密集型任务中的准确性，并构建了新基准ChartP-Bench验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在文本推理和自修正方面表现优异，但在以视觉感知为核心的复杂任务（如图表解析）中仍存在数据遗漏、错位和幻觉等问题，缺乏有效的视觉层面自检机制。

Method: 受人类用手指作为视觉锚点阅读图表的启发，提出VSR范式：模型生成像素级定位→可视化→将可视化结果反馈给自身进行迭代检查与修正；在图表解析任务中实例化为ChartVSR，分为Refine Stage（视觉反馈迭代精确定位）与Decode Stage（基于验证后的定位解析结构化数据）；同时构建高难度新基准ChartP-Bench。

Result: ChartVSR在图表解析任务上显著优于现有方法，尤其在处理视觉密集图表时大幅降低数据遗漏、错位和幻觉错误；ChartP-Bench为该领域提供了更具挑战性的评估基准；VSR被验证为一种通用的视觉反馈机制。

Conclusion: VSR范式通过引入可反馈的像素级视觉锚点，有效弥补了LVLM在视觉感知准确性上的短板，为提升各类视觉中心任务的精度提供了新思路和通用框架。

Abstract: While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.

</details>


### [34] [MMA: Multimodal Memory Agent](https://arxiv.org/abs/2602.16493)
*Yihao Lu,Wanru Cheng,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出多模态记忆代理（MMA），通过动态可靠性评分机制（结合来源可信度、时间衰减与冲突感知共识）改进长时程多模态代理的记忆检索与证据加权，并引入MMA-Bench基准评估信念动态；实验表明MMA显著提升稳定性、选择性效用与安全性，且揭示了RAG代理中由基础模型继承的‘视觉安慰剂效应’。


<details>
  <summary>Details</summary>
Motivation: 长时程多模态代理依赖外部记忆，但基于相似性的检索常召回过时、低可信或相互冲突的信息，导致过度自信错误。

Method: 提出Multimodal Memory Agent（MMA），为每个检索项分配动态可靠性得分（融合源可信度、时间衰减和冲突感知网络共识），并据此重加权证据、在支持不足时主动拒答；同时构建可控的多模态矛盾基准MMA-Bench。

Result: 在FEVER上准确率持平但方差降低35.2%、选择性效用提升；在LoCoMo中安全配置下提升可操作准确率并减少错误回答；在MMA-Bench的Vision模式下Type-B准确率达41.18%，而基线崩溃至0.0%。

Conclusion: MMA通过动态可靠性建模有效缓解记忆检索中的可信度与一致性问题，显著提升多模态代理的鲁棒性、安全性和选择性决策能力，并揭示了视觉模态引入的隐性偏差问题。

Abstract: Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often surfaces stale, low-credibility, or conflicting items, which can trigger overconfident errors. We propose Multimodal Memory Agent (MMA), which assigns each retrieved memory item a dynamic reliability score by combining source credibility, temporal decay, and conflict-aware network consensus, and uses this signal to reweight evidence and abstain when support is insufficient. We also introduce MMA-Bench, a programmatically generated benchmark for belief dynamics with controlled speaker reliability and structured text-vision contradictions. Using this framework, we uncover the "Visual Placebo Effect", revealing how RAG-based agents inherit latent visual biases from foundation models. On FEVER, MMA matches baseline accuracy while reducing variance by 35.2% and improving selective utility; on LoCoMo, a safety-oriented configuration improves actionable accuracy and reduces wrong answers; on MMA-Bench, MMA reaches 41.18% Type-B accuracy in Vision mode, while the baseline collapses to 0.0% under the same protocol. Code: https://github.com/AIGeeksGroup/MMA.

</details>


### [35] [Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection](https://arxiv.org/abs/2602.16494)
*Alexis Winter,Jean-Vincent Martini,Romaric Audigier,Angelique Loesch,Bertrand Luvison*

Main category: cs.CV

TL;DR: 本文提出了一种针对目标检测模型的统一对抗攻击基准框架，系统评估了攻击可迁移性（尤其CNN到ViT）及对抗训练策略有效性，发现现代攻击对Transformer架构迁移性差，且混合多目标高扰动攻击的数据集能带来最强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目标检测模型在自动驾驶等关键系统中应用广泛，但其对抗脆弱性严重威胁安全；而当前防御研究受限于缺乏标准化评估，导致攻击与防御方法难以公平比较。

Method: 构建面向数字、非补丁式攻击的统一基准框架，引入解耦定位与分类误差的指标，并采用多种感知度量评估扰动代价；在此框架下对前沿攻击和多种检测器进行大规模实验。

Result: 1）现代对抗攻击对Transformer架构（如ViT）迁移性显著下降；2）采用混合多种目标（如空间与语义）的高扰动攻击样本构成的数据集进行对抗训练，效果优于单一攻击类型训练。

Conclusion: 统一评估基准对推动目标检测鲁棒性研究至关重要；提升迁移性需新攻击设计，而混合多目标攻击训练是当前最有效的防御策略。

Abstract: Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.

</details>


### [36] [DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images](https://arxiv.org/abs/2602.16502)
*Zeng Tao,Ying Jiang,Yunuo Chen,Tianyi Xie,Huamin Wang,Yingnian Wu,Yin Yang,Abishek Sampath Kumar,Kenji Tashiro,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: DressWild 是一种新型前馈式管线，能从单张野外图像中重建物理一致的2D裁剪纸样及对应3D服装，利用视觉语言模型归一化姿态并提取3D感知特征，通过Transformer融合后预测可编辑、可仿真、可分层试穿的纸样参数。


<details>
  <summary>Details</summary>
Motivation: 现有前馈方法难以处理多样姿态与视角，而基于优化的方法计算昂贵、难以扩展；实际应用需要可编辑、可分离、可仿真的服装纸样。

Method: 提出 DressWild 前馈管线：利用视觉语言模型（VLM）在图像级归一化姿态，提取姿态感知且3D信息增强的服装特征，经Transformer编码器融合后预测2D缝纫纸样参数。

Result: 在野外单图输入下，无需多视角或迭代优化，即可鲁棒恢复多样化缝纫纸样及对应3D服装，支持物理仿真、纹理合成与多层虚拟试穿。

Conclusion: DressWild 提供了一种高效、可扩展的解决方案，推动了真实感服装建模、仿真与动画的发展。

Abstract: Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.

</details>


### [37] [Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.16545)
*Kaiting Liu,Hazel Doughty*

Main category: cs.CV

TL;DR: 本文提出了一种名为'类别拆分'的新任务，旨在无需大量新标注数据的情况下，将视频识别模型中粗粒度类别细分为更精细的子类别，并保持其他类别的准确率。作者设计了一种零样本编辑方法，利用视频分类器潜在的组合结构进行细粒度区分，并辅以少量样本微调，显著优于现有视觉-语言基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频识别模型通常在固定、粗粒度的类别体系上训练，难以适应任务和定义的变化；重新标注和训练成本高昂，亟需一种能动态细化类别的高效方法。

Method: 提出零样本编辑方法，利用视频分类器的潜在组合结构实现类别拆分；并结合低样本微调策略，以零样本结果为初始化提升性能。

Result: 在新建的视频类别拆分基准上，该方法在新拆分子类别上显著提升准确率，同时不损害其余类别性能，大幅超越视觉-语言基线模型。

Conclusion: 类别拆分是一种实用且可扩展的模型编辑范式，零样本初始化加低样本微调的策略有效平衡了泛化性与适应性，为视频识别系统的持续演进提供了新路径。

Abstract: Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.

</details>


### [38] [Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face](https://arxiv.org/abs/2602.16569)
*Nicolò Di Domenico,Annalisa Franco,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 本文提出了一种基于Arc2Face身份条件生成模型的新型人脸融合攻击方法，该方法在保持身份信息的同时生成高逼真度融合图像，在多个数据集上展现出与传统地标法相当的攻击潜力。


<details>
  <summary>Details</summary>
Motivation: 针对电子身份证件中人脸识别系统面临的人脸融合攻击威胁，尤其是护照注册过程中缺乏活体监督采集所导致的安全漏洞。

Method: 基于Arc2Face这一身份条件化的人脸基础模型，从紧凑的身份表征合成高保真度人脸图像，实现新型人脸融合攻击。

Result: 在多个封闭测试数据集（包括两个新构建的FEI和ONOT衍生融合人脸数据集）上，该方法的融合攻击潜力指标与当前最优的基于关键点的方法相当。

Conclusion: 所提深度学习方法能有效保留并调控身份信息，生成具备高攻击性的融合人脸，对现有证件人脸识别系统构成实质性威胁，凸显了活体检测与安全注册流程升级的紧迫性。

Abstract: Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.

</details>


### [39] [A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification](https://arxiv.org/abs/2602.16590)
*Qi You,Yitai Cheng,Zichao Zeng,James Haworth*

Main category: cs.CV

TL;DR: 本文提出CLIP-MHAdapter，一种轻量级CLIP适配方法，在patch token上引入多头自注意力机制以建模局部依赖，显著提升街景图像属性分类性能，同时保持低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的街景图像属性分类方法多依赖全局图像嵌入，难以捕捉复杂街景中细粒度、局部化的属性信息，且计算成本高。

Method: 提出CLIP-MHAdapter，在CLIP视觉编码器输出的patch tokens上附加一个带多头自注意力机制的瓶颈MLP，以建模patch间依赖关系，仅引入约140万可训练参数。

Result: 在Global StreetScapes数据集的8个属性分类任务上达到SOTA或具有竞争力的精度，同时计算成本低。

Conclusion: CLIP-MHAdapter验证了利用局部patch交互增强CLIP适应街景细粒度理解的有效性，为轻量高效视觉适配提供了新思路。

Abstract: Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.

</details>


### [40] [Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge](https://arxiv.org/abs/2602.16664)
*Jiaming Liu,Felix Petersen,Yunhe Gao,Yabin Zhang,Hyojin Kim,Akshay S. Chaudhari,Yu Sun,Stefano Ermon,Sergios Gatidis*

Main category: cs.CV

TL;DR: 本文提出了一种名为Self-Supervised Semantic Bridge（SSB）的框架，通过引入自监督视觉编码器学习几何不变但外观鲁棒的语义表征，构建共享潜在空间以指导扩散模型桥接，从而在无需跨域监督的情况下实现高保真、空间一致的无配对图像翻译。


<details>
  <summary>Details</summary>
Motivation: 现有对抗式扩散和扩散反演方法分别存在泛化能力差和重建保真度低的问题，亟需一种无需目标域对抗损失、且能提升翻译空间一致性和保真度的新范式。

Method: 提出SSB框架：利用自监督视觉编码器提取对表观变化鲁棒但保留几何结构的语义特征，构建跨域共享的语义潜在空间，并以此作为条件引导扩散桥模型进行图像翻译。

Result: 在医学图像合成任务中，SSB在域内与域外设置下均显著优于现有强基线；同时可自然扩展至高质量文本引导编辑任务。

Conclusion: SSB通过融合外部语义先验与自监督表征学习，有效解耦几何与外观信息，在无配对、无跨域监督条件下实现了更鲁棒、高保真的图像翻译，为扩散模型在下游应用中提供了新思路。

Abstract: Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.

</details>


### [41] [PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction](https://arxiv.org/abs/2602.16669)
*Bo Lang,Nirav Savaliya,Zhihao Zheng,Jinglun Feng,Zheng-Hang Yeh,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 本文提出了一种端到端在线高精矢量化地图构建框架，通过语义感知查询生成、历史光栅化地图记忆、历史地图引导和短期未来引导模块，提升地图实例跟踪与预测的时序一致性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的HD地图构建方法存在随机查询初始化和隐式时序建模问题，导致全局地图构建中出现时序不一致与不稳定。

Method: 提出包含四个核心模块的端到端框架：1）语义感知查询生成器（空间对齐语义掩码初始化查询）；2）历史光栅化地图记忆（存储实例级历史地图）；3）历史地图引导模块（将光栅地图信息融入跟踪查询）；4）短期未来引导模块（基于历史轨迹预测实例短期运动并提供位置提示）。

Result: 在nuScenes和Argoverse2数据集上显著优于SOTA方法，兼具高性能与高效率。

Conclusion: 所提框架有效提升了在线HD矢量化地图构建的时序一致性、稳定性与预测合理性，为自动驾驶提供更可靠的结构化地图支持。

Abstract: High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.

</details>


### [42] [VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection](https://arxiv.org/abs/2602.16681)
*Yingyuan Yang,Tian Lan,Yifei Gao,Yimeng Lu,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.CV

TL;DR: 本文提出VETime，首个统一时序与视觉模态的时序异常检测框架，通过细粒度视觉-时序对齐与动态融合，兼顾点级定位精度与全局上下文建模能力，在零样本场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时序异常检测模型在点异常（精细定位）与上下文异常（全局感知）之间存在根本性权衡：1D时序模型缺乏全局视角，2D视觉模型则因时间不对齐和点级分辨率低而受限。

Method: 提出VETime框架，包含可逆图像转换、片级时序对齐模块以构建共享视觉-时序时间线；并设计异常窗口对比学习与任务自适应多模态融合机制，实现两模态优势互补。

Result: 在零样本设置下显著超越SOTA方法，定位精度更高、计算开销低于当前视觉方法。

Conclusion: VETime成功弥合了时序建模与视觉建模在TSAD中的鸿沟，验证了细粒度跨模态对齐与动态融合的有效性，为多模态时序理解提供了新范式。

Abstract: Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.

</details>


### [43] [Learning Situated Awareness in the Real World](https://arxiv.org/abs/2602.16682)
*Chuhan Li,Ruilin Han,Joy Hsu,Yongyuan Liang,Rajiv Dhawan,Jiajun Wu,Ming-Hsuan Yang,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本文提出SAW-Bench，首个面向真实世界视频的自我中心情境感知评测基准，聚焦观察者视角下的空间关系理解，揭示当前多模态基础模型在该任务上存在显著性能差距（37.66%）及几何推理缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型评测基准偏重环境中心的空间关系，忽视观察者中心（即以佩戴者视角、姿态、运动为参照）的情境感知能力，亟需新基准填补空白。

Method: 构建SAW-Bench基准：采集786段真实场景第一人称视频（Ray-Ban Meta智能眼镜），含2071组人工标注问答对，覆盖6类观察者中心感知任务，并对主流多模态模型进行系统评测与归因分析。

Result: 最佳模型Gemini 3 Flash仍落后人类37.66%；模型虽能利用部分几何线索，但难以建模一致的相机几何，导致系统性空间推理错误。

Conclusion: SAW-Bench推动多模态模型从被动场景理解迈向具身化、观察者中心的空间智能评测，为未来研究提供新方向和挑战。

Abstract: A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.

</details>


### [44] [Are Object-Centric Representations Better At Compositional Generalization?](https://arxiv.org/abs/2602.16689)
*Ferdinand Kapl,Amir Mohammad Karimi Mamaghan,Maximilian Seitzer,Karl Henrik Johansson,Carsten Marr,Stefan Bauer,Andrea Dittadi*

Main category: cs.CV

TL;DR: 本文提出了一种在视觉丰富的环境中评估对象中心（OC）表示对组合泛化能力影响的VQA基准，涵盖三个受控视觉世界（CLEVRTex、Super-CLEVR和MOVi-C），系统比较了OC与稠密视觉编码器（如DINOv2、SigLIP2）在组合泛化上的表现，发现OC方法在数据量少、多样性低或计算受限时更具优势。


<details>
  <summary>Details</summary>
Motivation: 缺乏在视觉丰富场景中系统验证对象中心（OC）表示是否真正提升组合泛化能力的实证研究，现有证据有限。

Method: 构建跨三个可控视觉世界的VQA基准（CLEVRTex、Super-CLEVR、MOVi-C），控制训练数据多样性、样本量、表征维度、下游模型容量与计算开销；以DINOv2和SigLIP2及其OC变体为基线模型进行公平对比实验。

Result: （1）OC方法在更难的组合泛化任务中显著优于稠密表示；（2）稠密表示仅在较简单任务中略优，但需更高下游计算开销；（3）OC模型样本效率更高，在少量图像下即达强泛化性能，稠密模型需更多数据与多样性才能追平或超越。

Conclusion: 当数据规模、数据多样性或下游计算资源任一受限时，对象中心表示能提供更强的组合泛化能力，支持其作为提升泛化鲁棒性的有效建模范式。

Abstract: Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.

</details>


### [45] [Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning](https://arxiv.org/abs/2602.16702)
*Mingjia Shi,Yinhan He,Yaochen Zhu,Jundong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为Saliency-Aware Principle (SAP)的选择机制，用于提升视觉-语言模型（VLMs）在推理过程中的视觉接地稳定性与多路径推理能力，无需额外训练且模型无关。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在推理时视觉输入仅在初始提供，后续文本生成易导致视觉接地错误累积，且粗粒度的视觉引导难以支撑长文本推理。

Method: 提出SAP方法，基于高层推理原则而非词元级轨迹进行选择，支持视觉证据的动态重咨询与多路径并行推理，具备模型无关性和数据免费特性。

Result: SAP在同等token预算下显著降低物体幻觉，推理更稳定、响应延迟更低，性能媲美甚至优于CoT式长序列推理。

Conclusion: SAP为VLMs提供了高效、鲁棒、低开销的推理增强范式，有效缓解视觉-语言联合推理中的接地退化问题。

Abstract: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.

</details>


### [46] [TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos](https://arxiv.org/abs/2602.16711)
*Namitha Padmanabhan,Matthew Gwilliam,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 本文提出TeCoNeRV方法，通过空间-时间分解、残差存储和时序一致性正则化，显著提升超网络视频压缩性能，在UVG等数据集上实现PSNR提升与码率降低。


<details>
  <summary>Details</summary>
Motivation: 现有隐式神经表示（INR）视频压缩方法难以兼顾高分辨率、编码效率和内存开销；超网络方法虽快但质量低、体积大、内存消耗高。

Method: 1) 将短视频段分解为时空patch tubelets以降低预训练内存开销；2) 采用残差式权重存储减少码流大小；3) 引入时序相干性正则化，使权重变化与视频内容对齐。

Result: 在UVG数据集480p/720p上PSNR分别提升2.47dB和5.35dB，码率降低36%，编码速度提升1.5–3倍，并首次在480p/720p/1080p分辨率上验证超网络方法有效性。

Conclusion: TeCoNeRV有效解决了超网络视频压缩中的质量、码率、速度与内存四大瓶颈，为INR视频压缩提供了可扩展的实用化路径。

Abstract: Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [47] [The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts](https://arxiv.org/abs/2602.15843)
*Warren Johnson*

Main category: cs.CL

TL;DR: 本文验证了代码生成与链式思维推理对提示压缩的不同鲁棒性，揭示了'困惑度悖论'机制，并提出了任务感知自适应压缩算法TAAC，在降低成本的同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 解决前序研究在基准覆盖范围有限、'困惑度悖论'机制未验证、缺乏自适应算法三方面的不足。

Method: 在六大代码与四大推理基准上验证压缩阈值泛化性；开展首次逐token困惑度分析（n=723）；提出任务感知自适应压缩算法TAAC，并通过MBPP（n=1800）验证其系统性效果。

Result: 确认压缩阈值跨语言与难度泛化；发现'困惑度悖论'：关键数值token因低困惑度被误删；签名注入使pass rate提升34个百分点；TAAC实现22%成本降低且质量保留96%，优于固定比率压缩7%。

Conclusion: 提示压缩效果高度依赖任务类型与token语义角色，需任务感知的自适应策略；'困惑度悖论'揭示了现有压缩方法的内在缺陷，签名注入与TAAC为实用化提供了新路径。

Abstract: In "Compress or Route?" (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the "perplexity paradox" mechanism unvalidated, and provided no adaptive algorithm. This paper addresses all three gaps. First, we validate across six code benchmarks (HumanEval, MBPP, HumanEval+, MultiPL-E) and four reasoning benchmarks (GSM8K, MATH, ARC-Challenge, MMLU-STEM), confirming the compression threshold generalizes across languages and difficulties. Second, we conduct the first per-token perplexity analysis (n=723 tokens), revealing a "perplexity paradox": code syntax tokens are preserved (high perplexity) while numerical values in math problems are pruned despite being task-critical (low perplexity). Signature injection recovers +34 percentage points in pass rate (5.3% to 39.3%; Cohen's h=0.890). Third, we propose TAAC (Task-Aware Adaptive Compression), achieving 22% cost reduction with 96% quality preservation, outperforming fixed-ratio compression by 7%. MBPP validation (n=1,800 trials) confirms systematic variation: 3.6% at r=0.3 to 54.6% at r=1.0.

</details>


### [48] [Language Model Representations for Efficient Few-Shot Tabular Classification](https://arxiv.org/abs/2602.15844)
*Inwon Kang,Parikshit Ram,Yi Zhou,Horst Samulowitz,Oshani Seneviratne*

Main category: cs.CL

TL;DR: 本文提出TaRL方法，利用现有大语言模型（LLM）的语义嵌入进行少样本Web表格分类，通过去公共成分和软温度校准提升性能，在低数据场景下达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: Web中存在大量异构表格数据，而专门的表格模型需大量标注和训练；已部署的LLMs为语义任务提供了基础设施，本文探索能否直接复用其嵌入能力实现轻量、少样本的表格分类。

Method: 提出TaRL（Table Representation with Language Model）范式：对表格每行提取LLM语义嵌入，去除所有嵌入的公共成分以增强判别性，并引入可学习的softmax温度进行校准；使用基于手工特征的元学习器预测最优温度。

Result: 在k≤32的少样本、语义丰富的Web表格分类任务上，TaRL性能媲美当前最优专用模型；验证了复用现有LLM基础设施进行高效Web表格理解的可行性。

Conclusion: 无需训练专用模型或大规模微调，仅通过嵌入后处理与温度校准，即可有效释放LLM嵌入在少样本表格分类中的潜力，为Web原生结构化数据理解提供轻量实用的新路径。

Abstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified method that can effectively leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly integral component of web infrastructure for tasks like semantic search. This raises a crucial question: can we leverage these already-deployed LLMs to classify structured data in web-native tables (e.g., product catalogs, knowledge base exports, scientific data portals), avoiding the need for specialized models or extensive retraining? This work investigates a lightweight paradigm, $\textbf{Ta}$ble $\textbf{R}$epresentation with $\textbf{L}$anguage Model~($\textbf{TaRL}$), for few-shot tabular classification that directly utilizes semantic embeddings of individual table rows. We first show that naive application of these embeddings underperforms compared to specialized tabular models. We then demonstrate that their potentials can be unlocked with two key techniques: removing the common component from all embeddings and calibrating the softmax temperature. We show that a simple meta-learner, trained on handcrafted features, can learn to predict an appropriate temperature. This approach achieves performance comparable to state-of-the-art models in low-data regimes ($k \leq 32$) of semantically-rich tables. Our findings demonstrate the viability of reusing existing LLM infrastructure for efficient semantics-driven pathway to reuse existing LLM infrastructure for Web table understanding.

</details>


### [49] [KD4MT: A Survey of Knowledge Distillation for Machine Translation](https://arxiv.org/abs/2602.15845)
*Ona de Gibert,Joseph Attieh,Timothee Mickus,Yves Scherrer,Jörg Tiedemann*

Main category: cs.CL

TL;DR: This survey comprehensively reviews 105 papers on Knowledge Distillation for Machine Translation (KD4MT), categorizing methodological advances and practical applications, identifying research gaps, evaluation inconsistencies, risks (e.g., hallucination, bias), and the evolving role of LLMs; it also provides a public database and glossary.


<details>
  <summary>Details</summary>
Motivation: To systematically synthesize the rapidly growing body of work on Knowledge Distillation for Machine Translation (KD4MT), address the lack of unified evaluation practices, identify research gaps, and provide practical guidance given KD's dual role as both a compression tool and a general-purpose knowledge transfer mechanism in MT.

Method: A comprehensive literature survey of 105 papers on KD4MT, involving qualitative and quantitative analysis, categorization by methodology and application, identification of trends and gaps, risk assessment, and synthesis of practical guidelines; supplemented by a publicly available database and glossary.

Result: Identification of common trends, key research gaps, absence of standardized evaluation, practical guidelines for method selection, and risks like increased hallucination and bias amplification; insights into how LLMs are reshaping the KD4MT field.

Conclusion: KD4MT is a rich and evolving field where KD serves beyond compression—it fundamentally shapes supervision, translation quality, and efficiency; however, progress is hindered by fragmented evaluation and underexplored risks, necessitating coordinated efforts, standardized benchmarks, and careful deployment—especially with LLMs.

Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency.
  This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.

</details>


### [50] [Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs](https://arxiv.org/abs/2602.15846)
*Xinyu Gao,Shaonan Wang,Nai Ding*

Main category: cs.CL

TL;DR: 本文提出了一种无需修改原始模型结构的、兼容现有检查点的门控树交叉注意力（GTCA）方法，通过引入预计算的句法成分块记忆来增强解码器-only大语言模型对语法扰动的鲁棒性，同时不损害其原有推理与问答能力。


<details>
  <summary>Details</summary>
Motivation: 解码器-only大语言模型虽性能强大，但对细微语法扰动敏感，影响下游推理可靠性；而直接注入句法结构易破坏预训练模型已有能力。

Method: 设计一种与现有检查点兼容的门控树交叉注意力（GTCA）分支，读取预计算的句法成分块记忆，保持主干架构不变；采用token更新掩码和分阶段训练控制结构化更新的范围与时序。

Result: 在多个基准和不同Transformer主干上，GTCA显著提升语法鲁棒性，优于持续训练基线，且不损害多选题问答与常识推理性能。

Conclusion: GTCA为解码器-only大语言模型提供了一种实用、检查点兼容的语法鲁棒性增强路径。

Abstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch that reads precomputed constituency chunk memory while leaving backbone architecture unchanged. Our design uses a token update mask and staged training to control the scope and timing of structural updates. Across benchmarks and Transformer backbones, GTCA strengthens syntactic robustness beyond continued-training baselines without compromising Multiple-Choice QA performance or commonsense reasoning, providing a practical checkpoint-compatible route to more syntax-robust decoder-only LLMs.

</details>


### [51] [Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models](https://arxiv.org/abs/2602.15847)
*Pranav Bhandari,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本文研究了大语言模型中人格特质引导向量的几何关系，发现即使去除线性重叠，不同特质间仍存在显著的几何依赖性，表明人格特质在模型中处于轻微耦合的子空间，难以完全独立控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设人格特质可独立控制，本文旨在检验该假设是否成立。

Method: 分析LLaMA-3-8B和Mistral-8B中提取的五大性格特质引导向量，并采用多种几何约束方案（包括无约束、软/硬正交化）进行研究。

Result: 人格引导方向存在显著几何依赖性；硬正交化虽强制几何独立，但无法消除跨特质行为影响，且削弱引导强度。

Conclusion: LLM中人格特质并非完全独立，而是处于轻微耦合的子空间，限制了完全独立的特质控制。

Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.

</details>


### [52] [Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling](https://arxiv.org/abs/2602.15848)
*Andrius Matšenas,Anet Lello,Tõnis Lees,Hans Peep,Kim Lilii Tamm*

Main category: cs.CL

TL;DR: 本研究验证了大语言模型（LLMs）作为问卷式人格评估的动态替代方案的有效性，发现其与金标准IPIP-50问卷具有中等程度的聚合效度，且用户感知准确性相当。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型能否作为传统问卷式人格评估（如IPIP-50）的动态、交互式替代方案。

Method: 采用被试内实验设计（N=33），通过引导式LLM对话生成大五人格得分，并与IPIP-50问卷结果进行比较，同时测量参与者对两种方法生成结果的感知准确性。

Result: LLM与IPIP-50在尽责性、开放性和神经质维度上得分无显著差异（统计等价），但在宜人性和外向性上存在显著差异；整体聚合效度中等（r=0.38–0.58）；用户认为LLM生成的人格档案与问卷结果同样准确。

Conclusion: LLM驱动的对话式人格评估是一种有前景的新心理测量方法，但需针对特定人格特质进行校准优化。

Abstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.

</details>


### [53] [Preference Optimization for Review Question Generation Improves Writing Quality](https://arxiv.org/abs/2602.15849)
*Karun Sharma,Vidushee Vats,Shengzhi Li,Yuxiang Wang,Zhongtian Sun,Prayag Tiwari*

Main category: cs.CL

TL;DR: 本文提出IntelliReward奖励模型和IntelliAsk提问生成模型，通过改进LLM生成审稿问题的质量，强调实质性、基于证据的问题，显著提升推理与写作能力评估表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的同行评审问题生成方法往往只停留在表面，超过50%的问题词汇来自论文第一页，缺乏深度和证据支撑。

Method: 构建冻结自回归LLM+可训练多头注意力的IntelliReward奖励模型；结合Decoupled Clip与DAPO策略优化训练IntelliAsk提问生成模型，使其符合人类专家对努力程度、证据支持和内容扎根性的标准。

Result: IntelliAsk在MuSR（68.3 vs 64.7 Acc）和WritingBench（8.31 vs 8.07）等基准上超越Qwen3-32B基线；IntelliReward能更准确预测专家偏好。

Conclusion: 高质量审稿问题生成不仅提升评审质量，也反映并促进模型在推理与写作等更广泛能力上的进步；所开源资源为评估LLM生成问题的扎根性、努力度与证据性提供了新基准。

Abstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which outperforms API-based SFT baselines in predicting expert-level human preferences. By applying Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) with IntelliReward, we train IntelliAsk, a question-generation model aligned with human standards of effort, evidence, and grounding. We find consistent improvements on reasoning and writing benchmarks, suggesting reviewer-question quality correlates with broader capabilities. Compared to the Qwen3-32B base model, IntelliAsk shows measurable gains across diverse benchmarks, specifically improving performance on reasoning tasks like MuSR (68.3 vs 64.7 Acc) and complex writing evaluations such as WritingBench (8.31 vs 8.07). We release our implementation, expert preference annotations, and the IntelliReward model to provide an automatic evaluation benchmark for grounding, effort, and evidence in LLM-generated review questions.

</details>


### [54] [Large Language Models for Assisting American College Applications](https://arxiv.org/abs/2602.15850)
*Zhengliang Liu,Weihang You,Peng Shu,Junhao Chen,Yi Pan,Hanqi Jiang,Yiwei Li,Zhaojun Ding,Chao Cao,Xinliang Li,Yifan Zhou,Ruidong Zhang,Shaochen Xu,Wei Ruan,Huaqin Zhao,Dajiang Zhu,Tianming Liu*

Main category: cs.CL

TL;DR: EZCollegeApp是一个基于大语言模型的系统，帮助高中生梳理大学申请表、依据权威招生文件生成回答建议，并保持人类对最终回复的完全控制。


<details>
  <summary>Details</summary>
Motivation: 美国大学申请流程碎片化、表格重复且条件复杂、问题模糊需跨源查证，给高中生带来巨大负担。

Method: 提出映射优先范式，分离表单理解与答案生成；集成官方招生文档摄取、检索增强型问答和人机协同聊天界面。

Result: 实现了结构化表单解析、权威依据的回答建议、不自动提交的安全交互；通过自动化测试与人工质量评估验证有效性。

Conclusion: EZCollegeApp提升了申请效率与准确性，同时保障用户自主权与数据隐私，开源代码促进教育公平技术发展。

Abstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that assists high-school students by structuring application forms, grounding suggested answers in authoritative admissions documents, and maintaining full human control over final responses. The system introduces a mapping-first paradigm that separates form understanding from answer generation, enabling consistent reasoning across heterogeneous application portals. EZCollegeApp integrates document ingestion from official admissions websites, retrieval-augmented question answering, and a human-in-the-loop chatbot interface that presents suggestions alongside application fields without automated submission. We describe the system architecture, data pipeline, internal representations, security and privacy measures, and evaluation through automated testing and human quality assessment. Our source code is released on GitHub (https://github.com/ezcollegeapp-public/ezcollegeapp-public) to facilitate the broader impact of this work.

</details>


### [55] [Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey](https://arxiv.org/abs/2602.15851)
*David Y. Liu,Aditya Joshi,Paul Dawson*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在叙事理论应用中的研究进展，提出一个基于叙事学的分类法，分析了数据集、任务、理论与NLP方法趋势，并指出当前缺乏统一叙事评估基准的问题，主张未来应聚焦于理论驱动的指标构建、大规模跨学科分析及用于验证/修正叙事理论的实验。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理（NLP）与叙事学交叉研究日益增多，但缺乏系统性梳理和理论对齐；现有工作在叙事定义、评估基准和模型比较上存在困难，亟需理论引导的框架整合。

Method: 通过文献综述方式，梳理NLP中叙事相关研究，构建涵盖叙事数据集、任务、理论基础及方法（如提示工程、微调）的分类体系，并结合 narratology 经典区分进行分析。

Result: 识别出叙事研究在NLP中的主要模式与趋势；揭示LLMs促进抽象叙事概念与NLP流程对接的能力；指出统一叙事基准缺失的挑战；提出以理论为本、分属性评估、跨学科分析和理论可验证实验为方向的未来路径。

Conclusion: 叙事NLP研究需回归叙事学理论根基，放弃追求单一‘叙事质量’通用基准，转向精细化、可验证、跨学科的理论驱动型研究范式，从而推动更系统、更有深度的叙事计算研究。

Abstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the following: narrative datasets and tasks, narrative theories and NLP pipeline and methodological trends in prompting and fine-tuning. We highlight how LLMs enable easy connections of NLP pipelines with abstract narrative concepts and opportunities for interdisciplinary collaboration. Challenges remain in attempts to work towards any unified definition or benchmark of narrative related tasks, making model comparison difficult. For future directions, instead of the pursuit of a single, generalised benchmark for 'narrative quality', we believe that progress benefits more from efforts that focus on the following: defining and improving theory-based metrics for individual narrative attributes to incrementally improve model performance; conducting large-scale, theory-driven literary/social/cultural analysis; and creating experiments where outputs can be used to validate or refine narrative theories. This work provides a contextual foundation for more systematic and theoretically informed narrative research in NLP by providing an overview to ongoing research efforts and the broader narrative studies landscape.

</details>


### [56] [Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints](https://arxiv.org/abs/2602.15852)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级审计流程，用于在临床NLP模型开发中识别并抑制时间与词汇泄漏，以提升模型在真实临床场景中的安全性、校准性与时间有效性。


<details>
  <summary>Details</summary>
Motivation: 临床NLP模型易受时间与词汇泄漏影响，导致预测性能虚高，威胁患者安全与临床工作流，亟需构建安全可部署的系统。

Method: 设计并集成可解释性驱动的轻量级审计流水线，在模型最终训练前识别和抑制泄漏相关信号；以择期脊柱手术后次日出院预测为案例开展实证评估。

Result: 经审计的模型表现出更保守、更优校准的概率估计，显著降低对出院相关词汇线索的依赖，提升了时间有效性与行为鲁棒性。

Conclusion: 面向临床部署的NLP系统应优先保障时间有效性、概率校准与行为鲁棒性，而非追求乐观的预测指标。

Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial risks for real-world deployment, where overconfident or temporally invalid predictions can disrupt clinical workflows and compromise patient safety. This study focuses on system-level design choices required to build safe and deployable clinical NLP under temporal leakage constraints. We present a lightweight auditing pipeline that integrates interpretability into the model development process to identify and suppress leakage-prone signals prior to final training. Using next-day discharge prediction after elective spine surgery as a case study, we evaluate how auditing affects predictive behavior, calibration, and safety-relevant trade-offs. Results show that audited models exhibit more conservative and better-calibrated probability estimates, with reduced reliance on discharge-related lexical cues. These findings emphasize that deployment-ready clinical NLP systems should prioritize temporal validity, calibration, and behavioral robustness over optimistic performance.

</details>


### [57] [A Lightweight Explainable Guardrail for Prompt Safety](https://arxiv.org/abs/2602.15853)
*Md Asiful Islam,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级可解释防护方法LEG，通过多任务学习联合训练提示分类器和解释分类器，并采用合成数据与新型损失函数提升性能与可解释性，在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有不安全提示分类方法缺乏可解释性、模型过大以及依赖有偏LLM生成标注数据的问题。

Method: 采用多任务学习架构联合训练提示分类器和词级解释分类器；使用反确认偏差策略生成合成解释数据；设计结合交叉熵、focal loss与基于不确定性的加权损失函数。

Result: LEG在域内和域外三个数据集上的分类与可解释性指标均达到或超过SOTA，且模型尺寸显著更小。

Conclusion: LEG是一种高效、轻量且可解释的不安全提示检测方法，具备良好的泛化能力与实用潜力。

Abstract: We propose a lightweight explainable guardrail (LEG) method for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel strategy that counteracts the confirmation biases of LLMs. Lastly, LEG's training process uses a novel loss that captures global explanation signals and combines cross-entropy and focal losses with uncertainty-based weighting. LEG obtains equivalent or better performance than the state-of-the-art for both prompt classification and explainability, both in-domain and out-of-domain on three datasets, despite the fact that its model size is considerably smaller than current approaches. If accepted, we will release all models and the annotated dataset publicly.

</details>


### [58] [Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization](https://arxiv.org/abs/2602.15854)
*Jingyi Xu,Xingyu Ren,Zhiqiang You,Yumeng Zhang,Zhoupeng Shou*

Main category: cs.CL

TL;DR: 本文提出了一种名为Goal-Oriented Preference Optimization (GOPO)的分层强化学习框架，用于提升任务型对话系统的长程任务成功率。该框架通过Expert Agent（优化多轮目标偏好）和Customer Service Agent（按策略生成响应）解耦策略规划与响应生成，并引入新指标TSE进行评估，在多个数据集上显著优于PPO、Memento及大模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在任务型对话中多采用token级似然或偏好优化，难以对齐长程任务成功目标。

Method: 提出GOPO框架：包含Expert Agent（在对话轨迹层面优化多轮目标偏好）和Customer Service Agent（严格遵循选定策略生成响应），并引入基于真实电商交互数据构建的序列级指标Task-focused Sequential Engagement (TSE)。

Result: 在Mgshop数据集上，GOPO比PPO和Memento分别提升TSE达7.7%和10.3%；14B模型超越Qwen-235B和GPT-5.2达2.7%和1.5%；消融实验验证Expert Agent对长程优化的关键作用。

Conclusion: GOPO为商业场景下的任务型对话系统建立了新范式，显著提升长程任务成功率与序列级表现，代码与数据集将开源。

Abstract: Large language models show potential in task-oriented dialogue systems, yet existing training methods often rely on token-level likelihood or preference optimization, which poorly align with long-horizon task success. To address this, we propose Goal-Oriented Preference Optimization (GOPO), a hierarchical reinforcement learning framework that decouples strategy planning from response generation via an Expert Agent and a Customer Service Agent. The Expert Agent optimizes multi-turn goal preferences at the dialogue-trajectory level, while the Customer Service Agent generates responses strictly aligned with the selected strategy. We evaluate GOPO on public benchmarks and e-commerce customer service datasets, and introduce Task-focused Sequential Engagement (TSE), a sequence-level metric derived from real e-commerce interaction data. On the Mgshop dataset, GOPO improves TSE by 7.7% and 10.3% over PPO and Memento, with consistent gains in sequence-level reward and generation quality. Furthermore, a 14B model trained with GOPO achieves 2.7% and 1.5% higher TSE than Qwen-235B and GPT-5.2, respectively. Ablation studies confirm the Expert Agent's critical role in long-horizon optimization. GOPO demonstrates consistent improvements across other datasets as well. This work establishes a new paradigm for task-oriented dialogue systems in commercial scenarios, with code and datasets to be made public.

</details>


### [59] [Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling](https://arxiv.org/abs/2602.16485)
*Jeffrey T. H. Wong,Zixi Zhang,Junyi Liu,Yiren Zhao*

Main category: cs.CL

TL;DR: 本文提出Team-of-Thoughts架构，通过异构智能体与协调器-工具范式提升多智能体系统性能，在多个推理与代码生成基准上显著超越同构基线。


<details>
  <summary>Details</summary>
Motivation: 现有MAS依赖静态、同质模型配置，难以发挥不同后训练模型的各自优势。

Method: 提出Team-of-Thoughts架构，包含协调器校准机制（筛选强协调能力模型）和工具智能体自评估协议（刻画各自主领域专长），在推理时依据能力画像动态调度最适配的工具智能体。

Result: 在五个推理与代码生成基准上表现一致更优；AIME24和LiveCodeBench准确率分别达96.67%和72.53%，显著高于同构角色扮演基线（80%和65.93%）。

Conclusion: 异构智能体协同可通过协调器-工具范式有效建模与调度，显著提升多智能体系统任务性能。

Abstract: Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.

</details>


### [60] [Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective](https://arxiv.org/abs/2602.15856)
*Yunhao Liu,Zian Jia,Xinyu Gao,Kanjun Xu,Yun Xiong*

Main category: cs.CL

TL;DR: 本文提出SeleCom框架，通过查询条件化信息选择替代传统全压缩方法，提升RAG中软上下文压缩的效果与效率。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文压缩方法依赖全压缩，导致与LLM生成行为冲突且稀释任务相关的信息密度，影响性能。

Method: 提出SeleCom：一种基于选择器的软压缩框架，将编码器角色重新定义为查询条件化的信息选择器；采用仅解码器结构，并在大规模、多样、难度分级的合成QA数据集上结合课程学习进行训练。

Result: SeleCom显著优于现有软压缩方法，在保持或超越非压缩基线性能的同时，降低计算量和延迟33.8%~84.6%。

Conclusion: 全压缩在RAG软上下文压缩中既不可行也不必要；查询条件化选择机制更契合LLM生成需求，能有效提升压缩质量与系统效率。

Abstract: Retrieval-Augmented Generation (RAG) effectively grounds Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context compression aims to address this by encoding long documents into compact embeddings, yet they often underperform non-compressed RAG due to their reliance on auto-encoder-like full-compression that forces the encoder to compress all document information regardless of relevance to the input query.
  In this work, we conduct an analysis on this paradigm and reveal two fundamental limitations: (I) Infeasibility, full-compression conflicts with the LLM's downstream generation behavior; and (II) Non-necessity: full-compression is unnecessary and dilutes task-relevant information density. Motivated by these insights, we introduce SeleCom, a selector-based soft compression framework for RAG that redefines the encoder's role as query-conditioned information selector. The selector is decoder-only and is trained with a massive, diverse and difficulty-graded synthetic QA dataset with curriculum learning.
  Extensive experiments show that SeleCom significantly outperforms existing soft compression approaches and achieves competitive or superior performance to non-compression baselines, while reducing computation and latency by 33.8%~84.6%.

</details>


### [61] [ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models](https://arxiv.org/abs/2602.16609)
*Antoine Chaffin,Luca Arnaboldi,Amélie Chatelain,Florent Krzakala*

Main category: cs.CL

TL;DR: 本文研究了多向量模型的预训练，发现大规模多向量预训练能显著提升模型性能；提出的ColBERT-Zero模型仅用公开数据即超越依赖闭源强数据的现有模型，并探讨了监督微调与预训练对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有最优多向量模型依赖于在强单向量模型上进行小规模知识蒸馏，但其预训练过程未针对多向量结构优化，本文旨在探索直接进行大规模多向量预训练的效果。

Method: 提出并实现了完全基于多向量结构（如ColBERT）的大规模预训练方案（ColBERT-Zero），仅使用公开数据；同时对比分析了知识蒸馏、监督微调与预训练设置对齐等策略的有效性。

Result: ColBERT-Zero在同等规模下超越GTE-ModernColBERT及基座模型GTE-ModernBERT；加入监督微调可显著逼近全量预训练效果，跳过高成本无监督阶段；预训练与微调设置对齐对模型迁移至关重要。

Conclusion: 大规模多向量预训练是提升多向量检索模型性能的关键路径；相比知识蒸馏，从头设计并预训练多向量模型更具潜力，且需重视训练流程各阶段的一致性。

Abstract: Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.

</details>


### [62] [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)
*Yi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CRAF的协同推理与自适应融合框架，用于多源异构平台的舆情分析，通过结合传统特征方法与大语言模型，在跨平台语义对齐、动态特征加权、联合优化和多模态视频分析等方面实现创新，并在多个数据集上取得性能提升。


<details>
  <summary>Details</summary>
Motivation: 公共舆论分析面临多源异构数据在结构、语义和平台偏差上的挑战，亟需能统一建模并保留源特性的方法。

Method: 提出CRAF框架，包含四个核心组件：跨平台协同注意力模块、分层自适应融合机制、联合优化策略（共享潜在空间学习主题与情感）、以及支持OCR/ASR/视觉情感分析的多模态视频提取能力。

Result: 理论证明CRAF泛化界更紧；实验显示其在三个多平台数据集上主题聚类ARI达0.76（+4.1%），情感分析F1达0.84（+3.8%），新平台标注数据需求降低75%。

Conclusion: CRAF有效融合多源异构舆情信息，兼顾平台特性与任务需求，在理论保证与实际性能上均优于现有方法，具备强跨平台适应性与多模态扩展能力。

Abstract: The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrates traditional feature-based methods with large language models (LLMs) through a structured multi-stage reasoning mechanism. Our approach features four key innovations: (1) a cross-platform collaborative attention module that aligns semantic representations while preserving source-specific characteristics, (2) a hierarchical adaptive fusion mechanism that dynamically weights features based on both data quality and task requirements, (3) a joint optimization strategy that simultaneously learns topic representations and sentiment distributions through shared latent spaces, and (4) a novel multimodal extraction capability that processes video content from platforms like Douyin and Kuaishou by integrating OCR, ASR, and visual sentiment analysis. Theoretical analysis demonstrates that CRAF achieves a tighter generalization bound with a reduction of O(sqrt(d log K / m)) compared to independent source modeling, where d is feature dimensionality, K is the number of sources, and m is sample size. Comprehensive experiments on three multi-platform datasets (Weibo-12, CrossPlatform-15, NewsForum-8) show that CRAF achieves an average topic clustering ARI of 0.76 (4.1% improvement over best baseline) and sentiment analysis F1-score of 0.84 (3.8% improvement). The framework exhibits strong cross-platform adaptability, reducing the labeled data requirement for new platforms by 75%.

</details>


### [63] [State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models](https://arxiv.org/abs/2602.15858)
*Annie Wong,Aske Plaat,Thomas Bäck,Niki van Stein,Anna V. Kononova*

Main category: cs.CL

TL;DR: 本文系统研究了在动态环境中，大型语言模型（LLMs）的状态表征方式（粒度、结构、空间定位）对其推理与决策性能的影响，发现轨迹摘要、自然语言表征和文本化空间编码（如地图）最有效，且表征设计本身比信息可用性更重要；但当前模型在长时序多子任务合成上仍显脆弱。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs从静态推理走向动态交互环境，其性能高度依赖于对变化状态的表征能力；而该因素此前未被系统探究。

Method: 在固定模型参数前提下，系统性地控制变量：状态粒度（长文本 vs 摘要）、结构（自然语言 vs 符号化）、空间接地（纯文本 vs 图像 vs 文本地图），并在多个序列决策基准上评估。

Result: 1）轨迹摘要可降噪并稳定长程推理；2）自然语言表征鲁棒性最强，符号化表征仅对具备强结构输出先验（如JSON）的模型有益；3）图像输入增益有限，而文本空间编码（如地图）效果最佳，因其构造过程强制模型执行空间推理。

Conclusion: 状态表征的设计是影响动态环境中LLM性能的关键独立因素；但即便优化表征，现有LLM/VLM在长时序、多子任务协同推理方面仍存在根本性脆弱性。

Abstract: As large language models (LLMs) move from static reasoning tasks toward dynamic environments, their success depends on the ability to navigate and respond to an environment that changes as they interact at inference time. An underexplored factor in these settings is the representation of the state. Holding model parameters fixed, we systematically vary three key aspects: (1) state granularity (long form versus summary), (2) structure (natural language versus symbolic), and (3) spatial grounding (text-only versus images or textual map encodings) across sequential decision-making benchmarks. We find that trajectory summarisation improves performance by reducing noise and stabilising long-horizon reasoning. Second, natural language representations are the most robust across models, whereas structured encodings help mainly for models with strong code or structured output priors, such as JSON schemas. Third, while image-inputs show some benefit, text-based spatial encodings prove most effective. This advantage stems not from the spatial information itself, but from the act of construction, which compels the model to perform the spatial reasoning that static input does not elicit. Overall, we demonstrate that design choices for representing state are a decisive factor in performance, distinct from the availability of information itself. We note, however, that even with improved representations, current LLMs and VLMs remain brittle over long horizons, particularly when they must synthesise information to manage multiple subtasks to reach a goal.

</details>


### [64] [From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI Assistants](https://arxiv.org/abs/2602.15859)
*Krittin Pachtrachai,Petmongkon Pornpichitsuwan,Wachiravit Modecrua,Touchapon Kraisingkorn*

Main category: cs.CL

TL;DR: 本文提出了一种端到端框架，利用历史通话转录文本构建和评估面向客户行业的对话式AI助手，通过PIPA风格评分筛选高质量对话、LLM提取结构化知识用于RAG、模块化提示工程控制行为，并在房地产与专业招聘领域验证了其高准确率、强鲁棒性及约30%的自主处理率。


<details>
  <summary>Details</summary>
Motivation: 构建面向客户行业的可靠对话式AI助手面临噪声数据、知识碎片化和需精准人工接管等挑战，尤其在依赖实时信息的领域更为突出。

Method: 基于历史通话转录文本，采用简化PIPA框架评分并筛选高质量对话；用大语言模型提取结构化知识作为RAG唯一知识源；通过从单体到模块化、可管控的提示调优控制助手行为；使用转录文本驱动的用户模拟器和红队测试进行多维评估。

Result: 在房地产和专业招聘两个高难度领域中，助手可自主处理约30%的通话，事实准确率与拒答行为接近完美，并在对抗性测试中表现出强鲁棒性。

Conclusion: 该端到端框架有效应对了真实业务场景中数据噪声、知识整合与安全可控等核心挑战，为实时性强、自动化程度低的行业提供了可行的对话AI落地路径。

Abstract: Building reliable conversational AI assistants for customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge, and the requirement for accurate human hand-off - particularly in domains that depend heavily on real-time information. This paper presents an end-to-end framework for constructing and evaluating a conversational AI assistant directly from historical call transcripts. Incoming transcripts are first graded using a simplified adaptation of the PIPA framework, focusing on observation alignment and appropriate response behavior, and are filtered to retain only high-quality interactions exhibiting coherent flow and effective human agent responses. Structured knowledge is then extracted from curated transcripts using large language models (LLMs) and deployed as the sole grounding source in a Retrieval-Augmented Generation (RAG) pipeline. Assistant behavior is governed through systematic prompt tuning, progressing from monolithic prompts to lean, modular, and governed designs that ensure consistency, safety, and controllable execution. Evaluation is conducted using a transcript-grounded user simulator, enabling quantitative measurement of call coverage, factual accuracy, and human escalation behavior. Additional red teaming assesses robustness against prompt injection, out-of-scope, and out-of-context attacks. Experiments are conducted in the Real Estate and Specialist Recruitment domains, which are intentionally challenging and currently suboptimal for automation due to their reliance on real-time data. Despite these constraints, the assistant autonomously handles approximately 30 percents of calls, achieves near-perfect factual accuracy and rejection behavior, and demonstrates strong robustness under adversarial testing.

</details>


### [65] [Reranker Optimization via Geodesic Distances on k-NN Manifolds](https://arxiv.org/abs/2602.15860)
*Wen G. Gong*

Main category: cs.CL

TL;DR: Maniscope是一种基于流形几何的轻量级重排序方法，利用k-NN图上的测地距离提升RAG中检索结果的相关性排序效果，在保持高精度的同时显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有神经重排序方法（如cross-encoder或LLM）计算开销大、延迟高（3–5秒），难以满足实时RAG需求。

Method: 构建检索文档候选集的k近邻流形，通过计算其上的测地距离融合全局余弦相似度与局部流形几何结构，以更好捕捉语义关系。

Result: 在BEIR八个数据集上验证，Maniscope在三个最难数据集上NDCG@3分别提升7.0%、1.6%、2.8%，平均延迟仅4.7ms（比HNSW快3.2倍，比cross-encoder快10–45倍，比LLM-Reranker快840倍），精度损失<2%。

Conclusion: Maniscope是一种高效、低延迟、高精度的几何重排序方法，适合实时RAG部署，并将开源。

Abstract: Current neural reranking approaches for retrieval-augmented generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document candidates. This approach combines global cosine similarity with local manifold geometry to capture semantic structure that flat Euclidean metrics miss. Evaluating on eight BEIR benchmark datasets (1,233 queries), Maniscope outperforms HNSW graph-based baseline on the three hardest datasets (NFCorpus: +7.0%, TREC-COVID: +1.6%, AorB: +2.8% NDCG@3) while being 3.2x faster (4.7 ms vs 14.8 ms average). Compared to cross-encoder rerankers, Maniscope achieves within 2% accuracy at 10-45x lower latency. On TREC-COVID, LLM-Reranker provides only +0.5% NDCG@3 improvement over Maniscope at 840x higher latency, positioning Maniscope as a practical alternative for real-time RAG deployment. The method requires O(N D + M^2 D + M k log k) complexity where M << N , enabling sub-10 ms latency. We plan to release Maniscope as open-source software.

</details>


### [66] [CAST: Achieving Stable LLM-based Text Analysis for Data Analytics](https://arxiv.org/abs/2602.15861)
*Jinxiang Xie,Zihao Li,Wei He,Rui Ding,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 本文提出CAST框架，通过算法化提示和思考前置机制提升大语言模型在表格文本分析中摘要与标注任务的输出稳定性，并设计了CAST-S和CAST-T稳定性评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在表格文本分析的摘要和标注任务中难以满足数据分析所需的高输出稳定性要求。

Method: 提出CAST框架，包含算法化提示（约束有效推理路径）和思考前置（强制生成前明确中间结论）；并设计CAST-S（摘要稳定性）和CAST-T（标注稳定性）评估指标。

Result: 在多个公开基准和不同LLM主干模型上实验表明，CAST显著提升稳定性（最高提升16.2%稳定性得分），同时保持或提升输出质量。

Conclusion: CAST通过约束模型潜在推理路径，有效提升了LLM在表格文本分析任务中的输出稳定性，为数据驱动应用提供了更可靠的基础。

Abstract: Text analysis of tabular data relies on two core operations: \emph{summarization} for corpus-level theme extraction and \emph{tagging} for row-level labeling. A critical limitation of employing large language models (LLMs) for these tasks is their inability to meet the high standards of output stability demanded by data analytics. To address this challenge, we introduce \textbf{CAST} (\textbf{C}onsistency via \textbf{A}lgorithmic Prompting and \textbf{S}table \textbf{T}hinking), a framework that enhances output stability by constraining the model's latent reasoning path. CAST combines (i) Algorithmic Prompting to impose a procedural scaffold over valid reasoning transitions and (ii) Thinking-before-Speaking to enforce explicit intermediate commitments before final generation. To measure progress, we introduce \textbf{CAST-S} and \textbf{CAST-T}, stability metrics for bulleted summarization and tagging, and validate their alignment with human judgments. Experiments across publicly available benchmarks on multiple LLM backbones show that CAST consistently achieves the best stability among all baselines, improving Stability Score by up to 16.2\%, while maintaining or improving output quality.

</details>


### [67] [Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation](https://arxiv.org/abs/2602.15862)
*Guoshan Liu,Bin Zhu,Yian Li,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种语义驱动的两阶段框架，通过动作与食材预测验证、监督微调（SFT）与强化微调（RFT）结合，以及语义置信度评分与修正模块（SCSR），显著提升了基于食物图像生成菜谱的语义准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的菜谱生成方法虽在词汇指标（如BLEU、ROUGE）上表现良好，但常生成语义错误的动作或食材，缺乏语义合理性。

Method: 提出两阶段框架：第一阶段用动作推理数据集和食材语料库进行监督微调（SFT）；第二阶段采用频率感知奖励进行强化微调（RFT），提升长尾动作预测与食材泛化能力；并引入语义置信度评分与修正（SCSR）模块对输出进行过滤与纠正。

Result: 在Recipe1M数据集上达到当前最优性能，语义保真度显著提升。

Conclusion: 语义接地的建模范式比单纯依赖词汇匹配更有效，能实质性改善生成菜谱的合理性与实用性。

Abstract: Recent advances in Multimodal Large Language Models (MLMMs) have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically grounded framework that predicts and validates actions and ingredients as internal context for instruction generation. Our two-stage pipeline combines supervised fine-tuning (SFT) with reinforcement fine-tuning (RFT): SFT builds foundational accuracy using an Action-Reasoning dataset and ingredient corpus, while RFT employs frequency-aware rewards to improve long-tail action prediction and ingredient generalization. A Semantic Confidence Scoring and Rectification (SCSR) module further filters and corrects predictions. Experiments on Recipe1M show state-of-the-art performance and markedly improved semantic fidelity.

</details>


### [68] [Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning](https://arxiv.org/abs/2602.15863)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 本文发现LLM通过自我生成few-shot示例提升推理能力的关键在于“生成过程”本身，而非生成的示例；实验表明集成式提示（Integrated prompting）显著优于解耦式提示（Decoupled prompting）和零样本提示，注意力分析进一步支持该结论。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现LLM可通过自生成few-shot样例提升推理性能，但其内在机制不明，导致难以有效应用该技术。

Method: 在多种LLM架构上系统评估三种提示策略：零样本提示、集成式提示（模型在同一提示中创建并求解问题）、解耦式提示（复用自生成样例但排除其生成上下文）；并辅以注意力机制分析。

Result: 集成式提示在五种主流模型上始终优于零样本和解耦式提示；解耦式提示仅带来微弱增益；注意力分析显示二者存在显著差异。

Conclusion: 自生成提示的有效性源于问题构建过程本身，而非生成的样例内容，这对设计更优提示策略具有重要指导意义。

Abstract: Recent studies have shown that Large Language Models (LLMs) can improve their reasoning performance through self-generated few-shot examples, achieving results comparable to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear, making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key benefit arises not from the generated examples themselves but from the act of creating them. To validate this, on reasoning-intensive tasks across diverse LLM architectures, we systematically evaluate three prompting strategies for in-context learning: (1) Zero-shot prompting; (2) Integrated prompting, where LLMs create and solve problems within a single, unified prompt; and (3) Decoupled prompting, where self-generated examples are reused as in-context examples, but the context of their creation itself is excluded. We conduct experiments across five widely used model architectures, demonstrating that Integrated prompting consistently outperforms both Zero-shot and Decoupled prompting. In contrast, Decoupled prompting offers only marginal gains over Zero-shot. Further, for a more in-depth analysis, we conduct an attention analysis and observe significant differences in attention patterns between Integrated and Decoupled prompting. These findings suggest that the advantage of self-generation prompting comes from the process of problem creation, not the examples themselves, providing valuable insights for designing more effective prompting strategies.

</details>


### [69] [NLP Privacy Risk Identification in Social Media (NLP-PRISM): A Survey](https://arxiv.org/abs/2602.15866)
*Dhiman Goswami,Jai Kruthunz Naveen Kumar,Sanchari Das*

Main category: cs.CL

TL;DR: 本文提出NLP-PRISM框架，系统评估社交媒体NLP应用中的六维隐私风险，发现现有研究在隐私保护与模型效用间存在明显权衡，并呼吁加强匿名化、隐私感知学习与公平性训练。


<details>
  <summary>Details</summary>
Motivation: NLP在社交媒体分析中广泛应用，但处理含PII、行为线索和元数据的内容带来监控、画像和定向广告等隐私风险，亟需系统性风险评估方法。

Method: 综述203篇论文，构建涵盖数据收集、预处理、可见性、公平性、计算风险和合规性的六维NLP-PRISM隐私风险识别框架，并在六类NLP任务中实证检验其有效性。

Result: Transformer模型在隐私保护微调下F1下降1%-23%；隐私覆盖存在显著缺口；模型效用下降2%-9%，MIA AUC达0.81，AIA准确率达0.75。

Conclusion: 当前社交媒体NLP研究在隐私保护方面严重不足，需推动更强的匿名化技术、隐私感知学习范式及公平驱动的训练策略，以实现伦理化NLP实践。

Abstract: Natural Language Processing (NLP) is integral to social media analytics but often processes content containing Personally Identifiable Information (PII), behavioral cues, and metadata raising privacy risks such as surveillance, profiling, and targeted advertising. To systematically assess these risks, we review 203 peer-reviewed papers and propose the NLP Privacy Risk Identification in Social Media (NLP-PRISM) framework, which evaluates vulnerabilities across six dimensions: data collection, preprocessing, visibility, fairness, computational risk, and regulatory compliance. Our analysis shows that transformer models achieve F1-scores ranging from 0.58-0.84, but incur a 1% - 23% drop under privacy-preserving fine-tuning. Using NLP-PRISM, we examine privacy coverage in six NLP tasks: sentiment analysis (16), emotion detection (14), offensive language identification (19), code-mixed processing (39), native language identification (29), and dialect detection (24) revealing substantial gaps in privacy research. We further found a (reduced by 2% - 9%) trade-off in model utility, MIA AUC (membership inference attacks) 0.81, AIA accuracy 0.75 (attribute inference attacks). Finally, we advocate for stronger anonymization, privacy-aware learning, and fairness-driven training to enable ethical NLP in social media contexts.

</details>


### [70] [Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?](https://arxiv.org/abs/2602.15867)
*Berry Gerrits*

Main category: cs.CL

TL;DR: 本文通过让大型语言模型（LLMs）玩经典文字冒险游戏Zork，评估其问题解决与推理能力。实验发现，主流模型（ChatGPT、Claude、Gemini）平均完成度不足10%，详细指令或“延展思考”均未提升表现；定性分析揭示其在元认知、策略反思与从历史中学习等方面存在根本局限。


<details>
  <summary>Details</summary>
Motivation: 评估当代大语言模型在结构化自然语言交互环境中的真实问题解决与推理能力，尤其关注其元认知和持续学习能力。

Method: 在Zork游戏中测试ChatGPT、Claude和Gemini等主流闭源模型，设置最小化与详细指令两种条件，以得分作为主要评估指标，并辅以对模型动作序列与推理过程的定性分析。

Result: 所有模型平均得分低于35分（满分350），最高为Claude Opus 4.5约75分；详细指令和‘extended thinking’无改善；模型表现出重复无效动作、策略不一致、无法利用对话历史学习等现象。

Conclusion: 当前LLMs在需要动态规划、自我监控与经验迭代的文本游戏任务中存在显著推理缺陷，暴露其元认知能力薄弱，提示其‘推理’可能更多是模式匹配而非真正的问题求解。

Abstract: In this positioning paper, we evaluate the problem-solving and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate appropriate action sequences to succeed in the game. We test the performance of leading proprietary models - ChatGPT, Claude, and Gemini - under both minimal and detailed instructions, measuring game progress through achieved scores as the primary metric. Our results reveal that all tested models achieve less than 10% completion on average, with even the best-performing model (Claude Opus 4.5) reaching only approximately 75 out of 350 possible points. Notably, providing detailed game instructions offers no improvement, nor does enabling ''extended thinking''. Qualitative analysis of the models' reasoning processes reveals fundamental limitations: repeated unsuccessful actions suggesting an inability to reflect on one's own thinking, inconsistent persistence of strategies, and failure to learn from previous attempts despite access to conversation history. These findings suggest substantial limitations in current LLMs' metacognitive abilities and problem-solving capabilities within the domain of text-based games, raising questions about the nature and extent of their reasoning capabilities.

</details>


### [71] [Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning](https://arxiv.org/abs/2602.15868)
*Magnus Boman*

Main category: cs.CL

TL;DR: 本文提出了一种基于多带图灵机的LLM交互形式化模型，将LLM各环节（字符、分词、词表、参数、激活、概率分布、输出）映射为独立纸带，从而精确定位失败模式所在阶段，并解释了思维链等技术的作用机制与局限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在看似简单的任务上仍存在失败现象，缺乏对其内部处理流程和失败根源的精确刻画与分析框架。

Method: 构建一个确定性多带图灵机模型，每条纸带对应LLM处理流程中的一个关键组件（如输入字符、token、词表、参数、激活、概率分布、输出文本），通过该形式化模型对LLM行为进行阶段化建模与故障归因。

Result: 成功将LLM常见失败（如计数任务失败）定位到具体阶段（如分词阶段破坏字符级结构）；阐明思维链提示的本质是将部分计算外显到输出纸带，同时揭示其根本局限；为LLM分析提供了可验证、非几何化的严谨框架。

Conclusion: 该图灵机形式化模型为理解、诊断和改进LLM提供了新的理论基础，弥补了纯经验规律（如缩放定律）在错误分析上的不足，推动LLM研究向更可解释、可验证的方向发展。

Abstract: Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.

</details>


### [72] [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)
*Noopur Zambare,Kiana Aghakasiri,Carissa Lin,Carrie Ye,J. Ross Mitchell,Mohamed Abdalla*

Main category: cs.CL

TL;DR: 本文系统评估了不同规模的预训练语言模型在临床去标识化任务中的性能，发现小模型在降低推理成本的同时能实现与大模型相当甚至更好的跨文化、跨性别泛化能力，并提出了面向多文化场景优化的BERT-MultiCulture-DEID模型系列。


<details>
  <summary>Details</summary>
Motivation: 以往研究未充分考察大语言模型在临床去标识化任务中对不同格式、文化背景和性别的泛化能力，亟需系统性评估与改进。

Method: 系统评估了微调后的Transformer模型（BERT系列）、小型LLM（Llama 1-8B、Qwen 1.5-7B）和大型LLM（Llama-70B、Qwen-72B）；在多语言、多性别姓名数据上进行微调；构建并开源BERT-MultiCulture-DEID模型系列。

Result: 小模型在显著降低推理成本的同时，达到甚至超过大模型的跨文化（中文、印地语、西班牙语等）和跨性别姓名识别性能；BERT-MultiCulture-DEID在多语言变体数据上表现稳健。

Conclusion: 首次量化了去标识化中效率与泛化能力的权衡关系，为公平、高效的临床隐私保护提供了切实可行的技术路径。

Abstract: Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B, Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identification. We show that smaller models achieve comparable performance while substantially reducing inference cost, making them more practical for deployment. Moreover, we demonstrate that smaller models can be fine-tuned with limited data to outperform larger models in de-identifying identifiers drawn from Mandarin, Hindi, Spanish, French, Bengali, and regional variations of English, in addition to gendered names. To improve robustness in multi-cultural contexts, we introduce and publicly release BERT-MultiCulture-DEID, a set of de-identification models based on BERT, ClinicalBERT, and ModernBERT, fine-tuned on MIMIC with identifiers from multiple language variants. Our findings provide the first comprehensive quantification of the efficiency-generalizability trade-off in de-identification and establish practical pathways for fair and efficient clinical de-identification.
  Details on accessing the models are available at: https://doi.org/10.5281/zenodo.18342291

</details>


### [73] [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)
*Shuhui Qu*

Main category: cs.CL

TL;DR: VDLM是一种新型语言模型，通过在语义变量嵌入空间中应用掩码扩散和轨迹感知优化，实现多步推理中的迭代精炼，避免了传统自回归模型的不可逆解码问题。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在多步推理中存在左到右、不可逆的解码限制，难以进行修订。

Method: 提出VDLM模型，将语义规划与文本渲染分离；在语义变量嵌入上采用LLaDA风格的掩码扩散以支持潜空间迭代优化；使用轨迹感知优化对规划器进行后训练，利用嵌入空间的奖励与价值信号；引入Vec2Text渲染器及嵌入扰动提升噪声鲁棒性。

Result: 在九个涵盖通用推理、数学和代码的基准测试中，VDLM在预训练阶段具竞争力，并在长文本生成任务的后训练阶段显著超越其他基线模型。

Conclusion: 嵌入空间的后训练与鲁棒的潜空间到文本渲染对扩散式语言建模具有显著有效性。

Abstract: Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then post-trains the planner with trajectory-aware optimization using embedding-space rewards and values, avoiding text decoding inside the RL loop. To convert planned embeddings back to text, we use a \textbf{Vec2Text} renderer and introduce \textbf{embedding perturbations} to robustify decoding under planner noise. Across nine benchmarks spanning general reasoning, math, and code, VDLM is competitive in pre-training and yields substantial post-training improvements on long-form generation tasks, outperforming other baselines. These results highlight the effectiveness of embedding-space post-training and robust latent-to-text rendering for diffusion language modeling.

</details>


### [74] [CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content](https://arxiv.org/abs/2602.15871)
*Diletta Abbonato*

Main category: cs.CL

TL;DR: 本文提出了一种名为CheckIfExist的开源网络工具，用于通过CrossRef、Semantic Scholar和OpenAlex等多源数据库实时验证参考文献的真实性，以应对大语言模型在学术写作中产生的参考文献幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在学术工作流中的广泛应用导致了参考文献幻觉（即生成看似合理但实际不存在的引用），已出现在NeurIPS和ICLR等顶级会议论文中，亟需自动化验证机制。

Method: 开发了名为CheckIfExist的开源Web工具，采用级联验证架构，结合字符串相似性算法，在CrossRef、Semantic Scholar和OpenAlex三个学术数据库中进行多源验证，并计算多维匹配置信度得分。

Result: 该工具支持单条及批量BibTeX引用验证，可在数秒内返回经验证的APA格式引用和可导出的BibTeX记录。

Conclusion: CheckIfExist填补了现有参考管理工具缺乏实时真实性验证以及商业检测服务受限于免费额度或高昂费用的空白，为学术界提供了一种高效、开放、易用的引用验证解决方案。

Abstract: The proliferation of large language models (LLMs) in academic workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such as NeurIPS and ICLR, underscoring the urgency of automated verification mechanisms. This paper presents "CheckIfExist", an open-source web-based tool designed to provide immediate verification of bibliographic references through multi-source validation against CrossRef, Semantic Scholar, and OpenAlex scholarly databases. While existing reference management tools offer bibliographic organization capabilities, they do not provide real-time validation of citation authenticity. Commercial hallucination detection services, though increasingly available, often impose restrictive usage limits on free tiers or require substantial subscription fees. The proposed tool fills this gap by employing a cascading validation architecture with string similarity algorithms to compute multi-dimensional match confidence scores, delivering instant feedback on reference authenticity. The system supports both single-reference verification and batch processing of BibTeX entries through a unified interface, returning validated APA citations and exportable BibTeX records within seconds.

</details>


### [75] [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)
*Xingda Lyu,Gongfu Lyu,Zitai Yan,Yuxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种新型检索增强生成（RAG）方法——Prompt-Enhanced Parametric RAG（P-RAG），融合参数化知识与外部检索证据，并结合思维链（CoT）提示和LoRA微调，在生物医学问答任务中显著超越标准RAG。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）受限于静态训练数据，而传统RAG又高度依赖知识库质量，因此需探索更鲁棒、自适应的RAG架构以提升生物医学等专业领域的问答性能。

Method: 提出P-RAG混合架构，集成LLM内部参数化知识与外部检索证据；采用Chain-of-Thought（CoT）提示引导推理，并基于LoRA对LLaMA-3.2-1B-Instruct进行生物医学领域微调；在PubMedQA和2WikiMultihopQA上评估三种RAG变体。

Result: P-RAG在PubMedQA上F1达93.33%，较Standard RAG提升10.47个百分点（相对提升12.64%）；在2WikiMultihopQA上总分达33.44%，约为Standard RAG（17.83%）的两倍；CoT对多跳推理提升显著，但单跳效果不一。

Conclusion: P-RAG展现出在生物医学问答中高精度、可扩展及上下文自适应的优势，为结合参数化知识与检索增强提供了新范式。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG, and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybrid architecture that integrates parametric knowledge within the LLM and retrieved evidence, guided by Chain-of-Thought (CoT) prompting and Low-Rank Adaptation (LoRA) fine-tuning-on both general and biomedical datasets. Using LLaMA-3.2-1B-Instruct fine-tuned via LoRA, we evaluate on PubMedQA and 2WikiMultihopQA. P-RAG outperforms Standard RAG on PubMedQA by 10.47 percentage points in F1 (93.33% vs. 82.86%; 12.64% relative). On 2WikiMultihopQA, P-RAG nearly doubles the overall score vs. Standard RAG (33.44% vs. 17.83%) and achieves 44.03% on the Compare subset (with 42.74% Bridge, 21.84% Inference, 8.60% Compose). CoT prompting substantially improves multi-hop reasoning but yields mixed results for simpler, single-hop queries. These findings underscore P-RAG's potential for accurate, scalable, and contextually adaptive biomedical question answering. Our contributions include: (1) LoRA-based fine-tuning of LLaMA-3.2-1B-Instruct for biomedical QA, (2) introduction of P-RAG with Chain-of-Thought prompting, and (3) state-of-the-art results on PubMedQA and 2WikiMultihopQA.

</details>


### [76] [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)
*Haihui Pan,Yuzhong Hong,Shaoke Lv,Junwei Bao,Hongfei Jiang,Yang Song*

Main category: cs.CL

TL;DR: 本文提出QEMPO方法，在保证大语言模型输出质量的前提下提升其输出多样性，通过理论分解对齐任务为质量和多样性两个分布，并设计在线与离线训练方法进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法虽提升LLM输出质量，却降低输出多样性；而提升多样性的方法又常损害性能，亟需兼顾二者的新方法。

Method: 提出质量约束下的熵最大化策略优化（QEMPO），将对齐任务分解为质量与多样性两个分布，通过施加不同约束生成不同策略，并设计在线与离线训练方法进行优化。

Result: 实验表明QEMPO在提升输出多样性的同时，性能达到或优于RLHF。

Conclusion: QEMPO能有效平衡LLM输出的质量与多样性，是一种有潜力的新型对齐优化框架。

Abstract: Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.

</details>


### [77] [Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion](https://arxiv.org/abs/2602.15895)
*Pengcheng Zhou,Haochen Li,Zhiqiang Nie,JiaLe Chen,Qing Gong,Weizhen Zhang,Chun Yu*

Main category: cs.CL

TL;DR: 本文提出CogitoRAG，一种受人类情景记忆启发的检索增强生成框架，通过提取和演化语义主干（Semantic Gist）、构建多维知识图谱、查询分解、实体扩散检索及CogniRank重排序等机制，提升LLM在复杂问答与多任务生成中的知识整合与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架因文本离散表示导致语义完整性丢失和检索偏差，需借鉴人类认知记忆机制提升语义保持与关联检索能力。

Method: 提出CogitoRAG框架：离线阶段将语料提炼为‘主干记忆’并构建成融合实体、关系事实与记忆节点的多维知识图谱；在线阶段通过查询分解模块拆解复杂问题，实体扩散模块在图上进行结构引导与频率奖励的关联检索，并用CogniRank算法融合扩散分数与语义相似度重排序，最终以‘段落-记忆配对’形式提供高密度证据。

Result: 在五个主流QA基准和GraphBench多任务生成任务上显著超越现有SOTA RAG方法，验证其在复杂知识集成与推理上的优越性。

Conclusion: CogitoRAG通过模拟人类认知记忆过程，有效缓解了传统RAG中语义断裂与检索失准问题，为构建更鲁棒、可解释的检索增强生成系统提供了新范式。

Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.

</details>


### [78] [Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens](https://arxiv.org/abs/2602.15896)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Wen Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于token的多模态知识图谱推理基础模型TOFU，通过将结构、视觉和文本信息离散化为模态特定token，并采用分层融合与混合消息机制，实现跨不同多模态知识图谱的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MMKGR方法多为归纳式设定，难以泛化到新知识图谱；而现有知识图谱基础模型（KGFMs）主要利用结构模式，忽略了丰富的多模态信号。

Method: 提出TOFU模型：将结构、视觉和文本信息离散化为模态特定token，并采用分层融合架构与混合消息机制进行token处理，以获得可迁移的多模态知识图谱推理特征。

Result: 在17个涵盖转导式、归纳式和全归纳式的多模态知识图谱上实验表明，TOFU持续优于强KGFM和MMKGR基线模型，尤其在未见MMKG上表现优异。

Conclusion: TOFU是一种具备强跨MMKG泛化能力的多模态知识图谱推理基础模型，有效融合了多模态信息与图结构信息。

Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they mainly exploit structural patterns and ignore rich multi-modal signals. We address these gaps by proposing a token-based foundation model (TOFU) for MMKGR, which exhibits strong generalization across different MMKGs. TOFU discretizes structural, visual, and textual information into modality-specific tokens. TOFU then employs a hierarchical fusion architecture with mixture-of-message mechanisms, aiming to process these tokens and obtain transferable features for MMKGR. Experimental results on 17 transductive, inductive, and fully-inductive MMKGs show that TOFU consistently outperforms strong KGFM and MMKGR baselines, delivering strong performance on unseen MMKGs.

</details>


### [79] [Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation](https://arxiv.org/abs/2602.15897)
*Xinguo Feng,Zhongkui Ma,Zihan Wang,Alsharif Abuadbba,Guangdong Bai*

Main category: cs.CL

TL;DR: 本文提出GHOST防御机制，通过在token层面进行混淆，切断梯度、嵌入和token空间间的内在联系，有效抵御梯度反演攻击（GIA），在保护隐私的同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度扰动的防御方法因未能彻底打破梯度、嵌入与token空间之间的语义相似性而效果有限，亟需一种能从根本上解耦三者关系的新机制。

Method: 提出GHOST：一种token级混淆机制，包含两步——多准则搜索语义不同但嵌入相近的候选token，再选择最优‘影子token’以最小化对关键训练特征的影响，并保持与原始token内部输出的一致性。

Result: 在BERT至Llama等多种模型和数据集上验证，GHOST将数据恢复率降至1%，分类F1达0.92、困惑度为5.45，显著优于现有方法，且对自适应攻击鲁棒。

Conclusion: GHOST通过token空间语义断连实现高效隐私保护，兼顾模型效用，为协同学习中的梯度安全提供了新范式。

Abstract: Training and fine-tuning large-scale language models largely benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs' direct mapping from gradient space to token space. However, these methods often fall short due to the retention of semantics similarity across gradient, embedding, and token spaces. In this work, we propose a novel defense mechanism named GHOST (gradient shield with obfuscated tokens), a token-level obfuscation mechanism that neutralizes GIAs by decoupling the inherent connections across gradient, embedding, and token spaces. GHOST is built upon an important insight: due to the large scale of the token space, there exist semantically distinct yet embedding-proximate tokens that can serve as the shadow substitutes of the original tokens, which enables a semantic disconnection in the token space while preserving the connection in the embedding and gradient spaces. GHOST comprises a searching step, which identifies semantically distinct candidate tokens using a multi-criteria searching process, and a selection step, which selects optimal shadow tokens to ensure minimal disruption to features critical for training by preserving alignment with the internal outputs produced by original tokens. Evaluation across diverse model architectures (from BERT to Llama) and datasets demonstrates the remarkable effectiveness of GHOST in protecting privacy (as low as 1% in recovery rate) and preserving utility (up to 0.92 in classification F1 and 5.45 in perplexity), in both classification and generation tasks against state-of-the-art GIAs and adaptive attack scenarios.

</details>


### [80] [MultiCube-RAG for Multi-hop Question Answering](https://arxiv.org/abs/2602.15898)
*Jimeng Shi,Wei Hu,Runchu Tian,Bowen Jin,Wonbin Kweon,SeongKu Kang,Yunfan Kang,Dingqi Ye,Sizhe Zhou,Shaowen Wang,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的多立方体检索增强生成（MultiCube-RAG）方法，利用本体驱动的多维立方体结构建模多跳问答中的主体、属性与关系，通过分解查询并逐维检索提升准确率、效率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法难以准确捕捉多跳QA所需的结构化语义，图结构方法存在噪声大、计算开销高及单步检索无法支持多跳推理的问题；基于训练的方法又面临收敛不稳定和资源消耗大的挑战。

Method: 构建本体驱动的多维正交立方体结构，每个立方体专精于一类主体建模；提出MultiCube-RAG方法，将复杂多跳查询沿立方体维度分解为多个子查询，并依次在适配的立方体中进行多步推理与检索。

Result: 在四个多跳QA数据集上，MultiCube-RAG相较多种基线平均准确率提升8.9%，同时展现出更高效率和内在可解释性。

Conclusion: MultiCube-RAG是一种训练自由、结构清晰、可解释性强且高效的多跳问答解决方案，有效克服了现有RAG方法在结构建模与多步推理上的关键局限。

Abstract: Multi-hop question answering (QA) necessitates multi-step reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and computationally expensive. Moreover, most methods rely on single-step retrieval, neglecting the need for multi-hop reasoning processes. Recent training-based approaches attempt to incentivize the large language models (LLMs) for iterative reasoning and retrieval, but their training processes are prone to unstable convergence and high computational overhead. To address these limitations, we devise an ontology-based cube structure with multiple and orthogonal dimensions to model structural subjects, attributes, and relations. Built on the cube structure, we propose MultiCube-RAG, a training-free method consisting of multiple cubes for multi-step reasoning and retrieval. Each cube specializes in modeling a class of subjects, so that MultiCube-RAG flexibly selects the most suitable cubes to acquire the relevant knowledge precisely. To enhance the query-based reasoning and retrieval, our method decomposes a complex multi-hop query into a set of simple subqueries along cube dimensions and conquers each of them sequentially. Experiments on four multi-hop QA datasets show that MultiCube-RAG improves response accuracy by 8.9% over the average performance of various baselines. Notably, we also demonstrate that our method performs with greater efficiency and inherent explainability.

</details>


### [81] [Doc-to-LoRA: Learning to Instantly Internalize Contexts](https://arxiv.org/abs/2602.15902)
*Rujikorn Charakorn,Edoardo Cetin,Shinnosuke Uesaka,Robert Tjarko Lange*

Main category: cs.CL

TL;DR: 本文提出Doc-to-LoRA（D2L），一种轻量级超网络，可在单次前向传播中为大语言模型（LLM）生成LoRA适配器，实现上下文信息的快速、低开销蒸馏，显著降低长上下文推理的内存与延迟开销。


<details>
  <summary>Details</summary>
Motivation: Transformer的二次方注意力计算导致长上下文推理内存消耗高、速度慢；传统上下文蒸馏（CD）虽可将信息注入参数，但逐提示蒸馏因训练成本和延迟过高而不可行。

Method: 提出Doc-to-LoRA（D2L）：一个元学习的轻量级超网络，接收新提示后在单次前向中生成适配目标LLM的LoRA适配器，使后续查询无需重复读取原始上下文，从而节省KV缓存与推理开销。

Result: 在'针在 haystack'长上下文任务中，D2L在超出LLM原生上下文窗口4倍以上时仍达近似零样本完美准确率；在真实QA数据集上，D2L优于标准CD，同时显著降低峰值内存与更新延迟。

Conclusion: D2L为LLM提供了高效、低延迟的上下文自适应能力，支持高频知识更新与个性化对话，推动长上下文场景下实用化部署。

Abstract: Long input sequences are central to in-context learning, document understanding, and multi-step reasoning of Large Language Models (LLMs). However, the quadratic attention cost of Transformers makes inference memory-intensive and slow. While context distillation (CD) can transfer information into model parameters, per-prompt distillation is impractical due to training costs and latency. To address these limitations, we propose Doc-to-LoRA (D2L), a lightweight hypernetwork that meta-learns to perform approximate CD within a single forward pass. Given an unseen prompt, D2L generates a LoRA adapter for a target LLM, enabling subsequent queries to be answered without re-consuming the original context, reducing latency and KV-cache memory consumption during inference of the target LLM. On a long-context needle-in-a-haystack task, D2L successfully learns to map contexts into adapters that store the needle information, achieving near-perfect zero-shot accuracy at sequence lengths exceeding the target LLM's native context window by more than 4x. On real-world QA datasets with limited compute, D2L outperforms standard CD while significantly reducing peak memory consumption and update latency. We envision that D2L can facilitate rapid adaptation of LLMs, opening up the possibility of frequent knowledge updates and personalized chat behavior.

</details>


### [82] [DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting](https://arxiv.org/abs/2602.15958)
*Md Mofijul Islam,Md Sirajus Salekin,Nivedha Balakrishnan,Vincil C. Bishop,Niharika Jain,Spencer Romo,Bob Strahan,Boyi Xie,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: 本文提出了首个面向文档包分割任务的综合基准数据集DocSplit，旨在评估大语言模型在多页异构文档包中识别文档边界、分类文档类型及维持正确页面顺序的能力，并揭示了现有模型在处理复杂文档分割任务时的显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档理解常需处理由多个文档拼接而成的异构多页文档包，但文档包分割这一基础任务尚未得到充分研究。

Method: 构建了包含五个不同复杂度数据集的DocSplit基准，形式化定义了文档包分割任务，并提出新的评估指标；对多模态大语言模型进行了广泛实验评估。

Result: 实验揭示了当前多模态大语言模型在处理乱序页面、交错文档及缺乏明确分隔的文档等真实挑战时存在显著性能差距。

Conclusion: DocSplit为法律、金融、医疗等文档密集型领域提供了系统性评估框架，推动文档理解能力的发展，并已开源数据集以支持后续研究。

Abstract: Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.

</details>


### [83] [A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023)
*Junghyun Min,Na-Rae Han,Jena D. Hwang,Nathan Schneider*

Main category: cs.CL

TL;DR: This paper studies Korean postpositional verb-based constructions (PVCs), a class of multiword adpositions, analyzes them using Korean Wikipedia data, contrasts them with non-MWEs and light verb constructions, and proposes annotation guidelines to support future Korean MWE research and cross-lingual alignment.


<details>
  <summary>Details</summary>
Motivation: Korean multiword expressions, especially multiword adpositions, are underrepresented in cross-lingual annotation frameworks like PARSEME; there is a lack of systematic analysis, annotated resources, and integration for Korean MWEs.

Method: The authors survey and analyze PVCs from Korean Wikipedia data, contrast them with non-MWEs and light verb constructions (LVCs), and develop annotation guidelines based on this analysis.

Result: A systematic analysis of Korean PVCs is presented, along with proposed annotation guidelines tailored for Korean multiword adpositions.

Conclusion: The study fills a gap in Korean MWE research by characterizing PVCs and offering annotation guidelines that enable future resource development and alignment with multilingual frameworks.

Abstract: Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

</details>


### [84] [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)
*Bradley McDanel,Steven Li,Harshit Khaitan*

Main category: cs.CL

TL;DR: 本文提出Answer-Informed Oracle来评估token重要性，并发现现有token-ranking方法在不同层间重要性估计不稳定；为此，作者提出Cross-Layer Attention Aggregation（CLAA）方法，通过跨层聚合注意力分数提升稳定性，在TTFT上相较全KV缓存基线最高提速39%。


<details>
  <summary>Details</summary>
Motivation: 现有token-ranking启发式方法在长上下文LLM推理的prefill阶段存在token重要性估计不稳定、层间差异大的问题，且缺乏独立于具体架构的评估方式。

Method: 提出Answer-Informed Oracle作为token重要性的真值标准（基于生成答案对输入prompt的注意力），诊断现有方法层间不一致性，并据此设计Cross-Layer Attention Aggregation（CLAA）——跨层聚合注意力分数以提升鲁棒性。

Result: CLAA显著缩小了与Oracle上界之间的差距，在Time-to-First-Token（TTFT）上相较Full KV Cache基线最多降低39%。

Conclusion: 跨层聚合是提升token-ranking稳定性的关键，Answer-Informed Oracle为评估和改进此类方法提供了可解释、可复现的诊断工具。

Abstract: The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific architectures is challenging. To address this, we introduce an Answer-Informed Oracle, which defines ground-truth token importance by measuring attention from generated answers back to the prompt. This oracle reveals that existing heuristics exhibit high variance across layers: rankings can degrade sharply at specific layers, a failure mode invisible to end-to-end benchmarks. The diagnosis suggests a simple fix: aggregate scores across layers rather than relying on any single one. We implement this as Cross-Layer Attention Aggregation (CLAA), which closes the gap to the oracle upper bound and reduces Time-to-First-Token (TTFT) by up to 39\% compared to the Full KV Cache baseline.

</details>


### [85] [Surgical Activation Steering via Generative Causal Mediation](https://arxiv.org/abs/2602.16080)
*Aruna Sankaranarayanan,Amir Zur,Atticus Geiger,Dylan Hadfield-Menell*

Main category: cs.CL

TL;DR: 本文提出了生成因果中介（GCM）方法，用于在语言模型中定位并干预影响长文本输出行为的关键组件（如注意力头），以控制二元概念（如诗歌vs散文风格），并在拒绝回答、谄媚倾向和风格迁移任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 如何在语言模型中干预那些弥散在长文本响应多个token中的行为？

Method: 提出生成因果中介（GCM）流程：构建对比输入-输出数据集，量化各模型组件对对比概念的中介效应，并选择最强中介组件进行干预 steering。

Result: GCM成功定位长文本中表达的概念，在拒绝、谄媚、风格迁移三任务及三个模型上，用稀疏注意力头干预时持续优于相关性探针基线。

Conclusion: GCM为定位与控制语言模型长文本响应提供了一种有效方法。

Abstract: Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.

</details>


### [86] [Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085)
*Sean Trott,Samuel Taylor,Cameron Jones,James A. Michaelov,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 本文通过测试41个开源语言模型在错误信念任务中的表现，发现部分模型对隐含知识状态具有敏感性，但无一能完全解释人类行为；大模型敏感性更高且心理测量预测力更强；研究还提出并验证了一个新假设：人类和语言模型均倾向于在使用非事实动词（如‘认为’）提示知识状态时归因错误信念，该效应在人类与模型间幅度相当，暗示语言分布统计可能解释此现象。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖少量闭源语言模型，限制了对人类社会认知理论的严格检验及对语言模型能力的全面评估；需利用更大规模开源模型样本推进相关研究。

Method: 在41个来自不同家族的开源语言模型上复现并扩展错误信念任务实验，分析其对知识状态线索（如非事实动词 vs 间接动作描述）的响应，并与人类行为对比；进一步基于模型行为提出并检验关于人类认知的新假设。

Result: 34%的模型表现出对隐含知识状态的敏感性；大模型敏感性与心理测量预测力更高；人类与模型均在‘John thinks...’线索下比‘John looks...’线索下更易归因错误信念，且该线索效应的人类幅度落在模型效应分布范围内。

Conclusion: 使用大规模开源语言模型可有效检验人类认知理论并评估模型能力；语言的统计特性可能解释部分人类社会推理偏差（如知识线索效应），但无法解释核心的错误信念敏感性差异。

Abstract: Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

</details>


### [87] [Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities](https://arxiv.org/abs/2602.16093)
*Shankar Padmanabhan,Mustafa Omer Gul,Tanya Goyal*

Main category: cs.CL

TL;DR: 本文提出了一种名为DiSC的持续知识适应方法，通过分割上下文进行蒸馏，在不牺牲原有能力（如指令遵循、推理和事实知识）的前提下，有效学习新知识。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法在从新文档语料中学习新知识的同时，防止对先前习得能力的遗忘。

Method: 提出Distillation via Split Contexts (DiSC)，通过将训练样本划分为不同段落分别构建师生分布，并最小化共享token上的KL散度，避免训练中显式生成步骤。

Result: 在四个后训练模型和两个适应领域上的实验表明，DiSC在学习新知识与缓解旧能力遗忘之间取得了最优权衡。

Conclusion: DiSC是一种高效、简洁的持续知识适应方法，显著优于现有微调与蒸馏方法。

Abstract: Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of earlier learned capabilities. To address this, we introduce Distillation via Split Contexts (DiSC), a simple context-distillation based approach for continual knowledge adaptation. \methodname~derives student and teacher distributions by conditioning on distinct segments of the training example and minimizes the KL divergence between the shared tokens. This allows us to efficiently apply context-distillation without requiring explicit generation steps during training. We run experiments on four post-trained models and two adaptation domains. Compared to prior finetuning and distillation methods for continual adaptation, DiSC consistently reports the best trade-off between learning new knowledge and mitigating forgetting of previously learned skills like instruction-following, reasoning, and factual knowledge.

</details>


### [88] [Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis](https://arxiv.org/abs/2602.16144)
*Rong Fu,Wenxin Zhang,Ziming Wang,Chunlei Meng,Jiaxuan Lu,Jiekai Wu,Kangan Qian,Hao Zhang,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出了Missing-by-Design (MBD)框架，用于可撤销的多模态情感分析，支持选择性删除特定模态数据，并提供可验证的删除证书，在隐私保护与模型性能间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 随着多模态系统处理越来越多敏感个人数据，用户或监管方可能要求撤回特定模态数据，因此需要具备可撤销能力以满足隐私合规和用户自主权需求。

Method: MBD结合结构化表征学习与可认证参数修改流程：学习属性感知嵌入，利用生成器重建缺失模态；对删除请求，采用显著性驱动的候选选择与校准高斯更新，生成可机器验证的模态删除证书。

Result: 在基准数据集上的实验表明，MBD在输入不完整时仍保持强预测性能，并实现了实用的隐私-效用权衡。

Conclusion: MBD将‘精准遗忘’（surgical unlearning）确立为全量重训练的高效替代方案，为可撤销多模态学习提供了统一、可验证的框架。

Abstract: As multimodal systems increasingly process sensitive personal data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal sentiment analysis that combines structured representation learning with a certifiable parameter-modification pipeline. Revocability is critical in privacy-sensitive applications where users or regulators may request removal of modality-specific information. MBD learns property-aware embeddings and employs generator-based reconstruction to recover missing channels while preserving task-relevant signals. For deletion requests, the framework applies saliency-driven candidate selection and a calibrated Gaussian update to produce a machine-verifiable Modality Deletion Certificate. Experiments on benchmark datasets show that MBD achieves strong predictive performance under incomplete inputs and delivers a practical privacy-utility trade-off, positioning surgical unlearning as an efficient alternative to full retraining.

</details>


### [89] [Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution](https://arxiv.org/abs/2602.16154)
*Nithin Sivakumaran,Shoubin Yu,Hyunji Lee,Yue Zhang,Ali Payani,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文提出REMUL方法，通过多听众执行推理链（CoT）来提升其忠实性，同时兼顾任务性能，在多个基准上显著改善了忠实性指标和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有链式推理（CoT）常不能真实反映大语言模型的实际计算过程，影响可解释性；且提升忠实性与可解释性往往损害任务性能，存在权衡问题。

Method: 提出Reasoning Execution by Multiple Listeners（REMUL），一种多方强化学习方法：一个说话者模型生成推理链，被截断后交由多个听众模型执行并续写至答案；说话者依据听众能否成功执行而获得奖励，并辅以掩码监督微调确保答案正确性。

Result: 在BIG-Bench Extra Hard、MuSR、ZebraLogicBench和FOLIO等多个推理基准上，REMUL显著提升了三种忠实性指标（hint attribution、early answering AOC、mistake injection AOC），同时提高了准确率；分析表明该方法具有跨领域鲁棒性、提升可读性、并生成更短更直接的推理链。

Conclusion: REMUL有效缓解了推理忠实性与任务性能之间的权衡，为构建既可信又高效的大模型推理机制提供了新范式。

Abstract: Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution by Multiple Listeners (REMUL), a multi-party reinforcement learning approach. REMUL builds on the hypothesis that reasoning traces which other parties can follow will be more faithful. A speaker model generates a reasoning trace, which is truncated and passed to a pool of listener models who "execute" the trace, continuing the trace to an answer. Speakers are rewarded for producing reasoning that is clear to listeners, with additional correctness regularization via masked supervised finetuning to counter the tradeoff between faithfulness and performance. On multiple reasoning benchmarks (BIG-Bench Extra Hard, MuSR, ZebraLogicBench, and FOLIO), REMUL consistently and substantially improves three measures of faithfulness -- hint attribution, early answering area over the curve (AOC), and mistake injection AOC -- while also improving accuracy. Our analysis finds that these gains are robust across training domains, translate to legibility gains, and are associated with shorter and more direct CoTs.

</details>


### [90] [LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers](https://arxiv.org/abs/2602.16162)
*Peiqi Sui*

Main category: cs.CL

TL;DR: 本文指出不确定性是当前大语言模型（LLM）在创意写作中表现平庸的关键未被充分研究的限制因素；通过信息论方法量化人类写作与模型生成文本间的‘不确定性差距’，发现人类文本不确定性显著更高，且该差距与写作质量强相关；作者呼吁发展能区分有害幻觉与有益文学模糊性的新型不确定性感知对齐范式。


<details>
  <summary>Details</summary>
Motivation: 文学理论认为不确定性是创造性表达的必要条件，但当前LLM对齐策略为保障事实性和减少幻觉，倾向于压制不确定性，导致生成文本陈腐刻板；这一矛盾尚未被系统量化和分析。

Method: 提出并形式化‘不确定性差距’概念，基于信息熵等指标，在高质量故事数据集上对28个LLM进行受控的信息论分析，对比人类作者文本与模型续写文本的不确定性水平，并分层比较基础模型、指令微调模型与推理增强模型，以及创意写作与功能型任务的差异。

Result: 实证发现：（1）人类写作不确定性显著高于所有测试LLM；（2）指令微调与推理模型进一步拉大该差距；（3）该差距在创意写作中比功能任务中更显著；（4）不确定性差距与人工评估的写作质量呈强负相关。

Conclusion: 要实现人类水平的创意写作能力，需构建新型对齐范式——既能抑制破坏性幻觉，又能保留并鼓励具有文学价值的建设性不确定性（即创造性模糊性）。

Abstract: We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and cliché-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize this tension by quantifying the "uncertainty gap" between human-authored stories and model-generated continuations. Through a controlled information-theoretic analysis of 28 LLMs on high-quality storytelling datasets, we demonstrate that human writing consistently exhibits significantly higher uncertainty than model outputs. We find that instruction-tuned and reasoning models exacerbate this trend compared to their base counterparts; furthermore, the gap is more pronounced in creative writing than in functional domains, and strongly correlates to writing quality. Achieving human-level creativity requires new uncertainty-aware alignment paradigms that can distinguish between destructive hallucinations and the constructive ambiguity required for literary richness.

</details>


### [91] [Beyond Learning: A Training-Free Alternative to Model Adaptation](https://arxiv.org/abs/2602.16189)
*Namkyung Yoon,Kyeonghyun Yoo,Wooyong Jung,Sanghong Kim,Hwangnam Kim*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的‘模型移植’技术，通过识别并迁移语言模型中任务特异的局部激活模块，显著提升欠佳模型性能，验证了语言模型存在任务局部化模组，并开辟了模型移植新研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有提升语言模型性能的方法资源消耗大，缺乏能立即生效的轻量替代方案；作者假设语言模型内部存在功能特异的局部模块，可被识别与复用。

Method: 基于激活分析识别在推理任务下稳定且局部激活变化的模块，将其从源模型直接移植到目标模型中，不进行任何训练或微调。

Result: 在跨代模型间移植使欠佳模型性能达目标基线的2倍，gap-based recovery超100%；在基础模型与指令微调模型间移植，性能达目标基线约2.33倍，gap-based recovery最高达100%。

Conclusion: 语言模型具备任务局部化模组结构，通过模块移植可实现有意义的能力迁移；该工作为语言模型的模块化理解与轻量干预提供了实证支持，并正式提出‘模型移植’这一新研究方向。

Abstract: Despite the continuous research and evolution of language models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each language model has a local module inside that is suitable for a specific function. First, this work identifies a set of modules showing consistent and local activation changes under an inference workload through activation-based analysis. Subsequently, we transplant an internal module that is properly activated for a specific task into the target model, leading to immediate and measurable functional changes without additional training or fine-tuning. To experimentally demonstrate the effectiveness of the transplant technique, we quantify the relationship between transplant strength and performance improvement under different conditions for two language models. In the cross-generation setting, we find that transplanting activation-selected modules can substantially improve the underperforming model, reaching up to twice the target baseline and achieving gap-based recovery above 100%. Moreover, in transplant experiments between a base model and its instruction-tuned counterpart, transplantation improves the underperforming model toward the stronger baseline, yielding up to about 2.33 times the target baseline with gap-based recovery reaching up to 100% in the best case. These results show that meaningful capacity transfer can be realized through the implantation of highly localized modules implied by language models. Overall, this work provides empirical evidence for task-localized modularity in language models and presents a new research area: model transplantation.

</details>


### [92] [The Validity of Coreference-based Evaluations of Natural Language Understanding](https://arxiv.org/abs/2602.16200)
*Ian Porada*

Main category: cs.CL

TL;DR: 本文通过扩展共指消解评估方法，揭示了当前评估结果的收敛性与冲突性，并提出一种基于事件相对可能性推断的新评估方式，发现现代语言模型虽在标准基准上表现优异，但泛化能力仍受限，暴露出测量效度等问题。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解评估方法存在测量效度问题（如共指定义不统一、不同基准排名不一致），导致结论难以推广，需系统性反思和改进评估实践。

Method: 1）分析标准共指消解评估的设计缺陷；2）提出并实施一种聚焦于事件相对可能性推断能力的新评估范式。

Result: 现代语言模型在标准基准上性能优于早期基线，但在评估条件微调后泛化能力明显下降，不同基准间结果不一致，暴露测量效度不足。

Conclusion: 当前NLP范式在共指消解任务上兼具进步（如准确率提升）与局限（如效度低、泛化弱），亟需构建更可靠、更具人类一致性的评估方法与模型。

Abstract: In this thesis, I refine our understanding as to what conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and considering the extent to which evaluation results are either converging or conflicting. First, I analyze standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to issues of measurement validity - including contestedness (multiple, competing definitions of coreference) and convergent validity (evaluation results that rank models differently across benchmarks). Second, I propose and implement a novel evaluation focused on testing systems' ability to infer the relative plausibility of events, a key aspect of resolving coreference. Through this extended evaluation, I find that contemporary language models demonstrate strong performance on standard benchmarks - improving over earlier baseline systems within certain domains and types of coreference - but remain sensitive to the evaluation conditions: they often fail to generalize in ways one would expect a human to be capable of when evaluation contexts are slightly modified. Taken together, these findings clarify both the strengths, such as improved accuracy over baselines on widely used evaluations, and the limitations of the current NLP paradigm, including weaknesses in measurement validity, and suggest directions for future work in developing better evaluation methods and more genuinely generalizable systems.

</details>


### [93] [Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications](https://arxiv.org/abs/2602.16201)
*Sanket Badhe,Deep Shah,Nehal Kathrotia*

Main category: cs.CL

TL;DR: 本文提出了一种系统性分析大语言模型中长尾知识的框架，涵盖定义、丢失/失真机制、技术缓解方法及公平性等社会技术影响，并指出当前评估方法对长尾行为的掩盖问题，最后讨论了隐私、可持续性和治理等开放挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在平均性能上随规模提升而改善，但在低频、领域特定、文化及时间敏感等长尾知识上仍存在持续且未被充分刻画的失败。

Method: 构建了一个四轴分析框架：长尾知识的定义方式、训练与推理中长尾知识丢失或失真的机制、缓解这些失败的技术干预措施、以及这些失败对公平性、可问责性、透明度和用户信任的影响。同时分析了现有评估实践如何掩盖长尾行为。

Result: 提出了一个统一的概念框架，用于理解长尾知识在大语言模型中的定义、丢失、评估与实际表现；揭示了评估方法对罕见但重要失败的掩盖问题；识别出隐私、可持续性与治理等方面的开放挑战。

Conclusion: 长尾知识问题不仅关乎技术性能，更涉及社会技术维度；需跨学科视角与系统性方法来定义、评估与治理长尾知识在部署模型中的表现。

Abstract: Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives.
  We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.

</details>


### [94] [Are LLMs Ready to Replace Bangla Annotators?](https://arxiv.org/abs/2602.16241)
*Md. Najib Hasan,Touseef Hasan,Souvika Sarkar*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）作为零样本标注器在孟加拉语仇恨言论检测任务中的可靠性，发现其存在显著的标注偏差与不稳定性，且模型规模增大并不必然提升标注质量；较小但任务适配性更强的模型反而更稳定。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs作为自动化标注器在低资源、身份敏感场景（如孟加拉语仇恨言论）下的可靠性与偏见问题，因人类标注者在此类任务中亦存在高分歧，偏差可能引发严重下游影响。

Method: 对17个LLM在统一评估框架下开展系统性基准测试，聚焦零样本设置下的孟加拉语仇恨言论标注行为分析。

Result: 发现LLMs普遍存在标注偏差和判断不稳定性；模型规模与标注质量无正相关，部分小型任务对齐模型表现更一致。

Conclusion: 当前LLMs在低资源、敏感标注任务中存在重要局限，部署前需审慎评估，不能仅依赖模型规模。

Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.

</details>


### [95] [Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation](https://arxiv.org/abs/2602.16290)
*Jonathan Mutal,Perla Al Almaoui,Simon Hengchen,Pierrette Bouillon*

Main category: cs.CL

TL;DR: 本文提出了Aladdin-FTI系统，用于阿拉伯方言的生成与翻译，支持多种方言、现代标准阿拉伯语及英语之间的双向翻译与文本生成，并开源了代码和模型。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言在自然语言处理研究中长期被忽视，因其缺乏标准化和高度变异性，而大语言模型为将其建模为多中心语言提供了新机会。

Method: 提出Aladdin-FTI系统，支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特阿拉伯方言的文本生成，以及这些方言与现代标准阿拉伯语（MSA）和英语之间的双向翻译。

Result: 成功构建并提交了AMITYA共享任务的系统，实现了多方言生成与跨语言翻译能力，并公开了代码与训练模型。

Conclusion: Aladdin-FTI验证了大语言模型在建模阿拉伯语多中心性方面的有效性，为低资源方言NLP提供了可行路径。

Abstract: Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.

</details>


### [96] [MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models](https://arxiv.org/abs/2602.16298)
*Martin Hyben,Sebastian Kula,Jan Cegin,Jakub Simko,Ivan Srba,Robert Moro*

Main category: cs.CL

TL;DR: 本文介绍了Multi-Check-Worthy (MultiCW) 多语言数据集，用于检测值得核查的声明，并在多种语言、领域和文本风格上对微调模型与零样本大语言模型进行了基准测试，结果表明微调模型在分类准确率和跨分布泛化能力上均优于零样本大模型。


<details>
  <summary>Details</summary>
Motivation: 当前媒体从业者在事实核查中缺乏对值得核查声明（check-worthy claims）的自动化支持，而大型语言模型（LLMs）在此关键步骤上的应用仍有限。

Method: 构建了包含16种语言、7个主题领域和2种写作风格的平衡多语言数据集MultiCW（共123,722样本），并设计了4种新语言的27,761样本OOD评估集；对比评测了3种微调多语言Transformer模型与15种商用/开源LLM在零样本设置下的性能。

Result: 微调模型在声明分类任务上持续优于零样本LLM，并在语言、领域和风格等跨分布场景中展现出强泛化能力。

Conclusion: MultiCW为多语言自动事实核查提供了严谨基准，支持对微调模型与前沿LLM在check-worthy claim检测任务上的系统性比较。

Abstract: Large Language Models (LLMs) are beginning to reshape how media professionals verify information, yet automated support for detecting check-worthy claims a key step in the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing styles. It consists of 123,722 samples, evenly distributed between noisy (informal) and structured (formal) texts, with balanced representation of check-worthy and non-check-worthy classes across all languages. To probe robustness, we also introduce an equally balanced out-of-distribution evaluation set of 27,761 samples in 4 additional languages. To provide baselines, we benchmark 3 common fine-tuned multilingual transformers against a diverse set of 15 commercial and open LLMs under zero-shot settings. Our findings show that fine-tuned models consistently outperform zero-shot LLMs on claim classification and show strong out-of-distribution generalization across languages, domains, and styles. MultiCW provides a rigorous multilingual resource for advancing automated fact-checking and enables systematic comparisons between fine-tuned models and cutting-edge LLMs on the check-worthy claim detection task.

</details>


### [97] [MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks](https://arxiv.org/abs/2602.16313)
*Zexue He,Yu Wang,Churan Zhi,Yuanzhe Hu,Tzu-Ping Chen,Lang Yin,Ze Chen,Tong Arthur Wu,Siru Ouyang,Zihan Wang,Jiaxin Pei,Julian McAuley,Yejin Choi,Alex Pentland*

Main category: cs.CL

TL;DR: 本文提出MemoryArena，一个用于评估具有记忆能力的智能体在多轮交互中记忆与行动耦合能力的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将记忆和行动分开测试，无法反映真实场景中二者紧密耦合的关系。

Method: 构建MemoryArena评估框架，包含人工设计的多阶段、子任务相互依赖的代理任务，要求智能体在多会话中通过经验提炼记忆并用于后续决策。

Result: 实验表明，在LoCoMo等长上下文记忆基准上表现优异的智能体，在MemoryArena中表现较差，揭示了当前评估体系的不足。

Conclusion: MemoryArena填补了对智能体记忆-行动联合能力评估的空白，推动更贴近实际应用的记忆能力评测发展。

Abstract: Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings, memorization and action are tightly coupled: agents acquire memory while interacting with the environment, and subsequently rely on that memory to solve future tasks. To capture this setting, we introduce MemoryArena, a unified evaluation gym for benchmarking agent memory in multi-session Memory-Agent-Environment loops. The benchmark consists of human-crafted agentic tasks with explicitly interdependent subtasks, where agents must learn from earlier actions and feedback by distilling experiences into memory, and subsequently use that memory to guide later actions to solve the overall task. MemoryArena supports evaluation across web navigation, preference-constrained planning, progressive information search, and sequential formal reasoning, and reveals that agents with near-saturated performance on existing long-context memory benchmarks like LoCoMo perform poorly in our agentic setting, exposing a gap in current evaluations for agents with memory.

</details>


### [98] [Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346)
*Nivya Talokar,Ayush K Tarun,Murari Mandal,Maksym Andriushchenko,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出STING框架，用于多轮红队测试LLM智能体在执行非法任务时的滥用风险，通过自适应多步探测和判别式评估，揭示了现有单轮测试方法的不足，并在多语言场景下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体滥用评测基准主要关注单轮提示，无法反映真实多轮交互中智能体被诱导执行有害或非法任务的风险，存在评估盲区。

Method: 提出STING（Sequential Testing of Illicit N-step Goal execution）自动化红队框架：构建基于良性身份的多步非法计划，利用判别智能体追踪各阶段完成情况，并采用时间至首次越狱（time-to-first-jailbreak）建模，引入发现曲线、危害比归因及受限平均越狱发现（RMJD）等分析工具。

Result: 在AgentHarm场景中，STING显著高于单轮提示与适配后的多轮聊天基线的非法任务完成率；六种非英语语种实验表明，攻击成功率与非法任务完成率并不随语言资源降低而系统性上升，与传统聊天机器人结论不同。

Conclusion: STING为真实部署环境下（多轮、多语言）的LLM智能体滥用风险评估提供了实用、可扩展的评测框架，推动更鲁棒的安全评估实践。

Abstract: LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.

</details>


### [99] [Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents](https://arxiv.org/abs/2602.16379)
*Mohammad H. A. Monfared,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 本文提出了一种面向方面情感分析（ABSA）的智能体式数据增强方法，通过迭代生成与验证提升合成数据质量，并在多个子任务和数据集上验证其优于传统提示式生成方法，尤其对轻量级模型T5-Base增益显著。


<details>
  <summary>Details</summary>
Motivation: 提升ABSA任务中合成数据的质量与标签保真度，尤其解决需生成方面术语的任务中现有提示方法的局限性。

Method: 设计一种基于智能体（agentic）结构的数据增强方法，包含迭代生成与验证机制；同时构建指令一致的提示式基线以控制变量；在ATE、ATSC、ASPE三个子任务、四个SemEval数据集及T5-Base与Tk-Instruct两个模型上进行评估。

Result: 智能体式增强在标签保真度上优于提示式方法，尤其在需生成方面术语的任务中；与真实数据联合使用时性能提升更显著；对T5-Base增益明显，使其性能接近更强的Tk-Instruct。

Conclusion: 智能体式数据增强是一种有效提升ABSA模型训练数据质量的方法，其结构优势在模型能力受限时尤为突出，为低资源或轻量模型提供了实用增强策略。

Abstract: We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE)), four SemEval datasets, and two encoder-decoder models: T5-Base and Tk-Instruct. Our results show that the agentic augmentation outperforms raw prompting in label preservation of the augmented data, especially when the tasks require aspect term generation. In addition, when combined with real data, agentic augmentation provides higher gains, consistently outperforming prompting-based generation. These benefits are most pronounced for T5-Base, while the more heavily pretrained Tk-Instruct exhibits smaller improvements. As a result, augmented data helps T5-Base achieve comparable performance with its counterpart.

</details>


### [100] [TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers](https://arxiv.org/abs/2602.16429)
*Ido Levy,Eilam Shapira,Yinon Goldshtein,Avi Yaeli,Nir Mashkif,Segev Shlomov*

Main category: cs.CL

TL;DR: 本文提出TabAgent框架，用轻量级文本-表格分类器替代智能体系统中闭合集决策任务中的大语言模型调用，显著降低延迟和推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的智能体系统在闭合集决策任务（如路由、筛选、门控、验证）中重复调用LLM，导致部署慢、成本高。

Method: TabAgent包含三部分：(i) 从执行轨迹中提取结构化模式、状态与依赖特征（TabSchema）；(ii) 利用模式对齐的合成数据增强监督（TabSynth）；(iii) 使用轻量级分类器（TabHead）对候选对象打分。

Result: 在长时序AppWorld基准上，TabAgent保持任务成功率，消除短列表阶段的LLM调用，延迟降低约95%，推理成本降低85–91%；并可泛化至其他智能体决策头。

Conclusion: TabAgent为生产级智能体架构中以学习型判别式模块替代生成式瓶颈提供了新范式。

Abstract: Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a framework for replacing generative decision components in closed-set selection tasks with a compact textual-tabular classifier trained on execution traces. TabAgent (i) extracts structured schema, state, and dependency features from trajectories (TabSchema), (ii) augments coverage with schema-aligned synthetic supervision (TabSynth), and (iii) scores candidates with a lightweight classifier (TabHead). On the long-horizon AppWorld benchmark, TabAgent maintains task-level success while eliminating shortlist-time LLM calls, reducing latency by approximately 95% and inference cost by 85-91%. Beyond tool shortlisting, TabAgent generalizes to other agentic decision heads, establishing a paradigm for learned discriminative replacements of generative bottlenecks in production agent architectures.

</details>


### [101] [IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models](https://arxiv.org/abs/2602.16467)
*Saurabh Bharti,Gaurav Azad,Abhinaw Jagtap,Nachiket Tapas*

Main category: cs.CL

TL;DR: 本文提出了IndicEval，一个基于真实高难度考试题（UPSC、JEE、NEET）的多语言（英/印地语）、跨学科LLM评测平台，强调现实学术严谨性；实验发现CoT提示有效提升推理准确率，模型间性能差异显著，且印地语表现明显弱于英语，揭示双语推理与领域迁移的现存短板。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评测框架多依赖合成数据，缺乏真实学术场景和多语言复杂性的反映，尤其在印度等多语教育环境中评估不足。

Method: 构建IndicEval基准平台，整合UPSC、JEE、NEET的真实考题（STEM与人文学科，英文与印地语），采用Zero-Shot、Few-Shot与Chain-of-Thought（CoT）提示策略自动评估，并支持模型与语言的模块化扩展。

Result: 1）CoT提示在各学科与语言中均显著提升推理准确率；2）不同模型（Gemini 2.0 Flash、GPT-4、Claude、LLaMA 3-70B）性能差异显著，尤其在高复杂度考试中；3）印地语表现普遍劣于英语，零样本下退化尤为严重。

Conclusion: IndicEval为多语言教育场景下的LLM提供了实践导向、可扩展的严格评测基础，揭示了当前模型在双语推理与跨领域泛化上的关键瓶颈，为提升推理鲁棒性与语言适应性提供明确改进方向。

Abstract: The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.

</details>


### [102] [Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning](https://arxiv.org/abs/2602.16469)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 本文研究了机器翻译数据（translationese）对小型英语语言模型训练的影响，发现源语言的类型学相似性和词汇多样性分别影响模型的语法性能和困惑度。


<details>
  <summary>Details</summary>
Motivation: 机器翻译数据广泛用于多语言NLP，但其与母语文本存在系统性差异（即translationese），这种差异可能影响模型学习；需探究不同源语言的translationese如何影响模型的语言建模与语法判断能力。

Method: 在来自24种类型学和资源分布各异的源语言的英译语料上训练小型英语语言模型，系统分析源语言特征（如类型学距离、词汇多样性）与模型性能（困惑度、语法判断）之间的关系。

Result: 源语言显著影响模型行为：整体困惑度主要受翻译语料词汇多样性驱动，而语法性能则与源语言和英语的类型学相似性高度相关（数据充足时）。

Conclusion: translationese并非均质噪声，其语言学属性（如类型学距离）会定向塑造模型的语言能力，提示在使用翻译数据时需考虑源语言特性。

Abstract: Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.

</details>


### [103] [Learning to Learn from Language Feedback with Social Meta-Learning](https://arxiv.org/abs/2602.16488)
*Jonathan Cook,Diego Antognini,Martin Klissarov,Claudiu Musat,Edward Grefenstette*

Main category: cs.CL

TL;DR: 本文提出社会元学习（SML）方法，通过微调大语言模型（LLMs）使其在对话中主动寻求并利用语言反馈来解决问题，显著提升其在模糊、多轮交互任务中的适应性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在对话中难以从纠正性反馈中学习，且缺乏主动寻求反馈的能力，导致对话僵化、单向、缺乏人类对话的适应性。

Method: 将人类的社会元学习（SML）理念形式化为一种微调方法，在模拟教学对话中训练LLMs主动 soliciting 并利用语言反馈；将静态任务转化为交互式社会学习问题。

Result: SML训练后的模型能跨领域泛化（如数学训练提升代码反馈学习能力），更擅长处理信息逐步揭示的欠指定任务，减少过早作答，更主动提问以获取关键信息。

Conclusion: SML提供了一种可扩展的方法，使AI系统能有效从语言反馈中持续学习，增强其在真实交互场景中的适应性和鲁棒性。

Abstract: Large language models (LLMs) often struggle to learn from corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning (SML) in humans - the process of learning how to learn from others. We formulate SML as a finetuning methodology, training LLMs to solicit and learn from language feedback in simulated pedagogical dialogues, where static tasks are converted into interactive social learning problems. SML effectively teaches models to use conversation to solve problems they are unable to solve in a single turn. This capability generalises across domains; SML on math problems produces models that better use feedback to solve coding problems and vice versa. Furthermore, despite being trained only on fully-specified problems, these models are better able to solve underspecified tasks where critical information is revealed over multiple turns. When faced with this ambiguity, SML-trained models make fewer premature answer attempts and are more likely to ask for the information they need. This work presents a scalable approach to developing AI systems that effectively learn from language feedback.

</details>


### [104] [From Growing to Looping: A Unified View of Iterative Computation in LLMs](https://arxiv.org/abs/2602.16490)
*Ferdinand Kapl,Emmanouil Angelis,Kaitlin Maile,Johannes von Oswald,Stefan Bauer*

Main category: cs.CL

TL;DR: 本文揭示了循环计算（looping）和深度增长（depth growing）在提升模型推理能力方面的内在联系，指出二者通过相似的深度特征（如晚期层依赖增强、循环模式复现）实现迭代计算，并证明二者可组合使用以进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 循环计算和深度增长都被发现能提升模型推理能力，但二者关系尚不明确，本文旨在从机制层面统一解释其共性。

Method: 通过分析模型深度方向的行为特征（如层依赖性、模式重复性），比较循环模型与深度增长模型的内在行为；进一步实验验证二者组合（如对深度增长模型进行推理时循环）及适应性（如更多上下文或微调数据）的效果。

Result: 发现二者具有收敛的深度特征，支持其共享迭代计算机制；组合使用可使部分推理任务准确率提升达2倍；二者均比基线更适应更多上下文或微调数据；高质量数学预训练能进一步放大深度增长效果，并可通过局部循环适配进一步提升。

Conclusion: 循环计算与深度增长是互补且实用的迭代计算诱导与扩展方法，可用于系统性提升大模型推理能力。

Abstract: Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring patterns aligned with the looped or grown block. These shared signatures support the view that their gains stem from a common form of iterative computation. Building on this connection, we show that the two techniques are adaptable and composable: applying inference-time looping to the middle blocks of a depth-grown model improves accuracy on some reasoning primitives by up to $2\times$, despite the model never being trained to loop. Both approaches also adapt better than the baseline when given more in-context examples or additional supervised fine-tuning data. Additionally, depth-grown models achieve the largest reasoning gains when using higher-quality, math-heavy cooldown mixtures, which can be further boosted by adapting a middle block to loop. Overall, our results position depth growth and looping as complementary, practical methods for inducing and scaling iterative computation to improve reasoning.

</details>


### [105] [Optimizing Soft Prompt Tuning via Structural Evolution](https://arxiv.org/abs/2602.16500)
*Zhenzhen Huang,Chaoning Zhang,Haoyu Bian,Songbo Zhang,Chi-lok Andy Tai,Jiaquan Zhang,Caiyan Qin,Jingjing Qu,Yalan Ye,Yang Yang,Heng Tao Shen*

Main category: cs.CL

TL;DR: 本文提出了一种基于拓扑形态演化的软提示调优优化方法，利用持续同调量化软提示在连续参数空间中的结构表征及其训练演化过程，并设计了拓扑软提示损失（TSLoss）以提升性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 软提示调优缺乏显式语义和可追溯的训练行为，导致其可解释性受限。

Method: 引入拓扑数据分析（TDA）中的持续同调来量化软提示的结构表征与训练演化，并据此构建拓扑软提示损失（TSLoss）用于优化。

Result: 实验表明TSLoss能加速收敛、提升调优性能，并提供从结构与拓扑视角理解与优化软提示的可解释方法。

Conclusion: 拓扑稳定的软提示具有更优下游性能，TSLoss为软提示调优提供了兼具性能提升与可解释性的新范式。

Abstract: Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.

</details>


### [106] [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)
*Taja Kuzman Pungeršek,Peter Rupnik,Daniela Širinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文提出了ParlaCAP——一个用于分析欧洲议会议程设置的大规模多语言数据集，并设计了一种基于教师-学生框架的低成本、领域适配的政策主题分类方法，利用大语言模型生成标注数据并微调多语言编码器，在准确性和可扩展性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有CAP分类器依赖人工标注但数据域外（out-of-domain），难以准确捕捉议会语境下的政策议题；同时缺乏大规模、结构化、多语言的议会发言标注数据集支持跨国比较研究。

Method: 采用教师-学生框架：以高性能大语言模型（LLM）作为‘教师’，在ParlaMint多语言议会语料（800万条演讲）上自动生成CAP schema标注；再以多语言编码器（如mBERT/XLM-R）为‘学生’，在LLM生成的标注数据上微调，构建领域专用分类器；同时集成ParlaSent情感预测与丰富元数据。

Result: LLM与人工标注者间一致性接近人-人一致性（inter-annotator agreement）；所提模型在CAP主题分类任务上显著优于基于非议会数据训练的现有分类器；ParlaCAP数据集已发布，含CAP标签、发言人/党派元数据及情感预测，支撑三项实证用例（议题注意力分布、情感模式、性别差异）。

Conclusion: ParlaCAP不仅提供首个大规模、多语言、细粒度议会政策议题标注数据集，还验证了LLM辅助标注在政治文本领域建模中的有效性与可靠性，为计算社会科学特别是议程设置与政治表征的跨国比较研究奠定新基础。

Abstract: This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.

</details>


### [107] [Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset](https://arxiv.org/abs/2602.16571)
*Zhuqian Zhou,Kirk Vanacore,Bakhtawar Ahtisham,Jinsook Lee,Doug Pietrzak,Daryl Hedley,Jorge Dias,Chris Shaw,Ruth Schäfer,René F. Kizilcec*

Main category: cs.CL

TL;DR: 本文提出MathEd-PII数据集与数学教育对话中PII检测的新方法，强调需结合数学领域知识以减少误删教学关键内容，提升去标识化后的数据实用性。


<details>
  <summary>Details</summary>
Motivation: 通用PII检测系统在数学辅导对话中因数字表达式易被误判为身份标识（如日期、ID），导致过度脱敏，损害教学数据的分析效用。

Method: 构建首个面向数学辅导对话的PII检测基准数据集MathEd-PII（含1000场会话），采用人机协同LLM流程生成隐私保护替代项；提出基于密度的分段方法定位误红区域，并对比Presidio基线与三种LLM提示策略（基础/数学感知/分段感知）。

Result: 数学感知提示显著优于基线（F1：0.821 vs. 0.379），大幅降低数字类假阳性；证实数值歧义是主要失效模式，且数学密集区域误删集中。

Conclusion: 面向数学辅导数据的实用型去标识化必须融合领域知识，本文提供新基准与实证支持，推动教育数据安全共享。

Abstract: Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the "numeric ambiguity" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.

</details>


### [108] [CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes](https://arxiv.org/abs/2602.16607)
*Miguel Marques,Ana Luísa Fernandes,Ana Filipa Pacheco,Rute Rebouças,Inês Cantante,José Isidro,Luís Filipe Cunha,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano,Ricardo Campos*

Main category: cs.CL

TL;DR: 本文提出了CitiLink-Summ数据集，首个面向欧洲葡萄牙语市政会议纪要主题摘要的高质量人工标注语料库，并基于该数据集建立了生成式模型和大语言模型的基线性能。


<details>
  <summary>Details</summary>
Motivation: 市政会议纪要内容冗长难懂，公民难以获取关键信息；而低资源语言（如欧洲葡萄牙语）中缺乏高质量人工摘要数据集，严重制约了该领域自动摘要研究的发展。

Method: 构建包含100份会议纪要、2322条人工撰写主题摘要的CitiLink-Summ语料库；采用BART、PRIMERA等先进生成模型及大语言模型进行摘要生成实验；使用ROUGE、BLEU、METEOR和BERTScore等指标评估性能。

Result: 提供了首个欧洲葡萄牙语市政领域摘要任务基准，验证了多种生成模型在该任务上的可行性与局限性，为后续研究奠定基础。

Conclusion: CitiLink-Summ填补了低资源语言行政文本摘要数据集的空白，推动了面向复杂政务文档的NLP研究，具有重要资源价值与实践意义。

Abstract: Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.

</details>


### [109] [Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models](https://arxiv.org/abs/2602.16608)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文提出了一种名为上下文感知分层积分梯度（CA-LIG）的统一归因框架，用于提升Transformer模型的可解释性，通过在每层内计算积分梯度并融合类别特异性注意力梯度，生成具有符号意义、上下文敏感的归因图，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法仅依赖最终层归因、缺乏上下文感知、无法统一建模局部与全局模式、且不能刻画相关性在层间的演化及结构组件对决策的影响。

Method: 提出CA-LIG框架：在每个Transformer块内进行分层积分梯度计算，并将token级归因与类别特异性注意力梯度融合，生成带符号、上下文敏感的分层归因图。

Result: 在多种任务（情感分析、长文档分类、低资源语言仇恨言论检测、图像分类）和模型（BERT、XLM-R、AfroLM、MAE-ViT）上验证，CA-LIG归因更忠实、对上下文依赖更敏感、可视化更语义清晰。

Conclusion: CA-LIG提供了更全面、上下文感知且可靠的Transformer决策解释，推动了深度神经模型的实用可解释性与概念理解。

Abstract: Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.

</details>


### [110] [Who can we trust? LLM-as-a-jury for Comparative Assessment](https://arxiv.org/abs/2602.16610)
*Mengjie Qian,Guangzhi Sun,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 本文提出BT-sigma模型，通过引入判别参数来建模LLM作为裁判时的可靠性差异，从而在无需人工标注的情况下提升自然语言生成评估中的成对比较排序效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM自动评估方法常假设所有LLM裁判可靠性相同，但实际中其判断存在偏差、不一致且跨任务性能差异大，且缺乏人工标注用于校准。

Method: 提出BT-sigma——一种面向裁判感知的Bradley-Terry模型扩展，在仅使用成对比较数据的前提下，联合推断项目排名与每个LLM裁判的判别参数（即可靠性）。

Result: 在NLG评估基准数据集上，BT-sigma持续优于基于平均的聚合方法；所学判别参数与LLM判断的环一致性指标高度相关；进一步分析表明其可视为一种无监督校准机制。

Conclusion: BT-sigma能有效建模LLM裁判间的可靠性差异，提升排序鲁棒性与准确性，为无监督LLM评估提供了新范式。

Abstract: Large language models (LLMs) are increasingly applied as automatic evaluators for natural language generation assessment often using pairwise comparative judgements. Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment probabilities may be biased and inconsistent. Furthermore, human-labelled supervision for judge calibration may be unavailable. We first empirically demonstrate that inconsistencies in LLM comparison probabilities exist and show that it limits the effectiveness of direct probability-based ranking. To address this, we study the LLM-as-a-jury setting and propose BT-sigma, a judge-aware extension of the Bradley-Terry model that introduces a discriminator parameter for each judge to jointly infer item rankings and judge reliability from pairwise comparisons alone. Experiments on benchmark NLG evaluation datasets show that BT-sigma consistently outperforms averaging-based aggregation methods, and that the learned discriminator strongly correlates with independent measures of the cycle consistency of LLM judgments. Further analysis reveals that BT-sigma can be interpreted as an unsupervised calibration mechanism that improves aggregation by modelling judge reliability.

</details>


### [111] [AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models](https://arxiv.org/abs/2602.16639)
*Adib Sakhawat,Fardeen Sadab*

Main category: cs.CL

TL;DR: 本文提出了对抗性资源提取游戏（AREG）基准，用于评估大语言模型（LLM）在动态、对抗性交互中的社会智能，特别是说服与抵抗能力；发现二者弱相关且存在系统性防御优势，表明社会影响能力并非单一维度。


<details>
  <summary>Details</summary>
Motivation: 现有评估多局限于静态文本生成，难以刻画LLM在真实社会互动（如说服与抵抗）中的动态能力，亟需支持多轮对抗性交互的评估框架。

Method: 设计零和、多轮谈判形式的Adversarial Resource Extraction Game（AREG）基准，通过循环赛方式在前沿模型间进行对抗测试，并结合量化得分与语言行为分析（如承诺寻求、验证寻求等策略）。

Result: 说服与抵抗能力弱相关（ρ=0.33），二者经验上分离；所有模型的抵抗得分均高于说服得分，呈现系统性防御优势；增量式承诺寻求策略提升资源提取成功率，而验证寻求式回应比直接拒绝更利于成功防御。

Conclusion: LLM的社会影响力不是单维能力，仅聚焦说服的评估框架会掩盖其在对抗交互中的不对称脆弱性；AREG为细粒度、双向社会智能评估提供了新范式。

Abstract: Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.

</details>


### [112] [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)
*Subrit Dikshit*

Main category: cs.CL

TL;DR: 本文提出了Quecto-V1，一个专为印度法律领域定制的小型语言模型（124M参数），基于GPT-2架构从零训练，仅使用印度成文法语料；通过8位量化压缩至150MB以下，支持离线CPU运行，在法定条款检索任务上超越通用小型模型，兼顾高精度、低资源与数据主权。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在法律智能应用中造成的资源鸿沟问题：现有先进系统依赖大参数量（7B+）和云端推理，导致资源受限从业者难以使用，并带来数据主权风险。

Method: 构建领域专用小型语言模型Quecto-V1，基于定制化GPT-2架构（124M参数），从零训练于印度成文法语料（IPC、CrPC、宪法）；强调法律词汇密度；采用后训练8位量化（GGUF格式）以降低部署门槛。

Result: Quecto-V1在法定定义与刑罚条款检索任务中实现高保真度，优于通用小型模型；量化后模型体积<150MB，可在消费级CPU离线运行；8位量化使模型体积减少74%，检索准确率仅下降<3.5%。

Conclusion: 在法律等专业性高、容错率低的领域，领域专用训练结合激进量化可提供一种可行、隐私优先、低资源依赖的替代方案，替代巨型云端模型。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes "lexical density" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.

</details>


### [113] [Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment](https://arxiv.org/abs/2602.16660)
*Yuyan Bu,Xiaohao Liu,ZhaoXing Ren,Yaodong Yang,Juntao Dai*

Main category: cs.CL

TL;DR: 本文提出了一种资源高效、即插即用的多语言一致性（MLC）损失函数，用于提升大语言模型在多语言场景下的安全对齐效果，仅需多语言提示变体，无需低资源语言的额外响应级监督。


<details>
  <summary>Details</summary>
Motivation: 现有方法扩展LLM安全对齐至多语言时，依赖大量目标语言高质量监督数据或高资源语言两两对齐，可扩展性差。

Method: 提出多语言一致性（MLC）损失，通过增强多语言表征向量的共线性，在语义层面实现单步方向一致性，可嵌入现有单语对齐流程。

Result: 在不同模型架构与对齐范式下验证有效，显著提升多语言安全对齐效果，对通用模型能力影响小，并改善跨语言泛化能力。

Conclusion: MLC是一种实用、低监督开销的多语言一致性对齐方案，适用于资源受限的多语言部署场景。

Abstract: The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.

</details>


### [114] [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699)
*Wenxuan Ding,Nicholas Tomlin,Greg Durrett*

Main category: cs.CL

TL;DR: 本文提出Calibrate-Then-Act（CTA）框架，通过向大语言模型（LLM）显式提供环境先验信息，使其能更优地权衡探索成本与不确定性，在信息检索和编程等序贯决策任务中提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM在解决需与环境交互获取信息的复杂任务时，面临成本与不确定性之间的权衡问题（如是否编写测试验证代码），但现有方法缺乏对这种权衡的显式建模。

Method: 将信息检索、编程等任务形式化为带隐状态的序贯决策问题；引入CTA框架，在推理前向LLM注入环境先验以支持成本-不确定性权衡；该方法在监督微调与强化学习训练下均适用。

Result: 在信息寻求型问答和简化编程任务上，CTA显著提升了LLM的探索效率与决策质量，优于基线方法，且效果在RL训练后仍保持。

Conclusion: 显式引导LLM进行成本-收益权衡可有效提升其在不确定环境中的自主决策能力，CTA是一种通用且鲁棒的增强范式。

Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.

</details>


### [115] [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)
*Hee Seung Hwang,Xindi Wu,Sanghyuk Chun,Olga Russakovsky*

Main category: cs.CL

TL;DR: 本文提出REFINE框架，通过强化学习和下一序列预测（NSP）目标改进快速权重模型，显著提升其长上下文建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有快速权重架构受限于传统的单词预测（NTP）训练范式，无法有效建模多词语义连贯性和长程依赖。

Method: 提出REFINE：基于预测熵选择关键位置、生成多词rollout、自监督序列级奖励、使用GRPO优化；支持训练中、训后及测试时训练。

Result: 在LaCT-760M和DeltaNet-1.3B上，REFINE在needle-in-a-haystack检索、长上下文问答及LongBench多项任务中均优于NTP监督微调。

Conclusion: REFINE为快速权重架构提供了高效且通用的长上下文建模增强方法。

Abstract: Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [116] [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)
*Jieyi Bi,Zhiguang Cao,Jianan Zhou,Wen Song,Yaoxin Wu,Jie Zhang,Yining Ma,Cathy Wu*

Main category: cs.AI

TL;DR: 本文提出Construct-and-Refine (CaR)框架，首次实现基于显式学习的可行性精炼，高效处理神经路由求解器中的复杂硬约束。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器在简单路径问题上表现优异，但在复杂硬约束下受限于可行性掩码或隐式可行性感知等方法，效率低或不适用。

Method: 提出Construct-and-Refine (CaR)框架，包含联合训练机制以引导构造模块生成适配轻量改进（如仅10步）的高质量多样解，并首次采用构造-改进共享表征（统一编码器）。

Result: 在典型硬约束路由任务上，CaR在可行性、解质量与计算效率方面均超越经典及现有神经SOTA方法。

Conclusion: CaR是首个通用且高效的神经路由求解器约束处理框架，通过显式学习和表征共享显著提升复杂约束下的性能。

Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.

</details>


### [117] [Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037)
*Cameron Cagan,Pedram Fard,Jiazi Tian,Jingya Cheng,Shawn N. Murphy,Hossein Estiri*

Main category: cs.AI

TL;DR: 本文研究了自主代理工作流中的优化不稳定性问题，发现持续自主优化反而会降低分类器性能，尤其在低流行度类别中表现更差；通过引入选择代理（selector agent）进行事后最优迭代选择，可有效防止灾难性失败，并在临床症状检测任务中显著超越专家构建的词典。


<details>
  <summary>Details</summary>
Motivation: 自主代理工作流虽具潜力，但其失败模式缺乏系统刻画，尤其是优化过程中性能意外下降的现象亟待研究。

Method: 基于开源框架Pythia开展自动化提示优化实验，针对三种不同流行度的临床症状（呼吸急促、胸痛、长新冠脑雾）评估验证敏感度变化；对比引导代理（主动干预）与选择代理（事后筛选）两种干预策略的效果。

Result: 观察到验证敏感度在0.0–1.0间剧烈振荡，且振荡幅度与类别流行度成反比；在3%流行度下出现高准确率（95%）却零检出阳性样本的隐蔽失败；选择代理成功避免灾难性失败，并在脑雾和胸痛检测F1分数上分别超越专家词典331%和7%。

Conclusion: 优化不稳定是自主AI系统的关键失败模式，尤其在低流行度分类任务中；相比主动干预，基于回顾性选择的稳定化策略更为有效。

Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.

</details>


### [118] [How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039)
*Hang Li,Kaiqi Yang,Xianxuan Long,Fedor Filippov,Yucheng Chu,Yasemin Copur-Gencturk,Peng He,Cory Miller,Namsoo Shin,Joseph Krajcik,Hui Liu,Jiliang Tang*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型（LLMs）在自动教育评估（尤其是自动评分）中不确定性量化方法的有效性与可靠性，分析了不同模型、任务和解码策略对不确定性估计的影响，并为构建更可靠的不确定性感知评分系统提供实践指导。


<details>
  <summary>Details</summary>
Motivation: LLM在自动评估中虽具灵活性，但其输出的不确定性会影响教学决策的稳定性与可靠性，亟需系统研究其不确定性量化方法在教育场景中的适用性。

Method: 对多种不确定性量化方法在多个评估数据集、LLM家族及生成控制设置下进行基准测试与综合分析，刻画LLM在评分任务中的不确定性行为模式。

Result: 揭示了不同不确定性度量在教育评分场景中的表现差异，识别出模型家族、评估任务类型和解码策略是影响不确定性估计的关键因素。

Conclusion: 当前不确定性量化方法在教育自动评分中仍存在适用性局限；本研究为未来构建更可靠、可解释的不确定性感知 grading 系统奠定了基础。

Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

</details>


### [119] [Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination](https://arxiv.org/abs/2602.16050)
*Amir Hosseinian,MohammadReza Zare Shahneh,Umer Mansoor,Gilbert Szeto,Kirill Karlin,Nima Aghaeepour*

Main category: cs.AI

TL;DR: January Mirror 是一个基于循证医学的内分泌学临床推理系统，在120题内分泌学考试中以87.5%准确率显著优于前沿大模型（如GPT-5.2、Gemini-3-Pro）及人类参考水平，且具备高证据可追溯性与审计性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用医学考试中表现良好，但在快速更新指南和复杂证据层级的亚专科临床推理上仍面临挑战。

Method: 构建了整合精选内分泌与心代谢证据库及结构化推理架构的January Mirror系统，采用封闭式证据约束（无外部检索），并与具备实时网络访问能力的前沿LLM（GPT-5、GPT-5.2、Gemini-3-Pro）进行对比评估。

Result: Mirror在120题考试中准确率达87.5%（95% CI: 80.4–92.3%），显著高于人类参考（62.3%）及各LLM；最难30题中达76.7%；Top-2准确率为92.5%；74.2%输出引用指南级证据，引文准确率100%。

Conclusion: 在亚专科临床推理中，精心策划并明确来源的证据库可超越无约束网络检索，提升性能与临床部署所需的可审计性。

Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.

</details>


### [120] [Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066)
*Martin Klissarov,Jonathan Cook,Diego Antognini,Hao Sun,Jingling Li,Natasha Jaques,Claudiu Musat,Edward Grefenstette*

Main category: cs.AI

TL;DR: 本文提出了一种将交互式上下文学习能力作为可训练技能的新框架，通过多轮教学式交互提升大模型对语言反馈的动态适应能力，并实现跨领域泛化与自我修正能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型训练范式依赖静态语料，缺乏对交互式反馈循环的建模能力，难以在协作场景中动态适应；而人类学习高度依赖纠错反馈，这一能力亟需被显式建模和训练。

Method: 将单轮可验证任务转化为由信息不对称驱动的多轮教学式交互；通过训练模型预测教师批评（即建模反馈环境），使其内化外部反馈信号，从而获得上下文可塑性与自修正能力。

Result: 经该方法训练的小模型在多轮任务上的表现接近大一个数量级的模型；展现出强跨领域泛化能力（如从数学迁移到编程、谜题、迷宫导航）；并能实现无需外部教师的自我纠正。

Conclusion: 交互式上下文学习是一种可被显式训练的核心能力，而非仅靠规模涌现的副产品；该范式为模型的持续自适应与自我改进提供了统一路径。

Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

</details>


### [121] [GPSBench: Do Large Language Models Understand GPS Coordinates?](https://arxiv.org/abs/2602.16105)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: 本文提出了GPSBench数据集，用于评估大语言模型（LLMs）在地理空间推理方面的能力，涵盖几何坐标运算与结合世界知识的地理推理任务；实验表明当前LLMs在GPS推理上仍具挑战性，表现出任务间性能差异、地理知识层级退化等特点，并验证了坐标增强与微调的影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地应用于导航、机器人和地图等物理世界交互场景，其对GPS坐标和真实地理信息的推理能力变得至关重要，但该能力目前尚未被系统研究。

Method: 构建包含57,800个样本、覆盖17项任务的GPSBench基准数据集，聚焦模型内在能力（而非工具调用），对14个SOTA LLMs进行评测，并分析其在几何计算与地理知识推理上的表现差异、噪声鲁棒性、坐标增强效果及微调权衡。

Result: 发现LLMs在地理推理上普遍优于几何坐标计算；地理知识呈层级退化（国家级强、城市级弱）；对坐标扰动具有鲁棒性，表明具备真实坐标理解而非记忆；GPS坐标增强可提升下游任务性能，但微调会带来几何能力提升与世界知识下降的权衡。

Conclusion: GPSBench揭示了当前LLMs在地理空间推理上的关键短板与特性，为后续建模、评估与改进提供了坚实基础和公开资源。

Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench

</details>


### [122] [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424)
*Philipp Schoenegger,Matt Carlson,Chris Schneider,Chris Daly*

Main category: cs.AI

TL;DR: 本文提出了一种基于刺激-意义模型的多智能体语义一致性认证协议，通过实证测试确保智能体对术语的理解一致，并引入‘核心受控推理’机制以保证分歧有界；实验表明该方法显著降低语义分歧。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统缺乏验证智能体间术语理解一致性的方法：自然语言可解释但易发生语义漂移，学习到的协议高效但不透明。

Method: 提出基于刺激-意义模型的认证协议，对智能体在可观测事件上的术语使用进行统计检验；定义‘核心受控推理’（仅使用已认证术语），并设计再认证与重协商机制。

Result: 仿真中核心受控推理将分歧降低72–96%；在微调语言模型验证中降低51%。

Conclusion: 该框架为可验证的智能体间通信提供了首个可行路径，支持语义一致性的形式化保障与动态维护。

Abstract: Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms ("core-guarded reasoning") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.

</details>


### [123] [Learning Personalized Agents from Human Feedback](https://arxiv.org/abs/2602.16173)
*Kaiqu Liang,Julia Kruk,Shengyi Qian,Xianjun Yang,Shengjie Bi,Yuanshun Yao,Shaoliang Nie,Mingyang Zhang,Lijuan Liu,Jaime Fernández Fisac,Shuyan Zhou,Saghar Hosseini*

Main category: cs.AI

TL;DR: 本文提出PAHF框架，通过在线交互和显式用户记忆实现AI代理的持续个性化，包含预动作澄清、偏好检索和后动作反馈更新三步循环，并在具身操作和在线购物任务中验证其快速学习和适应偏好变化的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态数据集，难以应对新用户和随时间变化的用户偏好。

Method: 提出PAHF框架，采用三步循环：预动作澄清以消除歧义、从显式用户记忆中检索偏好以指导动作、利用后动作反馈更新记忆以适应偏好漂移；并设计四阶段评估协议和两个基准任务。

Result: 理论分析与实验表明，结合显式记忆与双通道反馈（预动作与后动作）对持续个性化至关重要；PAHF显著加快学习速度，持续优于无记忆和单通道基线，在初始个性化误差和偏好变化适应性上均有提升。

Conclusion: PAHF框架通过引入显式用户记忆与双通道反馈机制，有效解决了AI代理在动态个性化中的关键挑战，为构建真正以用户为中心的智能代理提供了可行路径。

Abstract: Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents learn online from live interaction using explicit per-user memory. PAHF operationalizes a three-step loop: (1) seeking pre-action clarification to resolve ambiguity, (2) grounding actions in preferences retrieved from memory, and (3) integrating post-action feedback to update memory when preferences drift. To evaluate this capability, we develop a four-phase protocol and two benchmarks in embodied manipulation and online shopping. These benchmarks quantify an agent's ability to learn initial preferences from scratch and subsequently adapt to persona shifts. Our theoretical analysis and empirical results show that integrating explicit memory with dual feedback channels is critical: PAHF learns substantially faster and consistently outperforms both no-memory and single-channel baselines, reducing initial personalization error and enabling rapid adaptation to preference shifts.

</details>


### [124] [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435)
*Arun Vignesh Malarkkan,Wangyang Ying,Yanjie Fu*

Main category: cs.AI

TL;DR: 本文提出CAFE框架，将自动特征工程（AFE）重新定义为因果引导的序列决策过程，结合因果发现与强化学习，显著提升特征构建的鲁棒性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有AFE方法依赖统计启发式，导致特征在分布偏移下表现脆弱；需引入因果结构以提升鲁棒性与泛化能力。

Method: CAFE分两阶段：I阶段通过稀疏有向无环图学习特征与目标间的软因果先验，划分因果类型；II阶段采用级联多智能体深度Q学习，结合分层奖励塑造与因果组级探索策略选择因果组和变换算子。

Result: 在15个公开基准上，CAFE较强基线最高提升7%（分类macro-F1/回归逆相对绝对误差），收敛更快、耗时更少；在协变量偏移下性能下降减少约4倍，生成更紧凑、归因更稳定的特征集。

Conclusion: 将因果结构作为软归纳先验（而非刚性约束）可显著提升自动特征工程的鲁棒性与效率。

Abstract: Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.

</details>


### [125] [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179)
*Sushant Mehta,Logan Ritchie,Suhaas Garre,Nick Heiner,Edwin Chen*

Main category: cs.AI

TL;DR: 本文提出CoreCraft——一个高保真企业级强化学习环境，用于训练AI代理完成真实客服工作流；通过GRPO等方法训练GLM-4.6后，不仅在本环境任务通过率显著提升，还在多个OOD基准上实现跨领域泛化提升，表明高质量、多样化、真实性的环境设计是促进AI代理能力泛化的关键。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在真实企业任务中表现有限（如GPT-5.2、Claude Opus 4.6任务通过率<30%），亟需能衡量并提升AI代理在复杂、多步、领域特定工作流中泛化能力的高保真训练环境。

Method: 构建CoreCraft——EnterpriseGym中的首个全功能企业仿真环境（含2500+实体、14类实体、23种工具）；采用Group Relative Policy Optimization（GRPO）与自适应裁剪方法，在单轮训练中优化GLM-4.6。

Result: GLM-4.6在CoreCraft评估任务中通过率从25.37%提升至36.76%；更关键的是，在BFCL Parallel、τ²-Bench Retail和Toolathlon三个OOD基准上分别提升+4.5%、+7.4%、+6.8%（Pass@1）。

Conclusion: 环境的质量（task-centric建模）、多样性（专家编写多维rubric）与真实性（企业级工作流）共同驱动了AI代理能力的跨分布泛化，验证了‘好环境催生好泛化’的核心论点。

Abstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\% to 36.76\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\% on BFCL Parallel, +7.4\% on $τ^2$-Bench Retail, and +6.8\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.

</details>


### [126] [Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage](https://arxiv.org/abs/2602.16192)
*Hiroaki Yamanaka,Daisuke Miyashita,Takashi Toi,Asuka Maki,Taiga Ikeda,Jun Deguchi*

Main category: cs.AI

TL;DR: 本文探讨了实现人工超级智能（ASI）所需的关键设计概念——“记忆”，提出并验证了四种替代现有主流范式的记忆架构思路，强调保留原始经验、按需提取、从海量概率性经验中发现深层洞见，以及通过共享经验提升采集效率。


<details>
  <summary>Details</summary>
Motivation: 当前主流的“提取后存储”范式存在信息丢失风险，难以支撑ASI所需的灵活、通用和持续学习能力；而“记忆”作为ASI的核心基础尚未被系统探索。

Method: 提出并对比分析四种记忆设计思路：1）“先存储、后按需提取”；2）从大规模概率性经验中挖掘深层洞察；3）通过共享已存经验提升新经验采集效率；4）讨论其可行性与挑战。辅以简单实验验证其有效性。

Result: 实验证明所提方法在信息保全性、任务泛化性和经验利用效率方面优于传统范式；识别出阻碍研究的关键挑战（如存储成本、检索机制、经验表征等），并提出若干待研方向。

Conclusion: 构建面向ASI的记忆系统不应局限于信息压缩与筛选，而应转向以原始经验为基石、支持动态、多任务、可扩展的认知架构；该方向虽具挑战，但极具潜力且亟待深入探索。

Abstract: Driven by our mission of "uplifting the world with memory," this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed "extract then store," involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the "store then on-demand extract" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.

</details>


### [127] [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246)
*Yun-Shiuan Chuang,Chaitanya Kulkarni,Alec Chiu,Avinash Thangali,Zijie Pan,Shivani Shekhar,Yirou Ge,Yixi Li,Uma Kona,Linsey Pang,Prakhar Mehrotra*

Main category: cs.AI

TL;DR: 本文提出了一种名为Proxy State-Based Evaluation的LLM驱动仿真评估框架，用于评估交互式大语言模型代理，该框架无需依赖高成本的确定性后端，而是通过LLM状态追踪器和LLM裁判实现稳定、可扩展、可靠的评估。


<details>
  <summary>Details</summary>
Motivation: 现有代理基准（如tau-bench）依赖于完全确定性的后端，构建与迭代成本高；需兼顾可靠模型比较与生成高质量on-policy训练数据。

Method: 提出基于代理状态的评估框架：给定场景（含用户目标、事实、期望终态及行为），由LLM状态追踪器从交互轨迹中推断结构化代理状态，并由LLM裁判验证目标完成度及检测工具/用户幻觉；支持敏感性分析与ablation研究。

Result: 该基准在不同模型族和推理努力下产生稳定且具区分性的排名；on-/off-policy rollout生成的监督信号可泛化至未见场景；模拟器幻觉率接近零；人与LLM裁判一致性>90%。

Conclusion: Proxy State-Based Evaluation是一种实用、可扩展的工业级LLM代理评估替代方案，摆脱了对确定性数据库的依赖。

Abstract: Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.

</details>


### [128] [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)
*Marissa A. Weis,Maciej Wołczyk,Rajai Nasser,Rif A. Saurous,Blaise Agüera y Arcas,João Sacramento,Alexander Meulemans*

Main category: cs.AI

TL;DR: 本文提出利用序列模型的上下文学习能力，使多智能体在无需硬编码假设或显式时间尺度分离的情况下实现相互学习感知与合作。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于对合作者学习规则的硬编码假设或严格区分快慢学习者，限制了合作行为的可扩展性与自然性。

Method: 训练序列模型智能体对抗多样化的合作者分布，使其在单次交互中通过上下文学习自发形成最佳响应策略。

Result: 序列模型在上下文内自适应导致对勒索的脆弱性，进而引发相互塑造学习动态，最终自然涌现出合作行为。

Conclusion: 基于序列模型的标准去中心化强化学习结合合作者多样性，为可扩展地习得合作行为提供了新路径。

Abstract: Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-learners" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.

</details>


### [129] [Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach](https://arxiv.org/abs/2602.16481)
*Zihao Li,Fabrizio Russo*

Main category: cs.AI

TL;DR: 本文提出将大语言模型（LLMs）作为不完美专家用于因果假设驱动的论辩（Causal ABA）框架，融合变量语义先验与条件独立性证据，在标准基准和语义合成图上取得SOTA性能，并设计新评估协议缓解LLM记忆偏差。


<details>
  <summary>Details</summary>
Motivation: 因果图构建依赖专家知识，而纯数据驱动方法缺乏可解释性和形式保证；需结合数据与人类/类人先验以提升因果发现的可靠性与可解释性。

Method: 将LLM视为‘不完美专家’，从中提取变量名与描述所蕴含的语义结构先验，嵌入Causal ABA符号推理框架，并与统计得到的条件独立性证据联合推理因果图。

Result: 在标准因果发现基准（如ASIA、Sachs）和语义驱动的合成图上达到SOTA性能；提出新评估协议有效缓解LLM因训练数据重叠导致的虚假性能（memorisation bias）。

Conclusion: LLM可有效提供高质量语义先验，增强因果ABA的实用性与鲁棒性；符号+神经混合范式是可信因果发现的重要路径，且需专门评估设计以防伪阳性。

Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

</details>


### [130] [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)
*Felix Fricke,Simon Malberg,Georg Groh*

Main category: cs.AI

TL;DR: 本文提出Framework of Thoughts (FoT)，一个用于构建和优化动态推理方案的通用基础框架，具备超参数调优、提示优化、并行执行与智能缓存等功能，显著提升推理效率、降低成本并提高任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理提示方案（如Chain of Thought、Tree of Thoughts等）依赖静态、问题特定的结构，缺乏对动态或未知问题的适应性，且在超参数、提示、运行时和成本方面常未充分优化。

Method: 提出Framework of Thoughts（FoT）框架，集成超参数自动调优、提示优化、并行执行与智能缓存机制，并在其中实现Tree of Thoughts、Graph of Thoughts和ProbTree三种方案进行验证。

Result: 实验表明，FoT能显著加快执行速度、降低提示成本，并在多个任务上取得更高分数；代码已开源。

Conclusion: FoT为构建动态、高效、可优化的推理方案提供了统一、灵活且实用的基础框架，推动大模型推理能力的工程化发展。

Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.

</details>


### [131] [Creating a digital poet](https://arxiv.org/abs/2602.16578)
*Vered Tohar,Tsahi Hayat,Amir Leshem*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型能否创作出优秀的诗歌，并通过为期七个月的工作坊，利用专家反馈对模型进行迭代式提示调整（无需重新训练），使其发展出独特风格和连贯诗集。在盲测中，人类与AI诗歌的作者识别率接近随机水平，且该AI诗人作品已由商业出版社出版。


<details>
  <summary>Details</summary>
Motivation: 探讨机器是否能创作出具有艺术价值的诗歌，并由此引发关于艺术本质、创造力与作者身份的根本性问题。

Method: 采用迭代式上下文内专家反馈的工作坊模式，对大型语言模型进行长期提示工程（不涉及模型重训练），辅以定量与定性分析评估其风格演化与作品一致性。

Result: 模型发展出独特诗歌风格与连贯诗集，生成笔名与作者形象；在50名人文领域学生与毕业生参与的双盲测试中，人/AI诗歌识别率分别为54%和52%，无统计显著性；最终其诗集由商业出版社正式出版。

Conclusion: 工作坊式提示工程可实现长周期、高质量的创造性塑造，挑战传统对创造力与作者权的理解，推动相关哲学与实践讨论。

Abstract: Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.

</details>


### [132] [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653)
*Yangjie Xu,Lujun Li,Lama Sleem,Niccolo Gentile,Yewei Song,Yiqun Wang,Siming Ji,Wenbo Wu,Radu State*

Main category: cs.AI

TL;DR: 本文研究Agent Skill框架对小语言模型（SLMs）的有效性，提出其数学定义，并在多个任务上系统评估不同规模模型的表现，发现中等规模SLMs（12B–30B）显著受益，而80B代码专用模型可媲美闭源基线且更高效。


<details>
  <summary>Details</summary>
Motivation: 工业场景中受限于数据安全与预算，难以持续调用公有API，且SLMs在高度定制化任务中泛化能力有限，亟需验证Agent Skill是否能提升SLMs性能。

Method: 提出Agent Skill过程的正式数学定义，并在两个开源任务和一个真实保险理赔数据集上，对不同规模语言模型进行系统性评估。

Result: 微小模型难以稳定选择技能；中等规模SLMs（12B–30B）显著受益；约80B参数的代码专用模型性能媲美闭源基线，同时提升GPU效率。

Conclusion: Agent Skill框架对SLMs具有明确适用边界与实用价值，为SLM主导环境下的技能部署提供了可操作的指导。

Abstract: Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.

</details>


### [133] [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666)
*Stephan Rabanser,Sayash Kapoor,Peter Kirgis,Kangheng Liu,Saiteja Utpala,Arvind Narayanan*

Main category: cs.AI

TL;DR: 本文提出了一套涵盖一致性、鲁棒性、可预测性和安全性四个维度的12个具体指标，用于全面评估AI智能体的可靠性，揭示当前智能体在实际应用中仍存在显著可靠性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法仅依赖单一成功率指标，掩盖了AI智能体在一致性、抗干扰能力、失败可预测性及错误严重程度等方面的深层问题，难以反映其在真实场景中的可靠性。

Method: 基于安全关键工程理念，构建包含12个具体指标的可靠性评估框架，覆盖一致性、鲁棒性、可预测性与安全性四大维度，并在两个互补基准上评测14种智能体模型。

Result: 实验表明，尽管AI智能体在传统能力指标上持续提升，但在可靠性各维度上的改进微乎其微；新指标能有效暴露其长期存在的可靠性短板。

Conclusion: 单一成功率不足以衡量AI智能体的实际可靠性；所提多维指标体系可弥补传统评估不足，为理解智能体行为、退化模式与失效机制提供系统化分析工具。

Abstract: AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [134] [EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices](https://arxiv.org/abs/2602.15836)
*Mengyun Liu,Shanshan Huang,Jianan Jiang*

Main category: cs.RO

TL;DR: 本文提出EdgeNav-QE框架，结合QLoRA量化与动态早退机制，在边缘设备上高效部署大型动作模型（LAMs），显著降低延迟与内存占用，同时保持较高导航成功率。


<details>
  <summary>Details</summary>
Motivation: 大型动作模型（LAMs）在自主导航中潜力巨大，但其多十亿参数规模难以在资源受限的边缘设备上实时部署，面临内存与延迟瓶颈。

Method: 提出EdgeNav-QE框架：1）采用4比特量化+低秩适配（QLoRA）压缩骨干网络；2）引入动态早退（DEE）机制，根据任务复杂度自适应决定是否提前终止推理。

Result: 在Habitat-Sim+Matterport3D上基于OpenVLA-7B验证：相比全精度基线，延迟降低82.7%，内存减少66.7%，导航成功率保持81.8%；较静态早退方法延迟再降17.9%。

Conclusion: 动态早退与量化协同优化是实现边缘端高效、安全LAM部署的有效路径，内容感知的自适应计算对关键任务至关重要。

Abstract: Large Action Models (LAMs) have shown immense potential in autonomous navigation by bridging high-level reasoning with low-level control. However, deploying these multi-billion parameter models on edge devices remains a significant challenge due to memory constraints and latency requirements. In this paper, we propose EdgeNav-QE, a novel framework that integrates Quantized Low-Rank Adaptation (QLoRA) with a dynamic early-exit (DEE) mechanism to optimize LAMs for real-time edge navigation. By quantizing the backbone to 4-bit precision and strategically placing early-exit branches, we enable the model to terminate inference early for simple navigation tasks while retaining full depth for complex decision-making. Experimental results on the Habitat-Sim environment with Matterport3D dataset using OpenVLA-7B backbone, demonstrate that EdgeNav-QE reduces inference latency by 82.7% and memory footprint by 66.7% compared to full-precision baselines, while maintaining 81.8% navigation success rate. Furthermore, it outperforms state-of-the-art static early-exit method by 17.9% in latency, demonstrating the superiority of content-aware adaptive computation for safety-critical applications.

</details>


### [135] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 本文提出了一种基于‘冲突’概念的两阶段仿真测试框架，用于提升自动驾驶系统（ADS）的安全评估效率与多样性：先搜索潜在冲突场景，再针对性变异以诱发碰撞，显著提高了碰撞类型发现数量和测试效率。


<details>
  <summary>Details</summary>
Motivation: 现有仿真测试方法主要关注已接近碰撞的场景，忽视了其他潜在危险情形，导致安全评估覆盖不全、效率低下。

Method: 提出以‘冲突’作为中间目标的两阶段框架：第一阶段在仿真中主动搜索冲突场景；第二阶段对冲突场景进行定向变异，诱导实际碰撞；在Baidu Apollo平台上实现并验证。

Result: 单次运行可发现最多12种不同碰撞类型，碰撞类型多样性是当前最优基线方法的两倍，且所需仿真次数更少。

Conclusion: 将‘冲突’作为中间优化目标能有效拓展搜索空间，显著提升ADS安全评估的效率与有效性。

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [136] [TurboADMM: A Structure-Exploiting Parallel Solver for Multi-Agent Trajectory Optimization](https://arxiv.org/abs/2602.15838)
*Yucheng Chen*

Main category: cs.RO

TL;DR: 本文提出了TurboADMM，一种专用于多智能体轨迹优化的单机QP求解器，通过ADMM分解、Riccati预热启动和参数化QP热启动三者协同设计，在智能体数量上实现近似线性复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有QP求解器无法同时有效利用时间结构、智能体分解和迭代相似性，导致在处理大规模多智能体密集耦合问题时扩展性差。

Method: 提出TurboADMM求解器，包含三个核心组件：(1) ADMM分解实现并行化的每智能体子问题求解并保持块三对角结构；(2) Riccati预热启动利用时间结构为各智能体QP提供高质量初值；(3) 在qpOASES中采用参数化QP热启动复用KKT系统QR分解。

Result: TurboADMM在多智能体数量上展现出经验上的近线性计算复杂度，显著提升求解效率与可扩展性。

Conclusion: TurboADMM通过系统性协同设计三种技术，在保持精度的同时大幅提升多智能体轨迹优化QP问题的求解速度和规模适应能力，优于通用及部分结构化求解器。

Abstract: Multi-agent trajectory optimization with dense interaction networks require solving large coupled QPs at control rates, yet existing solvers fail to simultaneously exploit temporal structure, agent decomposition, and iteration similarity. One usually treats multi-agent problems monolithically when using general-purpose QP solvers (OSQP, MOSEK), which encounter scalability difficulties with agent count. Structure-exploiting solvers (HPIPM) leverage temporal structure through Riccati recursion but can be vulnerable to dense coupling constraints. We introduce TurboADMM, a specialized single-machine QP solver that achieves empirically near linear complexity in agent count through systematic co-design of three complementary components: (1) ADMM decomposition creates per-agent subproblems solvable in parallel, preserving block-tridiagonal structure under dense coupling; (2) Riccati warmstart exploits temporal structure to provide high-quality primal-dual initialization for each agent's QP; (3) parametric QP hotstart \footnote{In the paper, we refer warmstart as the technique that uses the Riccati equation results as auxiliary QP initialization for a single QP solve, while hotstart as reusing the QR factorization across QP solve iterations.}in qpOASES reuses similar KKT system factorizations across ADMM iterations.

</details>


### [137] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: 本文提出NOMAD方法，利用基于目标城市地图的自博弈多智能体强化学习，无需人类示范数据即可实现自动驾驶策略在新城市的适应。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在新城市部署成本高、速度慢，主要瓶颈在于需要收集大量人类示范轨迹来适应新城市的道路几何、交通规则和交互模式。

Method: 提出NO data Map-based self-play for Autonomous Driving (NOMAD)，在基于目标城市地图构建的仿真环境中，采用自博弈多智能体强化学习进行策略适应，并使用简单奖励函数。

Result: NOMAD显著提升了目标城市的任务成功率和轨迹真实性，验证了其作为数据密集型城市迁移方法的有效且可扩展替代方案。

Conclusion: NOMAD证明了仅依靠地图与元信息、无需人类示范数据即可实现跨城市自动驾驶策略适应的可行性与优越性。

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page: https://nomaddrive.github.io/

</details>


### [138] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 本文系统回顾了2015–2025年间社会机器人与扩展现实（XR）交互的实证研究，发现该领域仍处于早期阶段：实验多限于实验室模拟，硬件/软件/机器人细节常缺失，机器人交互性弱，生物信号等XR潜力未被充分利用；研究者与参与者群体偏年轻、男性、西方、技术背景；存在硬件延迟、样本小且同质、实验周期短等局限。作者提出五阶段路线图以提升方法论严谨性、生态效度、交互质量、样本多样性及构建领域分类体系。


<details>
  <summary>Details</summary>
Motivation: 扩展现实（XR）在人机交互（HRI）中日益受关注，但在社会机器人领域的实证研究仍严重不足，缺乏系统性梳理与方法学反思，亟需厘清现状、问题与发展方向。

Method: 采用系统性文献综述方法，筛选2015–2025年间6527篇同行评议论文，最终纳入33项严格符合标准的实证研究；从XR与机器人应用情境、数据采集与分析方法、研究者与参与者人口统计特征、挑战与未来议程四个维度进行编码与分析。

Result: 发现当前社会XR-HRI研究高度依赖实验室模拟；关键技术细节（如硬件、软件、机器人型号）报告不全；机器人多为被动视觉刺激；XR设备的生物信号（如眼动）与日志功能未被有效利用；研究团队与参与者以西方、年轻、男性、技术背景为主，人口统计信息常缺失；主要局限包括硬件延迟、小规模同质样本、短暂浅层实验周期。

Conclusion: 社会XR-HRI尚处萌芽期，要使其成为生态效度高、方法可靠的社会机器人研究工具，必须推动方法论创新、增强真实场景应用、提升机器人交互能力、扩大样本多样性，并建立统一的领域分类体系。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [139] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: ReasonNavi 是一种受人类导航启发的零样本具身导航框架，结合多模态大语言模型（MLLM）与确定性规划器，通过地图分割、语义推理与轨迹执行实现高效、可解释、无需微调的全局感知导航。


<details>
  <summary>Details</summary>
Motivation: 具身智能体常因仅依赖局部第一人称视角而缺乏全局预见能力，导致探索低效；而人类则先基于地图进行全局规划，再局部执行，该工作旨在模仿这一‘先推理、后行动’范式。

Method: 将俯视地图划分为房间区域并采样候选目标节点，构建离散推理空间；利用MLLM分阶段推理选择最符合指令（物体/图像/文本目标）的候选节点；再通过基于在线构建占据地图的确定性动作规划器将所选航点转化为可执行轨迹，并结合预训练检测与分割模型保障目标识别鲁棒性。

Result: 在三个导航任务上持续超越需大量训练或复杂场景建模的现有方法，具备零样本能力、无需MLLM微调、规避强化学习策略脆弱性，且随基础模型升级自然扩展。

Conclusion: ReasonNavi 提供了一种可扩展、可解释、全局感知的具身导航新范式，弥合了语义推理与具身控制之间的鸿沟。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page: https://reasonnavi.github.io/

</details>


### [140] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: 本文提出MARVL方法，通过多阶段引导和视觉语言模型微调，解决机器人强化学习中密集奖励函数设计的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 设计密集奖励函数对高效机器人强化学习至关重要，但手动工程限制了其可扩展性和自动化；现有VLM奖励存在任务进展误对齐、空间定位困难和任务语义理解有限等问题。

Method: MARVL微调视觉语言模型以提升空间与语义一致性，并将任务分解为多阶段子任务，结合任务方向投影实现轨迹敏感性。

Result: 在Meta-World基准上，MARVL显著优于现有VLM奖励方法，在稀疏奖励操作任务中展现出更高的样本效率和鲁棒性。

Conclusion: MARVL为自动化、可扩展的机器人强化学习奖励设计提供了有效新范式。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [141] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种面向触觉-视觉-语言（TVL）模型的可靠性感知测试时自适应（TTA）框架，通过建模各模态的可靠性来应对异步跨模态分布偏移，在样本过滤、特征融合和优化正则化三方面提升鲁棒性，并在TAG-C等基准上显著优于现有TTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在多模态场景下缺乏对各模态可靠性的显式建模，难以应对触觉、视觉、语言模态异步发生的分布偏移，导致模型在部分模态失效时表现脆弱。

Method: 提出可靠性感知TTA框架：基于预测不确定性与扰动响应估计每种模态的可靠性；利用该共享可靠性信号实现不可靠样本过滤、自适应多模态特征融合、以及可靠性引导的测试时优化正则化。

Result: 在TAG-C基准及其它TVL任务中，该方法显著超越强TTA基线，在严重模态损坏下最高提升准确率49.9%。

Conclusion: 显式建模模态级可靠性对提升TVL模型在分布偏移下的测试时鲁棒性至关重要。

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [142] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: Fly0提出一种解耦语义推理与几何规划的VLN新框架，通过三阶段流水线提升导航精度与鲁棒性，在仿真和真实环境中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法在语义理解与控制精度之间存在权衡：MLLM虽推理能力强，但直接作为低层控制器会导致高延迟、轨迹振荡和几何接地弱等问题。

Method: Fly0采用三阶段解耦框架：(1) MLLM模块将自然语言指令定位到2D像素坐标；(2) 基于深度数据的几何投影模块将2D目标映射至3D空间；(3) 几何规划器生成无碰撞轨迹。

Result: 在仿真与真实环境中，Fly0相较SOTA基线成功率达20%以上提升，导航误差（NE）降低约50%，且具备视觉丢失下的鲁棒导航能力。

Conclusion: 解耦语义与几何模块可有效缓解MLLM部署瓶颈，提升VLN系统的实时性、稳定性与泛化能力，为具身智能导航提供新范式。

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at https://github.com/xuzhenxing1/Fly0.

</details>


### [143] [FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution](https://arxiv.org/abs/2602.15882)
*Jingjing Fan,Yushan Liu,Shoujie Li,Botao Ren,Siyuan Li,Xiao-Ping Zhang,Wenbo Ding,Zhidong Deng*

Main category: cs.RO

TL;DR: FUTURE-VLA 是一种面向机器人长时序控制与未来预测的统一视觉-语言架构，通过时序自适应压缩与潜空间自回归，在保持单帧推理延迟的同时，支持16倍扩展的时空窗口，并引入可解释的预测引导人机协同机制。


<details>
  <summary>Details</summary>
Motivation: 现有通用视觉语言模型虽能处理长视频，但在机器人部署中受限于长历史处理和高维未来预测带来的高延迟。

Method: 提出FUTURE-VLA架构：1）采用双侧效率范式，包括时序自适应压缩以提升时空信息密度；2）潜空间自回归实现动作动力学与可视化未来预览的联合建模；3）预测引导的人在环执行门控机制。

Result: 在LIBERO、RoboTwin和真实Piper平台分别达到99.2%、75.4%、78.0%的成功率，时空窗口扩大16倍，推理延迟与单帧基准持平。

Conclusion: FUTURE-VLA成功弥合了通用视觉语言模型与机器人实时控制之间的鸿沟，实现了高效、可解释、可交互的长时序预测与控制统一。

Abstract: General vision-language models increasingly support unified spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained by the prohibitive latency of processing long-horizon histories and generating high-dimensional future predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon control and future forecasting as a monolithic sequence-generation task. Adopting a dual-sided efficiency paradigm, FUTURE-VLA leverages a temporally adaptive compression strategy to maximize spatiotemporal information density, enabling the ingestion of extensive multi-view histories while maintaining constant inference latency. Simultaneously, it performs latent-space autoregression to align actionable dynamics with reviewable visual look-aheads in a single forward pass. These real-time predictive capabilities further enable a prediction-guided Human-In-the-Loop mechanism via interactive execution gating, allowing operators to dynamically validate behaviors based on interpretable future previews. Extensive evaluations demonstrate that FUTURE-VLA establishes new state-of-the-art performance, attaining success rates of 99.2% on LIBERO, 75.4% on RoboTwin, and 78.0% on a real-world Piper platform, all with a $16\times$ extended spatiotemporal window while maintaining the inference latency of a single-frame baseline.

</details>


### [144] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: 本文指出SLAM领域陷入‘置信度陷阱’，过度关注基准测试分数而忽视原则性不确定性估计，主张将一致且实时的不确定性计算作为主要成功指标。


<details>
  <summary>Details</summary>
Motivation: SLAM社区过于重视基准分数，导致系统几何精度高但概率上不一致且鲁棒性差。

Method: 提出一种范式转变，强调一致性与实时性的不确定性估计应成为核心评估指标。

Result: 呼吁将不确定性估计提升为SLAM系统设计与评估的首要目标。

Conclusion: 需摆脱‘置信度陷阱’，建立以概率一致性与实时不确定性计算为导向的新评估范式。

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [145] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种新型紧凑型四自由度运动跟踪设备（IMTD），专为腹腔镜手术培训与评估设计，具备高精度、低成本、易集成等特点，并能提供实时客观反馈以提升外科训练效果。


<details>
  <summary>Details</summary>
Motivation: 针对腹腔镜手术培训中对器械运动精确跟踪、固定中心运动模拟及与标准箱式训练器无缝集成的需求，开发一种实用、低成本、易部署的运动跟踪设备。

Method: 设计并实现了具有四自由度的IMTD设备，涵盖运动学建模、机械结构设计、传感器集成与原型开发；通过与光学动捕系统（MoCap）对比，验证其在角度与平移运动上的跟踪精度与可靠性；进一步评估精度、流畅性、速度和整体运动效率等关键性能指标。

Result: IMTD在手术器械运动跟踪方面表现出高准确性与可靠性，可有效捕捉腹腔镜操作手势；具备低成本、一体化设计优势，易于在培训环境中部署；能提供实时、客观的操作反馈。

Conclusion: IMTD是一种适用于腹腔镜手术培训与评估的实用、经济、可扩展的运动跟踪工具，有助于缩短初学者学习曲线，并为手势评分算法与标准化培训协议的后续研究奠定基础。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [146] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种用于脊柱手术中钻孔操作的新型3T2R机械结构，基于改进型全平移R-CUBE机构，通过三阶段（平移、传递、旋转）设计实现高运动学性能，并基于真实患者轨迹进行了优化。


<details>
  <summary>Details</summary>
Motivation: 脊柱手术中需在椎骨上钻孔以植入椎弓根螺钉，需要具备特定运动能力（3T2R）的高精度、高安全性手术机器人机构。

Method: 提出一种增强型全平移R-CUBE机构，引入改进连杆以增加旋转自由度；将机构划分为三个功能阶段，分别建模其运动学与速度模型，并进行耦合分析；基于真实患者钻孔轨迹对机构参数进行运动学性能优化。

Result: 成功设计并建模了一种具备3T2R自由度的新型手术钻孔机构，实现了满足临床钻孔轨迹要求的高运动学性能。

Conclusion: 该机构架构兼顾了手术所需的刚性、可达性与运动灵活性，验证了基于R-CUBE衍生构型在微创脊柱手术机器人中的可行性与优势。

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [147] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 本文提出AsymmetricHuberEKF滤波器，通过引入非负NLOS偏差的物理先验和不对称损失函数，解决灾后无人机定位中因非视距传播导致的统计-几何退化（SGD）问题，并结合主动感知策略提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 灾后废墟中NLOS传播导致测距偏差严格非负，而传统对称鲁棒估计器（如Huber、Tukey）假设误差对称，造成理论失配，引发统计-几何退化（SGD）；同时数据驱动方法受限于训练数据稀缺与仿真到现实的差距。

Method: 提出物理驱动的AsymmetricHuberEKF，推导并嵌入反映NLOS非负特性的不对称损失函数；理论证明标准对称滤波器是其退化情形；设计协同主动感知策略以提供双边信息，缓解SGD。

Result: 在2D垂直俯视扫描场景中验证，相比对称基线方法显著加快收敛速度。

Conclusion: AsymmetricHuberEKF通过融合物理先验与主动感知，在数据稀缺、几何受限的灾后定位任务中提供了更鲁棒、高效的基础模块。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [148] [VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation](https://arxiv.org/abs/2602.15899)
*Anna Gelencsér-Horváth,Gergely Dinya,Dorka Boglárka Erős,Péter Halász,Islam Muhammad Muqsit,Kristóf Karacs*

Main category: cs.RO

TL;DR: SceneVGGT 是一个结合 SLAM 与语义建图的时空 3D 场景理解框架，支持长视频流处理，具备几何一致性、时序语义连贯性和低 GPU 内存占用（<17GB），适用于交互式辅助导航。


<details>
  <summary>Details</summary>
Motivation: 为实现自主与辅助导航，需兼顾实时性、几何一致性与语义连贯性的高效 3D 场景理解框架。

Method: 基于 VGGT 构建滑动窗口流水线；通过相机位姿对齐局部子图以保证几何一致性；利用 VGGT 跟踪头将 2D 实例掩码提升至 3D 并维持对象身份时序一致性；将物体投影至估计地面平面支持辅助导航。

Result: GPU 内存稳定低于 17 GB，不随输入长度增长；在 ScanNet++ 上点云性能具有竞争力；支持交互式音频反馈辅助导航。

Conclusion: SceneVGGT 在保持鲁棒语义识别的同时实现了高效、可扩展的 3D 场景理解，适用于实时辅助导航任务。

Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

</details>


### [149] [Adaptive Illumination Control for Robot Perception](https://arxiv.org/abs/2602.15900)
*Yash Turkar,Shekoufeh Sadeghi,Karthik Dantu*

Main category: cs.RO

TL;DR: 本文提出Lightning框架，通过闭环光照控制提升低光和高动态范围下的视觉SLAM鲁棒性，结合重光照建模、离线优化与模仿学习，在不增加硬件负担前提下显著提升定位精度并降低功耗。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于原始图像质量；而主动光照虽有潜力，但其对成像的影响复杂且难以预测，易引发高光、饱和等失败模式。

Method: Lightning框架包含三阶段：1）训练Co-Located Illumination Decomposition（CLID）模型，分解环境光与光源贡献，支持多强度图像合成；2）基于合成数据求解离线Optimal Intensity Schedule（OIS），权衡SLAM图像效用、功耗与时间平滑性；3）通过行为克隆将OIS蒸馏为实时Illumination Control Policy（ILC），部署于移动机器人。

Result: 在评估中，Lightning显著提升了SLAM轨迹鲁棒性，并减少了不必要的照明功耗。

Conclusion: Lightning证明了闭环可编程光照控制是提升低光/高动态范围下视觉SLAM性能的有效新范式，兼顾物理一致性、计算效率与泛化能力。

Abstract: Robot perception under low light or high dynamic range is usually improved downstream - via more robust feature extraction, image enhancement, or closed-loop exposure control. However, all of these approaches are limited by the image captured these conditions. An alternate approach is to utilize a programmable onboard light that adds to ambient illumination and improves captured images. However, it is not straightforward to predict its impact on image formation. Illumination interacts nonlinearly with depth, surface reflectance, and scene geometry. It can both reveal structure and induce failure modes such as specular highlights and saturation. We introduce Lightning, a closed-loop illumination-control framework for visual SLAM that combines relighting, offline optimization, and imitation learning. This is performed in three stages. First, we train a Co-Located Illumination Decomposition (CLID) relighting model that decomposes a robot observation into an ambient component and a light-contribution field. CLID enables physically consistent synthesis of the same scene under alternative light intensities and thereby creates dense multi-intensity training data without requiring us to repeatedly re-run trajectories. Second, using these synthesized candidates, we formulate an offline Optimal Intensity Schedule (OIS) problem that selects illumination levels over a sequence trading off SLAM-relevant image utility against power consumption and temporal smoothness. Third, we distill this ideal solution into a real-time controller through behavior cloning, producing an Illumination Control Policy (ILC) that generalizes beyond the initial training distribution and runs online on a mobile robot to command discrete light-intensity levels. Across our evaluation, Lightning substantially improves SLAM trajectory robustness while reducing unnecessary illumination power.

</details>


### [150] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 本文提出了一种面向自主帆船的时空覆盖路径规划框架，结合空间域的拓扑形态约束与时间域的预报感知前视规划，以应对风场和流场非均匀、时变带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 自主帆船虽适合长期海洋观测，但其性能各向异性且受时变非均匀风/流场影响显著，现有覆盖方法（如往复式扫描）效果受限，相关路径规划研究尚不充分。

Method: 提出一种时空联合的覆盖路径规划框架：(1) 空间域引入基于拓扑的形态学约束，保障覆盖紧凑连续；(2) 时间域采用预报感知的前视规划，预判环境演化并实现前瞻性决策。

Result: 在随机非均匀、时变海洋环境（含部分方向不可达场景）下的仿真表明，该方法能生成高效可行的覆盖路径，而传统策略常失效。

Conclusion: 本工作首次为在非均匀及时变海洋环境中运行的自主帆船提供了专用覆盖路径规划解决方案，为未来多帆船协同覆盖奠定基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [151] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: DreamZero是一种基于预训练视频扩散模型的世界动作模型（WAM），通过联合建模视频与动作来学习物理动态，显著提升在新任务与环境中的泛化能力，并支持实时闭环控制及跨形态迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型擅长语义泛化，但在未知物理运动和新环境中的泛化能力不足。

Method: 提出DreamZero，构建于预训练视频扩散骨干网络之上，作为世界动作模型（WAM），通过预测未来世界状态与动作、以视频为密集物理演化表征，联合建模视频与动作；采用模型与系统优化实现14B参数模型7Hz实时闭环控制；支持基于视频示范与少量玩数据的跨形态迁移。

Result: 在真实机器人实验中，相较SOTA VLA模型，新任务与新环境泛化性能提升超2倍；视频示范迁移带来超42%相对性能提升；仅30分钟玩数据即可完成少样本形态适配并保持零样本泛化能力。

Conclusion: DreamZero通过将视频扩散模型转化为世界动作模型，突破了VLA在物理泛化与实时控制上的瓶颈，为具身智能提供了可扩展、可迁移的新范式。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [152] [Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control](https://arxiv.org/abs/2602.15954)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理信息神经网络（PINNs）的航天器姿态动力学建模方法，相比纯数据驱动方法显著提升了预测精度与闭环控制性能，并在MPC框架下展现出更强鲁棒性与更快响应速度。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的建模复杂耗时，而纯数据驱动模型稳定性差、泛化能力弱，亟需兼顾准确性与可靠性的建模新方法。

Method: 构建高保真仿真数据集，对比纯数据驱动神经网络与嵌入物理约束（如刚体动力学方程）的PINN建模；并将二者分别集成至模型预测控制（MPC）框架中进行闭环验证；进一步提出线性-非线性混合控制策略。

Result: PINN模型使平均相对误差降低68.17%；在MPC中实现更优跟踪性能和不确定性鲁棒性；混合控制策略使设定时间减少61.52%–76.42%（含测量噪声与飞轮摩擦）。

Conclusion: 将先验物理知识融入神经网络训练可显著提升航天器姿态模型的可靠性与控制性能，PINNs是替代传统建模与纯学习方法的有效途径。

Abstract: Reliable spacecraft attitude control depends on accurate prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC) are employed, where performance is limited by the quality of the internal system model. For spacecraft with complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally heavy. Learning-based system identification presents a compelling alternative; however, models trained exclusively on data frequently exhibit fragile stability properties and limited extrapolation capability. This work explores Physics-Informed Neural Networks (PINNs) for modeling spacecraft attitude dynamics and contrasts it with a conventional data-driven approach. A comprehensive dataset is generated using high-fidelity numerical simulations, and two learning methodologies are investigated: a purely data-driven pipeline and a physics-regularized approach that incorporates prior knowledge into the optimization process. The results indicate that embedding physical constraints during training leads to substantial improvements in predictive reliability, achieving a 68.17% decrease in mean relative error relative. When deployed within an MPC architecture, the physics-informed models yield superior closed-loop tracking performance and improved robustness to uncertainty. Furthermore, a hybrid control formulation that merges the learned nonlinear dynamics with a nominal linear model enables consistent steady-state convergence and significantly faster response, reducing settling times by 61.52%-76.42% under measurement noise and reaction wheel friction.

</details>


### [153] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 本文探讨了人类意图的多面性，基于心理学和沟通研究提出了一个综合性的意图分类框架，并将其应用于机器人学中，以促进从纯技术增强向以人为本的研究范式转变。


<details>
  <summary>Details</summary>
Motivation: 现有机器人研究常将人类意图等同于特定任务目标，缺乏对意图多面性的统一定义，本文旨在填补这一理论空白。

Method: 结合心理学与沟通研究的理论成果，构建意图分类框架，并通过协作搜索与物体运输两个用例进行实证分析。

Result: 提出了一套适用于机器人学的人类意图分类体系，并展示了其在实际机器人研究场景中的映射与应用价值。

Conclusion: 理解人类意图的多样性对于发展真正以人为本的机器人系统至关重要，该框架为未来人机协同研究提供了理论基础与实践指导。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [154] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了ODYN，一种新型的全移位原始-对偶非内点法二次规划（QP）求解器，专为高效处理密集和稀疏QP问题而设计。它结合了全移位非线性互补问题（NCP）函数与近端乘子法，在不依赖约束线性独立性的前提下，稳健应对病态与退化问题，并具备优异的热启动性能，适用于机器人、AI等实时序列优化场景。


<details>
  <summary>Details</summary>
Motivation: 现有QP求解器在处理病态、退化、约束不满足线性独立性条件的问题时存在鲁棒性不足、热启动性能差等问题，难以满足机器人和AI中实时、序列化及可微分优化的需求。

Method: 提出全移位原始-对偶框架，融合全移位NCP函数与近端乘子法，避免内点法限制；支持热启动；提供开源实现，并在Maros-Mészáros基准集上验证；进一步集成至OdynSQP（SQP预测控制）、ODYNLayer（隐式可微优化层）和ODYNSim（接触动力学仿真）三个应用中。

Result: 在小到大规模QP问题上达到业界领先收敛性能；显著优于现有求解器的热启动能力；成功应用于预测控制、深度学习可微优化层和接触动力学仿真三大典型场景。

Conclusion: ODYN是一种鲁棒、高效、可嵌入且可微分的QP求解器，突破了传统内点法的局限，为机器人和AI中的实时优化与学习提供了新工具。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [155] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 本文研究了感知不确定性传播与校准对基于感知的运动规划的影响，发现引入上游不确定性传播的方法在复杂闭环场景中具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要在决策中考虑感知数据带来的固有不确定性，但现有不确定性感知规划器可能对预测不确定性校准不敏感，而该问题尚未被量化分析。

Method: 通过在nuPlan规划基准上比较两种具有不同不确定性传播程度的预测-规划流程，并在nuPlan挑战场景中进行闭环评估，分析感知不确定性传播与校准的影响。

Result: 引入上游不确定性传播的方法在复杂闭环场景中展现出更优的泛化能力。

Conclusion: 上游不确定性传播对提升规划器在真实复杂场景中的鲁棒性和泛化性至关重要，不确定性校准是影响规划性能的关键因素。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [156] [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073)
*Kevin Kai-Chun Chang,Ekin Beyazit,Alberto Sangiovanni-Vincentelli,Tichakorn Wongpiromsarn,Sanjit A. Seshia*

Main category: cs.RO

TL;DR: 本文提出了ScenicRules基准，用于在随机环境中评估自动驾驶系统在多目标优先级规范下的表现，通过形式化目标、分层规则框架和Scenic语言建模场景，有效暴露智能体在优先级目标上的失败。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶评估基准缺乏对多目标优先级关系和形式化环境场景建模的结合，难以反映真实复杂交通中的权衡与上下文依赖。

Method: 提出ScenicRules基准，包括：1）形式化多样化定量评估目标；2）设计可解释、可适配的分层规则框架（Hierarchical Rulebook）编码多目标及其优先级；3）基于Scenic语言构建紧凑而具代表性的多样化驾驶场景集（含近事故情形）。

Result: 实验表明，所形式化的目标和分层规则框架与人类驾驶判断高度一致，且该基准能有效揭示智能体在优先级目标上的失败。

Conclusion: ScenicRules为自动驾驶系统提供了首个融合多目标优先级与形式化环境建模的评估基准，提升了评估的真实性、可解释性与实用性。

Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.

</details>


### [157] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 本文提出了一种结合学习与模型的混合方法，利用多模态触觉传感实时检测并抑制多指机械手在手内滑动，通过在线更新零空间内的内部抓取力实现快速闭环稳定（<50ms）。


<details>
  <summary>Details</summary>
Motivation: 解决多指机器人抓取中手内滑动难以实时检测与抑制的问题，提升抓取鲁棒性与响应速度。

Method: 融合压电（PzE）快速滑动检测与压阻（PzR）接触定位的多模态触觉感知；在线构建抓取矩阵；滑动发生时，在保持物体外力不变前提下，通过二次规划更新零空间内的内部抓取力，并满足执行器限制。

Result: 理论感知-指令延迟为35–40 ms（其中PzR更新5 ms，QP求解约4 ms）；滑动起始检测延迟仅20 ms；实验证明可在外部扰动下实现多指抓取的闭环稳定。

Conclusion: 将解析式力控制与学习型触觉线索结合，兼顾鲁棒性与快速响应；系统延迟主要受限于实验数据通路，而非计算本身，具备实现亚50 ms闭环稳定的明确路径。

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [158] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 本文提出了一种基于广角相机图像测量的方法，用于自动引导叉车（AGF）精确插入托盘孔中，通过测量托盘俯仰角及相机与叉子坐标系间的标定信息，实现对叉子高度、伸缩位置和倾角的精准控制。


<details>
  <summary>Details</summary>
Motivation: 为使自主导引叉车（AGF）能自动完成将叉子插入托盘孔的操作，需精确控制叉子的高度、伸缩位置和倾斜角度以匹配托盘孔的位置与朝向。

Method: 提出两种图像测量方法：一是利用广角相机图像测量托盘在相机坐标系下的俯仰角；二是简便获取相机坐标系与叉子坐标系之间的标定信息，以便将图像测量结果应用于叉子控制。实验中将广角相机固定在伸缩式叉车背板上，采集前方托盘的图像并处理。

Result: 通过对比图像测量值与人工测量值，在不同托盘俯仰角、托盘与叉子相对高度以及托盘是否装载等条件下评估误差，结果表明误差在安全插入叉子的允许范围内。

Conclusion: 所提出的图像测量方法可有效支持AGF自动完成叉取操作，具备实际应用可行性。

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [159] [World Model Failure Classification and Anomaly Detection for Autonomous Inspection](https://arxiv.org/abs/2602.16182)
*Michelle Ho,Muhammad Fadhil Ginting,Isaac R. Ward,Andrzej Reinke,Mykel J. Kochenderfer,Ali-akbar Agha-Mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 本文提出了一种结合监督式失败分类与异常检测的混合框架，用于自主巡检机器人对工业场景仪表读数的实时故障预测与分类（成功/已知失败/OOD异常），基于世界模型与共形预测，实现实时部署并超越人类判断速度。


<details>
  <summary>Details</summary>
Motivation: 自主巡检机器人虽可降低成本与风险，但因遮挡、视角受限或环境突变导致读数不准，亟需能区分正常、已知失败与未知异常（OOD）的鲁棒分类机制。

Method: 构建策略无关、分布无关的混合框架：以世界模型为骨干处理压缩视频流，引入两个由共形预测（CP）设定的决策函数，联合实现三类（成功/已知失败/异常）分类。

Result: 在办公与工业现场采集的仪表视频数据上验证，准确率超90%，分类早于人工判断；成功实现实时部署于Boston Dynamics Spot机器人。

Conclusion: 该框架可支撑自主巡检中的鲁棒前瞻性故障检测，并可作为反馈信号优化模型训练与数据质量评估。

Abstract: Autonomous inspection robots for monitoring industrial sites can reduce costs and risks associated with human-led inspection. However, accurate readings can be challenging due to occlusions, limited viewpoints, or unexpected environmental conditions. We propose a hybrid framework that combines supervised failure classification with anomaly detection, enabling classification of inspection tasks as a success, known failure, or anomaly (i.e., out-of-distribution) case. Our approach uses a world model backbone with compressed video inputs. This policy-agnostic, distribution-free framework determines classifications based on two decision functions set by conformal prediction (CP) thresholds before a human observer does. We evaluate the framework on gauge inspection feeds collected from office and industrial sites and demonstrate real-time deployment on a Boston Dynamics Spot. Experiments show over 90% accuracy in distinguishing between successes, failures, and OOD cases, with classifications occurring earlier than a human observer. These results highlight the potential for robust, anticipatory failure detection in autonomous inspection tasks or as a feedback signal for model training to assess and improve the quality of training data. Project website: https://autoinspection-classification.github.io

</details>


### [160] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 本文提出了一种安全的信息论学习模型预测控制（SIT-LMPC）算法，用于机器人在复杂不确定环境中执行迭代任务，兼顾鲁棒性、安全性与高性能。


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂不确定环境中执行迭代任务时，需平衡控制策略的鲁棒性、安全性与高性能。

Method: 基于信息论的模型预测控制框架，结合自适应惩罚法保障安全性，并利用归一化流从历史轨迹中学习价值函数以实现更丰富的不确定性建模；算法支持GPU高度并行化实现实时优化。

Result: 在基准仿真和硬件实验中，SIT-LMPC能迭代提升系统性能，同时稳健满足系统约束。

Conclusion: SIT-LMPC是一种适用于离散时间非线性随机系统的安全、高效、可迭代优化的控制方法，具备实际部署潜力。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [161] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 本文提出了一种面向非平面地形的非平面模型预测控制（MPC）框架，通过几何感知建模与递归稀疏高斯过程（GP）学习残差动力学，实现实时地形自适应，并在Isaac Sim中验证了其在3D复杂表面上的高精度轨迹跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在非平面地形上难以准确建模复杂车辆动力学，亟需一种能适应多变三维地形几何特性的控制方法。

Method: 提出几何感知建模方法，利用递归稀疏高斯过程学习车辆动力学残差，并结合Model Predictive Path Integral（MPPI）控制器实现参考轨迹跟踪。

Result: 在自定义Isaac Sim环境中验证表明，该框架能在挑战性3D表面上保持高跟踪精度。

Conclusion: 所提非平面MPC框架结合数据驱动建模与实时自适应能力，有效提升了自动驾驶车辆在非平面地形上的控制性能。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [162] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度学习的无标记6D位姿估计方法，用于增强去中心化多机器人SLAM系统中机器人间的相对定位精度，尤其适用于存在感知歧义、视角差异大或光照条件恶劣（如反射、过曝）的场景，并在类行星环境实地测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多机器人SLAM中，由于感知歧义或视角差异，跨机器人回环检测困难；而依赖标定的标志物（如AprilTag）的方法受限于观测距离和光照鲁棒性。

Method: 将基于深度学习的无标记6D位姿估计集成到去中心化多机器人SLAM系统中，实现机器人间直接互观与图连接。

Result: 实验表明该方法显著提升了机器人团队间的相对定位精度，并在类行星环境实地测试中验证了其有效性与鲁棒性。

Conclusion: 无标记深度学习位姿估计可有效替代传统标志物方案，提升多机器人SLAM在复杂真实环境中的协同建图与定位能力。

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [163] [Machine Learning Driven Prediction of the Behavior of Biohybrid Actuators](https://arxiv.org/abs/2602.16330)
*Michail-Antisthenis Tsompanas,Marco Perez Hernandez,Faisal Abdul-Fattah,Karim Elhakim,Mostafa Ibrahim,Judith Fuentes,Florencia Lezcano,Riccardo Collu,Massimo Barbaro,Stefano Lai,Samuel Sanchez,Andrew Adamatzky*

Main category: cs.RO

TL;DR: 本文研究了利用监督学习方法（包括随机森林、神经网络和LSTM）对骨骼肌基生物混合执行器（BHM）进行静态与动态建模，以提升其可控性与可预测性；静态模型预测最大输出力（R²=0.9425），动态LSTM模型构建数字孪生实现高精度时序力预测（R²=0.9956），为未来自适应控制提供基础。


<details>
  <summary>Details</summary>
Motivation: 骨骼肌基生物混合执行器虽具高效运动潜力，但其固有的生物变异性与非线性严重制约了可控性与可预测性。

Method: 采用监督学习方法：1）构建静态预测模型（随机森林与神经网络回归器），输入肌肉样本、电刺激参数及基线力，预测最大输出力；2）构建基于LSTM的动态建模框架，作为数字孪生复现电刺激响应下的力时间序列。

Result: 静态模型最优R²达0.9425；动态LSTM模型R²达0.9956；两类模型均展现出高预测精度。

Conclusion: 静态模型可用于面向特定应用与目标力输出的执行器性能优化；动态模型为未来生物混合机器人系统开发鲁棒自适应控制策略奠定了基础。

Abstract: Skeletal muscle-based biohybrid actuators have proved to be a promising component in soft robotics, offering efficient movement. However, their intrinsic biological variability and nonlinearity pose significant challenges for controllability and predictability. To address these issues, this study investigates the application of supervised learning, a form of machine learning, to model and predict the behavior of biohybrid machines (BHMs), focusing on a muscle ring anchored on flexible polymer pillars. First, static prediction models (i.e., random forest and neural network regressors) are trained to estimate the maximum exerted force achieved from input variables such as muscle sample, electrical stimulation parameters, and baseline exerted force. Second, a dynamic modeling framework, based on Long Short-Term Memory networks, is developed to serve as a digital twin, replicating the time series of exerted forces observed in response to electrical stimulation. Both modeling approaches demonstrate high predictive accuracy. The best performance of the static models is characterized by R2 of 0.9425, whereas the dynamic model achieves R2 of 0.9956. The static models can enable optimization of muscle actuator performance for targeted applications and required force outcomes, while the dynamic model provides a foundation for developing robustly adaptive control strategies in future biohybrid robotic systems.

</details>


### [164] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种基于安全强化学习的双四足机器人协同运输方法，通过约束马尔可夫博弈建模、成本-优势分解与约束分配机制，在狭窄环境中保障安全性与协作性能。


<details>
  <summary>Details</summary>
Motivation: 在狭窄环境中，多机器人协同运输面临可行区域受限、避碰与高效协作难以兼顾的挑战。

Method: 将任务建模为全协作约束马尔可夫博弈；提出成本-优势分解法以保证团队约束总和不超限；设计约束分配机制实现个体自主任务分配。

Result: 仿真与实时实验表明，该方法在双四足机器人协同运输中相比现有方法具有更高成功率与性能。

Conclusion: 所提安全强化学习框架能有效平衡狭窄环境下的安全性与协作效率，支持自主、鲁棒的多机器人协同运输。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [165] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: 本文提出了MoMa-SG框架，用于构建包含可交互物体的语义-运动学3D场景图，通过RGB-D序列实现对物体运动的鲁棒估计与关节建模，并引入Arti4D-Semantic数据集支持评估。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实环境中无法预判物体运动，需弥合语义、几何与运动学之间的鸿沟，以支持长时程移动操作任务。

Method: 提出MoMa-SG框架：基于RGB-D序列进行时序交互分割与遮挡鲁棒点跟踪，将点轨迹提升至3D空间；采用统一扭量估计方法联合优化旋转与平移关节参数；结合父子关系推理容器关系；并构建Arti4D-Semantic数据集。

Result: 在两个数据集上完成全面评估与消融实验；真实场景中在四足机器人和移动机械臂上验证了语义-运动学场景图对日常家居环境中铰接物体操作的有效性。

Conclusion: MoMa-SG成功融合语义、几何与运动学信息，构建出可用于真实机器人操作的语义-运动学3D场景图，显著提升了对铰接物体的感知与操控能力。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.

</details>


### [166] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯系统辨识框架，联合高精度估计机器人状态轨迹与物理参数，融合物理约束、能量回归器与高效优化算法，在仿真与实机实验中显著提升参数估计精度与控制性能。


<details>
  <summary>Details</summary>
Motivation: 提高机器人物理参数（如惯性、摩擦）和状态轨迹联合估计的准确性与一致性，尤其在存在非线性摩擦、接触和动态扰动等复杂场景下。

Method: 构建基于贝叶斯推断的系统辨识框架，嵌入逆动力学、接触与闭环约束及完整关节摩擦模型作为硬约束；采用能量基回归器增强参数可观测性；支持不等式/等式先验；引入能量观测辅助解耦摩擦效应；设计参数化等式约束Riccati递推以实现线性时间复杂度。

Result: 在仿真与Unitree B1+Z1硬件平台上验证，相比前向动力学与解耦辨识基线，收敛更快、惯性与摩擦误差更低、接触一致性更好；嵌入MPC后，在复杂地形运动中跟踪性能显著提升。

Conclusion: 该框架实现了高精度、物理一致且可扩展的联合状态-参数估计，为高性能模型预测控制提供了更可靠的动态模型基础。

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [167] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 本文提出了一种基于水下对接站与微型ROV的常驻式水下监测系统，通过融合声学（USBL）与视觉（ArUco+卡尔曼滤波）导航实现自主对接与巡检，在90米深度验证了90%对接成功率和4分钟内完成巡检任务，证明了无缆、长期、自主水下监测的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有海洋观测受限于高成本与低频次，缺乏持久、自主、无需水面持续支持的监测能力；常驻式水下机器人因自主性、鲁棒性与机械可靠性难题而难以部署。

Method: 设计并部署一套包含水下对接站与增强感知/计算能力的微型ROV系统；ROV利用USBL进行粗定位，结合ArUco视觉标记与扩展卡尔曼滤波实现精确定位与自主对接，并执行本地化巡检任务。

Result: 在90米实海环境中实现90%自主对接成功率，单次完整巡检任务耗时约4分钟，成功验证声-视融合导航在真实水下场景中的有效性与系统可靠性。

Conclusion: 该常驻ROV系统证明了无缆、长期、自主水下作业的技术可行性，为可扩展、低成本的海洋环境持续监测提供了新范式。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [168] [Markerless 6D Pose Estimation and Position-Based Visual Servoing for Endoscopic Continuum Manipulators](https://arxiv.org/abs/2602.16365)
*Junhyun Park,Chunggil An,Myeongbo Park,Ihsan Ullah,Sihyeong Park,Minho Hwang*

Main category: cs.RO

TL;DR: 本文提出了一种无需标记物的双目立体6D位姿估计与基于位置的视觉伺服框架，用于柔性连续体机器人在内窥镜手术中的精确闭环控制。通过仿真训练、多特征融合网络、前馈渲染修正模块及自监督仿真到现实迁移，实现了亚毫米级位姿估计精度和显著优于开环控制的闭环跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人在柔性内窥镜手术中具有高灵巧性，但因迟滞、柔顺性和远端传感受限，其精确位姿估计与闭环控制仍具挑战；现有视觉方法受限于几何可观测性差和计算开销大。

Method: 构建了统一的无标记双目6D位姿估计与位置式视觉伺服框架：1）基于照片级真实感仿真生成大规模带像素级标注数据；2）设计双目感知的多特征融合网络（分割掩码、关键点、热图、边界框）；3）引入前馈式基于渲染的位姿残差修正模块以保证几何一致性；4）采用自监督sim-to-real适应策略提升真实场景性能。

Result: 实测1000个样本平均平移误差0.83 mm、旋转误差2.76°；无标记闭环视觉伺服实现平均平移误差2.07 mm、旋转误差7.41°，较开环分别降低85%和59%，且在重复定点任务中表现出高重复性。

Conclusion: 本工作首次实现了完全无标记、无嵌入传感的连续体机器人位姿估计驱动的位置式视觉伺服闭环控制，为微创手术机器人提供了高精度、低硬件依赖的解决方案。

Abstract: Continuum manipulators in flexible endoscopic surgical systems offer high dexterity for minimally invasive procedures; however, accurate pose estimation and closed-loop control remain challenging due to hysteresis, compliance, and limited distal sensing. Vision-based approaches reduce hardware complexity but are often constrained by limited geometric observability and high computational overhead, restricting real-time closed-loop applicability. This paper presents a unified framework for markerless stereo 6D pose estimation and position-based visual servoing of continuum manipulators. A photo-realistic simulation pipeline enables large-scale automatic training with pixel-accurate annotations. A stereo-aware multi-feature fusion network jointly exploits segmentation masks, keypoints, heatmaps, and bounding boxes to enhance geometric observability. To enforce geometric consistency without iterative optimization, a feed-forward rendering-based refinement module predicts residual pose corrections in a single pass. A self-supervised sim-to-real adaptation strategy further improves real-world performance using unlabeled data. Extensive real-world validation achieves a mean translation error of 0.83 mm and a mean rotation error of 2.76° across 1,000 samples. Markerless closed-loop visual servoing driven by the estimated pose attains accurate trajectory tracking with a mean translation error of 2.07 mm and a mean rotation error of 7.41°, corresponding to 85% and 59% reductions compared to open-loop control, together with high repeatability in repeated point-reaching tasks. To the best of our knowledge, this work presents the first fully markerless pose-estimation-driven position-based visual servoing framework for continuum manipulators, enabling precise closed-loop control without physical markers or embedded sensing.

</details>


### [169] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: 本文提出了一种名为SLOT的软体四足机器人，采用3D打印TPU腿和腱驱动，结合离散Cosserat杆理论建模软腿大变形与接触，并通过模块化全身体动力学框架连接软肢与刚体躯干；进一步嵌入凸模型预测控制，实时优化地面反作用力并映射到腱驱动，实验验证其在爬行与行走中具有高精度（质心轨迹RMSE<5mm）和抗扰稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究基于物理信息的建模与控制方法，以应对软体腿式机器人中大变形、分布弹性、腱驱动及地面接触等复杂耦合动力学挑战，并提升模型可扩展性与实时控制可行性。

Method: 采用离散Cosserat杆理论建模每条软腿的连续体动力学；构建模块化全身体动力学框架，将软腿通过物理一致的反作用力耦合至刚性躯干；嵌入凸模型预测控制（MPC），在0.495秒预测时域内优化地面反作用力，并通过物理信息驱动的力-角度关系映射至腱驱动。

Result: 控制器在多种扰动下实现渐近稳定；实物实验中爬行与行走步态的质心轨迹RMSE小于5 mm；实现了高效、高保真度的实时仿真与控制。

Conclusion: 该框架为软体四足机器人提供了可推广的、可扩展且可复用的基于模型的运动控制方法，推动了连续体软肢与刚体运动动力学的统一建模与控制集成。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [170] [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444)
*Yixue Zhang,Kun Wu,Zhi Gao,Zhen Zhao,Pei Ren,Zhiyuan Xu,Fei Liao,Xinhua Wang,Shichao Fan,Di Wu,Qiuxuan Feng,Meng Li,Zhengping Che,Chang Liu,Jian Tang*

Main category: cs.RO

TL;DR: 本文提出RoboGene框架，用于自动生成多样化、物理可行的机器人操作任务，以解决真实世界机器人数据稀缺问题；通过多样性采样、自我反思和人机协同优化，显著提升VLA模型性能。


<details>
  <summary>Details</summary>
Motivation: 机器人通用操作受限于真实世界交互数据稀缺，而人工收集成本高、扩展性差，现有基础模型易生成不切实际的任务指令。

Method: 提出RoboGene智能体框架，包含多样性驱动采样、物理约束自我反思机制和人机闭环优化；在单臂、双臂及移动机器人上生成任务，并构建18k轨迹数据集，设计新指标评估任务质量、可行性与多样性。

Result: RoboGene在任务生成质量上显著优于GPT-4o、Gemini 2.5 Pro等SOTA基础模型；基于其预训练的VLA模型在真实实验中成功率和泛化能力更高。

Conclusion: 高质量、多样化的任务自动生成对提升VLA模型性能至关重要；RoboGene为机器人数据工程提供了可扩展、物理可信的自动化范式。

Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.

</details>


### [171] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 本文提出了一种面向动态环境的机械臂反应式运动规划框架，通过张量化粒子权重更新显式建模障碍物运动状态，并结合障碍物感知的MPPI规划方法，在不确定感知与控制下实现更安全、更快速的避障。


<details>
  <summary>Details</summary>
Motivation: 在动态非结构化场景中，传统反应式运动生成受限于静态感知和系统动力学假设，难以可靠建模动态障碍物并优化不确定性下的无碰撞轨迹。

Method: 提出张量化的粒子权重更新方案以显式维护障碍物速度与协方差；构建障碍物感知的MPPI规划模型，联合传播机器人-障碍物动力学，在不确定性下预测并评估未来运动。

Result: 在仿真及含噪声的真实环境中验证，该框架在多静态/动态障碍物规避任务中显著优于现有基于MPPI的感知-规划基线方法，提升了安全性与反应性。

Conclusion: 显式建模机器人-障碍物联合动力学能有效提升动态环境下反应式规划的性能，为感知-规划紧耦合提供了模型驱动的新范式。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [172] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 本文提出了一种统一的跌倒安全方法，通过将人类跌倒与恢复姿态的约束性与感知-运动联合表征相结合，实现人形机器人在复杂地形中的零样本跌倒恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法将跌倒安全割裂为多个子问题或依赖无视觉的端到端策略，且难以泛化到非平坦地形；根本原因在于将跌倒安全视为整体数据复杂性，导致可扩展性和泛化性受限。

Method: 基于人类示范（平坦地形）与仿真复杂地形训练特权教师模型，并蒸馏为仅依赖本体感知与前视深度的部署型学生模型；学生通过匹配教师‘目标-上下文’隐空间表征（融合下一目标姿态与局部地形）进行反应学习，而非分离感知与动作编码。

Result: 在仿真和真实Unitree G1人形机器人上验证了该方法在多种非平坦环境中的鲁棒零样本跌倒安全性，无需真实世界微调。

Conclusion: 该统一框架突破了传统跌倒安全方法的碎片化与泛化瓶颈，证明了借助对齐的人类先验与联合感知-运动表征可实现高效、可迁移的跌倒恢复能力。

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/

</details>


### [173] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种完全去中心化的范围辅助定位与编队控制方法，结合机载里程计和机器人间距离测量进行相对位姿估计，并将编队控制建模为考虑状态估计不确定性的因子图推理问题，实现了分米级精度的定位与控制。


<details>
  <summary>Details</summary>
Motivation: 集中式方法扩展性差，且全局参考的外部定位系统（如GPS）在某些环境中不可用，亟需一种可扩展、无需外部基础设施的分布式协同定位与控制方案。

Method: 采用块坐标下降法实现无需严格机器人间协调的去中心化定位；将形成控制建模为考虑状态估计不确定性的因子图推理问题，并设计高效求解算法。

Result: 所提方法完全去中心化、无需专用轨迹维持编队，在室内外多种真实实验中实现了分米级的定位与编队控制精度。

Conclusion: 该方法有效解决了多机器人系统在无全局定位条件下的协同定位与形成控制难题，兼具鲁棒性、实用性与高精度。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [174] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种通过优化传感器采样率和噪声协方差来保证移动机器人轨迹估计精度的新方法，将问题建模为半定规划并进行了仿真与实物实验验证。


<details>
  <summary>Details</summary>
Motivation: 高精度传感器和高采样率虽能提升轨迹估计精度，但受限于成本与资源约束，需在精度需求下反向设计可行的传感器参数（如采样率或噪声协方差）。

Method: 将传感器调度（采样率）和传感器噪声协方差的联合设计问题建模为半定规划（SDP），利用现成求解器求解；支持两种设定：固定协方差求最小采样率，或固定采样率求最大允许协方差。

Result: 在仿真和真实实验中验证了所计算的传感器参数可达到目标估计精度，并能识别出在给定系统与传感器条件下无法实现的精度要求。

Conclusion: 该方法为资源受限下的感知-估计协同设计提供了可计算、可验证的理论框架，兼具实用性与理论严谨性。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [175] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种基于模板引导最优枢轴扫描的自主超声工作流，以提高肾脏成像效率和覆盖度，减少探头 footprint，并在仿真和活体实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统手动超声检查存在操作者依赖性强、缺乏三维定位信息及易致职业性肌肉骨骼疾病等问题；现有机器人超声系统虽能实现标准化三维采集，但无法确定最优成像窗口，导致扫描盲目、声影干扰和器官覆盖不全。

Method: 提出一种自主工作流：先进行探索性成像获取肾脏部分观测；再将数据配准至肾脏模板以估计器官位姿；最后在固定点执行沿肾脏长轴对齐的枢轴扫描，最小化探头平移。

Result: 仿真表明60%探索比例在定位精度与扫描效率间取得最佳平衡；活体实验显示肾脏定位精度达7.36 mm和13.84度；相比基线方法，探头足迹缩短约75 mm。

Conclusion: 利用解剖模板引导探头最优对齐可显著提升机器人超声肾脏成像的空间效率与覆盖完整性，验证了该方法的可行性与优势。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [176] [Learning to unfold cloth: Scaling up world models to deformable object manipulation](https://arxiv.org/abs/2602.16675)
*Jack Rome,Stephen James,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了一种基于改进DreamerV2强化学习架构的空中布料操作方法，通过引入表面法向量输入、修改重放缓冲区和数据增强策略，增强了世界模型对布料物理复杂性的建模能力，并在仿真和真实机器人零样本部署中验证了其对多种布料类型空中展开任务的良好泛化性能。


<details>
  <summary>Details</summary>
Motivation: 布料作为典型可变形物体，其复杂物理特性使操作任务极具挑战；需设计能泛化到不同形状、尺寸、折叠与褶皱模式及外观变化的通用操作策略。

Method: 基于DreamerV2强化学习架构，引入表面法向量作为输入，并修改重放缓冲区与数据增强流程，以增强世界模型对布料物理特性的表征能力。

Result: 在仿真和真实机器人零样本部署中均成功实现了多种布料类型的空中展开任务，验证了所提方法的强泛化能力。

Conclusion: 改进的世界模型（含表面法向量、重放缓冲与数据增强优化）可有效提升机器人对复杂可变形物体（如布料）的操作泛化性能。

Abstract: Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.

</details>


### [177] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: 本文提出HERO新范式，结合大视觉模型的泛化能力与仿真训练的控制性能，通过残差感知的末端执行器跟踪策略，将跟踪误差降低3.2倍，实现人形机器人在真实复杂环境中对日常物体的通用视觉-运动操作。


<details>
  <summary>Details</summary>
Motivation: 现有基于真实世界模仿学习的方法因难以收集大规模数据而泛化能力有限，亟需一种能兼顾视觉理解通用性与精确末端控制的新范式。

Method: 提出HERO框架：1）设计残差感知的末端执行器跟踪策略，融合逆运动学、学习型前向动力学神经模型、目标调整与重规划；2）模块化系统中用开放词汇大视觉模型处理视觉输入，仿真训练提升控制性能。

Result: 末端执行器跟踪误差降低3.2倍；系统在办公室、咖啡馆等多样真实场景中成功操作杯子、苹果、玩具等物体，工作台高度范围43–92cm；仿真与实物实验验证了模块化与端到端有效性。

Conclusion: HERO实现了视觉理解与运动控制的协同增强，为人形机器人在日常环境中的通用物体交互提供了可扩展、可部署的新路径。

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [178] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: 本文提出EgoScale框架，利用超大规模（20854小时）的自我视角人类动作视频数据训练视觉-语言-动作（VLA）模型，发现人类数据规模与验证损失之间存在对数线性缩放规律，并证明该损失可预测真实机器人性能；通过‘大规模人类预训练+轻量级人机对齐中训练’的两阶段迁移策略，在仅需少量机器人监督下实现了高自由度灵巧操作和一次性任务适应，显著提升成功率并具备跨机器人本体泛化能力。


<details>
  <summary>Details</summary>
Motivation: 如何有效利用人类行为这一可扩展数据源来实现灵巧操作仍不明确，尤其在大规模人类数据能否支持细粒度、高自由度灵巧操作方面缺乏验证。

Method: 提出EgoScale框架：1）基于超大规模（>20,854小时）动作标注的自我视角人类视频训练Vision Language Action (VLA)模型；2）发现人类数据规模与验证损失的log-linear scaling law；3）采用两阶段迁移策略——大规模人类预训练 + 轻量级对齐的人机中训练。

Result: 最终策略使22自由度灵巧手平均成功率提升54%（相比无预训练基线），且能有效迁移到低自由度机械手上，验证了大规模人类运动数据作为可复用、本体无关运动先验的有效性。

Conclusion: 大规模人类动作数据是可预测、可扩展的灵巧操作监督信号源；EgoScale框架通过数据规模与结构化迁移策略，实现了高效、泛化性强的人到机器人灵巧操作迁移。

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [179] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 本文提出了一种参数化的标准手部表示方法，统一多种灵巧手结构，支持跨形态的零样本策略迁移。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧操作策略通常依赖固定手部设计，难以泛化到具有不同运动学和结构布局的新手部形态。

Method: 构建统一的参数空间与标准URDF格式，结合VAE学习结构化潜在流形，并开发基于该表示的条件抓取策略。

Result: 在仿真与真实世界任务中验证了框架有效性，如对未见过的3指LEAP Hand实现81.9%零样本抓取成功率。

Conclusion: 该框架统一了表征空间与动作空间，为面向通用灵巧操作的跨手部学习提供了可扩展基础。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [180] [FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation](https://arxiv.org/abs/2602.16034)
*Xinrui He,Ting-Wei Li,Tianxin Wei,Xuying Ning,Xinyu He,Wenxuan Bao,Hanghang Tong,Jingrui He*

Main category: cs.IR

TL;DR: 本文提出FeDecider框架，解决大语言模型（LLM）在联邦跨域推荐（Federated CDR）中因本地适配器过拟合和隐式表征导致的跨域相似性难衡量问题；通过解耦低秩更新的方向分量与个性化加权聚合，提升隐私保护下的跨域协同推荐性能。


<details>
  <summary>Details</summary>
Motivation: 将LLM引入联邦跨域推荐面临两大挑战：一是域特异性本地适配器易过拟合，参数更新幅值差异导致聚合偏差；二是LLM隐式编码知识，难以像传统推荐模型那样显式、可比地建模用户/物品表征，从而难以度量异构域间的相似性。

Method: 提出FeDecider框架：1）解耦各客户端低秩更新，仅共享方向分量以抑制尺度相关噪声；2）各客户端学习个性化权重，实现数据感知的跨域更新融合。

Result: 在多个异构数据集上的大量实验验证了FeDecider在联邦跨域推荐任务中的有效性，显著优于基线方法。

Conclusion: FeDecider通过方向性参数共享与个性化加权聚合，有效缓解了LLM在联邦跨域场景下的过拟合与跨域表征对齐难题，为隐私保护下的大模型跨域协同推荐提供了可行路径。

Abstract: Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider.

</details>


### [181] [Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System](https://arxiv.org/abs/2602.16124)
*Jiang Zhang,Yubo Wang,Wei Chang,Lu Han,Xingying Cheng,Feng Zhang,Min Li,Songhao Jiang,Wei Zheng,Harry Tran,Zhen Wang,Lei Chen,Yueming Wang,Benyu Zhang,Xiangjun Fan,Bi Xue,Qifan Wang*

Main category: cs.IR

TL;DR: 本文提出了一种名为MultiFaceted Learnable Index (MFLI)的新型可学习索引方法，统一学习多面项嵌入与索引结构，实现实时、免ANN搜索的大规模推荐检索。


<details>
  <summary>Details</summary>
Motivation: 现有ANN检索存在两方面问题：一是嵌入学习与索引构建分离，导致检索质量次优（尤其对冷启动物品）；二是每次请求仍需执行ANN搜索，工业级场景下计算开销大。

Method: 提出MFLI框架：通过残差量化构建多面分层码本，并与物品嵌入联合训练；设计支持实时更新的高效多面索引结构；服务阶段直接使用学习到的分层索引定位相关物品，完全规避ANN搜索。

Result: 在数十亿用户真实数据上实验表明，MFLI相比SOTA方法：参与度任务召回率提升最高达11.8%，冷内容分发提升达57.29%，语义相关性提升13.5%；线上部署验证了更高的用户参与度、更低的流行度偏差和更高的服务效率。

Conclusion: MFLI实现了嵌入与索引的端到端协同学习，解决了传统ANN检索中离线索引滞后与在线计算昂贵的根本矛盾，为大规模实时推荐系统提供了一种更高效、更精准的检索范式。

Abstract: Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\%, cold-content delivery by up to 57.29\%, and semantic relevance by 13.5\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.

</details>


### [182] [Retrieval Collapses When AI Pollutes the Web](https://arxiv.org/abs/2602.16136)
*Hongyeon Yu,Dongchan Kim,Young-Bum Kim*

Main category: cs.IR

TL;DR: 本文提出了'Retrieval Collapse'概念，描述了AI生成内容泛滥导致检索系统质量下降的两阶段过程，并通过实验分析了SEO式和对抗式污染对检索效果的影响。


<details>
  <summary>Details</summary>
Motivation: AI生成内容在Web上迅速增多，对信息检索构成结构性风险，特别是影响搜索引擎和RAG系统对LLM生成证据的依赖。

Method: 通过控制实验，分别测试高质量SEO式内容和对抗式内容对检索系统的影响，评估不同检索器（如BM25和LLM-based rankers）在污染环境下的表现。

Result: 在SEO污染下，67%的内容污染导致超80%的曝光污染，答案准确率稳定但依赖合成来源；在对抗污染下，BM25暴露约19%有害内容，而LLM排序器展现出更强的抑制能力。

Conclusion: 检索管道可能悄然转向合成证据，需制定检索感知策略以防止Web基础系统陷入质量持续下降的自强化循环。

Abstract: The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval pipeline. We analyzed this dynamic through controlled experiments involving both high-quality SEO-style content and adversarially crafted content. In the SEO scenario, a 67\% pool contamination led to over 80\% exposure contamination, creating a homogenized yet deceptively healthy state where answer accuracy remains stable despite the reliance on synthetic sources. Conversely, under adversarial contamination, baselines like BM25 exposed $\sim$19\% of harmful content, whereas LLM-based rankers demonstrated stronger suppression capabilities. These findings highlight the risk of retrieval pipelines quietly shifting toward synthetic evidence and the need for retrieval-aware strategies to prevent a self-reinforcing cycle of quality decline in Web-grounded systems.

</details>


### [183] [MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking](https://arxiv.org/abs/2602.16299)
*Mathias Vast,Victor Morand,Basile van Cooten,Laure Soulier,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: 本文提出MICE（Minimal Interaction Cross-Encoders），通过精简交叉编码器中冗余或有害的交互，构建一种新型轻量级late-interaction架构，在显著降低推理延迟（4倍）的同时，保持接近标准交叉编码器的域内检索效果，并在跨域场景下展现出更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 交叉编码器虽在排序效果上领先，但推理开销大，难以用于首阶段检索或重排序；现有加速方法（如稀疏注意力）与提升首阶段效果的方法（如late-interaction模型）彼此割裂，缺乏融合视角。

Method: 基于对交叉编码器内部机制的深入分析，系统性移除其中 detrimental 或 unnecessary 的交互，推导出一种类 late-interaction 的新型轻量架构 MICE。

Result: MICE 在 ID 和 OOD 数据集上均表现优异：推理延迟降低 4 倍，性能媲美 ColBERT 等 late-interaction 模型，ID 效果接近标准交叉编码器，OOD 泛化能力更优。

Conclusion: MICE 成功弥合了交叉编码器高效推理与 late-interaction 模型低开销之间的鸿沟，为信息检索提供了一种兼具效果、效率与泛化能力的新范式。

Abstract: Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD.

</details>


### [184] [The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems](https://arxiv.org/abs/2602.16315)
*Gabriele Barlacchi,Margherita Lalli,Emanuele Ferragina,Fosca Giannotti,Dino Pedreschi,Luca Pappalardo*

Main category: cs.IR

TL;DR: 本文提出了一种更现实的推荐系统反馈循环模型，考虑隐式反馈、周期性重训练、推荐采纳概率及系统异质性，并在零售与音乐流媒体数据上验证，发现个体消费多样性可能随推荐采纳率提高而增加，但群体需求往往加剧流行度集中；静态评估中观察到的个体多样性提升是虚假的，长期来看其实际持续下降。


<details>
  <summary>Details</summary>
Motivation: 现有模拟研究对推荐系统反馈循环的假设不现实，导致对其系统性影响理解不足。

Method: 提出一个能捕捉隐式反馈、周期性重训练、概率化推荐采纳和异质推荐系统的反馈循环模型，并在在线零售和音乐流媒体数据上进行实证分析。

Result: 提高推荐采纳率可能导致个体消费逐步多样化，但群体需求重新分布常加剧流行度集中；固定采纳率下，随时间推移个体多样性持续下降。

Conclusion: 需超越静态评估，显式建模反馈循环动态以设计更合理的推荐系统。

Abstract: Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.

</details>


### [185] [Variable-Length Semantic IDs for Recommender Systems](https://arxiv.org/abs/2602.16375)
*Kirill Khrylchenko*

Main category: cs.IR

TL;DR: 本文提出了一种用于推荐系统的可变长度语义标识符（semantic IDs）方法，通过离散变分自编码器与Gumbel-Softmax重参数化，在概率框架下学习自适应长度的物品表示，克服了固定长度语义ID的低效性和训练不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有语义标识符采用固定长度，无法适配真实商品目录中流行项与长尾项信息需求差异，且与自然语言中高频概念描述更短的规律不符；同时，新兴通信研究中的可变长度消息机制尚未被系统引入推荐系统。

Method: 提出基于离散变分自编码器（discrete VAE）和Gumbel-Softmax重参数化的模型，使语义ID长度可自适应学习，避免REINFORCE训练不稳定性和固定长度约束。

Result: 实现了更高效、更符合自然语言规律的语义ID生成，在大基数物品空间中提升了生成式推荐模型的训练可行性与表达能力。

Conclusion: 将新兴通信中的可变长度协议思想引入推荐系统是可行且有效的，所提方法为生成式推荐中的语义ID设计提供了新范式。

Abstract: Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem.
  However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems.
  In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.

</details>


### [186] [From Latent to Observable Position-Based Click Models in Carousel Interfaces](https://arxiv.org/abs/2602.16541)
*Santiago de Leon-Martinez,Robert Moro,Branislav Kveton,Maria Bielikova*

Main category: cs.IR

TL;DR: 本文研究了适用于轮播界面的位置点击模型，提出了三种新型位置点击模型，包括首个无需潜在变量且结合眼动追踪数据的观察到的检查位置基础模型（OEPBM），并通过实验表明基于梯度的优化方法效果更佳，但仅靠点击数据建模存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有点击模型主要针对单一排序列表设计，而现代推荐系统越来越多地采用轮播等复杂界面，需要适配的新模型。

Method: 提出三种针对轮播界面的位置点击模型，其中OEPBM首次不使用潜在变量并融合眼动追踪得到的观察检查信号；实现通用框架，支持多种优化技术，并对比梯度法与EM、MLE等经典方法。

Result: 梯度优化持续获得更高点击似然；OEPBM在点击预测和检查模式拟合用户行为方面表现最优；但点击拟合好不等于检查/浏览建模真实，揭示纯点击模型在复杂界面上的根本局限。

Conclusion: 纯点击数据不足以准确建模轮播界面中的用户检查与浏览行为，需引入更多行为信号来设计更合理的点击模型。

Abstract: Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors.
  In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation.
  Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems.

</details>


### [187] [Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models](https://arxiv.org/abs/2602.16587)
*Luankang Zhang,Yonghao Huang,Hang Lv,Mingjia Yin,Liangyue Li,Zulong Chen,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 本文提出了一种无需训练的推理时子空间对齐框架，以解决链式思维（CoT）推理在语义ID推荐基础模型中导致性能下降的问题，通过压缩推理链和偏差减除对比解码来缓解文本漂移，从而在不牺牲ID基础准确性的情况下提升推理效果。


<details>
  <summary>Details</summary>
Motivation: 链式思维（CoT）推理集成到语义ID推荐基础模型（如OpenOneRec）中反而会降低推荐性能，其根本原因在于通用子空间中的文本惯性——冗长的推理主导推理过程，使模型忽视关键的语义ID。

Method: 提出一种无需训练的推理时子空间对齐框架，包括推理链压缩与偏差减除的对比解码，以缓解无依据的文本漂移。

Result: 实验表明该方法能有效校准推理过程，使基础模型在利用推理能力的同时保持ID基础的准确性。

Conclusion: 推理时子空间对齐可克服CoT在ID推荐中引发的文本惯性问题，实现推理能力与ID语义准确性的协同提升。

Abstract: Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [188] [Evaluating Collective Behaviour of Hundreds of LLM Agents](https://arxiv.org/abs/2602.16662)
*Richard Willis,Jianing Zhao,Yali Du,Joel Z. Leibo*

Main category: cs.MA

TL;DR: 本文提出了一种评估LLM自主代理在社会困境中集体行为的新框架，发现较新模型在个体利益优先时反而导致更差的社会结果，并通过文化演化模拟揭示了向不良社会均衡收敛的风险。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型（LLM）的自主代理在社会中日益部署，理解其在社会困境中的集体行为变得至关重要。

Method: 构建了一个评估框架，使LLM生成可解释、可检查的算法策略，并支持数百代理的大规模群体仿真；结合文化演化模型模拟用户对代理的选择过程。

Result: 较新LLM倾向于产生更差的社会结果；当合作收益降低或人口规模增大时，系统易收敛至不良社会均衡。

Conclusion: LLM代理的集体行为存在潜在社会风险，需在部署前通过可解释策略评估与大规模仿真进行审慎检验；作者开源了评估套件以支持开发者自查。

Abstract: As autonomous agents powered by LLM are increasingly deployed in society, understanding their collective behaviour in social dilemmas becomes critical. We introduce an evaluation framework where LLMs generate strategies encoded as algorithms, enabling inspection prior to deployment and scaling to populations of hundreds of agents -- substantially larger than in previous work. We find that more recent models tend to produce worse societal outcomes compared to older models when agents prioritise individual gain over collective benefits. Using cultural evolution to model user selection of agents, our simulations reveal a significant risk of convergence to poor societal equilibria, particularly when the relative benefit of cooperation diminishes and population sizes increase. We release our code as an evaluation suite for developers to assess the emergent collective behaviour of their models.

</details>


### [189] [Consensus Based Task Allocation for Angles-Only Local Catalog Maintenance of Satellite Systems](https://arxiv.org/abs/2602.16678)
*Harrison Perone,Christopher W. Hays*

Main category: cs.MA

TL;DR: 本文提出了一种去中心化的任务分配算法，用于多颗通信卫星利用角度测量（有限视场）协同构建本地空间目标目录，显著降低了燃料消耗和目录不确定性。


<details>
  <summary>Details</summary>
Motivation: 地面跟踪难以满足近距离卫星编队对相对状态高精度估计的需求，需利用星载传感器与多星通信提升精度，但面临角度-only、有限视场下的观测调度与协调难题。

Method: 设计了一种去中心化的任务分配算法，支持多星在仅用角度测量且视场受限条件下，自主协调观测任务以更新本地目标目录。

Result: 通过数值仿真验证，该算法在燃料消耗与目录不确定性两个指标上显著优于现有方法构成的Pareto前沿。

Conclusion: 所提去中心化任务分配算法可有效提升多星协同空间态势感知的效率与精度，为未来分布式空间系统提供可行方案。

Abstract: In order for close proximity satellites to safely perform their missions, the relative states of all satellites and pieces of debris must be well understood. This presents a problem for ground based tracking and orbit determination since it may not be practical to achieve the required accuracy. Using space-based sensors allows for more accurate relative state estimates, especially if multiple satellites are allowed to communicate. Of interest to this work is the case where several communicating satellites each need to maintain a local catalog of communicating and non-communicating objects using angles-only limited field of view (FOV) measurements. However, this introduces the problem of efficiently scheduling and coordinating observations among the agents. This paper presents a decentralized task allocation algorithm to address this problem and quantifies its performance in terms of fuel usage and overall catalog uncertainty via numerical simulation. It was found that the new method significantly outperforms the uncertainty-fuel Pareto frontier formed by current approaches.

</details>


### [190] [Fairness Dynamics in Digital Economy Platforms with Biased Ratings](https://arxiv.org/abs/2602.16695)
*J. Martin Smit,Fernando P. Santos*

Main category: cs.MA

TL;DR: 本文研究数字服务平台中基于评分的歧视问题，提出一种进化博弈论模型，探讨平台如何通过调整推荐策略（如按声誉或保护群体特征）来平衡用户体验与公平性，并证明即使缺乏精确的偏见测量，也能改善推荐系统的公平性。


<details>
  <summary>Details</summary>
Motivation: 数字服务平台依赖用户评分建立信任，但这些评分系统可能对边缘化群体产生负面偏见，导致歧视；因此需设计能减少歧视、同时维持服务提供者高质量激励的平台机制。

Method: 构建进化博弈论模型，分析平台在推广高声誉服务提供者与特定受保护群体成员之间的权衡，并评估不同干预策略（如调节搜索结果中人口统计构成）对公平性和用户体验的影响。

Result: 发现用户体验与公平性之间存在根本权衡：优先推广高评分者有利于用户但加剧对边缘化群体的歧视；而调控搜索结果的人口构成是一种高效且对用户体验影响最小的减偏方法；即使缺乏准确的偏见量化数据，也仍可改进忽略保护特征的推荐系统。

Conclusion: 应在依赖评分促进合作行为的系统中主动采用反歧视设计，平台可通过谨慎的推荐策略干预，在不显著牺牲效率的前提下提升公平性。

Abstract: The digital services economy consists of online platforms that facilitate interactions between service providers and consumers. This ecosystem is characterized by short-term, often one-off, transactions between parties that have no prior familiarity. To establish trust among users, platforms employ rating systems which allow users to report on the quality of their previous interactions. However, while arguably crucial for these platforms to function, rating systems can perpetuate negative biases against marginalised groups. This paper investigates how to design platforms around biased reputation systems, reducing discrimination while maintaining incentives for all service providers to offer high quality service for users. We introduce an evolutionary game theoretical model to study how digital platforms can perpetuate or counteract rating-based discrimination. We focus on the platforms' decisions to promote service providers who have high reputations or who belong to a specific protected group. Our results demonstrate a fundamental trade-off between user experience and fairness: promoting highly-rated providers benefits users, but lowers the demand for marginalised providers against which the ratings are biased. Our results also provide evidence that intervening by tuning the demographics of the search results is a highly effective way of reducing unfairness while minimally impacting users. Furthermore, we show that even when precise measurements on the level of rating bias affecting marginalised service providers is unavailable, there is still potential to improve upon a recommender system which ignores protected characteristics. Altogether, our model highlights the benefits of proactive anti-discrimination design in systems where ratings are used to promote cooperative behaviour.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [191] [CADEvolve: Creating Realistic CAD via Program Evolution](https://arxiv.org/abs/2602.16317)
*Maksim Elistratov,Marina Barannikov,Gregory Ivanov,Valentin Khrulkov,Anton Konushin,Andrey Kuznetsov,Dmitrii Zhemchuzhnikov*

Main category: cs.GR

TL;DR: 本文提出CADEvolve，一种基于进化的方法和数据集，通过VLM引导的编辑与验证，从简单原始体逐步生成复杂CAD程序，最终构建包含130万条脚本的大规模高质量CAD数据集，并在多个基准上实现图像到CAD任务的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有公开CAD数据集多为简单草图拉伸序列，缺乏复杂操作、多步组合及设计意图，难以支撑CAD任务的有效微调；而直接使用冻结视觉语言模型（VLM）又因3D表征能力不足导致生成程序简单或无效。

Method: 提出CADEvolve：以简单几何体为起点，结合VLM指导的编辑操作与几何有效性验证，迭代演化生成复杂、可执行的CadQuery参数化建模程序；再经多阶段后处理与数据增强，构建大规模脚本-几何配对数据集。

Result: 生成8k个工业级复杂零件的CadQuery程序，经扩充后得到1.3M条脚本-渲染几何配对数据，覆盖全部CadQuery操作；在Image2CAD任务中，VLM微调后于DeepCAD、Fusion 360和MCB基准上均达SOTA。

Conclusion: CADEvolve有效缓解了CAD领域高质量训练数据稀缺问题，验证了进化式数据构造范式在提升AI驱动CAD能力上的有效性与可扩展性。

Abstract: Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks.

</details>


### [192] [Style-Aware Gloss Control for Generative Non-Photorealistic Rendering](https://arxiv.org/abs/2602.16611)
*Santiago Jimenez-Navarro,Belen Masia,Ana Serrano*

Main category: cs.GR

TL;DR: 本文提出了一种无监督生成模型，用于分析艺术风格与物体光泽（gloss）的表征关系，并构建了一个轻量级适配器，将风格与光泽解耦的潜在空间连接到潜扩散模型，实现对非真实感图像中风格和光泽的精细控制。


<details>
  <summary>Details</summary>
Motivation: 人类能从视觉外观（包括艺术作品）中推断材质特性，其中光泽是关键因素之一；但现有模型尚缺乏对光泽与艺术风格联合表征与解耦的深入研究。

Method: 构建了一个系统变化光泽与艺术风格的画家风格物体数据集；训练无监督生成模型，分析其潜在空间的层次结构与解耦性；设计轻量级适配器，桥接该潜在空间与潜扩散模型，支持可控图像合成。

Result: 发现潜在空间中光泽可被有效解耦于其他外观因素；所提方法在光泽与风格的解耦性与可控性上优于先前模型；实现了非真实感图像中对光泽和风格的细粒度编辑与合成。

Conclusion: 光泽在学习到的潜在表示中具有层级化、可解耦的结构，且可通过适配器机制有效融入生成式建模框架，为材质感知建模与可控艺术风格生成提供了新范式。

Abstract: Humans can infer material characteristics of objects from their visual appearance, and this ability extends to artistic depictions, where similar perceptual strategies guide the interpretation of paintings or drawings. Among the factors that define material appearance, gloss, along with color, is widely regarded as one of the most important, and recent studies indicate that humans can perceive gloss independently of the artistic style used to depict an object. To investigate how gloss and artistic style are represented in learned models, we train an unsupervised generative model on a newly curated dataset of painterly objects designed to systematically vary such factors. Our analysis reveals a hierarchical latent space in which gloss is disentangled from other appearance factors, allowing for a detailed study of how gloss is represented and varies across artistic styles. Building on this representation, we introduce a lightweight adapter that connects our style- and gloss-aware latent space to a latent-diffusion model, enabling the synthesis of non-photorealistic images with fine-grained control of these factors. We compare our approach with previous models and observe improved disentanglement and controllability of the learned factors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [193] [A Koopman-Bayesian Framework for High-Fidelity, Perceptually Optimized Haptic Surgical Simulation](https://arxiv.org/abs/2602.15834)
*Rohit Kaushik,Eva Kaushik*

Main category: cs.LG

TL;DR: 本文提出了一种融合非线性动力学、感知心理物理学与高频触觉渲染的统一框架，用于提升外科手术模拟的真实性。通过Koopman算子将软组织交互提升至增广状态空间实现线性化预测与控制，并基于Weber-Fechner和Stevens定律设计贝叶斯校准模块以适配个体感知阈值。实验表明该系统在多种手术任务中显著降低延迟（4.3ms）、力误差（<2.8%）并提升感知分辨能力（20%），优于传统弹簧-阻尼及能量型渲染方法。


<details>
  <summary>Details</summary>
Motivation: 提升外科手术模拟中触觉反馈的真实感与个体适应性，克服传统方法在非线性组织建模和人类感知一致性方面的局限。

Method: 采用Koopman算子构建软组织交互的增广线性状态空间模型；设计基于Weber-Fechner与Stevens定律的贝叶斯校准模块，动态适配个体力感知阈值；结合高频触觉渲染实现低延迟高保真力反馈。

Result: 平均渲染延迟为4.3 ms，力误差低于2.8%，感知分辨能力提升20%；MANOVA与回归分析证实其性能显著优于传统弹簧-阻尼及能量型渲染方法。

Conclusion: 该统一框架有效提升了手术模拟的触觉真实感与个体化水平，有望推动外科训练与VR医学教育发展，并为闭环神经反馈触觉接口奠定基础。

Abstract: We introduce a unified framework that combines nonlinear dynamics, perceptual psychophysics and high frequency haptic rendering to enhance realism in surgical simulation. The interaction of the surgical device with soft tissue is elevated to an augmented state space with a Koopman operator formulation, allowing linear prediction and control of the dynamics that are nonlinear by nature. To make the rendered forces consistent with human perceptual limits, we put forward a Bayesian calibration module based on WeberFechner and Stevens scaling laws, which progressively shape force signals relative to each individual's discrimination thresholds. For various simulated surgical tasks such as palpation, incision, and bone milling, the proposed system attains an average rendering latency of 4.3 ms, a force error of less than 2.8% and a 20% improvement in perceptual discrimination. Multivariate statistical analyses (MANOVA and regression) reveal that the system's performance is significantly better than that of conventional spring-damper and energy, based rendering methods. We end by discussing the potential impact on surgical training and VR, based medical education, as well as sketching future work toward closed, loop neural feedback in haptic interfaces.

</details>


### [194] [Memes-as-Replies: Can Models Select Humorous Manga Panel Responses?](https://arxiv.org/abs/2602.15842)
*Ryosuke Kohita,Seiichiro Yoshioka*

Main category: cs.LG

TL;DR: 本文提出了Meme Reply Selection任务，并构建了MaMe-Re基准数据集，旨在研究如何在社交对话中选择具有语境幽默感的表情包回复。研究发现大语言模型虽能捕捉部分社会线索，但在利用视觉信息和区分细微幽默差异方面仍存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 计算研究多关注表情包的内在属性，而其在对话中动态、语境化地制造幽默的使用方式尚未被充分研究，存在研究空白。

Method: 提出Meme Reply Selection任务，构建包含10万对人工标注（共50万条标注）的日语漫画面板与社交媒体帖子的MaMe-Re基准数据集，并对大语言模型在该任务上的表现进行系统分析。

Result: （1）LLMs初步展现出理解夸张等复杂社会线索的能力；（2）加入视觉信息未提升性能，暴露视觉理解与语境幽默应用之间的鸿沟；（3）LLMs在控制环境下可匹配人类判断，但难以区分语义相近选项间的细微幽默差异。

Conclusion: 当前模型在选择语境幽默回复方面仍面临重大挑战，需进一步研究融合多模态信息与社会语用建模的方法。

Abstract: Memes are a popular element of modern web communication, used not only as static artifacts but also as interactive replies within conversations. While computational research has focused on analyzing the intrinsic properties of memes, the dynamic and contextual use of memes to create humor remains an understudied area of web science. To address this gap, we introduce the Meme Reply Selection task and present MaMe-Re (Manga Meme Reply Benchmark), a benchmark of 100,000 human-annotated pairs (500,000 total annotations from 2,325 unique annotators) consisting of openly licensed Japanese manga panels and social media posts. Our analysis reveals three key insights: (1) large language models (LLMs) show preliminary evidence of capturing complex social cues such as exaggeration, moving beyond surface-level semantic matching; (2) the inclusion of visual information does not improve performance, revealing a gap between understanding visual content and effectively using it for contextual humor; (3) while LLMs can match human judgments in controlled settings, they struggle to distinguish subtle differences in wit among semantically similar candidates. These findings suggest that selecting contextually humorous replies remains an open challenge for current models.

</details>


### [195] [Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems](https://arxiv.org/abs/2602.15855)
*Barak Or*

Main category: cs.LG

TL;DR: 本文从卡尔曼滤波启发的视角研究混合推理系统的运行时稳定性，提出‘认知漂移’概念及基于创新信号统计的稳定性监测与恢复框架，在多步工具增强推理任务中验证了其提前检测不稳定性和有限时间内恢复稳定行为的能力。


<details>
  <summary>Details</summary>
Motivation: 混合推理系统在部分可观测和持续证据不匹配下的运行时行为尚不清楚，实际故障常表现为内部推理动态的渐进式发散，而非孤立预测错误。

Method: 将推理建模为受内部创新信号驱动的随机推断过程，定义认知漂移为可测量的运行时现象；提出以可检测性、有界发散性和可恢复性为标准的稳定性定义；构建基于创新统计监测、不稳定检测与恢复感知控制的运行时稳定性框架。

Result: 在多步工具增强推理任务上，该框架能可靠地在任务失败前检测到不稳定性，并在可行时于有限时间内重建有界的内部行为。

Conclusion: 运行时稳定性是不确定性下可靠推理所必需的系统级要求，需独立于任务正确性进行建模与保障。

Abstract: Hybrid reasoning systems that combine learned components with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime behavior under partial observability and sustained evidence mismatch remains poorly understood. In practice, failures often arise as gradual divergence of internal reasoning dynamics rather than as isolated prediction errors. This work studies runtime stability in hybrid reasoning systems from a Kalman-inspired perspective. We model reasoning as a stochastic inference process driven by an internal innovation signal and introduce cognitive drift as a measurable runtime phenomenon. Stability is defined in terms of detectability, bounded divergence, and recoverability rather than task-level correctness. We propose a runtime stability framework that monitors innovation statistics, detects emerging instability, and triggers recovery-aware control mechanisms. Experiments on multi-step, tool-augmented reasoning tasks demonstrate reliable instability detection prior to task failure and show that recovery, when feasible, re-establishes bounded internal behavior within finite time. These results emphasize runtime stability as a system-level requirement for reliable reasoning under uncertainty.

</details>


### [196] [Genetic Generalized Additive Models](https://arxiv.org/abs/2602.15877)
*Kaaustaaub Shankar,Kelly Cohen*

Main category: cs.LG

TL;DR: 本文提出使用多目标遗传算法NSGA-II自动优化广义可加模型（GAMs），在预测误差（RMSE）与复杂度惩罚（兼顾稀疏性、平滑性和不确定性）之间进行权衡，显著提升了模型的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: GAMs虽兼顾准确性和可解释性，但其结构需人工配置，过程繁琐且易次优。

Method: 采用多目标遗传算法NSGA-II联合优化GAMs，目标函数包括预测误差（RMSE）和一个综合反映稀疏性、平滑性与不确定性的复杂度惩罚项。

Result: 在California Housing数据集上，优化后的GAMs相比基线LinearGAMs，在精度上更优，或以显著更低的复杂度达到同等性能；所得模型更简单、更平滑、置信区间更窄。

Conclusion: 该框架为自动化构建高精度、高透明度的可解释模型提供了通用有效的方法。

Abstract: Generalized Additive Models (GAMs) balance predictive accuracy and interpretability, but manually configuring their structure is challenging. We propose using the multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly minimizing prediction error (RMSE) and a Complexity Penalty that captures sparsity, smoothness, and uncertainty. Experiments on the California Housing dataset show that NSGA-II discovers GAMs that outperform baseline LinearGAMs in accuracy or match performance with substantially lower complexity. The resulting models are simpler, smoother, and exhibit narrower confidence intervals, enhancing interpretability. This framework provides a general approach for automated optimization of transparent, high-performing models. The code can be found at https://github.com/KaaustaaubShankar/GeneticAdditiveModels.

</details>


### [197] [IT-OSE: Exploring Optimal Sample Size for Industrial Data Augmentation](https://arxiv.org/abs/2602.15878)
*Mingchun Sun,Rongqiang Zhao,Zhennan Huang,Songyu Ding,Jie Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论的最优样本量估计方法（IT-OSE），用于工业场景中的数据增强，同时设计了ICD评估指标，并在分类与回归任务中验证了其有效性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 工业场景中数据增强虽有效，但缺乏理论支撑的最优样本量（OSS）估计方法及评估指标，且OSS与影响因素的关系缺乏可解释性分析。

Method: 提出信息论最优样本量估计（IT-OSE）方法，构建区间覆盖与偏差（ICD）评分，并理论推导OSS与主导因素的关系。

Result: 相比经验估计，分类准确率平均提升4.38%，回归MAPE平均降低18.80%，ICD偏差平均降低49.30%；相比穷举搜索，计算与数据成本分别降低83.97%和93.46%。

Conclusion: IT-OSE提供了可靠、可解释、高效且泛化性强的OSS估计方案，显著提升了工业数据增强的实用性与稳定性。

Abstract: In industrial scenarios, data augmentation is an effective approach to improve model performance. However, its benefits are not unidirectionally beneficial. There is no theoretical research or established estimation for the optimal sample size (OSS) in augmentation, nor is there an established metric to evaluate the accuracy of OSS or its deviation from the ground truth. To address these issues, we propose an information-theoretic optimal sample size estimation (IT-OSE) to provide reliable OSS estimation for industrial data augmentation. An interval coverage and deviation (ICD) score is proposed to evaluate the estimated OSS intuitively. The relationship between OSS and dominant factors is theoretically analyzed and formulated, thereby enhancing the interpretability. Experiments show that, compared to empirical estimation, the IT-OSE increases accuracy in classification tasks across baseline models by an average of 4.38%, and reduces MAPE in regression tasks across baseline models by an average of 18.80%. The improvements in downstream model performance are more stable. ICDdev in the ICD score is also reduced by an average of 49.30%. The determinism of OSS is enhanced. Compared to exhaustive search, the IT-OSE achieves the same OSS while reducing computational and data costs by an average of 83.97% and 93.46%. Furthermore, practicality experiments demonstrate that the IT-OSE exhibits generality across representative sensor-based industrial scenarios.

</details>


### [198] [Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16196)
*Emile Anand,Richard Hoffmann,Sarah Liaw,Adam Wierman*

Main category: cs.LG

TL;DR: 本文提出了一种名为GMFS的图灵均场子采样框架，用于解决异质智能体交互下的大规模多智能体强化学习问题，通过按交互强度子采样κ个智能体，实现了多项式样本复杂度和O(1/√κ)的最优性差距。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中联合状态-动作空间随智能体数量指数增长，均场方法虽可缓解但假设智能体交互同质，而图灵框架虽能刻画异质性却计算昂贵。

Method: 提出GMFS框架，基于图灵加权均场，通过按交互强度子采样κ个智能体进行策略学习，并理论分析其样本复杂度与最优性差距。

Result: 理论证明GMFS具有poly(κ)的样本复杂度和O(1/√κ)的最优性差距；在机器人协同任务的数值实验中验证了其接近最优性能。

Conclusion: GMFS为异质交互的大规模多智能体协作提供了一种高效、可扩展且理论保证的解决方案。

Abstract: Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\texttt{GMFS}$, a $\textbf{G}$raphon $\textbf{M}$ean-$\textbf{F}$ield $\textbf{S}$ubsampling framework for scalable cooperative MARL with heterogeneous agent interactions. By subsampling $κ$ agents according to interaction strength, we approximate the graphon-weighted mean-field and learn a policy with sample complexity $\mathrm{poly}(κ)$ and optimality gap $O(1/\sqrtκ)$. We verify our theory with numerical simulations in robotic coordination, showing that $\texttt{GMFS}$ achieves near-optimal performance.

</details>


### [199] [BamaER: A Behavior-Aware Memory-Augmented Model for Exercise Recommendation](https://arxiv.org/abs/2602.15879)
*Qing Yang,Yuhao Jiang,Rui Wang,Jipeng Guo,Yejiang Wang,Xinghe Cheng,Zezheng Wu,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: 本文提出BamaER框架，通过行为感知和记忆增强技术提升习题推荐效果，解决了现有方法忽略学生交互行为和长期依赖建模不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有习题推荐方法仅将学生学习表示为习题序列，忽略了丰富的交互行为信息，且固定长度序列分割限制了早期学习经验的利用，导致学习进展估计偏差和知识掌握评估不准。

Method: 提出BamaER框架，包含三个模块：(i) 学习进展预测模块，采用三向混合编码捕获异构交互行为；(ii) 记忆增强知识追踪模块，使用动态记忆矩阵联合建模历史与当前知识状态；(iii) 习题筛选模块，将候选选择建模为多样性感知优化问题，并用河马优化算法求解。

Result: 在五个真实教育数据集上的实验表明，BamaER在多项评估指标上持续优于现有最优基线方法。

Conclusion: BamaER通过融合行为感知与记忆增强机制，有效提升了习题推荐的准确性、鲁棒性与覆盖度，为个性化教育推荐提供了新思路。

Abstract: Exercise recommendation focuses on personalized exercise selection conditioned on students' learning history, personal interests, and other individualized characteristics. Despite notable progress, most existing methods represent student learning solely as exercise sequences, overlooking rich behavioral interaction information. This limited representation often leads to biased and unreliable estimates of learning progress. Moreover, fixed-length sequence segmentation limits the incorporation of early learning experiences, thereby hindering the modeling of long-term dependencies and the accurate estimation of knowledge mastery. To address these limitations, we propose BamaER, a Behavior-aware memory-augmented Exercise Recommendation framework that comprises three core modules: (i) the learning progress prediction module that captures heterogeneous student interaction behaviors via a tri-directional hybrid encoding scheme; (ii) the memory-augmented knowledge tracing module that maintains a dynamic memory matrix to jointly model historical and current knowledge states for robust mastery estimation; and (iii) the exercise filtering module that formulates candidate selection as a diversity-aware optimization problem, solved via the Hippopotamus Optimization Algorithm to reduce redundancy and improve recommendation coverage. Experiments on five real-world educational datasets show that BamaER consistently outperforms state-of-the-art baselines across a range of evaluation metrics.

</details>


### [200] [Distributed physics-informed neural networks via domain decomposition for fast flow reconstruction](https://arxiv.org/abs/2602.15883)
*Yixiao Qian,Jiaxu Liu,Zewei Xia,Song Chen,Chao Xu,Shengze Cai*

Main category: cs.LG

TL;DR: 本文提出了一种面向大规模时空域流动重构的分布式物理信息神经网络（PINNs）框架，通过时空域分解、参考锚点归一化与非对称加权策略解决压力不确定性问题，并利用CUDA图与JIT编译优化训练性能，实现了近线性加速与高保真重构。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在大规模时空域流动重构中面临计算瓶颈和优化不稳定问题，亟需可扩展且物理一致的分布式求解方案。

Method: 提出分布式PINNs框架，采用时空域分解；设计参考锚点归一化与解耦的非对称加权策略以消除压力规范自由度；引入CUDA graphs与JIT编译加速高阶物理残差计算。

Result: 在复杂流动基准测试中实现近线性强扩展性与高保真速度/压力场重构，显著提升计算效率与物理一致性。

Conclusion: 该方法为复杂水动力学的可扩展、物理严谨的流动重构与理解提供了新路径。

Abstract: Physics-Informed Neural Networks (PINNs) offer a powerful paradigm for flow reconstruction, seamlessly integrating sparse velocity measurements with the governing Navier-Stokes equations to recover complete velocity and latent pressure fields. However, scaling such models to large spatiotemporal domains is hindered by computational bottlenecks and optimization instabilities. In this work, we propose a robust distributed PINNs framework designed for efficient flow reconstruction via spatiotemporal domain decomposition. A critical challenge in such distributed solvers is pressure indeterminacy, where independent sub-networks drift into inconsistent local pressure baselines. We address this issue through a reference anchor normalization strategy coupled with decoupled asymmetric weighting. By enforcing a unidirectional information flow from designated master ranks where the anchor point lies to neighboring ranks, our approach eliminates gauge freedom and guarantees global pressure uniqueness while preserving temporal continuity. Furthermore, to mitigate the Python interpreter overhead associated with computing high-order physics residuals, we implement a high-performance training pipeline accelerated by CUDA graphs and JIT compilation. Extensive validation on complex flow benchmarks demonstrates that our method achieves near-linear strong scaling and high-fidelity reconstruction, establishing a scalable and physically rigorous pathway for flow reconstruction and understanding of complex hydrodynamics.

</details>


### [201] [Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort](https://arxiv.org/abs/2602.15955)
*Shumeng Chen,Jane E. Huggins,Tianwen Ma*

Main category: cs.LG

TL;DR: 本文提出了一种基于自适应半监督EM-GMM算法的P300 BCI拼写器框架，显著减少校准所需标注数据量，并在多数被试上提升了字符识别准确率和信息传输率。


<details>
  <summary>Details</summary>
Motivation: 传统P300 BCI拼写器需大量标注校准数据构建二元分类器，效率低；亟需一种低校准开销、适用于小样本场景的实用方法。

Method: 提出统一的自适应半监督学习框架：利用少量标注校准数据，结合EM-GMM算法迭代更新二元分类器。

Result: 在15名被试中，9人字符级准确率≥0.7；其中7人新方法优于基准方法；整体提升ITR与BCI实用性。

Conclusion: 该半监督框架为真实场景下标注数据受限的P300 BCI拼写系统提供了高效、实用的解决方案。

Abstract: A P300 ERP-based Brain-Computer Interface (BCI) speller is an assistive communication tool. It searches for the P300 event-related potential (ERP) elicited by target stimuli, distinguishing it from the neural responses to non-target stimuli embedded in electroencephalogram (EEG) signals. Conventional methods require a lengthy calibration procedure to construct the binary classifier, which reduced overall efficiency. Thus, we proposed a unified framework with minimum calibration effort such that, given a small amount of labeled calibration data, we employed an adaptive semi-supervised EM-GMM algorithm to update the binary classifier. We evaluated our method based on character-level prediction accuracy, information transfer rate (ITR), and BCI utility. We applied calibration on training data and reported results on testing data. Our results indicate that, out of 15 participants, 9 participants exceed the minimum character-level accuracy of 0.7 using either on our adaptive method or the benchmark, and 7 out of these 9 participants showed that our adaptive method performed better than the benchmark. The proposed semi-supervised learning framework provides a practical and efficient alternative to improve the overall spelling efficiency in the real-time BCI speller system, particularly in contexts with limited labeled data.

</details>


### [202] [R$^2$Energy: A Large-Scale Benchmark for Robust Renewable Energy Forecasting under Diverse and Extreme Conditions](https://arxiv.org/abs/2602.15961)
*Zhi Sheng,Yuan Yuan,Guozhen Zhang,Yong Li*

Main category: cs.LG

TL;DR: 本文提出了R²Energy，一个用于NWP辅助可再生能源预测的大规模基准数据集，包含来自中国四个省份902个风电和光伏电站的1070万小时级高保真记录，并建立了一种无信息泄露的标准预测范式，通过极端天气标注下的分制评估揭示了模型鲁棒性与复杂度之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 随着极端天气事件频发，现有可再生能源预测模型在波动条件下的鲁棒性不足，亟需能保障电网稳定与运行安全的可靠预测方法。

Method: 构建R²Energy大规模基准数据集；设计无信息泄露、统一接入未来NWP信号的标准预测范式；引入专家标注的极端天气分制评估机制。

Result: 发现平均指标掩盖下的‘鲁棒性差距’，证实极端条件下模型可靠性取决于气象信息融合策略而非网络结构复杂度。

Conclusion: R²Energy为面向电力系统安全关键应用的预测模型评估与开发提供了原理性基础。

Abstract: The rapid expansion of renewable energy, particularly wind and solar power, has made reliable forecasting critical for power system operations. While recent deep learning models have achieved strong average accuracy, the increasing frequency and intensity of climate-driven extreme weather events pose severe threats to grid stability and operational security. Consequently, developing robust forecasting models that can withstand volatile conditions has become a paramount challenge. In this paper, we present R$^2$Energy, a large-scale benchmark for NWP-assisted renewable energy forecasting. It comprises over 10.7 million high-fidelity hourly records from 902 wind and solar stations across four provinces in China, providing the diverse meteorological conditions necessary to capture the wide-ranging variability of renewable generation. We further establish a standardized, leakage-free forecasting paradigm that grants all models identical access to future Numerical Weather Prediction (NWP) signals, enabling fair and reproducible comparison across state-of-the-art representative forecasting architectures. Beyond aggregate accuracy, we incorporate regime-wise evaluation with expert-aligned extreme weather annotations, uncovering a critical ``robustness gap'' typically obscured by average metrics. This gap reveals a stark robustness-complexity trade-off: under extreme conditions, a model's reliability is driven by its meteorological integration strategy rather than its architectural complexity. R$^2$Energy provides a principled foundation for evaluating and developing forecasting models for safety-critical power system applications.

</details>


### [203] [B-DENSE: Branching For Dense Ensemble Network Learning](https://arxiv.org/abs/2602.15971)
*Cherish Puniani,Tushar Kumar,Arnav Bendre,Gaurav Kumar,Shree Singhi*

Main category: cs.LG

TL;DR: 本文提出B-DENSE框架，通过多分支轨迹对齐实现扩散模型知识蒸馏中的密集中间轨迹监督，从而提升生成质量并缓解离散化误差。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽性能优异，但迭代采样导致高推理延迟；现有蒸馏方法因丢弃中间轨迹步骤而造成结构信息损失和显著离散化误差。

Method: 提出B-DENSE框架，修改学生网络架构以输出K倍扩展通道，每组通道对应教师轨迹中一个离散中间时间步，并训练各分支同时映射至教师整个目标时间步序列，实现密集轨迹对齐。

Result: 学生模型从训练初期即可学习有效导航解空间，图像生成质量优于基线蒸馏方法。

Conclusion: 密集中间轨迹对齐能有效缓解蒸馏中的离散化误差，提升生成质量，为高效扩散模型采样提供新思路。

Abstract: Inspired by non-equilibrium thermodynamics, diffusion models have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature results in high inference latency. While recent distillation techniques accelerate sampling, they discard intermediate trajectory steps. This sparse supervision leads to a loss of structural information and introduces significant discretization errors. To mitigate this, we propose B-DENSE, a novel framework that leverages multi-branch trajectory alignment. We modify the student architecture to output $K$-fold expanded channels, where each subset corresponds to a specific branch representing a discrete intermediate step in the teacher's trajectory. By training these branches to simultaneously map to the entire sequence of the teacher's target timesteps, we enforce dense intermediate trajectory alignment. Consequently, the student model learns to navigate the solution space from the earliest stages of training, demonstrating superior image generation quality compared to baseline distillation frameworks.

</details>


### [204] [Neighborhood Stability as a Measure of Nearest Neighbor Searchability](https://arxiv.org/abs/2602.16673)
*Thomas Vecchiato,Sebastian Bruch*

Main category: cs.LG

TL;DR: 本文提出了两种用于评估基于聚类的近似最近邻搜索（ANNS）在给定数据集上适用性的新度量：聚类邻域稳定性度量（clustering-NSM）和点邻域稳定性度量（point-NSM），二者均基于点间最近邻关系而非具体距离，因而适用于多种相似性度量。


<details>
  <summary>Details</summary>
Motivation: 缺乏分析工具来判断基于聚类的ANNS对特定数据集是否适用（即‘可搜索性’），本文旨在填补这一空白。

Method: 提出两个新度量：clustering-NSM（评估聚类质量，预测ANNS精度）和point-NSM（评估数据集本身的可聚类性，预测clustering-NSM）；二者均仅依赖最近邻关系，不依赖具体距离值。

Result: clustering-NSM被证明能有效预测ANNS准确性；point-NSM能有效预测clustering-NSM；两者结合可在仅知数据点的情况下判断该数据集是否适合用基于聚类的ANNS。

Conclusion: 所提度量为评估高维数据在欧氏空间（及其它基于最近邻的距离函数）中基于聚类的ANNS可行性提供了理论基础与实用工具。

Abstract: Clustering-based Approximate Nearest Neighbor Search (ANNS) organizes a set of points into partitions, and searches only a few of them to find the nearest neighbors of a query. Despite its popularity, there are virtually no analytical tools to determine the suitability of clustering-based ANNS for a given dataset -- what we call "searchability." To address that gap, we present two measures for flat clusterings of high-dimensional points in Euclidean space. First is Clustering-Neighborhood Stability Measure (clustering-NSM), an internal measure of clustering quality -- a function of a clustering of a dataset -- that we show to be predictive of ANNS accuracy. The second, Point-Neighborhood Stability Measure (point-NSM), is a measure of clusterability -- a function of the dataset itself -- that is predictive of clustering-NSM. The two together allow us to determine whether a dataset is searchable by clustering-based ANNS given only the data points. Importantly, both are functions of nearest neighbor relationships between points, not distances, making them applicable to various distance functions including inner product.

</details>


### [205] [Fast Online Learning with Gaussian Prior-Driven Hierarchical Unimodal Thompson Sampling](https://arxiv.org/abs/2602.15972)
*Tianchi Zhao,He Liu,Hongyin Shi,Jinliang Li*

Main category: cs.LG

TL;DR: 本文研究了一类具有高斯奖励反馈的多臂老虎机（MAB）问题，其中手臂按簇组织。作者基于Thompson采样算法（TSG），提出了适用于2层层次结构的TSCG算法，并进一步在奖励呈单峰分布时提出UTSCG算法，理论和实验均表明其优于标准TSG。


<details>
  <summary>Details</summary>
Motivation: 高斯分布具有普适性，许多现实问题（如毫米波通信、风险资产投资组合管理）中存在按簇分组的手臂结构，需设计更高效的学习算法。

Method: 提出两种新算法：TSCG（适用于2层层次结构的Thompson采样）和UTSCG（在奖励单峰假设下的改进版），并分别推导其理论后悔上界。

Result: 利用2层结构可降低后悔上界；在单峰假设下，UTSCG进一步降低后悔上界；数值实验验证了所提算法的优越性。

Conclusion: 引入手臂聚类结构与单峰性假设可显著提升Thompson采样在高斯奖励MAB问题中的性能，为相关应用提供了更优理论保障与实用算法。

Abstract: We study a type of Multi-Armed Bandit (MAB) problems in which arms with a Gaussian reward feedback are clustered. Such an arm setting finds applications in many real-world problems, for example, mmWave communications and portfolio management with risky assets, as a result of the universality of the Gaussian distribution. Based on the Thompson Sampling algorithm with Gaussian prior (TSG) algorithm for the selection of the optimal arm, we propose our Thompson Sampling with Clustered arms under Gaussian prior (TSCG) specific to the 2-level hierarchical structure. We prove that by utilizing the 2-level structure, we can achieve a lower regret bound than we do with ordinary TSG. In addition, when the reward is Unimodal, we can reach an even lower bound on the regret by our Unimodal Thompson Sampling algorithm with Clustered Arms under Gaussian prior (UTSCG). Each of our proposed algorithms are accompanied by theoretical evaluation of the upper regret bound, and our numerical experiments confirm the advantage of our proposed algorithms.

</details>


### [206] [Verifier-Constrained Flow Expansion for Discovery Beyond the Data](https://arxiv.org/abs/2602.15984)
*Riccardo De Santi,Kimon Protopapas,Ya-Ping Hsieh,Andreas Krause*

Main category: cs.LG

TL;DR: 本文提出Flow Expander（FE）方法，通过 verifier 约束下的熵最大化优化，扩展预训练流模型的采样分布至数据稀疏但可行的设计空间（如分子空间），提升生成多样性与有效性。


<details>
  <summary>Details</summary>
Motivation: 预训练流/扩散模型受限于有限训练数据，难以覆盖完整可行设计空间，制约科学发现中对新颖有效样本的生成需求。

Method: 引入强/弱 verifier 概念，构建基于概率空间优化的全局与局部流扩展框架；提出可扩展的镜像下降算法 Flow Expander（FE），在加噪状态空间上进行 verifier 约束的熵最大化。

Result: 理论证明 FE 在理想与一般条件下均具收敛性；实验表明 FE 能显著提升分子构象多样性，同时保持 100% 结构有效性。

Conclusion: FE 为利用轻量 verifier 引导流模型跳出数据分布、探索更大有效设计空间提供了可证、可扩展的通用范式。

Abstract: Flow and diffusion models are typically pre-trained on limited available data (e.g., molecular samples), covering only a fraction of the valid design space (e.g., the full molecular space). As a consequence, they tend to generate samples from only a narrow portion of the feasible domain. This is a fundamental limitation for scientific discovery applications, where one typically aims to sample valid designs beyond the available data distribution. To this end, we address the challenge of leveraging access to a verifier (e.g., an atomic bonds checker), to adapt a pre-trained flow model so that its induced density expands beyond regions of high data availability, while preserving samples validity. We introduce formal notions of strong and weak verifiers and propose algorithmic frameworks for global and local flow expansion via probability-space optimization. Then, we present Flow Expander (FE), a scalable mirror descent scheme that provably tackles both problems by verifier-constrained entropy maximization over the flow process noised state space. Next, we provide a thorough theoretical analysis of the proposed method, and state convergence guarantees under both idealized and general assumptions. Ultimately, we empirically evaluate our method on both illustrative, yet visually interpretable settings, and on a molecular design task showcasing the ability of FE to expand a pre-trained flow model increasing conformer diversity while preserving validity.

</details>


### [207] [Anatomy of Capability Emergence: Scale-Invariant Representation Collapse and Top-Down Reorganization in Neural Networks](https://arxiv.org/abs/2602.15997)
*Jayadev Billa*

Main category: cs.LG

TL;DR: 本文通过追踪多种几何度量，揭示了神经网络训练中能力涌现的几何机制：存在尺度不变的表示坍缩现象、自上而下的坍缩传播模式，以及表示几何对能力涌现的先导作用；但该几何信号在自然预训练模型（如Pythia）中不具任务级可迁移性，因此其价值在于阐明涌现的几何解剖结构及其适用边界，而非预测能力。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络训练过程中能力涌现的内在机制仍缺乏清晰的机械解释，尤其是其如何随训练动态演化。

Method: 系统追踪五种几何度量，在五个模型规模（405K–85M参数）、八个算法任务中120+次涌现事件，以及三个Pythia语言模型（160M–2.8B）上进行实证分析。

Result: 发现（1）训练初期普遍存在尺度不变的任务特异性表示坍缩；（2）坍缩呈自上而下跨层传播；（3）表示几何是能力涌现的强前导信号（75–100%），而局部学习系数同步、Hessian度量滞后；几何度量可粗略反映任务难度，但无法精确预测涌现时序；Pythia上全局模式复现，但任务级前导信号消失。

Conclusion: 本文刻画了能力涌现的‘几何解剖结构’及其边界条件——前导几何信号依赖于任务导向的训练对齐，在自然预训练中不成立，因此该框架旨在解释而非预测涌现。

Abstract: Capability emergence during neural network training remains mechanistically opaque. We track five geometric measures across five model scales (405K-85M parameters), 120+ emergence events in eight algorithmic tasks, and three Pythia language models (160M-2.8B). We find: (1) training begins with a universal representation collapse to task-specific floors that are scale-invariant across a 210X parameter range (e.g., modular arithmetic collapses to RANKME ~ 2.0 regardless of model size); (2) collapse propagates top-down through layers (32/32 task X model consistency), contradicting bottom-up feature-building intuition; (3) a geometric hierarchy in which representation geometry leads emergence (75-100% precursor rate for hard tasks), while the local learning coefficient is synchronous (0/24 precursor) and Hessian measures lag. We also delineate prediction limits: geometric measures encode coarse task difficulty but not fine-grained timing (within-class concordance 27%; when task ordering reverses across scales, prediction fails at 26%). On Pythia, global geometric patterns replicate but per-task precursor signals do not -- the precursor relationship requires task-training alignment that naturalistic pre-training does not provide. Our contribution is the geometric anatomy of emergence and its boundary conditions, not a prediction tool.

</details>


### [208] [Geometry-Aware Uncertainty Quantification via Conformal Prediction on Manifolds](https://arxiv.org/abs/2602.16015)
*Marzieh Amiri Shahbazi,Ali Baheri*

Main category: cs.LG

TL;DR: 本文提出了一种自适应测地共形预测框架，用于在黎曼流形（如球面）上实现更均匀的条件覆盖，通过使用测地非一致性分数和交叉验证的难度估计器来校准预测区域。


<details>
  <summary>Details</summary>
Motivation: 现有共形预测方法假设输出空间为欧几里得空间，在响应位于黎曼流形（如球面）时校准效果差，尤其在异方差噪声下表现不佳。

Method: 提出自适应测地共形预测：用测地非一致性分数替代欧氏残差，并用交叉验证的难度估计器进行归一化；生成的预测区域为球面上的测地圆帽，面积位置无关且自适应局部预测难度。

Result: 在强异方差球面合成实验和基于IGRF-14卫星数据的地磁场预测任务中，该方法显著降低条件覆盖变异性，提升最坏情况覆盖率至接近名义水平；而基于坐标系的基线方法因图册畸变浪费大量覆盖面积。

Conclusion: 自适应测地共形预测能有效提升黎曼流形上回归任务的分布无关覆盖质量，尤其适用于具有异方差性和几何结构的实际问题。

Abstract: Conformal prediction provides distribution-free coverage guaranties for regression; yet existing methods assume Euclidean output spaces and produce prediction regions that are poorly calibrated when responses lie on Riemannian manifolds. We propose \emph{adaptive geodesic conformal prediction}, a framework that replaces Euclidean residuals with geodesic nonconformity scores and normalizes them by a cross-validated difficulty estimator to handle heteroscedastic noise. The resulting prediction regions, geodesic caps on the sphere, have position-independent area and adapt their size to local prediction difficulty, yielding substantially more uniform conditional coverage than non-adaptive alternatives. In a synthetic sphere experiment with strong heteroscedasticity and a real-world geomagnetic field forecasting task derived from IGRF-14 satellite data, the adaptive method markedly reduces conditional coverage variability and raises worst-case coverage much closer to the nominal level, while coordinate-based baselines waste a large fraction of coverage area due to chart distortion.

</details>


### [209] [MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching](https://arxiv.org/abs/2602.16020)
*Cheng Zeng,Harry W. Sullivan,Thomas Egg,Maya M. Martirossyan,Philipp Höllmer,Jirui Jin,Richard G. Hennig,Adrian Roitberg,Stefano Martiniani,Ellad B. Tadmor,Mingjie Liu*

Main category: cs.LG

TL;DR: 本文提出MolCrystalFlow，一种基于流的生成模型，用于分子晶体结构预测，通过将分子视为刚体并联合学习晶格矩阵、分子取向和质心位置来解耦分子内复杂性与分子间堆积。


<details>
  <summary>Details</summary>
Motivation: 分子晶体结构预测是计算化学中的重大挑战，由于组成分子尺寸大及分子内/间相互作用复杂，现有生成模型难以扩展到全周期性分子晶体。

Method: 提出MolCrystalFlow流式生成模型，将分子嵌入为刚体，联合学习晶格矩阵、分子取向和质心位置；质心和取向在原生黎曼流形上表示，支持测地线流构建和保持几何对称性的图神经网络操作。

Result: 在两个开源分子晶体数据集上，MolCrystalFlow在大型周期性晶体生成任务中优于当前最先进生成模型和基于规则的结构生成方法，并可与通用机器学习势能结合加速预测。

Conclusion: MolCrystalFlow为数据驱动的分子晶体生成发现提供了新路径，推动了全周期性分子晶体结构预测的发展。

Abstract: Molecular crystal structure prediction represents a grand challenge in computational chemistry due to large sizes of constituent molecules and complex intra- and intermolecular interactions. While generative modeling has revolutionized structure discovery for molecules, inorganic solids, and metal-organic frameworks, extending such approaches to fully periodic molecular crystals is still elusive. Here, we present MolCrystalFlow, a flow-based generative model for molecular crystal structure prediction. The framework disentangles intramolecular complexity from intermolecular packing by embedding molecules as rigid bodies and jointly learning the lattice matrix, molecular orientations, and centroid positions. Centroids and orientations are represented on their native Riemannian manifolds, allowing geodesic flow construction and graph neural network operations that respects geometric symmetries. We benchmark our model against state-of-the-art generative models for large-size periodic crystals and rule-based structure generation methods on two open-source molecular crystal datasets. We demonstrate an integration of MolCrystalFlow model with universal machine learning potential to accelerate molecular crystal structure prediction, paving the way for data-driven generative discovery of molecular crystals.

</details>


### [210] [AI-CARE: Carbon-Aware Reporting Evaluation Metric for AI Models](https://arxiv.org/abs/2602.16042)
*KC Santosh,Srikanth Baride,Rodrigue Rizk*

Main category: cs.LG

TL;DR: 本文提出AI-CARE工具，用于评估机器学习模型的能耗与碳排放，并引入碳-性能权衡曲线以可视化性能与碳成本间的帕累托前沿，推动多目标、可持续的模型评估范式。


<details>
  <summary>Details</summary>
Motivation: 现有ML基准过度关注准确率等单一性能指标，忽视能源消耗和碳排放，难以满足移动设备、欠发达地区及气候敏感型企业的实际部署需求。

Method: 提出AI-CARE评估工具和碳-性能权衡曲线（Pareto前沿可视化），结合理论分析与典型ML工作负载的实证验证。

Result: 碳感知基准测试会改变模型相对排名，促使更准确且环境友好的架构被优先选择。

Conclusion: 倡导研究社区转向透明、多目标的评估方式，使机器学习发展与全球可持续发展目标保持一致。

Abstract: As machine learning (ML) continues its rapid expansion, the environmental cost of model training and inference has become a critical societal concern. Existing benchmarks overwhelmingly focus on standard performance metrics such as accuracy, BLEU, or mAP, while largely ignoring energy consumption and carbon emissions. This single-objective evaluation paradigm is increasingly misaligned with the practical requirements of large-scale deployment, particularly in energy-constrained environments such as mobile devices, developing regions, and climate-aware enterprises. In this paper, we propose AI-CARE, an evaluation tool for reporting energy consumption, and carbon emissions of ML models. In addition, we introduce the carbon-performance tradeoff curve, an interpretable tool that visualizes the Pareto frontier between performance and carbon cost. We demonstrate, through theoretical analysis and empirical validation on representative ML workloads, that carbon-aware benchmarking changes the relative ranking of models and encourages architectures that are simultaneously accurate and environmentally responsible. Our proposal aims to shift the research community toward transparent, multi-objective evaluation and align ML progress with global sustainability goals. The tool and documentation are available at https://github.com/USD-AI-ResearchLab/ai-care.

</details>


### [211] [MoE-Spec: Expert Budgeting for Efficient Speculative Decoding](https://arxiv.org/abs/2602.16052)
*Bradley McDanel,Steven Li,Sruthikesh Surineni,Harshit Khaitan*

Main category: cs.LG

TL;DR: 本文提出MoE-Spec，一种无需训练的验证时专家预算分配方法，通过在每层固定专家容量限制来解耦推测深度与内存开销，在MoE模型的推测解码中显著提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码在MoE模型上因并行验证导致大量专家被激活，引发内存压力和带宽瓶颈，削弱加速效果。

Method: MoE-Spec在验证阶段动态限制每层激活的专家数量，仅保留对验证贡献最大的专家，舍弃长尾低频专家，从而控制内存与带宽开销。

Result: 在多个模型规模和数据集上，MoE-Spec比当前最优方法EAGLE-3提升10–30%吞吐量，且支持通过收紧专家预算进一步降低延迟。

Conclusion: MoE-Spec是一种高效、灵活、无需训练的MoE模型推测解码优化方法，有效缓解了专家激活带来的硬件瓶颈。

Abstract: Speculative decoding accelerates Large Language Model (LLM) inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts (MoE) models, this parallelism introduces a severe bottleneck: large draft trees activate many unique experts, significantly increasing memory pressure and diminishing speedups from speculative decoding relative to autoregressive decoding. Prior methods reduce speculation depth when MoE verification becomes expensive. We propose MoE-Spec, a training-free verification-time expert budgeting method that decouples speculation depth from memory cost by enforcing a fixed expert capacity limit at each layer, loading only the experts that contribute most to verification and dropping the long tail of rarely used experts that drive bandwidth overhead. Experiments across multiple model scales and datasets show that this method yields 10--30\% higher throughput than state-of-the-art speculative decoding baselines (EAGLE-3) at comparable quality, with flexibility to trade accuracy for further latency reductions through tighter budgets.

</details>


### [212] [Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053)
*Mehrab Beikzadeh,Yasaman Asadollah Salmanpour,Ashima Suvarna,Sriram Sankararaman,Matteo Malgaroli,Majid Sarrafzadeh,Saadia Gabriel*

Main category: cs.LG

TL;DR: 本文提出了一种多目标直接偏好优化（MODPO）框架，用于对齐AI心理治疗系统与患者偏好和临床安全要求，在同质化任务中实现更均衡的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前AI心理治疗系统在对齐过程中仅独立优化单一目标，难以兼顾患者偏好与临床安全性，导致实际应用受限。

Method: 基于335名有心理健康经历者的偏好排序数据，构建涵盖共情、安全性、积极倾听等六个维度的奖励模型，并采用多目标直接偏好优化（MODPO）方法进行训练与对比评估。

Result: MODPO在共情（77.6%）与安全性（62.6%）上实现更好平衡，显著优于单目标优化；其治疗相关指标比通用沟通原则高17.2%；盲评显示临床医生一致偏好MODPO输出，LLM评估者一致性接近人-人信度。

Conclusion: 多目标对齐框架能更有效地协调患者体验与临床安全需求，为AI辅助心理干预提供了更具临床可行性的优化路径。

Abstract: Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.

</details>


### [213] [Extracting and Analyzing Rail Crossing Behavior Signatures from Videos using Tensor Methods](https://arxiv.org/abs/2602.16057)
*Dawon Ahn,Het Patel,Aemal Khattak,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 本文提出一种多视角张量分解框架，利用TimeSformer嵌入和非负对称CP分解，从铁路道口视频中挖掘跨地点、跨时段的驾驶员行为模式，发现地点比时间更能决定行为特征，尤其接近阶段最具判别性。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独分析每个铁路道口，难以发现跨地点的共性驾驶员行为模式，而实际安全干预需依赖对行为相似性的规模化识别。

Method: 构建涵盖Approach、Waiting、Clearance三阶段的多视图张量；使用TimeSformer提取各阶段视频嵌入；构造阶段特异性相似矩阵；应用非负对称CP分解挖掘潜在行为成分。

Result: 发现道口位置比一天中的时间更能决定行为模式；Approach阶段行为最具判别性；可视化显示按地理位置聚类明显，部分道口形成独立行为簇。

Conclusion: 该自动化框架可实现多道口行为模式的可扩展发现，支持按行为相似性对道口分组，为精准安全干预提供依据。

Abstract: Railway crossings present complex safety challenges where driver behavior varies by location, time, and conditions. Traditional approaches analyze crossings individually, limiting the ability to identify shared behavioral patterns across locations. We propose a multi-view tensor decomposition framework that captures behavioral similarities across three temporal phases: Approach (warning activation to gate lowering), Waiting (gates down to train passage), and Clearance (train passage to gate raising). We analyze railway crossing videos from multiple locations using TimeSformer embeddings to represent each phase. By constructing phase-specific similarity matrices and applying non-negative symmetric CP decomposition, we discover latent behavioral components with distinct temporal signatures. Our tensor analysis reveals that crossing location appears to be a stronger determinant of behavior patterns than time of day, and that approach-phase behavior provides particularly discriminative signatures. Visualization of the learned component space confirms location-based clustering, with certain crossings forming distinct behavioral clusters. This automated framework enables scalable pattern discovery across multiple crossings, providing a foundation for grouping locations by behavioral similarity to inform targeted safety interventions.

</details>


### [214] [Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated Recursive Training](https://arxiv.org/abs/2602.16065)
*Kevin Wang,Hongqian Niu,Didong Li*

Main category: cs.LG

TL;DR: 本文研究了生成式AI模型在递归训练过程中因数据污染（即使用早期AI生成的数据进行后续训练）所导致的问题，提出了一种无需对真实数据分布做假设的通用理论框架，并证明了即使存在数据污染，递归训练仍能收敛，且收敛速率取决于基线模型收敛速率与每轮迭代中真实数据占比的最小值。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（如大语言模型）广泛应用，其生成内容大量混入网络数据，导致后续模型训练数据被污染，形成递归训练循环；已有理论仅在高度简化假设下分析该问题，缺乏对现实复杂数据和现代灵活模型的适用性。

Method: 构建一个弱假设的通用理论框架，不对真实数据分布作离散或高斯等限制，允许生成模型为通用逼近器；分析递归训练的收敛性，并扩展至存在采样偏差的情形；辅以实证研究验证理论结果。

Result: 证明在数据污染下的递归训练依然收敛，收敛速率等于基线模型收敛速率与每轮真实数据比例的较小值；这是首个在无数据分布假设下关于递归训练的正向理论结果；理论结论得到实证支持。

Conclusion: 尽管AI生成数据污染不可避免，只要每轮训练中保留一定比例的真实数据，递归训练仍可稳健收敛；该结论为理解生成式AI的长期演化与数据生态提供了重要理论支撑。

Abstract: Generative Artificial Intelligence (AI), such as large language models (LLMs), has become a transformative force across science, industry, and society. As these systems grow in popularity, web data becomes increasingly interwoven with this AI-generated material and it is increasingly difficult to separate them from naturally generated content. As generative models are updated regularly, later models will inevitably be trained on mixtures of human-generated data and AI-generated data from earlier versions, creating a recursive training process with data contamination. Existing theoretical work has examined only highly simplified settings, where both the real data and the generative model are discrete or Gaussian, where it has been shown that such recursive training leads to model collapse. However, real data distributions are far more complex, and modern generative models are far more flexible than Gaussian and linear mechanisms. To fill this gap, we study recursive training in a general framework with minimal assumptions on the real data distribution and allow the underlying generative model to be a general universal approximator. In this framework, we show that contaminated recursive training still converges, with a convergence rate equal to the minimum of the baseline model's convergence rate and the fraction of real data used in each iteration. To the best of our knowledge, this is the first (positive) theoretical result on recursive training without distributional assumptions on the data. We further extend the analysis to settings where sampling bias is present in data collection and support all theoretical results with empirical studies.

</details>


### [215] [Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research](https://arxiv.org/abs/2602.16072)
*Chenda Duan,Yipeng Zhang,Sotaro Kanai,Yuanyi Ding,Atsuro Daida,Pengyue Yu,Tiancheng Zheng,Naoto Kuroda,Shaun A. Hussain,Eishi Asano,Hiroki Nariai,Vwani Roychowdhury*

Main category: cs.LG

TL;DR: 本文介绍了Omni-iEEG，一个大规模、标准化的术前颅内脑电图（iEEG）数据集，包含302名患者、178小时高分辨率记录及36,000+专家标注的病理事件，旨在推动可复现、可泛化且临床可转化的癫痫研究。


<details>
  <summary>Details</summary>
Motivation: 现有iEEG数据驱动方法受限于单中心、格式不统一、缺乏标准基准和病理事件标注，阻碍了可复现性、跨中心验证与临床应用。

Method: 通过整合与标准化多个公开iEEG数据源，在格式、元数据和临床标注（如致痫区、切除范围、手术结局）上实现高度协调，并提供大量专家验证的病理事件标注；定义基于临床先验的统一评估任务与指标，并开展端到端建模与跨域表征迁移实验。

Result: 构建了Omni-iEEG数据集（302患者，178小时记录，36K+标注），建立了临床意义明确的基准任务，验证了长时程iEEG端到端建模可行性及非神经生理领域预训练表征的迁移潜力。

Conclusion: Omni-iEEG为癫痫AI研究提供了可复现、可泛化、临床可转化的基础资源与评估框架，弥合了机器学习与临床癫痫研究之间的鸿沟。

Abstract: Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\textbf{302 patients}$ and $\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at omni-ieeg.github.io/omni-ieeg.

</details>


### [216] [Why Any-Order Autoregressive Models Need Two-Stream Attention: A Structural-Semantic Tradeoff](https://arxiv.org/abs/2602.16092)
*Patrick Pynadath,Ruqi Zhang*

Main category: cs.LG

TL;DR: 本文探讨了任意顺序自回归模型（AO-ARMs）中两流注意力机制的作用，指出其核心价值在于缓解结构信息与语义信息在注意力分配上的内在冲突，而非简单分离位置与内容；为此提出Decoupled RoPE方法验证该观点，并发现其在长序列上性能下降，佐证了结构性-语义性权衡的存在。


<details>
  <summary>Details</summary>
Motivation: 现有AO-ARMs依赖两流注意力以实现高性能，传统解释是解耦位置与内容，但作者质疑其背后存在更本质的结构性-语义性注意力权衡问题。

Method: 提出Decoupled RoPE——一种改进的旋转位置编码，能在不暴露目标token内容的前提下提供目标位置信息，从而将位置-内容分离与结构-语义权衡两个因素解耦。

Result: Decoupled RoPE在短序列上表现良好（此时结构邻近性与语义邻近性一致），但在长序列中性能显著下降（二者偏离时），表明两流注意力的关键作用在于应对结构-语义权衡，而非仅位置-内容分离。

Conclusion: 两流注意力的成功根源在于缓解任意序生成中固有的结构信息建模与语义信息建模之间的注意力资源竞争，这一结构性-语义性权衡比位置-内容分离更为根本。

Abstract: Any-order autoregressive models (AO-ARMs) offer a promising path toward efficient masked diffusion by enabling native key-value caching, but competitive performance has so far required two-stream attention, typically motivated as a means of decoupling token content from position. In this work, we argue that two-stream attention may be serving a more subtle role. We identify a structural-semantic tradeoff in any-order generation: the hidden representation at each step must simultaneously attend to semantically informative tokens for prediction and structurally recent tokens for summarization, objectives that compete for attention capacity in a single stream but can specialize across two streams. To isolate this tradeoff from position-content separation, we propose Decoupled RoPE, a modification to rotary position embeddings that provides target position information without revealing target content. Decoupled RoPE performs competitively at short sequence lengths--where semantic and structural proximity coincide--but degrades as sequence length increases and the two orderings diverge. These results suggest that the success of two-stream attention stems not merely from separating position from content, but from circumventing the deeper structural-semantic tradeoff inherent to any-order generation.

</details>


### [217] [Axle Sensor Fusion for Online Continual Wheel Fault Detection in Wayside Railway Monitoring](https://arxiv.org/abs/2602.16101)
*Afonso Lourenço,Francisca Osório,Diogo Risca,Goreti Marreiros*

Main category: cs.LG

TL;DR: 本文提出了一种语义感知、标签高效、持续学习的铁路故障诊断框架，结合VAE无监督学习、光纤光栅传感器语义元数据融合与轻量梯度提升分类器，在仅有少量标签和在线演化场景下实现鲁棒异常检测。


<details>
  <summary>Details</summary>
Motivation: 铁路轮轨界面易磨损失效，传统预测性维护方法依赖人工特征工程，而深度学习模型在在线演化工况下性能易退化，亟需一种低标签依赖、能持续适应新运行模式的可靠诊断方法。

Method: 采用变分自编码器（VAE）对加速度计时序信号进行无监督表征学习；利用AI驱动的峰检测从抗电磁干扰的光纤布拉格光栅（FBG）传感器中提取轴数、车轮索引、应变变形等语义元数据，并与VAE潜表示融合；采用轻量级梯度提升分类器进行监督异常评分；引入基于回放的持续学习策略防止灾难性遗忘。

Result: 模型能准确检测由踏面擦伤和平面化引起的微小缺陷，并在列车类型、速度、载荷及轨道轮廓等运行条件动态变化下保持稳定性能，仅需单个加速度计和应变片即可实现有效监测。

Conclusion: 该框架通过无监督表征、语义增强与持续学习的协同设计，在标签稀缺和工况演化场景下显著提升了铁路故障诊断的可靠性、适应性与实用性，为智能运维提供了新范式。

Abstract: Reliable and cost-effective maintenance is essential for railway safety, particularly at the wheel-rail interface, which is prone to wear and failure. Predictive maintenance frameworks increasingly leverage sensor-generated time-series data, yet traditional methods require manual feature engineering, and deep learning models often degrade in online settings with evolving operational patterns. This work presents a semantic-aware, label-efficient continual learning framework for railway fault diagnostics. Accelerometer signals are encoded via a Variational AutoEncoder into latent representations capturing the normal operational structure in a fully unsupervised manner. Importantly, semantic metadata, including axle counts, wheel indexes, and strain-based deformations, is extracted via AI-driven peak detection on fiber Bragg grating sensors (resistant to electromagnetic interference) and fused with the VAE embeddings, enhancing anomaly detection under unknown operational conditions. A lightweight gradient boosting supervised classifier stabilizes anomaly scoring with minimal labels, while a replay-based continual learning strategy enables adaptation to evolving domains without catastrophic forgetting. Experiments show the model detects minor imperfections due to flats and polygonization, while adapting to evolving operational conditions, such as changes in train type, speed, load, and track profiles, captured using a single accelerometer and strain gauge in wayside monitoring.

</details>


### [218] [Feature-based morphological analysis of shape graph data](https://arxiv.org/abs/2602.16120)
*Murad Hossen,Demetrio Labate,Nicolas Charon*

Main category: cs.LG

TL;DR: 本文提出了一种用于形状图（几何网络）数据集统计分析的计算流程，通过提取具有不变性的拓扑、几何和方向特征，支持组间比较、聚类与分类任务，并在道路网、神经元轨迹和星形胶质细胞成像等真实数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统图分析仅关注连通性结构，而形状图还需刻画网络分支的几何差异；现有方法缺乏对几何与拓扑联合不变特征的系统建模。

Method: 设计并提取满足关键不变性（如旋转、平移）的显式拓扑、几何和方向特征，构建统一特征表示，并用于下游统计分析任务（如组比较、聚类、分类）。

Result: 在城市道路网、神经元轨迹和 astrocyte 成像等多个真实形状图数据集上，该特征表示在分类、聚类等任务中优于多种基线方法（含非特征型方法）。

Conclusion: 显式构造兼具拓扑与几何不变性的特征是分析形状图数据的有效途径，所提流程具备跨领域适用性与统计可解释性。

Abstract: This paper introduces and demonstrates a computational pipeline for the statistical analysis of shape graph datasets, namely geometric networks embedded in 2D or 3D spaces. Unlike traditional abstract graphs, our purpose is not only to retrieve and distinguish variations in the connectivity structure of the data but also geometric differences of the network branches. Our proposed approach relies on the extraction of a specifically curated and explicit set of topological, geometric and directional features, designed to satisfy key invariance properties. We leverage the resulting feature representation for tasks such as group comparison, clustering and classification on cohorts of shape graphs. The effectiveness of this representation is evaluated on several real-world datasets including urban road/street networks, neuronal traces and astrocyte imaging. These results are benchmarked against several alternative methods, both feature-based and not.

</details>


### [219] [On the Power of Source Screening for Learning Shared Feature Extractors](https://arxiv.org/abs/2602.16125)
*Leo,Wang,Connor Mclaughlin,Lili Su*

Main category: cs.LG

TL;DR: 本文研究了在多源学习中如何选择最有效的数据源进行联合训练，以实现统计最优的子空间估计。作者提出了一种源筛选方法，证明在某些情况下，仅使用精心挑选的部分数据源即可达到最小最大最优性，即使丢弃大量数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常同时利用所有相关数据源进行训练，但低相关性或低质量的数据源可能阻碍表征学习。本文聚焦于如何从传统认为‘好’的数据源集合中筛选出最适合联合学习的子集。

Method: 在共享低维子空间的线性设定下，形式化定义‘信息丰富子群体’，提出相应的筛选算法与实用启发式方法，并结合理论分析与实验验证其有效性。

Result: 证明对一大类问题实例，仅训练一个精心选择的数据源子集即可实现最小最大最优的子空间估计；所提算法和启发式方法在合成与真实数据集上均被验证有效。

Conclusion: 源筛选在多源共享表征学习中起关键作用，合理选择数据源比简单融合所有可用源更能提升统计效率与模型性能。

Abstract: Learning with shared representation is widely recognized as an effective way to separate commonalities from heterogeneity across various heterogeneous sources. Most existing work includes all related data sources via simultaneously training a common feature extractor and source-specific heads. It is well understood that data sources with low relevance or poor quality may hinder representation learning. In this paper, we further dive into the question of which data sources should be learned jointly by focusing on the traditionally deemed ``good'' collection of sources, in which individual sources have similar relevance and qualities with respect to the true underlying common structure. Towards tractability, we focus on the linear setting where sources share a low-dimensional subspace. We find that source screening can play a central role in statistically optimal subspace estimation. We show that, for a broad class of problem instances, training on a carefully selected subset of sources suffices to achieve minimax optimality, even when a substantial portion of data is discarded. We formalize the notion of an informative subpopulation, develop algorithms and practical heuristics for identifying such subsets, and validate their effectiveness through both theoretical analysis and empirical evaluations on synthetic and real-world datasets.

</details>


### [220] [Investigating GNN Convergence on Large Randomly Generated Graphs with Realistic Node Feature Correlations](https://arxiv.org/abs/2602.16145)
*Mohammed Zain Ali Ahmed*

Main category: cs.LG

TL;DR: 本文提出了一种生成具有相关节点特征的随机图的新方法，以更真实地建模现实网络中的特征关联性，并理论与实验表明：在此类图上，图神经网络（GNN）可避免收敛，从而展现出比以往研究认为的更强的表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有对GNN在大规模随机图上收敛行为的研究大多忽略节点特征间的相关性，而现实中这种相关性普遍存在（如Barabási-Albert模型所体现的特性），导致其对GNN表达能力的评估失真。

Method: 设计一种新型随机图生成方法，使相邻节点的特征按特定采样方案保持相关性，并基于现实网络特性（如无标度性）进行建模；进而开展理论分析并用生成的大规模随机图进行实证验证。

Result: 理论分析表明，在所提图模型上GNN的收敛行为可在某些情况下被避免；实验在生成的大规模随机图上验证了该发散行为的存在。

Conclusion: GNN在具有真实特征相关性的图上可能比先前收敛性研究所揭示的更具表达能力，提示需重新评估其在现实图任务中的能力边界。

Abstract: There are a number of existing studies analysing the convergence behaviour of graph neural networks on large random graphs. Unfortunately, the majority of these studies do not model correlations between node features, which would naturally exist in a variety of real-life networks. Consequently, the derived limitations of GNNs, resulting from such convergence behaviour, is not truly reflective of the expressive power of GNNs when applied to realistic graphs. In this paper, we will introduce a novel method to generate random graphs that have correlated node features. The node features will be sampled in such a manner to ensure correlation between neighbouring nodes. As motivation for our choice of sampling scheme, we will appeal to properties exhibited by real-life graphs, particularly properties that are captured by the Barabási-Albert model. A theoretical analysis will strongly indicate that convergence can be avoided in some cases, which we will empirically validate on large random graphs generated using our novel method. The observed divergent behaviour provides evidence that GNNs may be more expressive than initial studies would suggest, especially on realistic graphs.

</details>


### [221] [ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding](https://arxiv.org/abs/2602.16147)
*Megan Lee,Seung Ha Hwang,Inhyeok Choi,Shreyas Darade,Mengchun Zhang,Kateryna Shapovalenko*

Main category: cs.LG

TL;DR: 本文提出ASPEN模型，通过谱特征与时间特征的乘性融合，在跨被试脑机接口中实现更优泛化性能。


<details>
  <summary>Details</summary>
Motivation: 由于个体神经信号差异大，基于EEG的脑机接口跨被试泛化困难；作者发现谱表征比时域波形更具跨被试稳定性，由此启发设计融合架构。

Method: 提出ASPEN混合架构，将谱特征流和时域特征流通过乘性融合（要求跨模态一致性）进行结合，并在三个EEG范式（SSVEP、P300、运动想象）及六个基准数据集上验证。

Result: ASPEN在六个数据集中三个达到最优未见被试准确率，其余表现具竞争力；谱特征确比时域信号具有更高跨被试相似性。

Conclusion: 乘性多模态融合能有效提升EEG跨被试泛化能力，且ASPEN可自适应地平衡谱与时间特征贡献。

Abstract: Cross-subject generalization in EEG-based brain-computer interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features exhibit consistently higher cross-subject similarity than temporal signals. Motivated by this observation, we introduce ASPEN, a hybrid architecture that combines spectral and temporal feature streams via multiplicative fusion, requiring cross-modal agreement for features to propagate. Experiments across six benchmark datasets reveal that ASPEN is able to dynamically achieve the optimal spectral-temporal balance depending on the paradigm. ASPEN achieves the best unseen-subject accuracy on three of six datasets and competitive performance on others, demonstrating that multiplicative multimodal fusion enables effective cross-subject generalization.

</details>


### [222] [Differentially Private Non-convex Distributionally Robust Optimization](https://arxiv.org/abs/2602.16155)
*Difei Xu,Meng Ding,Zebin Ma,Huanyi Xie,Youming Tao,Aicha Slaitane,Di Wang*

Main category: cs.LG

TL;DR: 本文研究了在差分隐私约束下的分布鲁棒优化（DP-DRO），提出了两种新算法DP Double-Spider和DP Recursive-Spider，分别适用于一般ψ-散度和KL散度下的非凸DP-DRO问题，并给出了理论收敛界与实验验证。


<details>
  <summary>Details</summary>
Motivation: 现实部署中常面临分布偏移、群体不平衡和对抗扰动等问题，传统ERM方法性能下降；同时DRO训练数据含敏感信息，需满足差分隐私要求，但现有DP-DRO研究较少，尤其针对非凸损失和有限和结构。

Method: 将ψ-散度DRO重写为单层优化问题，提出DP Double-Spider算法；对KL散度情形，转化为复合有限和优化问题，设计DP Recursive-Spider算法；均基于Spider-type方差缩减技术并满足(ε,δ)-差分隐私。

Result: DP Double-Spider获得梯度范数意义下O(1/√n + (√(d log(1/δ))/(nε))^{2/3})的效用界；DP Recursive-Spider在KL散度下达到O((√(d log(1/δ))/(nε))^{2/3})，匹配最优非凸DP-ERM结果；实验表明所提方法优于现有DP minimax优化方法。

Conclusion: 本文系统推进了非凸、有限和设定下DP-DRO的理论与算法研究，首次为通用ψ-散度和KL散度分别提供了高效且具理论保证的隐私保护DRO求解方案。

Abstract: Real-world deployments routinely face distribution shifts, group imbalances, and adversarial perturbations, under which the traditional Empirical Risk Minimization (ERM) framework can degrade severely.
  Distributionally Robust Optimization (DRO) addresses this issue by optimizing the worst-case expected loss over an uncertainty set of distributions, offering a principled approach to robustness.
  Meanwhile, as training data in DRO always involves sensitive information, safeguarding it against leakage under Differential Privacy (DP) is essential.
  In contrast to classical DP-ERM, DP-DRO has received much less attention due to its minimax optimization structure with uncertainty constraint.
  To bridge the gap, we provide a comprehensive study of DP-(finite-sum)-DRO with $ψ$-divergence and non-convex loss.
  First, we study DRO with general $ψ$-divergence by reformulating it as a minimization problem, and develop a novel $(\varepsilon, δ)$-DP optimization method, called DP Double-Spider, tailored to this structure.
  Under mild assumptions, we show that it achieves a utility bound of $\mathcal{O}(\frac{1}{\sqrt{n}}+ (\frac{\sqrt{d \log (1/δ)}}{n \varepsilon})^{2/3})$ in terms of the gradient norm, where $n$ denotes the data size and $d$ denotes the model dimension.
  We further improve the utility rate for specific divergences.
  In particular, for DP-DRO with KL-divergence, by transforming the problem into a compositional finite-sum optimization problem, we develop a DP Recursive-Spider method and show that it achieves a utility bound of $\mathcal{O}((\frac{\sqrt{d \log(1/δ)}}{n\varepsilon})^{2/3} )$, matching the best-known result for non-convex DP-ERM.
  Experimentally, we demonstrate that our proposed methods outperform existing approaches for DP minimax optimization.

</details>


### [223] [HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents](https://arxiv.org/abs/2602.16165)
*Jiangweizhi Peng,Yuanxin Liu,Ruida Zhou,Charles Fleming,Zhaoran Wang,Alfredo Garcia,Mingyi Hong*

Main category: cs.LG

TL;DR: 本文提出HiPER框架，通过分层规划-执行结构和分层优势估计（HAE）技术，提升大语言模型在稀疏奖励、长周期多轮决策任务中的强化学习训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法将LLM代理建模为单一时间尺度的扁平策略，在稀疏延迟奖励场景下难以有效进行信用分配，导致优化不稳定、效率低下。

Method: 提出HiPER：一种分层规划-执行RL框架，将策略分解为高层规划器（生成子目标）和底层执行器（完成子目标）；引入分层优势估计（HAE），在规划与执行两个层级分别进行信用分配，并保证无偏性与方差降低。

Result: 在ALFWorld和WebShop基准上达到97.4%和83.3%成功率，分别超越最优基线6.6%和8.3%，尤其在需多个依赖子任务的长周期任务中增益显著。

Conclusion: 显式分层分解对可扩展的多轮LLM代理RL训练至关重要，HiPER为解决稀疏奖励下的长程信用分配问题提供了有效范式。

Abstract: Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajectory without explicit temporal abstraction, which often leads to unstable optimization and inefficient credit assignment.
  We propose HiPER, a novel Hierarchical Plan-Execute RL framework that explicitly separates high-level planning from low-level execution. HiPER factorizes the policy into a high-level planner that proposes subgoals and a low-level executor that carries them out over multiple action steps. To align optimization with this structure, we introduce a key technique called hierarchical advantage estimation (HAE), which carefully assigns credit at both the planning and execution levels. By aggregating returns over the execution of each subgoal and coordinating updates across the two levels, HAE provides an unbiased gradient estimator and provably reduces variance compared to flat generalized advantage estimation.
  Empirically, HiPER achieves state-of-the-art performance on challenging interactive benchmarks, reaching 97.4\% success on ALFWorld and 83.3\% on WebShop with Qwen2.5-7B-Instruct (+6.6\% and +8.3\% over the best prior method), with especially large gains on long-horizon tasks requiring multiple dependent subtasks. These results highlight the importance of explicit hierarchical decomposition for scalable RL training of multi-turn LLM agents.

</details>


### [224] [Muon with Spectral Guidance: Efficient Optimization for Scientific Machine Learning](https://arxiv.org/abs/2602.16167)
*Binghang Lu,Jiahao Zhang,Guang Lin*

Main category: cs.LG

TL;DR: 本文提出了一种新型优化器SpecMuon，通过结合Muon的正交几何特性和模式相关的松弛标量辅助变量（RSAV）机制，改善物理信息神经网络等模型的训练稳定性与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络和神经算子常因梯度病态、多尺度频谱行为及物理约束引起的刚性而面临严重优化困难；Muon虽改进了几何条件，但其单位奇异值更新可能导致步长过大且缺乏稳定性保证。

Method: 提出SpecMuon优化器：将矩阵梯度按奇异值分解为模态，对主导谱方向分别应用RSAV更新，自适应调节步长，同时保持Muon的尺度平衡特性；将优化解释为多模态梯度流，并建立修正的能量耗散律等理论性质。

Result: 在Burgers方程、分数阶偏微分方程等基准问题上，SpecMuon在PINN、DeepONet及分数阶PINN-DeepONet中相较Adam、AdamW和原始Muon展现出更快收敛速度和更强稳定性。

Conclusion: SpecMuon通过谱感知的自适应更新机制，在保持理论严谨性（如线性收敛率、辅助变量有界性）的同时，有效缓解了物理信息学习中的优化难题，为刚性、多尺度物理建模提供了更鲁棒的优化工具。

Abstract: Physics-informed neural networks and neural operators often suffer from severe optimization difficulties caused by ill-conditioned gradients, multi-scale spectral behavior, and stiffness induced by physical constraints. Recently, the Muon optimizer has shown promise by performing orthogonalized updates in the singular-vector basis of the gradient, thereby improving geometric conditioning. However, its unit-singular-value updates may lead to overly aggressive steps and lack explicit stability guarantees when applied to physics-informed learning. In this work, we propose SpecMuon, a spectral-aware optimizer that integrates Muon's orthogonalized geometry with a mode-wise relaxed scalar auxiliary variable (RSAV) mechanism. By decomposing matrix-valued gradients into singular modes and applying RSAV updates individually along dominant spectral directions, SpecMuon adaptively regulates step sizes according to the global loss energy while preserving Muon's scale-balancing properties. This formulation interprets optimization as a multi-mode gradient flow and enables principled control of stiff spectral components. We establish rigorous theoretical properties of SpecMuon, including a modified energy dissipation law, positivity and boundedness of auxiliary variables, and global convergence with a linear rate under the Polyak-Lojasiewicz condition. Numerical experiments on physics-informed neural networks, DeepONets, and fractional PINN-DeepONets demonstrate that SpecMuon achieves faster convergence and improved stability compared with Adam, AdamW, and the original Muon optimizer on benchmark problems such as the one-dimensional Burgers equation and fractional partial differential equations.

</details>


### [225] [Discrete Stochastic Localization for Non-autoregressive Generation](https://arxiv.org/abs/2602.16169)
*Yunshu Wu,Jiayi Cheng,Partha Thakuria,Rob Brekelmans,Evangelos E. Papalexakis,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 本文提出DSL（离散随机定位）方法，通过在连续噪声水平上训练单个SNR不变去噪器，显著提升掩码扩散语言模型（MDLM）及其重掩码采样器（如ReMDM）的步效率，在低步数预算下大幅优于基线，且高步数时媲美自回归模型质量。


<details>
  <summary>Details</summary>
Motivation: 非自回归（NAR）生成虽降低解码延迟，但迭代精修易受错误累积和分布偏移影响；MDLM/ReMDM作为现代NAR迭代精修范式，其采样效率仍有提升空间。

Method: 提出DSL（Discrete Stochastic Localization），训练一个SNR不变的Diffusion Transformer，在从中间草稿噪声到端点掩码腐蚀的连续污染水平上统一建模，实现单模型覆盖多阶段去噪。

Result: 在OpenWebText上，DSL微调在低步数预算下带来显著MAUVE增益，仅需约1/4的去噪器评估次数即超越MDLM+ReMDM基线；高步数时达到与自回归模型相当的质量；分析表明其自校正能力与不确定性校准能力增强。

Conclusion: 仅通过改进训练策略（DSL），即可大幅提升MDLM/ReMDM类模型的采样效率与生成质量，验证了训练设计对NAR扩散语言模型性能的关键作用。

Abstract: Non-autoregressive (NAR) generation reduces decoding latency by predicting many tokens in parallel, but iterative refinement often suffers from error accumulation and distribution shift under self-generated drafts. Masked diffusion language models (MDLMs) and their remasking samplers (e.g., ReMDM) can be viewed as modern NAR iterative refinement, where generation repeatedly revises a partially observed draft. In this work we show that \emph{training alone} can substantially improve the step-efficiency of MDLM/ReMDM sampling. We propose \textsc{DSL} (Discrete Stochastic Localization), which trains a single SNR-invariant denoiser across a continuum of corruption levels, bridging intermediate draft noise and mask-style endpoint corruption within one Diffusion Transformer. On OpenWebText, \textsc{DSL} fine-tuning yields large MAUVE gains at low step budgets, surpassing the MDLM+ReMDM baseline with \(\sim\)4$\times$ fewer denoiser evaluations, and matches autoregressive quality at high budgets. Analyses show improved self-correction and uncertainty calibration, making remasking markedly more compute-efficient.

</details>


### [226] [Towards Secure and Scalable Energy Theft Detection: A Federated Learning Approach for Resource-Constrained Smart Meters](https://arxiv.org/abs/2602.16181)
*Diego Labate,Dipanwita Thakur,Giancarlo Fortino*

Main category: cs.LG

TL;DR: 本文提出了一种面向智能电网电能盗窃检测的隐私保护联邦学习框架，采用轻量级MLP模型和基础差分隐私机制，在保障用户数据隐私和设备资源约束的前提下，实现了高检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统集中式机器学习方法需聚合用户数据，引发严重隐私与安全问题；智能电表资源受限，难以运行复杂模型。

Method: 提出基于轻量级多层感知机（MLP）的联邦学习框架，并在本地模型更新中注入高斯噪声以实现基础差分隐私（DP）。

Result: 在真实智能电表数据集（IID与非IID分布）上验证，该方法在准确率、精确率、召回率和AUC等指标上表现优异，同时兼顾隐私性与计算效率。

Conclusion: 所提框架在隐私保护、模型轻量化与检测性能之间取得良好平衡，具备在下一代智能电网中实用化与规模化部署的潜力。

Abstract: Energy theft poses a significant threat to the stability and efficiency of smart grids, leading to substantial economic losses and operational challenges. Traditional centralized machine learning approaches for theft detection require aggregating user data, raising serious concerns about privacy and data security. These issues are further exacerbated in smart meter environments, where devices are often resource-constrained and lack the capacity to run heavy models. In this work, we propose a privacy-preserving federated learning framework for energy theft detection that addresses both privacy and computational constraints. Our approach leverages a lightweight multilayer perceptron (MLP) model, suitable for deployment on low-power smart meters, and integrates basic differential privacy (DP) by injecting Gaussian noise into local model updates before aggregation. This ensures formal privacy guarantees without compromising learning performance. We evaluate our framework on a real-world smart meter dataset under both IID and non-IID data distributions. Experimental results demonstrate that our method achieves competitive accuracy, precision, recall, and AUC scores while maintaining privacy and efficiency. This makes the proposed solution practical and scalable for secure energy theft detection in next-generation smart grid infrastructures.

</details>


### [227] [Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting](https://arxiv.org/abs/2602.16188)
*Filippos Bellos,NaveenJohn Premkumar,Yannis Avrithis,Nam H. Nguyen,Jason J. Corso*

Main category: cs.LG

TL;DR: 本文提出Temporal-Prior Conditioning（TPC）方法，将时间信息作为一等模态在多层中动态注入，通过可学习的时间序列token与冻结大语言模型编码的时序描述进行跨注意力交互，实现信号与时间信息的解耦，在低参数开销下显著提升长时序预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-for-time series方法仅在输入层浅层注入时间信息，导致深层中时间线索衰减，限制了模型的时序推理能力。

Method: 提出Temporal-Prior Conditioning（TPC），在patch流中附加少量可学习时间序列token，并在选定层中使其与由冻结LLM编码的紧凑、可读时序描述所生成的时间嵌入进行跨注意力交互，再通过自注意力将时间上下文反馈回主干；仅训练跨注意力模块，保持其余参数冻结。

Result: TPC在多个数据集的长时序预测任务上持续优于全量微调和浅层时间注入方法，达到当前最优性能。

Conclusion: 将时间建模为多层条件先验并显式解耦时序信号与时间语义，可在极小参数增量下大幅提升LLM在时间序列建模中的表现，验证了深度时间感知机制的有效性。

Abstract: LLM-for-time series (TS) methods typically treat time shallowly, injecting positional or prompt-based cues once at the input of a largely frozen decoder, which limits temporal reasoning as this information degrades through the layers. We introduce Temporal-Prior Conditioning (TPC), which elevates time to a first-class modality that conditions the model at multiple depths. TPC attaches a small set of learnable time series tokens to the patch stream; at selected layers these tokens cross-attend to temporal embeddings derived from compact, human-readable temporal descriptors encoded by the same frozen LLM, then feed temporal context back via self-attention. This disentangles time series signal and temporal information while maintaining a low parameter budget. We show that by training only the cross-attention modules and explicitly disentangling time series signal and temporal information, TPC consistently outperforms both full fine-tuning and shallow conditioning strategies, achieving state-of-the-art performance in long-term forecasting across diverse datasets. Code available at: https://github.com/fil-mp/Deep_tpc

</details>


### [228] [Rethinking Input Domains in Physics-Informed Neural Networks via Geometric Compactification Mappings](https://arxiv.org/abs/2602.16193)
*Zhenzhen Huang,Haoyu Bian,Jiaquan Zhang,Yibei Liu,Kuien Liu,Caiyan Qin,Guoqing Wang,Yang Yang,Chaoning Zhang*

Main category: cs.LG

TL;DR: 本文提出Geometric Compactification (GC)-PINN框架，通过可微几何紧致化映射重塑输入坐标，以对齐多尺度PDE中的几何结构，从而缓解梯度刚性和病态问题，提升训练稳定性、收敛速度与解精度。


<details>
  <summary>Details</summary>
Motivation: 现有PINN方法在固定坐标系下训练，难以对齐多尺度PDE中低频平滑与高频局域结构，导致梯度刚性与病态，影响收敛。

Method: 提出基于可微几何紧致化映射的范式，将PDE几何结构与残差算子谱特性耦合；设计三种映射策略（周期边界、远场尺度展开、局域奇异性），嵌入标准PINN架构而不改动其结构。

Result: 在典型1D/2D多尺度PDE上验证：残差分布更均匀、解精度更高、训练更稳定且收敛更快。

Conclusion: 几何紧致化映射能有效缓解PINN在多尺度PDE求解中的数值困难，为物理信息神经网络提供一种通用、即插即用的坐标预处理增强范式。

Abstract: Several complex physical systems are governed by multi-scale partial differential equations (PDEs) that exhibit both smooth low-frequency components and localized high-frequency structures. Existing physics-informed neural network (PINN) methods typically train with fixed coordinate system inputs, where geometric misalignment with these structures induces gradient stiffness and ill-conditioning that hinder convergence. To address this issue, we introduce a mapping paradigm that reshapes the input coordinates through differentiable geometric compactification mappings and couples the geometric structure of PDEs with the spectral properties of residual operators. Based on this paradigm, we propose Geometric Compactification (GC)-PINN, a framework that introduces three mapping strategies for periodic boundaries, far-field scale expansion, and localized singular structures in the input domain without modifying the underlying PINN architecture. Extensive empirical evaluation demonstrates that this approach yields more uniform residual distributions and higher solution accuracy on representative 1D and 2D PDEs, while improving training stability and convergence speed.

</details>


### [229] [ModalImmune: Immunity Driven Unlearning via Self Destructive Training](https://arxiv.org/abs/2602.16197)
*Rong Fu,Jia Yee Tan,Wenxin Zhang,Zijian Zhang,Ziming Wang,Zhaolu Kang,Muge Qi,Shuning Zhang,Simon Fong*

Main category: cs.LG

TL;DR: 本文提出ModalImmune训练框架，通过在训练中可控地坍缩选定模态信息，使模型学习对模态缺失或损坏具有鲁棒性的联合表征。


<details>
  <summary>Details</summary>
Motivation: 多模态系统在部署时易受输入通道部分或完全丢失的影响，导致真实场景中可靠性下降。

Method: ModalImmune框架结合谱自适应坍缩正则化、信息增益引导的干预控制器、曲率感知梯度掩码以及认证的Neumann截断超梯度方法，实现自动元参数适配。

Result: 在标准多模态基准上的实验表明，ModalImmune提升了模型对模态移除和损坏的鲁棒性，同时保持收敛稳定性与重建能力。

Conclusion: ModalImmune是一种有效提升多模态模型在模态缺失/损坏下鲁棒性的通用训练框架。

Abstract: Multimodal systems are vulnerable to partial or complete loss of input channels at deployment, which undermines reliability in real-world settings. This paper presents ModalImmune, a training framework that enforces modality immunity by intentionally and controllably collapsing selected modality information during training so the model learns joint representations that are robust to destructive modality influence. The framework combines a spectrum-adaptive collapse regularizer, an information-gain guided controller for targeted interventions, curvature-aware gradient masking to stabilize destructive updates, and a certified Neumann-truncated hyper-gradient procedure for automatic meta-parameter adaptation. Empirical evaluation on standard multimodal benchmarks demonstrates that ModalImmune improves resilience to modality removal and corruption while retaining convergence stability and reconstruction capacity.

</details>


### [230] [Training-Free Adaptation of Diffusion Models via Doob's $h$-Transform](https://arxiv.org/abs/2602.16198)
*Qijie Zhu,Zeqi Ye,Han Liu,Zhaoran Wang,Minshuo Chen*

Main category: cs.LG

TL;DR: 本文提出DOIT方法，一种无需训练、计算高效的扩散模型适配方法，适用于通用且不可微的奖励函数，通过Doob's h-变换实现测度传输，并提供理论收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型适配方法存在计算开销大、依赖奖励函数可微等强假设，且缺乏理论支撑。

Method: 提出基于测度传输的DOIT框架，利用Doob's h-变换在推理时动态校正采样过程，不修改预训练模型，支持非可微奖励。

Result: 在D4RL离线强化学习基准上，DOIT持续优于SOTA基线，同时保持高效采样。

Conclusion: DOIT是一种训练免费、适用范围广、具理论保障的扩散模型适配新范式。

Abstract: Adaptation methods have been a workhorse for unlocking the transformative power of pre-trained diffusion models in diverse applications. Existing approaches often abstract adaptation objectives as a reward function and steer diffusion models to generate high-reward samples. However, these approaches can incur high computational overhead due to additional training, or rely on stringent assumptions on the reward such as differentiability. Moreover, despite their empirical success, theoretical justification and guarantees are seldom established. In this paper, we propose DOIT (Doob-Oriented Inference-time Transformation), a training-free and computationally efficient adaptation method that applies to generic, non-differentiable rewards. The key framework underlying our method is a measure transport formulation that seeks to transport the pre-trained generative distribution to a high-reward target distribution. We leverage Doob's $h$-transform to realize this transport, which induces a dynamic correction to the diffusion sampling process and enables efficient simulation-based computation without modifying the pre-trained model. Theoretically, we establish a high probability convergence guarantee to the target high-reward distribution via characterizing the approximation error in the dynamic Doob's correction. Empirically, on D4RL offline RL benchmarks, our method consistently outperforms state-of-the-art baselines while preserving sampling efficiency.

</details>


### [231] [Linked Data Classification using Neurochaos Learning](https://arxiv.org/abs/2602.16204)
*Pooja Honna,Ayush Patravali,Nithin Nagaraj,Nanjangud C. Narendra*

Main category: cs.LG

TL;DR: 本文将神经混沌学习（NL）扩展到知识图谱等关联数据，通过节点聚合将图数据融入最简NL架构ChaosNet，并在同质与异质图数据集上验证其性能，发现其在同质图上效果更优。


<details>
  <summary>Details</summary>
Motivation: 将神经混沌学习（NL）从传统的可分数据和时间序列数据扩展到关联数据（特别是知识图谱），探索其在图结构数据上的适用性与性能。

Method: 在知识图谱上实施节点聚合以提取节点特征，并将聚合后的特征输入最简NL架构ChaosNet进行学习。

Result: 所提方法在同质图数据集上表现出优于异质图数据集的效能；同时提供了结果分析及未来工作建议。

Conclusion: 神经混沌学习可成功应用于知识图谱等关联数据，尤其适用于同质图场景，为低资源、小样本图学习提供新思路。

Abstract: Neurochaos Learning (NL) has shown promise in recent times over traditional deep learning due to its two key features: ability to learn from small sized training samples, and low compute requirements. In prior work, NL has been implemented and extensively tested on separable and time series data, and demonstrated its superior performance on both classification and regression tasks. In this paper, we investigate the next step in NL, viz., applying NL to linked data, in particular, data that is represented in the form of knowledge graphs. We integrate linked data into NL by implementing node aggregation on knowledge graphs, and then feeding the aggregated node features to the simplest NL architecture: ChaosNet. We demonstrate the results of our implementation on homophilic graph datasets as well as heterophilic graph datasets of verying heterophily. We show better efficacy of our approach on homophilic graphs than on heterophilic graphs. While doing so, we also present our analysis of the results, as well as suggestions for future work.

</details>


### [232] [Geometric Neural Operators via Lie Group-Constrained Latent Dynamics](https://arxiv.org/abs/2602.16209)
*Jiaquan Zhang,Fachrina Dewi Puspitasari,Songbo Zhang,Yibei Liu,Kuien Liu,Caiyan Qin,Fan Mo,Peng Wang,Yang Yang,Chaoning Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于李群流形约束（MCL）的新方法，通过在低秩李代数参数化的流形上进行群作用更新，为神经算子引入几何归纳偏置，显著提升多步长期预测的稳定性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在多层迭代和长时序推演中存在不稳定性，源于欧氏隐空间更新违反物理系统的几何与守恒律。

Method: 提出基于李群的流形约束（MCL）模块，利用低秩李代数参数化实现对隐表示的群作用更新，作为即插即用组件嵌入现有神经算子。

Result: 在1D Burgers、2D Navier-Stokes等PDE任务上，相对预测误差降低30–50%，仅增加2.26%参数量。

Conclusion: MCL通过显式建模几何约束，为提升神经算子长期预测保真度提供了可扩展、原理驱动的解决方案。

Abstract: Neural operators offer an effective framework for learning solutions of partial differential equations for many physical systems in a resolution-invariant and data-driven manner. Existing neural operators, however, often suffer from instability in multi-layer iteration and long-horizon rollout, which stems from the unconstrained Euclidean latent space updates that violate the geometric and conservation laws. To address this challenge, we propose to constrain manifolds with low-rank Lie algebra parameterization that performs group action updates on the latent representation. Our method, termed Manifold Constraining based on Lie group (MCL), acts as an efficient \emph{plug-and-play} module that enforces geometric inductive bias to existing neural operators. Extensive experiments on various partial differential equations, such as 1-D Burgers and 2-D Navier-Stokes, over a wide range of parameters and steps demonstrate that our method effectively lowers the relative prediction error by 30-50\% at the cost of 2.26\% of parameter increase. The results show that our approach provides a scalable solution for improving long-term prediction fidelity by addressing the principled geometric constraints absent in the neural operator updates.

</details>


### [233] [Graph neural network for colliding particles with an application to sea ice floe modeling](https://arxiv.org/abs/2602.16213)
*Ruibiao Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种基于图神经网络（GNN）的新型海冰建模方法——Collision-captured Network（CN），利用海冰天然的图结构（节点为冰块、边为物理相互作用），结合数据同化（DA）提升预测效率与精度，尤其适用于边缘冰区（MIZ）建模。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法计算成本高、可扩展性差，难以高效模拟海冰动态；而海冰天然具有图结构，适合用GNN建模并融合数据同化以提升预测能力。

Method: 构建一维图神经网络模型（CN），将冰块建模为节点、碰撞等物理交互建模为边，并集成数据同化（DA）技术进行学习与预测；在合成数据上验证模型性能。

Result: CN模型在保持预测精度的同时显著加速轨迹模拟，在有/无观测数据条件下均表现良好，验证了其在边缘冰区（MIZ）预报中的有效性与高效性。

Conclusion: GNN与数据同化相结合为海冰建模提供了更高效、可扩展的新范式，有望推动机器学习与地球系统建模的深度融合。

Abstract: This paper introduces a novel approach to sea ice modeling using Graph Neural Networks (GNNs), utilizing the natural graph structure of sea ice, where nodes represent individual ice pieces, and edges model the physical interactions, including collisions. This concept is developed within a one-dimensional framework as a foundational step. Traditional numerical methods, while effective, are computationally intensive and less scalable. By utilizing GNNs, the proposed model, termed the Collision-captured Network (CN), integrates data assimilation (DA) techniques to effectively learn and predict sea ice dynamics under various conditions. The approach was validated using synthetic data, both with and without observed data points, and it was found that the model accelerates the simulation of trajectories without compromising accuracy. This advancement offers a more efficient tool for forecasting in marginal ice zones (MIZ) and highlights the potential of combining machine learning with data assimilation for more effective and efficient modeling.

</details>


### [234] [UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection](https://arxiv.org/abs/2602.16216)
*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.LG

TL;DR: 本文提出UCTECG-Net，一种结合1D卷积与Transformer编码器的不确定性感知混合架构，用于联合处理原始ECG信号及其频谱图；在MIT-BIH和PTB数据集上性能领先，并通过多种不确定性量化方法验证其预测可靠性更强。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽提升了ECG自动分类性能，但预测可靠性缺乏可解释性，限制其在安全关键场景（如临床决策）中的应用。

Method: 提出UCTECG-Net模型，融合一维卷积与Transformer编码器，联合处理原始ECG信号和其短时傅里叶变换频谱图；集成Monte Carlo Dropout、Deep Ensembles和Ensemble Monte Carlo Dropout三种不确定性量化方法，并引入不确定性感知混淆矩阵及衍生指标进行评估。

Result: 在MIT-BIH Arrhythmia和PTB Diagnostic数据集上，UCTECG-Net在准确率（最高98.58%和99.14%）、精确率、召回率和F1分数上均优于LSTM、CNN1D和纯Transformer基线；其不确定性估计（尤其使用Ensemble或EMCD时）更可靠、与实际错误更对齐。

Conclusion: UCTECG-Net不仅提升了ECG分类性能，还提供了更可信的不确定性估计，为风险感知的心电诊断决策支持系统提供了更坚实的基础。

Abstract: Deep learning has improved automated electrocardiogram (ECG) classification, but limited insight into prediction reliability hinders its use in safety-critical settings. This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outperforms LSTM, CNN1D, and Transformer baselines in terms of accuracy, precision, recall and F1 score, achieving up to 98.58% accuracy on MIT-BIH and 99.14% on PTB. To assess predictive reliability, we integrate three uncertainty quantification methods (Monte Carlo Dropout, Deep Ensembles, and Ensemble Monte Carlo Dropout) into all models and analyze their behavior using an uncertainty-aware confusion matrix and derived metrics. The results show that UCTECG-Net, particularly with Ensemble or EMCD, provides more reliable and better-aligned uncertainty estimates than competing architectures, offering a stronger basis for risk-aware ECG decision support.

</details>


### [235] [Multi-Class Boundary Extraction from Implicit Representations](https://arxiv.org/abs/2602.16217)
*Jash Vira,Andrew Myers,Simon Ratcliffe*

Main category: cs.LG

TL;DR: 本文提出了一种面向多类别隐式神经表示的2D边界提取算法，强调拓扑一致性与水密性，并支持设定最小细节约束；在地质建模数据上验证了其适应性与复杂拓扑保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法从多类别隐式表示中提取保证拓扑正确且无孔洞的表面。

Method: 提出一种2D边界提取算法，专为多类别隐式表示设计，注重拓扑一致性、水密性及可调的最小细节约束。

Result: 算法在地质建模数据上展现出良好的适应性与复杂拓扑保持能力。

Conclusion: 该工作为多类别隐式表示的表面提取奠定了基础，首次实现了拓扑正确且水密的2D边界提取。

Abstract: Surface extraction from implicit neural representations modelling a single class surface is a well-known task. However, there exist no surface extraction methods from an implicit representation of multiple classes that guarantee topological correctness and no holes. In this work, we lay the groundwork by introducing a 2D boundary extraction algorithm for the multi-class case focusing on topological consistency and water-tightness, which also allows for setting minimum detail restraint on the approximation. Finally, we evaluate our algorithm using geological modelling data, showcasing its adaptiveness and ability to honour complex topology.

</details>


### [236] [Bayesian Quadrature: Gaussian Processes for Integration](https://arxiv.org/abs/2602.16218)
*Maren Mahsereci,Toni Karvonen*

Main category: cs.LG

TL;DR: This paper provides a comprehensive survey of Bayesian quadrature, covering its mathematical foundations, a systematic taxonomy of methods, theoretical guarantees, numerical experiments, and practical challenges, along with an extensive bibliography.


<details>
  <summary>Details</summary>
Motivation: Bayesian quadrature, though introduced in the 1980s, lacks a systematic and comprehensive treatment—this survey aims to fill that gap.

Method: The authors review mathematical foundations from multiple perspectives, propose a three-axis taxonomy (modelling, inference, sampling), collect theoretical guarantees, conduct controlled numerical experiments, and compile an exhaustive bibliography across disciplines.

Result: A unified framework and taxonomy for Bayesian quadrature methods, empirical insights into design choices, identification of practical limitations, and a broad, up-to-date bibliography.

Conclusion: Bayesian quadrature is a principled probabilistic integration method with rich theoretical underpinnings and practical potential, but its application faces non-trivial challenges that require careful consideration of modelling, inference, and sampling choices.

Abstract: Bayesian quadrature is a probabilistic, model-based approach to numerical integration, the estimation of intractable integrals, or expectations. Although Bayesian quadrature was popularised already in the 1980s, no systematic and comprehensive treatment has been published. The purpose of this survey is to fill this gap. We review the mathematical foundations of Bayesian quadrature from different points of view; present a systematic taxonomy for classifying different Bayesian quadrature methods along the three axes of modelling, inference, and sampling; collect general theoretical guarantees; and provide a controlled numerical study that explores and illustrates the effect of different choices along the axes of the taxonomy. We also provide a realistic assessment of practical challenges and limitations to application of Bayesian quadrature methods and include an up-to-date and nearly exhaustive bibliography that covers not only machine learning and statistics literature but all areas of mathematics and engineering in which Bayesian quadrature or equivalent methods have seen use.

</details>


### [237] [SEMixer: Semantics Enhanced MLP-Mixer for Multiscale Mixing and Long-term Time Series Forecasting](https://arxiv.org/abs/2602.16220)
*Xu Zhang,Qitong Wang,Peng Wang,Wei Wang*

Main category: cs.LG

TL;DR: 本文提出了SEMixer，一种轻量级多尺度模型，用于长期时间序列预测，通过随机注意力机制（RAM）和多尺度渐进混合链（MPMC）解决时间序列中的冗余、噪声及跨尺度语义鸿沟问题，并在多个公开数据集及真实无线网络数据挑战赛中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 时间序列中存在冗余和噪声，且非相邻尺度间存在语义鸿沟，导致多尺度时序依赖的对齐与融合困难。

Method: 提出SEMixer模型，包含随机注意力机制（RAM）——训练时捕获多样时间块交互、推理时通过dropout集成增强块级语义；以及多尺度渐进混合链（MPMC）——以内存高效方式堆叠RAM与MLP-Mixer，弥合跨尺度语义差距。

Result: 在10个公开数据集及2025 CCF AlOps挑战赛（基于21GB真实无线网络数据）上验证有效，获得第三名。

Conclusion: SEMixer通过RAM与MPMC协同实现了更优的多尺度建模与长期预测性能，兼具轻量化与实用性。

Abstract: Modeling multiscale patterns is crucial for long-term time series forecasting (TSF). However, redundancy and noise in time series, together with semantic gaps between non-adjacent scales, make the efficient alignment and integration of multi-scale temporal dependencies challenging. To address this, we propose SEMixer, a lightweight multiscale model designed for long-term TSF. SEMixer features two key components: a Random Attention Mechanism (RAM) and a Multiscale Progressive Mixing Chain (MPMC). RAM captures diverse time-patch interactions during training and aggregates them via dropout ensemble at inference, enhancing patch-level semantics and enabling MLP-Mixer to better model multi-scale dependencies. MPMC further stacks RAM and MLP-Mixer in a memory-efficient manner, achieving more effective temporal mixing. It addresses semantic gaps across scales and facilitates better multiscale modeling and forecasting performance. We not only validate the effectiveness of SEMixer on 10 public datasets, but also on the \textit{2025 CCF AlOps Challenge} based on 21GB real wireless network data, where SEMixer achieves third place. The code is available at the link https://github.com/Meteor-Stars/SEMixer.

</details>


### [238] [Amortized Predictability-aware Training Framework for Time Series Forecasting and Classification](https://arxiv.org/abs/2602.16224)
*Xu Zhang,Peng Wang,Yichen Li,Wei Wang*

Main category: cs.LG

TL;DR: 本文提出了一种通用的摊销可预测性感知训练框架（APTF），用于时间序列预测和分类任务，通过分层可预测性感知损失（HPL）和摊销模型来识别并适度惩罚低可预测性样本，从而提升模型鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据常含噪声，部分训练样本具有低可预测性、偏离正常分布，易导致训练不稳定或陷入局部最优，现有深度学习方法少有从训练角度识别和处理这类样本。

Method: 提出APTF框架，包含两个核心设计：(i) 分层可预测性感知损失（HPL），动态识别低可预测性样本并随训练进程渐进增强其损失惩罚；(ii) 摊销模型，缓解因模型偏差导致的可预测性估计误差，提升HPL效果。

Result: APTF在时间序列预测（TSF）和时间序列分类（TSC）任务上均取得性能提升，验证了其对低可预测性样本建模的有效性与泛化能力。

Conclusion: APTF是一种通用、有效的训练机制，能增强模型对噪声和异常模式的鲁棒性，为时间序列建模提供了新的训练视角。

Abstract: Time series data are prone to noise in various domains, and training samples may contain low-predictability patterns that deviate from the normal data distribution, leading to training instability or convergence to poor local minima. Therefore, mitigating the adverse effects of low-predictability samples is crucial for time series analysis tasks such as time series forecasting (TSF) and time series classification (TSC). While many deep learning models have achieved promising performance, few consider how to identify and penalize low-predictability samples to improve model performance from the training perspective. To fill this gap, we propose a general Amortized Predictability-aware Training Framework (APTF) for both TSF and TSC. APTF introduces two key designs that enable the model to focus on high-predictability samples while still learning appropriately from low-predictability ones: (i) a Hierarchical Predictability-aware Loss (HPL) that dynamically identifies low-predictability samples and progressively expands their loss penalty as training evolves, and (ii) an amortization model that mitigates predictability estimation errors caused by model bias, further enhancing HPL's effectiveness. The code is available at https://github.com/Meteor-Stars/APTF.

</details>


### [239] [Factored Latent Action World Models](https://arxiv.org/abs/2602.16229)
*Zizhao Wang,Chang Shi,Jiaheng Hu,Kevin Rohling,Roberto Martín-Martín,Amy Zhang,Peter Stone*

Main category: cs.LG

TL;DR: 本文提出了一种分解式潜在动作模型（FLAM），通过将场景分解为独立因子，每个因子学习自身的潜在动作和状态演化，从而在无动作视频中更准确地建模多实体动态，提升视频生成与下游策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于无动作视频学习潜在动作的方法多采用整体式逆/前向动力学模型，难以处理多实体同时运动的复杂场景。

Method: 提出分解式潜在动作模型（FLAM），将场景分解为多个独立因子，每个因子分别学习对应的潜在动作并预测自身下一时刻的状态。

Result: 在仿真与真实世界多实体数据集上的实验表明，FLAM在预测精度、表征质量及下游策略学习方面均优于先前方法。

Conclusion: 因子化建模潜在动作能更准确刻画复杂多实体动态，显著提升无动作视频驱动的世界模型性能。

Abstract: Learning latent actions from action-free video has emerged as a powerful paradigm for scaling up controllable world model learning. Latent actions provide a natural interface for users to iteratively generate and manipulate videos. However, most existing approaches rely on monolithic inverse and forward dynamics models that learn a single latent action to control the entire scene, and therefore struggle in complex environments where multiple entities act simultaneously. This paper introduces Factored Latent Action Model (FLAM), a factored dynamics framework that decomposes the scene into independent factors, each inferring its own latent action and predicting its own next-step factor value. This factorized structure enables more accurate modeling of complex multi-entity dynamics and improves video generation quality in action-free video settings compared to monolithic models. Based on experiments on both simulation and real-world multi-entity datasets, we find that FLAM outperforms prior work in prediction accuracy and representation quality, and facilitates downstream policy learning, demonstrating the benefits of factorized latent action models.

</details>


### [240] [Online Prediction of Stochastic Sequences with High Probability Regret Bounds](https://arxiv.org/abs/2602.16236)
*Matthias Frey,Jonathan H. Manton,Jingge Zhu*

Main category: cs.LG

TL;DR: 本文研究了在有限时间范围内对随机序列进行通用预测的问题，提出了高概率意义下的渐近最优后悔界，并证明了该界中置信度参数δ的指数无法进一步改进。


<details>
  <summary>Details</summary>
Motivation: 现有文献中的后悔界通常只在期望意义下成立，本文旨在推导出在高概率意义下同样成立的、形式相似的后悔界。

Method: 通过构造新的预测算法并结合概率不等式分析，推导出高概率后悔界；同时利用反证法和构造性例子证明了界中δ指数的紧性。

Result: 得到了形如O(T^{-1/2} δ^{-1/2})的高概率后悔界（成功概率至少为1−δ），并证明该界中δ的指数−1/2不可改进。

Conclusion: 在无额外假设的前提下，本文提出的高概率后悔界是最优的，填补了期望界与高概率界之间的理论空白。

Abstract: We revisit the classical problem of universal prediction of stochastic sequences with a finite time horizon $T$ known to the learner. The question we investigate is whether it is possible to derive vanishing regret bounds that hold with high probability, complementing existing bounds from the literature that hold in expectation. We propose such high-probability bounds which have a very similar form as the prior expectation bounds. For the case of universal prediction of a stochastic process over a countable alphabet, our bound states a convergence rate of $\mathcal{O}(T^{-1/2} δ^{-1/2})$ with probability as least $1-δ$ compared to prior known in-expectation bounds of the order $\mathcal{O}(T^{-1/2})$. We also propose an impossibility result which proves that it is not possible to improve the exponent of $δ$ in a bound of the same form without making additional assumptions.

</details>


### [241] [Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge](https://arxiv.org/abs/2602.16264)
*Zixian Wu,Xuebao Li,Yanfang Zheng,Rui Wang,Shunhuang Zhang,Jinfang Wei,Yongshang Lv,Liang Dong,Zamri Zainal Abidin,Noraisyah Mohamed Shah,Hongwei Ye,Pengchao Yan,Xuefeng Li,Xiaojia Ji,Xusheng Huang,Xiaotian Wang,Honglei Jin*

Main category: cs.LG

TL;DR: 本文首次提出了一种带有类依赖奖励（CDR）的监督分类框架，用于预测24小时内≥MM级太阳耀斑，并结合多种深度学习模型与CDR变体，在知识驱动特征和磁图数据上进行了系统评估与可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 提升太阳耀斑短期预测精度，尤其针对高影响≥MM级事件，并解决传统模型忽略不同类别误判代价差异的问题。

Method: 构建多源数据集（含LOS与矢量磁场参数、知识驱动特征）；设计并对比CNN、CNN-BiLSTM、Transformer及其CDR变体；开展特征重要性分析、奖励敏感性实验、SHAP可解释性分析及与NASA/CCMC基准的性能对比。

Result: CDR-Transformer在知识驱动特征上表现最优；R_VALUE与AREA_ACR是最关键LOS参数；融合LOS与矢量磁场提升Transformer性能；CDR模型对奖励设定鲁棒；SHAP显示CDR更关注TOTUSJH，Transformer更关注R_VALUE；CDR-Transformer优于NASA/CCMC。

Conclusion: 引入类依赖奖励机制显著提升耀斑预测性能与实用性，CDR-Transformer是当前最优方案，且具备良好鲁棒性与可解释性。

Abstract: In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.

</details>


### [242] [Regret and Sample Complexity of Online Q-Learning via Concentration of Stochastic Approximation with Time-Inhomogeneous Markov Chains](https://arxiv.org/abs/2602.16274)
*Rahul Singh,Siddharth Chandak,Eric Moulines,Vivek S. Borkar,Nicholas Bambos*

Main category: cs.LG

TL;DR: 本文首次为经典在线Q学习在无限时域折扣MDP中提供了高概率遗憾界，无需乐观性或奖励项；提出了一种结合ε-greedy与Boltzmann探索的平滑策略，实现了近似O~(N^{9/10})的间隙鲁棒遗憾界，并发展了适用于迭代与时变转移动态的收缩型马尔可夫随机逼近的高概率集中不等式。


<details>
  <summary>Details</summary>
Motivation: 现有Q学习算法的遗憾分析常依赖乐观性或bonus项，且缺乏对小次优间隙下性能退化的理论刻画；亟需不依赖这些强假设、具备间隙鲁棒性的高概率遗憾界。

Method: 1）分析带衰减温度的Boltzmann Q-learning；2）提出Smoothed ε_n-Greedy探索机制，融合ε-greedy与Boltzmann探索；3）建立针对时变、迭代依赖转移动态的收缩型马尔可夫随机逼近的高概率集中不等式。

Result: 1）Boltzmann Q-learning在大间隙下实现次线性遗憾，小间隙下可能退化至线性；2）Smoothed ε_n-Greedy获得近似O~(N^{9/10})的间隙鲁棒高概率遗憾界；3）提出的新集中不等式中收缩因子可随混合时间渐近趋于1，具独立理论价值。

Conclusion: 本文突破了传统Q学习遗憾分析对乐观性假设的依赖，通过新探索机制与新型集中不等式，实现了首个无bonus、高概率、间隙鲁棒的在线Q学习遗憾界，推动了强化学习理论基础的发展。

Abstract: We present the first high-probability regret bound for classical online Q-learning in infinite-horizon discounted Markov decision processes, without relying on optimism or bonus terms. We first analyze Boltzmann Q-learning with decaying temperature and show that its regret depends critically on the suboptimality gap of the MDP: for sufficiently large gaps, the regret is sublinear, while for small gaps it deteriorates and can approach linear growth. To address this limitation, we study a Smoothed $ε_n$-Greedy exploration scheme that combines $ε_n$-greedy and Boltzmann exploration, for which we prove a gap-robust regret bound of near-$\tilde{O}(N^{9/10})$. To analyze these algorithms, we develop a high-probability concentration bound for contractive Markovian stochastic approximation with iterate- and time-dependent transition dynamics. This bound may be of independent interest as the contraction factor in our bound is governed by the mixing time and is allowed to converge to one asymptotically.

</details>


### [243] [Fast KV Compaction via Attention Matching](https://arxiv.org/abs/2602.16284)
*Adam Zweiger,Xinghong Fu,Han Guo,Yoon Kim*

Main category: cs.LG

TL;DR: 本文提出了一种基于注意力匹配（Attention Matching）的快速上下文压缩方法，能在潜在空间中高效构建紧凑的键值缓存（KV cache），在极短时间内实现高达50倍压缩且几乎不损失性能。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文语言模型受限于KV缓存大小；传统token级摘要压缩损失大、性能下降明显；Cartridges等潜空间压缩方法虽效果好但优化慢、开销高。

Method: 提出注意力匹配框架，在潜空间中构造紧凑KV，以精确复现原始注意力输出并保持每KV头的注意力质量；该问题可分解为若干子问题，部分有闭式解，从而实现快速压缩。

Result: 所提方法显著提升了压缩时间与质量的Pareto前沿，在某些数据集上可在数秒内完成50倍压缩，且质量损失极小。

Conclusion: 注意力匹配是一种高效、可扩展的潜空间KV缓存压缩范式，兼顾速度与精度，适用于实际部署场景。

Abstract: Scaling language models to long contexts is often bottlenecked by the size of the key-value (KV) cache. In deployed settings, long contexts are typically managed through compaction in token space via summarization. However, summarization can be highly lossy, substantially harming downstream performance. Recent work on Cartridges has shown that it is possible to train highly compact KV caches in latent space that closely match full-context performance, but at the cost of slow and expensive end-to-end optimization. This work describes an approach for fast context compaction in latent space through Attention Matching, which constructs compact keys and values to reproduce attention outputs and preserve attention mass at a per-KV-head level. We show that this formulation naturally decomposes into simple subproblems, some of which admit efficient closed-form solutions. Within this framework, we develop a family of methods that significantly push the Pareto frontier of compaction time versus quality, achieving up to 50x compaction in seconds on some datasets with little quality loss.

</details>


### [244] [A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.16316)
*Guy Bar-Shalom,Ami Tavory,Itay Evron,Maya Bechler-Speicher,Ido Guy,Haggai Maron*

Main category: cs.LG

TL;DR: 本文提出了WS-KAN，首个专为Kolmogorov-Arnold Networks（KANs）设计的权重空间模型，利用其与MLPs共享的置换对称性，通过新提出的KAN-graph表示，并在多个任务上显著优于无结构基线。


<details>
  <summary>Details</summary>
Motivation: 现有权重空间模型在KANs上缺乏对称性分析与专用架构，限制了其性能；需填补该空白并提升KAN参数级学习能力。

Method: 发现KANs具有与MLPs相同的置换对称性，提出KAN-graph图表示，并基于此构建首个KAN专用权重空间模型WS-KAN，理论分析其表达能力（可复现输入KAN前向传播），并在自建KAN模型‘zoo’上实证评估。

Result: WS-KAN在所有测试任务中持续超越结构无关基线，常有显著优势；理论证明其能精确复现输入KAN的前向计算。

Conclusion: KANs具备可被利用的对称性，WS-KAN是首个有效建模KAN权重空间的架构，为KAN元学习与神经网络参数预测开辟新路径。

Abstract: Weight-space models learn directly from the parameters of neural networks, enabling tasks such as predicting their accuracy on new datasets. Naive methods -- like applying MLPs to flattened parameters -- perform poorly, making the design of better weight-space architectures a central challenge. While prior work leveraged permutation symmetries in standard networks to guide such designs, no analogous analysis or tailored architecture yet exists for Kolmogorov-Arnold Networks (KANs). In this work, we show that KANs share the same permutation symmetries as MLPs, and propose the KAN-graph, a graph representation of their computation. Building on this, we develop WS-KAN, the first weight-space architecture that learns on KANs, which naturally accounts for their symmetry. We analyze WS-KAN's expressive power, showing it can replicate an input KAN's forward pass - a standard approach for assessing expressiveness in weight-space architectures. We construct a comprehensive ``zoo'' of trained KANs spanning diverse tasks, which we use as benchmarks to empirically evaluate WS-KAN. Across all tasks, WS-KAN consistently outperforms structure-agnostic baselines, often by a substantial margin. Our code is available at https://github.com/BarSGuy/KAN-Graph-Metanetwork.

</details>


### [245] [Guide-Guard: Off-Target Predicting in CRISPR Applications](https://arxiv.org/abs/2602.16327)
*Joseph Bingham,Netanel Arussy,Saman Zonouz*

Main category: cs.LG

TL;DR: 本文提出了一种名为Guide-Guard的机器学习方法，用于预测CRISPR基因编辑中gRNA的脱靶行为，准确率达84%，且支持多基因联合训练。


<details>
  <summary>Details</summary>
Motivation: 随着CRISPR等基因编辑技术的发展，预测其脱靶效应成为关键挑战。

Method: 从数据驱动角度建模，并开发基于机器学习的Guide-Guard模型。

Result: Guide-Guard在预测gRNA脱靶行为上达到84%准确率，支持多基因联合训练并保持性能。

Conclusion: 该方法为提升CRISPR编辑安全性提供了可扩展、高精度的数据驱动解决方案。

Abstract: With the introduction of cyber-physical genome sequencing and editing technologies, such as CRISPR, researchers can more easily access tools to investigate and create remedies for a variety of topics in genetics and health science (e.g. agriculture and medicine). As the field advances and grows, new concerns present themselves in the ability to predict the off-target behavior. In this work, we explore the underlying biological and chemical model from a data driven perspective. Additionally, we present a machine learning based solution named \textit{Guide-Guard} to predict the behavior of the system given a gRNA in the CRISPR gene-editing process with 84\% accuracy. This solution is able to be trained on multiple different genes at the same time while retaining accuracy.

</details>


### [246] [HAWX: A Hardware-Aware FrameWork for Fast and Scalable ApproXimation of DNNs](https://arxiv.org/abs/2602.16336)
*Samira Nazari,Mohammad Saeed Almasi,Mahdi Taheri,Ali Azarpeyvand,Ali Mokhtari,Ali Mahani,Christian Herglotz*

Main category: cs.LG

TL;DR: HAWX是一个硬件感知的可扩展探索框架，通过在不同DNN抽象层级（算子、滤波器、层、模型）进行多级敏感性评分，指导异构近似计算（AxC）模块的选择性集成，并利用预测模型加速候选配置评估，在保持精度的同时显著提升搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有DNN硬件加速器设计中，近似计算（AxC）模块的集成缺乏系统性、可扩展的硬件感知搜索方法，导致搜索空间大、评估开销高，难以兼顾精度与硬件效率。

Method: 提出HAWX框架，采用多级敏感性评分机制（覆盖算子、滤波器、层、模型四级），结合精度/功耗/面积预测模型，实现对异构AxC块集成方案的快速评估；支持空间与时间架构，兼容商用或定制近似组件。

Result: 在LeNet-5上滤波器级搜索获得超10^6倍加速，层级别搜索加速23倍以上；在VGG-11、ResNet-18、EfficientNetLite等模型上验证了加速效果随网络规模呈指数增长，且精度与穷举搜索相当。

Conclusion: HAWX为DNN硬件加速器中异构近似计算的部署提供了高效、可扩展、硬件感知的自动化搜索范式，显著降低设计周期，适用于多种架构与组件来源。

Abstract: This work presents HAWX, a hardware-aware scalable exploration framework that employs multi-level sensitivity scoring at different DNN abstraction levels (operator, filter, layer, and model) to guide selective integration of heterogeneous AxC blocks. Supported by predictive models for accuracy, power, and area, HAWX accelerates the evaluation of candidate configurations, achieving over 23* speedup in a layer-level search with two candidate approximate blocks and more than (3*106)* speedup at the filter-level search only for LeNet-5, while maintaining accuracy comparable to exhaustive search. Experiments across state-of-the-art DNN benchmarks such as VGG-11, ResNet-18, and EfficientNetLite demonstrate that the efficiency benefits of HAWX scale exponentially with network size. The HAWX hardware-aware search algorithm supports both spatial and temporal accelerator architectures, leveraging either off-the-shelf approximate components or customized designs.

</details>


### [247] [The Implicit Bias of Adam and Muon on Smooth Homogeneous Neural Networks](https://arxiv.org/abs/2602.16340)
*Eitan Gronich,Gal Vardi*

Main category: cs.LG

TL;DR: 本文研究了动量优化器在齐次模型中的隐式偏差，证明了多种动量类算法（如Muon、MomentumGD、Signum、Adam等）在衰减学习率下近似于某种范数下的最速下降轨迹，因而隐式偏向对应范数下间隔最大化问题的KKT点。


<details>
  <summary>Details</summary>
Motivation: 理解动量类优化器在深度学习训练中为何能泛化良好，特别是其隐式正则化效应（即隐式偏差）在齐次模型中的表现。

Method: 理论分析：将最速下降法在齐次模型中的隐式偏差结果推广到归一化最速下降及带学习率调度的情形；证明多种动量优化器（Muon、MomentumGD、Signum、Adam及其组合）在衰减学习率下逼近特定范数下的最速下降轨迹；结合KKT条件分析其收敛到的解的几何性质。

Result: 证明了Muon（谱范数）、MomentumGD（ℓ₂范数）、Signum（ℓ∞范数）、Adam（ℓ∞范数）、Muon-Signum与Muon-Adam（混合范数）均隐式最大化各自对应范数下的分类间隔，并通过实验验证不同优化器导致不同范数下的最大间隔解。

Conclusion: 动量类优化器在齐次模型中具有明确的隐式偏差——它们趋向于特定范数下的最大间隔解，该范数由优化器所采用的范数结构决定；这统一并推广了此前关于最速下降和线性模型中动量法的隐式偏差研究。

Abstract: We study the implicit bias of momentum-based optimizers on homogeneous models. We first extend existing results on the implicit bias of steepest descent in homogeneous models to normalized steepest descent with an optional learning rate schedule. We then show that for smooth homogeneous models, momentum steepest descent algorithms like Muon (spectral norm), MomentumGD ($\ell_2$ norm), and Signum ($\ell_\infty$ norm) are approximate steepest descent trajectories under a decaying learning rate schedule, proving that these algorithms too have a bias towards KKT points of the corresponding margin maximization problem. We extend the analysis to Adam (without the stability constant), which maximizes the $\ell_\infty$ margin, and to Muon-Signum and Muon-Adam, which maximize a hybrid norm. Our experiments corroborate the theory and show that the identity of the margin maximized depends on the choice of optimizer. Overall, our results extend earlier lines of work on steepest descent in homogeneous models and momentum-based optimizers in linear models.

</details>


### [248] [Explainability for Fault Detection System in Chemical Processes](https://arxiv.org/abs/2602.16341)
*Georgios Gravanis,Dimitrios Kyriakou,Spyros Voutetakis,Simira Papadopoulou,Konstantinos Diamantaras*

Main category: cs.LG

TL;DR: 本文应用并比较了两种先进的可解释人工智能（XAI）方法——集成梯度（IG）和SHAP，用于解释LSTM故障诊断模型在田纳西伊斯曼过程（TEP）中的决策，验证其识别故障子系统的能力，并指出SHAP在部分情况下更贴近故障根源。


<details>
  <summary>Details</summary>
Motivation: 提升深度学习模型（如LSTM）在工业故障诊断中的可信度与可解释性，帮助工程师理解模型为何做出特定诊断决策，并定位故障发生的具体子系统。

Method: 采用模型无关的XAI方法Integrated Gradients（IG）和SHAP，对在TEP数据集上训练的高精度LSTM分类器进行事后解释分析，结合领域知识评估各方法识别关键特征与故障根因的一致性。

Result: IG和SHAP在多数情况下识别出相同的关键特征；SHAP在部分故障场景中展现出更强的根因定位能力；两种方法均能有效指向故障发生的子系统；该XAI框架具有跨过程迁移潜力。

Conclusion: IG与SHAP均可有效增强LSTM故障诊断模型的可解释性，尤其有助于子系统级故障归因；SHAP在机理一致性方面略优；所提XAI流程具备通用性和工程实用性。

Abstract: In this work, we apply and compare two state-of-the-art eXplainability Artificial Intelligence (XAI) methods, the Integrated Gradients (IG) and the SHapley Additive exPlanations (SHAP), that explain the fault diagnosis decisions of a highly accurate Long Short-Time Memory (LSTM) classifier. The classifier is trained to detect faults in a benchmark non-linear chemical process, the Tennessee Eastman Process (TEP). It is highlighted how XAI methods can help identify the subsystem of the process where the fault occurred. Using our knowledge of the process, we note that in most cases the same features are indicated as the most important for the decision, while insome cases the SHAP method seems to be more informative and closer to the root cause of the fault. Finally, since the used XAI methods are model-agnostic, the proposed approach is not limited to the specific process and can also be used in similar problems.

</details>


### [249] [Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks](https://arxiv.org/abs/2602.16357)
*Sarkis Ter Martirosyan,Xinyue Huang,David Qin,Anthony Yu,Stanislav Emelianov*

Main category: cs.LG

TL;DR: 本文提出了一种名为SPOI-AE的自动编码器，用于解决光声光谱成像中非线性和病态性导致的染色体浓度估计难题，无需线性假设，并在活体小鼠淋巴结图像上验证了其重建精度与生物合理性。


<details>
  <summary>Details</summary>
Motivation: 光声光谱（sPA）成像中染色体相对浓度的准确估计对揭示生理结构、功能和分子信息至关重要，但因非线性和病态性问题，浓度估计难以实现。

Method: 提出了Spectroscopic Photoacoustic Optical Inversion Autoencoder（SPOI-AE），不依赖线性假设，直接学习sPA光学反演与光谱解混；在未知真实浓度的活体小鼠淋巴结sPA图像上进行训练与测试，并用模拟淋巴结体模真值验证解混精度。

Result: SPOI-AE比传统算法更优地重建输入sPA像素，并提供生物学上一致的光学参数、染色体浓度及组织氧饱和度估计；在模拟体模验证中表现出高解混精度。

Conclusion: SPOI-AE是一种有效应对sPA成像非线性与病态性的数据驱动方法，可提升染色体定量分析的准确性与可靠性，具有潜在的生物医学应用价值。

Abstract: Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth.

</details>


### [250] [Improved Bounds for Reward-Agnostic and Reward-Free Exploration](https://arxiv.org/abs/2602.16363)
*Oran Ridel,Alon Cohen*

Main category: cs.LG

TL;DR: 本文研究了无奖励和奖励无关的探索问题，在不观察外部奖励的情况下，提出了一种新算法，显著放宽了对精度参数ε的要求，并建立了无奖励探索的紧下界。


<details>
  <summary>Details</summary>
Motivation: 现有方法在reward-agnostic设置中仅对极小的精度参数ε达到最优样本复杂度，限制了实用性；同时reward-free探索的上下界存在差距。

Method: 提出一种新算法，结合在线学习与精心设计的内部奖励来构建探索策略，以收集足够数据用于动力学估计，并在奖励揭示后计算ε-最优策略。

Result: 显著放宽了reward-agnostic探索中对ε的限制；建立了reward-free探索的紧下界，填补了已知上下界之间的空白。

Conclusion: 所提算法在理论和技术上均有创新，提升了reward-agnostic探索的适用性，并完善了reward-free探索的理论边界。

Abstract: We study reward-free and reward-agnostic exploration in episodic finite-horizon Markov decision processes (MDPs), where an agent explores an unknown environment without observing external rewards. Reward-free exploration aims to enable $ε$-optimal policies for any reward revealed after exploration, while reward-agnostic exploration targets $ε$-optimality for rewards drawn from a small finite class. In the reward-agnostic setting, Li, Yan, Chen, and Fan achieve minimax sample complexity, but only for restrictively small accuracy parameter $ε$. We propose a new algorithm that significantly relaxes the requirement on $ε$. Our approach is novel and of technical interest by itself. Our algorithm employs an online learning procedure with carefully designed rewards to construct an exploration policy, which is used to gather data sufficient for accurate dynamics estimation and subsequent computation of an $ε$-optimal policy once the reward is revealed. Finally, we establish a tight lower bound for reward-free exploration, closing the gap between known upper and lower bounds.

</details>


### [251] [Easy Data Unlearning Bench](https://arxiv.org/abs/2602.16400)
*Roy Rinberg,Pol Puigdemont,Martin Pawelczyk,Volkan Cevher*

Main category: cs.LG

TL;DR: 本文提出了一种统一且可扩展的机器遗忘评估基准套件，采用KLoM（边缘KL散度）指标简化评估流程，提供预计算模型集成、Oracle输出和即用型基础设施，以支持可复现、可扩展和公平的方法比较。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法评估技术难度大，基准测试设置复杂、工程开销高，缺乏标准化的评估框架。

Method: 设计并实现一个基于KLoM指标的统一基准套件，集成预计算模型、Oracle输出与轻量级运行基础设施，支持开箱即用的评估。

Result: 该基准显著降低了评估门槛，提升了不同遗忘算法间比较的可复现性、可扩展性与公平性。

Conclusion: 该基准为机器遗忘研究提供了实用基础，有望加速领域发展并推动最佳实践落地。

Abstract: Evaluating machine unlearning methods remains technically challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and streamlined infrastructure for running evaluations out of the box. By standardizing setup and metrics, it enables reproducible, scalable, and fair comparison across unlearning methods. We aim for this benchmark to serve as a practical foundation for accelerating research and promoting best practices in machine unlearning. Our code and data are publicly available.

</details>


### [252] [Learning with Locally Private Examples by Inverse Weierstrass Private Stochastic Gradient Descent](https://arxiv.org/abs/2602.16436)
*Jean Dufraiche,Paul Mangold,Michaël Perrot,Marc Tommasi*

Main category: cs.LG

TL;DR: 本文提出了一种基于Weierstrass变换的偏差校正方法，用于在非交互式本地差分隐私（LDP）下释放数据时消除二元分类中因噪声引入的偏差，并设计了新型优化算法IWP-SGD，理论证明其收敛速率为O(1/n)，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 非交互式本地差分隐私（LDP）虽支持数据一次性发布与重用，但引入的噪声会导致后续分析（尤其是二元分类）出现偏差，亟需偏差校正机制。

Method: 利用Weierstrass变换建模LDP释放数据带来的偏差，通过逆变换实现非线性函数的无偏估计，并据此构建新型随机梯度下降算法IWP-SGD。

Result: IWP-SGD理论上以O(1/n)速率收敛至真实总体风险最小化器，并在合成与真实数据集的二元分类任务中验证了其有效性。

Conclusion: 逆Weierstrass变换可有效校正LDP下的统计偏差，IWP-SGD为非交互式LDP下的高效无偏学习提供了新范式。

Abstract: Releasing data once and for all under noninteractive Local Differential Privacy (LDP) enables complete data reusability, but the resulting noise may create bias in subsequent analyses. In this work, we leverage the Weierstrass transform to characterize this bias in binary classification. We prove that inverting this transform leads to a bias-correction method to compute unbiased estimates of nonlinear functions on examples released under LDP. We then build a novel stochastic gradient descent algorithm called Inverse Weierstrass Private SGD (IWP-SGD). It converges to the true population risk minimizer at a rate of $\mathcal{O}(1/n)$, with $n$ the number of examples. We empirically validate IWP-SGD on binary classification tasks using synthetic and real-world datasets.

</details>


### [253] [Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment](https://arxiv.org/abs/2602.16438)
*Eva Paraschou,Line Harder Clemmensen,Sneha Das*

Main category: cs.LG

TL;DR: 本文研究了大语言模型（LLM）在针对单一敏感属性（如性别）进行公平性对齐时，可能引发其他未目标敏感属性上的偏见溢出（bias spillover）问题；实验发现，在模糊语境下，对性别进行对齐反而显著加剧了外貌、性取向和残障状态等维度的不公平，强调需构建上下文感知、多属性联合评估的公平性框架。


<details>
  <summary>Details</summary>
Motivation: 现有LLM公平性对齐方法多聚焦于单敏感属性，忽视公平性的多维性与情境依赖性，易导致未被关注属性上的偏见溢出，而该问题在LLM领域尚未被系统研究。

Method: 采用直接偏好优化（DPO）方法，在Mistral 7B、Llama 3.1 8B和Qwen 2.5 7B三个主流LLM上开展性别对齐，并基于BBQ基准，在模糊与明确语境下评估其对九个敏感属性的公平性影响。

Result: 观察到显著的偏见溢出效应：整体指标改善掩盖了模糊语境下的严重退化，尤其在外貌（p<0.001）、性取向和残障状态维度；单一属性对齐在不确定性下会加剧其他维度的不公平。

Conclusion: LLM公平性对齐必须超越单属性范式，引入上下文感知与多属性协同评估机制，以避免偏见转移与隐性歧视加剧。

Abstract: Conventional large language model (LLM) fairness alignment largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While extensively studied in machine learning, bias spillover remains critically underexplored in LLM alignment. In this work, we investigate how targeted gender alignment affects fairness across nine sensitive attributes in three state-of-the-art LLMs (Mistral 7B, Llama 3.1 8B, Qwen 2.5 7B). Using Direct Preference Optimization and the BBQ benchmark, we evaluate fairness under ambiguous and disambiguous contexts. Our findings reveal noticeable bias spillover: while aggregate results show improvements, context-aware analysis exposes significant degradations in ambiguous contexts, particularly for physical appearance ($p< 0.001$ across all models), sexual orientation, and disability status. We demonstrate that improving fairness along one attribute can inadvertently worsen disparities in others under uncertainty, highlighting the necessity of context-aware, multi-attribute fairness evaluation frameworks.

</details>


### [254] [Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA](https://arxiv.org/abs/2602.16442)
*Kamil Jeziorek,Piotr Wzorek,Krzysztof Blachut,Hiroshi Nakano,Manon Dampfhoffer,Thomas Mesquida,Hiroaki Nishi,Thomas Dalgaty,Tomasz Kryjak*

Main category: cs.LG

TL;DR: 本文提出了一种面向事件驱动音频处理的FPGA实现的事件图神经网络架构，利用人工耳蜗将时序信号转为稀疏事件流，在SHD和SSC数据集上实现了高精度、低参数量、低延迟与低功耗的硬件加速效果，首次实现了端到端事件音频关键词检测的FPGA部署。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式边缘传感器（尤其是产生离散事件流的神经形态设备）采集的数据量激增，亟需硬件感知的神经网络架构，以支持高效、低延迟、低功耗的本地处理。

Method: 基于事件图神经网络设计FPGA实现方案，结合人工耳蜗将音频时序信号转换为稀疏事件流，并在SoC FPGA上部署浮点与量化模型；融合图卷积层与循环序列建模，实现端到端事件驱动关键词检测（KWS）。

Result: 在SHD数据集上浮点模型达92.7%准确率（仅比SOTA低2.4%），参数量减少10倍以上；在SSC上达66.9–71.0%准确率；量化模型在SHD上达92.3%，较FPGA上其他脉冲神经网络高最多19.3%；首次在FPGA上完成SSC硬件评估；KWS系统实现最高95%词尾检测准确率，延迟仅10.53微秒，功耗1.18W。

Conclusion: 该工作验证了事件图神经网络在FPGA上的可行性与优越性，为事件驱动音频处理提供了高效、低功耗的硬件加速新范式，尤其在关键词检测任务中树立了能效基准。

Abstract: As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.

</details>


### [255] [GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation](https://arxiv.org/abs/2602.16449)
*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

Main category: cs.LG

TL;DR: 本文提出Generative ICDM（GICDM）方法，用于校正生成模型评估中因hubness现象导致的最近邻关系失真问题，并通过多尺度扩展提升性能，在合成与真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成模型评估常依赖高维嵌入空间计算样本距离，但该空间中的hubness现象会扭曲最近邻关系、偏差距离度量，影响评估可靠性。

Method: 基于经典Iterative Contextual Dissimilarity Measure（ICDM），提出Generative ICDM（GICDM），对真实与生成数据的邻域估计进行校正，并引入多尺度扩展以改善经验表现。

Result: 在合成与真实基准数据集上的大量实验表明，GICDM能解决hubness引发的评估失效问题，恢复距离度量的可靠性，并提升与人类判断的一致性。

Conclusion: GICDM是一种有效缓解hubness对生成模型评估干扰的新方法，提升了距离度量的鲁棒性与语义合理性。

Abstract: Generative model evaluation commonly relies on high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we introduce Generative ICDM (GICDM), a method to correct neighborhood estimation for both real and generated data. We introduce a multi-scale extension to improve empirical behavior. Extensive experiments on synthetic and real benchmarks demonstrate that GICDM resolves hubness-induced failures, restores reliable metric behavior, and improves alignment with human judgment.

</details>


### [256] [Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC](https://arxiv.org/abs/2602.16456)
*Abdulla Jasem Almansoori,Maria Ivanova,Andrey Veprikov,Aleksandr Beznosikov,Samuel Horváth,Martin Takáč*

Main category: cs.LG

TL;DR: 本文提出LoRSum方法，通过交替最小二乘更新高效求解LoRA优化的近端子问题，弥合了LoRA与全步长低秩投影（SVDLoRA）之间的差距，并支持低秩动量更新和预条件梯度下降，兼顾内存效率与性能。


<details>
  <summary>Details</summary>
Motivation: 解决LoRA微调与全步长低秩投影（SVDLoRA）之间的性能差距，同时保持LoRA的参数与内存效率。

Method: 提出LoRSum子程序，将LoRA优化建模为近端子问题，用交替最小二乘法高效求解，并证明其等价于隐式块幂法；进一步扩展为支持K-FAC、Shampoo等结构化预条件器的缩放版本。

Result: 在合成任务、CIFAR-100、GLUE、SQuAD v2和WikiText-103上实验表明，LoRSum在小幅计算开销下可达到或超越LoRA基线，无需全矩阵SVD且保持低参数量。

Conclusion: LoRSum是一种内存高效、理论有保证、可扩展至预条件优化的LoRA改进方法，统一并推广了多种现有低秩优化技术。

Abstract: Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. In this work, we address the gap between training with full steps with low-rank projections (SVDLoRA) and LoRA fine-tuning. We propose LoRSum, a memory-efficient subroutine that closes this gap for gradient descent by casting LoRA optimization as a proximal sub-problem and solving it efficiently with alternating least squares updates, which we prove to be an implicit block power method. We recover several recently proposed preconditioning methods for LoRA as special cases, and show that LoRSum can also be used for updating a low-rank momentum. In order to address full steps with preconditioned gradient descent, we propose a scaled variant of LoRSum that uses structured metrics such as K-FAC and Shampoo, and we show that storing the diagonal of these metrics still allows them to perform well while remaining memory-efficient. Experiments on a synthetic task, CIFAR-100, and language-model fine-tuning on GLUE, SQuAD v2, and WikiText-103, show that our method can match or improve LoRA baselines given modest compute overhead, while avoiding full-matrix SVD projections and retaining LoRA-style parameter efficiency.

</details>


### [257] [HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting](https://arxiv.org/abs/2602.16468)
*Jung Min Choi,Vijaya Krishna Yalavarthi,Lars Schmidt-Thieme*

Main category: cs.LG

TL;DR: 本文提出了一种名为分层补丁混合器（HPMixer）的新模型，用于长期多元时间序列预测，通过解耦建模周期性与残差动态，并结合可学习小波变换与多尺度分层补丁机制，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 在长期多元时间序列预测中，有效捕获周期模式和残差动态至关重要，但现有方法常将二者耦合建模，限制了表达能力与鲁棒性。

Method: HPMixer包含两个核心分支：1）周期分支采用带非线性通道MLP增强的可学习周期模块；2）残差分支使用可学习平稳小波变换（LSWT）提取频域表示，并经通道混合编码器和两级非重叠分层补丁机制建模多尺度残差变化。

Result: 在标准多元时间序列基准数据集上，HPMixer取得竞争性甚至SOTA的预测性能。

Conclusion: 解耦周期与残差建模、结合频域稳定表征与多尺度时域结构，是提升长期多元时间序列预测效果的有效范式。

Abstract: In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.

</details>


### [258] [Synthesis and Verification of Transformer Programs](https://arxiv.org/abs/2602.16473)
*Hongjian Jiang,Matthew Hague,Philipp Rümmer,Anthony Widjaja Lin*

Main category: cs.LG

TL;DR: 本文提出了C-RASP语言的自动验证与学习新方法，通过连接Lustre数据流程序验证技术实现高效验证，并设计基于局部搜索的学习算法，应用于Transformer程序优化与约束学习。


<details>
  <summary>Details</summary>
Motivation: C-RASP作为能表达Transformer能力的编程语言，其自动验证与学习缺乏有效方法，亟需提升可验证性与可学习性。

Method: 1）建立C-RASP与Lustre同步数据流程序的语义关联，复用先进SMT模型检测器；2）提出基于局部搜索的C-RASP示例学习算法。

Result: 实现了C-RASP的高效自动验证与从示例中学习，并在Transformer程序优化和基于部分规约的约束学习等基准任务上验证了有效性。

Conclusion: 所提验证与学习技术显著提升了C-RASP的实用性，为Transformer可解释性、可靠性与可控学习提供了新路径。

Abstract: C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).

</details>


### [259] [Fast and Scalable Analytical Diffusion](https://arxiv.org/abs/2602.16498)
*Xinyi Shang,Peng Sun,Jingyu Lin,Zhiqiang Shen*

Main category: cs.LG

TL;DR: 本文提出GoldDiff，一种无需训练的扩散模型框架，通过动态选择‘黄金子集’来加速推理，实现71倍加速并在ImageNet-1K上首次成功扩展分析型扩散模型。


<details>
  <summary>Details</summary>
Motivation: 分析型扩散模型虽具数学可解释性，但其标准形式需在每步推理中扫描全量数据，计算开销随数据集线性增长，严重制约可扩展性。

Method: 基于‘后验渐进集中’现象，提出动态时序感知的黄金子集扩散（GoldDiff），采用由粗到精的机制在推理时动态定位关键数据子集，并提供稀疏近似收敛至精确分数的理论保证。

Result: 在AFHQ上实现71倍加速且性能不降反升；首次在ImageNet-1K上成功运行分析型扩散模型，验证其大规模可扩展性。

Conclusion: GoldDiff打破了分析型扩散模型对全数据扫描的依赖，确立了一种可扩展、无需再训练的大规模生成建模范式。

Abstract: Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is necessary, uncovering the phenomenon of Posterior Progressive Concentration: the effective golden support of the denoising score is not static but shrinks asymptotically from the global manifold to a local neighborhood as the signal-to-noise ratio increases. Capitalizing on this, we propose Dynamic Time-Aware Golden Subset Diffusion (GoldDiff), a training-free framework that decouples inference complexity from dataset size. Instead of static retrieval, GoldDiff uses a coarse-to-fine mechanism to dynamically pinpoint the ''Golden Subset'' for inference. Theoretically, we derive rigorous bounds guaranteeing that our sparse approximation converges to the exact score. Empirically, GoldDiff achieves a $\bf 71 \times$ speedup on AFHQ while matching or achieving even better performance than full-scan baselines. Most notably, we demonstrate the first successful scaling of analytical diffusion to ImageNet-1K, unlocking a scalable, training-free paradigm for large-scale generative modeling.

</details>


### [260] [Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects](https://arxiv.org/abs/2602.16503)
*Vasilis Gkolemis,Loukas Kavouras,Dimitrios Kyriakopoulos,Konstantinos Tsopelas,Dimitrios Rontogiannis,Giuseppe Casalicchio,Theodore Dalamagas,Christos Diou*

Main category: cs.LG

TL;DR: 本文提出了一种新型可解释模型CALMs，通过为每个特征定义多个局部区域相关的单变量形状函数，在保持局部可加性的同时捕捉特征交互，兼顾了GAMs的可解释性和GA²Ms的准确性。


<details>
  <summary>Details</summary>
Motivation: GAMs虽可解释但难以建模特征交互；GA²Ms虽提升精度却牺牲可解释性与可审计性。需一种兼顾二者的新模型。

Method: 提出条件可加局部模型（CALMs），每个特征具有多个基于交互特征阈值划分的区域专属单变量形状函数；采用基于蒸馏的训练流程，结合区域感知的后向拟合进行学习。

Result: 在多类分类与回归任务上，CALMs持续优于GAMs，精度媲美GA²Ms。

Conclusion: CALMs在预测精度与模型可解释性之间实现了更优平衡，是一种有前景的可解释机器学习新范式。

Abstract: Generalized additive models (GAMs) offer interpretability through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model auditing. We propose \emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs allow multiple univariate shape functions per feature, each active in different regions of the input space. These regions are defined independently for each feature as simple logical conditions (thresholds) on the features it interacts with. As a result, effects remain locally additive while varying across subregions to capture interactions. We further propose a principled distillation-based training pipeline that identifies homogeneous regions with limited interactions and fits interpretable shape functions via region-aware backfitting. Experiments on diverse classification and regression tasks show that CALMs consistently outperform GAMs and achieve accuracy comparable with GA$^2$Ms. Overall, CALMs offer a compelling trade-off between predictive accuracy and interpretability.

</details>


### [261] [Small molecule retrieval from tandem mass spectrometry: what are we optimizing for?](https://arxiv.org/abs/2602.16507)
*Gaetan De Waele,Marek Wydmuch,Krzysztof Dembczyński,Wojciech Kotłowski,Willem Waegeman*

Main category: cs.LG

TL;DR: 本文研究了在LC-MS/MS数据分析中用于分子指纹预测的深度学习模型所采用的不同损失函数对性能的影响，揭示了指纹相似性与分子检索准确性之间存在根本性权衡。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习方法被广泛用于LC-MS/MS谱图的化合物识别，但不同损失函数对模型性能的影响尚不清楚。

Method: 通过理论分析，推导了常用损失函数的新型遗憾界（regret bounds），刻画其贝叶斯最优决策发生分歧的条件，并分析指纹预测精度与分子检索效果之间的关系。

Result: 发现优化指纹预测准确率通常会损害分子检索性能，反之亦然；该权衡取决于候选化合物集合的相似性结构。

Conclusion: 损失函数和分子指纹的选择应依据候选集的相似性结构进行权衡，不能单纯追求指纹预测精度。

Abstract: One of the central challenges in the computational analysis of liquid chromatography-tandem mass spectrometry (LC-MS/MS) data is to identify the compounds underlying the output spectra. In recent years, this problem is increasingly tackled using deep learning methods. A common strategy involves predicting a molecular fingerprint vector from an input mass spectrum, which is then used to search for matches in a chemical compound database. While various loss functions are employed in training these predictive models, their impact on model performance remains poorly understood. In this study, we investigate commonly used loss functions, deriving novel regret bounds that characterize when Bayes-optimal decisions for these objectives must diverge. Our results reveal a fundamental trade-off between the two objectives of (1) fingerprint similarity and (2) molecular retrieval. Optimizing for more accurate fingerprint predictions typically worsens retrieval results, and vice versa. Our theoretical analysis shows this trade-off depends on the similarity structure of candidate sets, providing guidance for loss function and fingerprint selection.

</details>


### [262] [Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study](https://arxiv.org/abs/2602.16523)
*Gerhard Stenzel,Isabella Debelic,Michael Kölle,Tobias Rohe,Leo Sünkel,Julian Hager,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 本文将定向量子电路合成（DQCS）与强化学习结合，支持连续单量子比特旋转门（Rx, Ry, Rz），提出一阶段（联合选门与角度）和两阶段（先选离散结构再优化角度）训练方法；PPO算法在稳定超参下成功，A2C失败；两种方法对基态和贝尔态制备成功率较高，但可扩展性受限于λ≈3–4及量子比特数；一阶段PPO更实用高效。


<details>
  <summary>Details</summary>
Motivation: 传统DQCS仅支持离散门选择，难以高效合成含参数化旋转的量子态；需探索强化学习在连续动作空间下的适用性与可扩展性。

Method: 基于Gymnasium和PennyLane实现强化学习框架，对比PPO与A2C算法；设计一阶段（端到端选门类型、作用量子比特、旋转角）与两阶段（先离散选路、再用Adam+参数移位法优化角度）训练范式；在2–10量子比特系统上评估不同目标复杂度（λ=1–5）。

Result: PPO在一阶段（lr≈5e-4，自保真度误差阈值0.01）和两阶段（lr≈1e-4）下均成功，A2C完全失效；基态制备成功率83%–99%，贝尔态61%–77%；但λ≥3–4或10量子比特时性能饱和；两阶段精度提升微弱但耗时约三倍。

Conclusion: 一阶段PPO是更实用的参数化量子态制备方案；当前方法存在可扩展性瓶颈；建议以该策略为基准，并与经典变分方法对比以探索进一步提升路径。

Abstract: We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations \(R_x\), \(R_y\), and \(R_z\). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with \(λ\) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately \(5\times10^{-4}\) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately \(10^{-4}\)). Both approaches reliably reconstruct computational basis states (between 83\% and 99\% success) and Bell states (between 61\% and 77\% success). However, scalability saturates for \(λ\) of approximately three to four and does not extend to ten-qubit targets even at \(λ=2\). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability.

</details>


### [263] [Capacity-constrained demand response in smart grids using deep reinforcement learning](https://arxiv.org/abs/2602.16525)
*Shafagh Abband Pashaki,Sepehr Maleki,Amir Badiee*

Main category: cs.LG

TL;DR: 本文提出了一种基于容量约束和经济激励的住宅智能电网需求响应方法，利用深度强化学习在满足电网容量限制的前提下，动态优化实时激励费率，有效降低峰值负荷并平滑总负荷曲线。


<details>
  <summary>Details</summary>
Motivation: 为维持电网容量限制、防止拥塞，并兼顾服务提供商与终端用户的经济利益，需设计一种能实时响应电价与负荷变化、同时考虑用户异质性偏好的需求响应机制。

Method: 采用分层架构：服务提供商根据批发电价和聚合住宅负荷调整每小时激励费率；建模用户异质偏好（通过家电级家庭能源管理系统及不满意成本）；使用深度强化学习在显式容量约束下学习最优实时激励策略。

Result: 基于三个真实家庭的用电与电价数据仿真表明，该方法可有效降低峰值需求，使峰均比相比无需求响应场景降低约22.82%。

Conclusion: 所提激励型需求响应框架在保障电网容量约束的同时，实现了供需双方共赢，并验证了深度强化学习在复杂、受限需求响应决策中的有效性。

Abstract: This paper presents a capacity-constrained incentive-based demand response approach for residential smart grids. It aims to maintain electricity grid capacity limits and prevent congestion by financially incentivising end users to reduce or shift their energy consumption. The proposed framework adopts a hierarchical architecture in which a service provider adjusts hourly incentive rates based on wholesale electricity prices and aggregated residential load. The financial interests of both the service provider and end users are explicitly considered. A deep reinforcement learning approach is employed to learn optimal real-time incentive rates under explicit capacity constraints. Heterogeneous user preferences are modelled through appliance-level home energy management systems and dissatisfaction costs. Using real-world residential electricity consumption and price data from three households, simulation results show that the proposed approach effectively reduces peak demand and smooths the aggregated load profile. This leads to an approximately 22.82% reduction in the peak-to-average ratio compared to the no-demand-response case.

</details>


### [264] [FEKAN: Feature-Enriched Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.16530)
*Sidharth S. Menon,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: 本文提出了一种新型Kolmogorov-Arnold网络变体FEKAN，通过特征增强提升计算效率与预测精度，同时不增加参数量，并在函数逼近、物理信息PDE求解及神经算子任务中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有KAN架构（如样条型、小波型、径向基型等）存在计算开销大、收敛慢的问题，限制了其可扩展性与实用性。

Method: 提出Feature-Enriched Kolmogorov-Arnold Networks（FEKAN），在保持KAN可解释性优势的同时，通过引入额外特征实现无参数增长的性能提升；并在多类基准任务（函数逼近、物理信息PDE、神经算子）上进行实验验证，辅以理论分析证明其更强的表示能力。

Result: FEKAN在所有测试任务中均展现出比SplineKAN、FastKAN、WavKAN等各类KAN变体更快的收敛速度和更高的逼近精度，并显著降低计算开销。

Conclusion: FEKAN是一种简单而高效的新架构，在不牺牲可解释性的前提下，有效解决了KAN的效率瓶颈，拓展了其在科学计算与深度学习中的实际应用潜力。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc., suffer from high computational cost and slow convergence, limiting scalability and practical applicability. Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a simple yet effective extension that preserves all the advantages of KAN while improving computational efficiency and predictive accuracy through feature enrichment, without increasing the number of trainable parameters. By incorporating these additional features, FEKAN accelerates convergence, increases representation capacity, and substantially mitigates the computational overhead characteristic of state-of-the-art KAN architectures. We investigate FEKAN across a comprehensive set of benchmarks, including function-approximation tasks, physics-informed formulations for diverse partial differential equations (PDEs), and neural operator settings that map between input and output function spaces. For function approximation, we systematically compare FEKAN against a broad family of KAN variants, FastKAN, WavKAN, ReLUKAN, HRKAN, ChebyshevKAN, RBFKAN, and the original SplineKAN. Across all tasks, FEKAN demonstrates substantially faster convergence and consistently higher approximation accuracy than the underlying baseline architectures. We also establish the theoretical foundations for FEKAN, showing its superior representation capacity compared to KAN, which contributes to improved accuracy and efficiency.

</details>


### [265] [Transfer Learning of Linear Regression with Multiple Pretrained Models: Benefiting from More Pretrained Models via Overparameterization Debiasing](https://arxiv.org/abs/2602.16531)
*Daniel Boharon,Yehuda Dar*

Main category: cs.LG

TL;DR: 本文研究了使用多个过参数化最小二乘预训练模型进行线性回归任务的迁移学习，提出了带距离惩罚的目标优化问题，并分析了测试误差；发现使用足够多的过参数化预训练模型有助于迁移学习，但存在过参数化偏差问题，为此提出了一种基于乘性校正因子的简单去偏方法。


<details>
  <summary>Details</summary>
Motivation: 探究在过参数化预训练模型下，如何有效利用多个预训练模型提升线性回归任务的迁移学习性能，并解决由此引入的过参数化偏差问题。

Method: 构建以目标数据集平方误差最小化为目标、同时惩罚与多个预训练模型距离的优化问题；理论推导测试误差表达式；识别过参数化偏差机制；提出基于乘性校正因子的去偏方法。

Result: 理论上阐明了使用足够多过参数化预训练模型对有益迁移学习的重要性；揭示了最小ℓ₂-范数解受限于训练样本张成子空间所导致的过参数化偏差；实证验证了所提去偏方法能有效缓解偏差并提升多模型迁移效果。

Conclusion: 多预训练模型迁移学习的效果依赖于模型数量与过参数化特性；过参数化偏差会制约性能，而简单的乘性校正可显著缓解该问题，从而更好利用多个预训练模型。

Abstract: We study transfer learning for a linear regression task using several least-squares pretrained models that can be overparameterized.
  We formulate the target learning task as optimization that minimizes squared errors on the target dataset with penalty on the distance of the learned model from the pretrained models. We analytically formulate the test error of the learned target model and provide the corresponding empirical evaluations.
  Our results elucidate when using more pretrained models can improve transfer learning. Specifically, if the pretrained models are overparameterized, using sufficiently many of them is important for beneficial transfer learning. However, the learning may be compromised by overparameterization bias of pretrained models, i.e., the minimum $\ell_2$-norm solution's restriction to a small subspace spanned by the training examples in the high-dimensional parameter space. We propose a simple debiasing via multiplicative correction factor that can reduce the overparameterization bias and leverage more pretrained models to learn a target predictor.

</details>


### [266] [Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning](https://arxiv.org/abs/2602.16543)
*Jialiang Fan,Shixiong Jiang,Mengyu Liu,Fanxin Kong*

Main category: cs.LG

TL;DR: 本文提出了一种面向安全强化学习（Safe RL）策略的黑盒对抗攻击框架，仅依赖专家示范和环境交互，无需访问被攻击策略的梯度或真实安全约束，即可有效揭示其脆弱性，并提供了理论可行性分析与扰动界。


<details>
  <summary>Details</summary>
Motivation: 现有Safe RL方法多假设环境良性，难以应对现实中的对抗扰动；且主流梯度攻击需访问策略内部梯度，不具实际可操作性。

Method: 基于专家示范和黑盒环境交互，联合学习约束模型与代理策略（surrogate policy），从而在无受害者策略梯度和真实安全约束条件下，实现基于梯度的对抗扰动优化。

Result: 在多个Safe RL基准上验证了该攻击框架的有效性，即使在特权访问受限的情况下仍能成功实施攻击。

Conclusion: 所提黑盒攻击框架能有效暴露Safe RL策略的安全隐患，理论分析支持其可行性与扰动可控性，为评估和提升Safe RL鲁棒性提供了新工具。

Abstract: Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.

</details>


### [267] [RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion](https://arxiv.org/abs/2602.16548)
*Tianmeng Hu,Yongzheng Cui,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: 本文提出了RIDER框架，利用强化学习直接优化RNA三维结构相似性，通过图神经网络生成扩散模型和基于3D自一致性度量的奖励函数，显著提升了结构相似性并生成与天然序列不同的新设计。


<details>
  <summary>Details</summary>
Motivation: 现有RNA逆向设计方法多依赖于天然序列恢复率作为评估指标，但该指标不能准确反映三维结构保真度，因为不同序列可能折叠成相似结构。

Method: 提出RIDER框架：1）构建并预训练以目标3D结构为条件的GNN生成扩散模型；2）采用改进的策略梯度算法，结合四个基于3D自一致性度量的任务特定奖励函数进行微调。

Result: 在原生序列恢复率上比SOTA方法提升9%；在所有3D结构相似性指标上提升超100%；生成的设计与天然序列明显不同。

Conclusion: RIDER通过直接优化三维结构相似性，克服了传统基于序列恢复评估的局限性，为功能性RNA设计提供了更可靠、更有效的逆向设计方法。

Abstract: The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.

</details>


### [268] [Illustration of Barren Plateaus in Quantum Computing](https://arxiv.org/abs/2602.16558)
*Gerhard Stenzel,Tobias Rohe,Michael Kölle,Leo Sünkel,Jonas Stein,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 本文研究了变分量子电路（VQCs）中参数共享对优化景观的影响，发现其虽减少参数量并提升全局最优解质量，却引入‘欺骗性梯度’，误导优化器；实验表明参数共享越多，梯度越强、欺骗性越高，导致Adam/SGD等经典优化器性能下降；作者提出欺骗性检测算法与量化评估框架，揭示参数共享在提升表达能力的同时显著增加优化难度。


<details>
  <summary>Details</summary>
Motivation: 参数共享在VQCs中被广泛用于缓解‘贫瘠高原’问题并降低参数维度，但其对优化景观的深层影响（如梯度误导性）尚未被系统研究。

Method: 通过系统性实验分析不同参数共享程度下的优化景观特性，提出梯度欺骗性检测算法，并构建量化框架评估量子电路优化难度。

Result: 参数共享程度越高，梯度幅值越大、欺骗性比率越高；经典梯度优化器（Adam、SGD）收敛性能随共享程度增加而显著退化，且对超参数敏感；参数共享可大幅提升电路表达能力，但以优化景观欺骗性剧增为代价。

Conclusion: 参数共享虽有益于表达能力和参数效率，却与经典梯度优化策略存在根本性不匹配；量子电路设计需兼顾参数共享与优化可行性，未来需发展适配欺骗性景观的新型优化方法。

Abstract: Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.

</details>


### [269] [A Scalable Approach to Solving Simulation-Based Network Security Games](https://arxiv.org/abs/2602.16564)
*Michael Lanier,Yevgeniy Vorobeychik*

Main category: cs.LG

TL;DR: MetaDOAR是一种轻量级元控制器，通过引入学习型分区感知过滤层和Q值缓存，增强Double Oracle/PSRO范式，以实现大规模网络环境中可扩展的多智能体强化学习。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在超大规模网络环境下因计算与内存开销过大而导致的可扩展性瓶颈问题，提升多智能体强化学习在真实网络决策任务中的实用性。

Method: 提出MetaDOAR框架：1）基于节点结构嵌入的紧凑状态投影；2）top-k设备分区选择机制；3）聚焦式束搜索与批评者（critic）协同；4）量化状态投影+局部动作标识的LRU缓存及保守k-hop缓存失效策略。

Result: 在大型网络拓扑上，MetaDOAR相比SOTA基线获得更高玩家收益，且内存占用与训练时间无显著增长。

Conclusion: MetaDOAR为大规模网络化决策问题提供了兼具效率、理论支撑与实用性的分层策略学习路径。

Abstract: We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.

</details>


### [270] [Steering diffusion models with quadratic rewards: a fine-grained analysis](https://arxiv.org/abs/2602.16570)
*Ankur Moitra,Andrej Risteski,Dhruv Rohatgi*

Main category: cs.LG

TL;DR: 本文研究了在预训练扩散模型上进行奖励倾斜采样的计算可行性问题，针对二次奖励函数进行了细粒度分析，提出了适用于低秩正定二次倾斜的高效算法，并证明了负定二次倾斜即使在一维情况下也是计算不可行的。


<details>
  <summary>Details</summary>
Motivation: 现有推理时算法多为启发式方法，存在多种失败模式，且对其何时能被高效改进缺乏理解。

Method: 本文采用细粒度计算复杂性分析，并引入Hubbard-Stratonovich变换作为新工具，结合线性奖励倾斜的可解性结果，构建适用于低秩正定二次奖励倾斜的高效采样算法。

Result: 证明线性奖励倾斜总可高效采样；提出低秩正定二次倾斜的高效采样算法；证明负定二次倾斜（即使秩为1）是计算不可行的。

Conclusion: 奖励倾斜采样的可行性高度依赖于奖励函数的结构（如符号与秩），不能一概而论；本文为推理时算法的理论基础提供了重要进展。

Abstract: Inference-time algorithms are an emerging paradigm in which pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of when these heuristics can be efficiently improved.
  In this paper, we consider the task of sampling from a reward-tilted diffusion model -- that is, sampling from $p^{\star}(x) \propto p(x) \exp(r(x))$ -- given a reward function $r$ and pre-trained diffusion oracle for $p$. We provide a fine-grained analysis of the computational tractability of this task for quadratic rewards $r(x) = x^\top A x + b^\top x$. We show that linear-reward tilts are always efficiently sampleable -- a simple result that seems to have gone unnoticed in the literature. We use this as a building block, along with a conceptually new ingredient -- the Hubbard-Stratonovich transform -- to provide an efficient algorithm for sampling from low-rank positive-definite quadratic tilts, i.e. $r(x) = x^\top A x$ where $A$ is positive-definite and of rank $O(1)$. For negative-definite tilts, i.e. $r(x) = - x^\top A x$ where $A$ is positive-definite, we prove that the problem is intractable even if $A$ is of rank 1 (albeit with exponentially-large entries).

</details>


### [271] [MoDE-Boost: Boosting Shared Mobility Demand with Edge-Ready Prediction Models](https://arxiv.org/abs/2602.16573)
*Antonios Tziorvas,George S. Theodoropoulos,Yannis Theodoridis*

Main category: cs.LG

TL;DR: 本文提出两种梯度提升模型（分类与回归）用于城市微出行需求预测，融合时空与上下文特征，在5分钟至1小时多时间尺度上实现高精度预测，并基于五个大都市的共享电单车/滑板车真实数据验证其优于现有方法及生成式AI模型。


<details>
  <summary>Details</summary>
Motivation: 城市需求预测对智能交通系统中的路径优化、调度和拥堵管理至关重要；现有方法难以充分捕捉现代城市微出行的复杂时空动态。

Method: 提出两种梯度提升模型变体（分类与回归），融合时间特征（如时段、周期性）与上下文特征（如天气、事件、POI等），支持多时间尺度（5分钟至1小时）的需求预测。

Result: 在五个大都市的e-scooter和e-bike真实数据集上，该方法性能优于当前SOTA方法及一个生成式AI模型，显著提升了短时至中时需求预测精度。

Conclusion: 所提方法为城市微出行管理提供了新视角，有助于应对快速城市化挑战，推动可持续、高效、宜居的城市发展。

Abstract: Urban demand forecasting plays a critical role in optimizing routing, dispatching, and congestion management within Intelligent Transportation Systems. By leveraging data fusion and analytics techniques, traffic demand forecasting serves as a key intermediate measure for identifying emerging spatial and temporal demand patterns. In this paper, we tackle this challenge by proposing two gradient boosting model variations, one for classiffication and one for regression, both capable of generating demand forecasts at various temporal horizons, from 5 minutes up to one hour. Our overall approach effectively integrates temporal and contextual features, enabling accurate predictions that are essential for improving the efficiency of shared (micro-) mobility services. To evaluate its effectiveness, we utilize open shared mobility data derived from e-scooter and e-bike networks in five metropolitan areas. These real-world datasets allow us to compare our approach with state-of-the-art methods as well as a Generative AI-based model, demonstrating its effectiveness in capturing the complexities of modern urban mobility. Ultimately, our methodology offers novel insights on urban micro-mobility management, helping to tackle the challenges arising from rapid urbanization and thus, contributing to more sustainable, efficient, and livable cities.

</details>


### [272] [AIFL: A Global Daily Streamflow Forecasting Model Using Deterministic LSTM Pre-trained on ERA5-Land and Fine-tuned on IFS](https://arxiv.org/abs/2602.16579)
*Maria Luisa Taccari,Kenza Tazi,Oisín M. Morrison,Andreas Grafberger,Juan Colonese,Corentin Carton de Wiart,Christel Prudhomme,Cinzia Mazzetti,Matthew Chantry,Florian Pappenberger*

Main category: cs.LG

TL;DR: 本文提出了AIFL，一种基于LSTM的全球日尺度确定性径流预报模型，通过两阶段训练（先在ERA5-Land再在IFS数据上微调）缓解再分析到业务预报的域偏移问题，在CARAVAN数据集上训练并验证，展现出优异的预报技能和极端事件检测能力。


<details>
  <summary>Details</summary>
Motivation: 数据驱动模型在从历史再分析数据转向实际业务预报时存在性能下降问题，亟需提升全球径流预报的可靠性以支持防洪和水资源管理。

Method: 提出AIFL模型：基于LSTM的确定性全球日尺度径流预报模型；采用两阶段训练策略——先在1980–2019年ERA5-Land再分析数据上预训练，再在2016–2019年IFS业务预报数据上微调，以适配数值天气预报的误差结构与偏差；训练数据来自CARAVAN数据集的18,588个流域。

Result: 在2021–2024年独立时间测试集上，中位修正KGE'达0.66、中位NSE达0.53；在极端事件检测方面表现优异；性能媲美当前最先进全球系统，且强迫数据流程透明可复现。

Conclusion: AIFL是首个在CARAVAN生态内端到端训练的全球水文AI模型，为全球水文学界提供了简洁、可靠、可业务化部署的基准模型。

Abstract: Reliable global streamflow forecasting is essential for flood preparedness and water resource management, yet data-driven models often suffer from a performance gap when transitioning from historical reanalysis to operational forecast products. This paper introduces AIFL (Artificial Intelligence for Floods), a deterministic LSTM-based model designed for global daily streamflow forecasting. Trained on 18,588 basins curated from the CARAVAN dataset, AIFL utilises a novel two-stage training strategy to bridge the reanalysis-to-forecast domain shift. The model is first pre-trained on 40 years of ERA5-Land reanalysis (1980-2019) to capture robust hydrological processes, then fine-tuned on operational Integrated Forecasting System (IFS) control forecasts (2016-2019) to adapt to the specific error structures and biases of operational numerical weather prediction. To our knowledge, this is the first global model trained end-to-end within the CARAVAN ecosystem. On an independent temporal test set (2021-2024), AIFL achieves high predictive skill with a median modified Kling-Gupta Efficiency (KGE') of 0.66 and a median Nash-Sutcliffe Efficiency (NSE) of 0.53. Benchmarking results show that AIFL is highly competitive with current state-of-the-art global systems, achieving comparable accuracy while maintaining a transparent and reproducible forcing pipeline. The model demonstrates exceptional reliability in extreme-event detection, providing a streamlined and operationally robust baseline for the global hydrological community.

</details>


### [273] [Sequential Membership Inference Attacks](https://arxiv.org/abs/2602.16596)
*Thomas Michel,Debabrota Basu,Emilie Kaufmann*

Main category: cs.LG

TL;DR: 本文提出了一种利用模型更新序列的最优成员推断（MI）攻击方法SeMI*，显著提升了隐私审计的紧致性。


<details>
  <summary>Details</summary>
Motivation: 现有成员推断攻击多针对静态模型，缺乏对动态更新模型的严谨分析；而现代AI模型频繁更新，需利用其动态特性提升MI攻击能力与隐私评估精度。

Method: 提出基于模型更新序列的最优MI攻击SeMI*，理论推导其在有限样本下的最优检测能力，并支持带/不带差分隐私的场景；进一步结合插入时机与‘金丝雀’样本优化隐私审计。

Result: SeMI*避免了仅用最终模型导致的MI信号稀释问题；理论结果涵盖已有渐近分析；实验表明其在多种数据分布和DP-SGD训练/微调模型上均优于基线方法。

Conclusion: 利用模型更新序列可构建更强大的MI攻击与更紧致的隐私审计框架，SeMI*为动态模型隐私分析提供了理论基础与实用工具。

Abstract: Modern AI models are not static. They go through multiple updates in their lifecycles. Thus, exploiting the model dynamics to create stronger Membership Inference (MI) attacks and tighter privacy audits are timely questions. Though the literature empirically shows that using a sequence of model updates can increase the power of MI attacks, rigorous analysis of the `optimal' MI attacks is limited to static models with infinite samples. Hence, we develop an `optimal' MI attack, SeMI*, that uses the sequence of model updates to identify the presence of a target inserted at a certain update step. For the empirical mean computation, we derive the optimal power of SeMI*, while accessing a finite number of samples with or without privacy. Our results retrieve the existing asymptotic analysis. We observe that having access to the model sequence avoids the dilution of MI signals unlike the existing attacks on the final model, where the MI signal vanishes as training data accumulates. Furthermore, an adversary can use SeMI* to tune both the insertion time and the canary to yield tighter privacy audits. Finally, we conduct experiments across data distributions and models trained or fine-tuned with DP-SGD demonstrating that practical variants of SeMI* lead to tighter privacy audits than the baselines.

</details>


### [274] [Predicting The Cop Number Using Machine Learning](https://arxiv.org/abs/2602.16600)
*Meagan Mann,Christian Muise,Erin Meger*

Main category: cs.LG

TL;DR: 本文探讨了使用经典机器学习方法和图神经网络预测图的警察数（cop number）的可行性，发现树模型和图神经网络均能高精度预测，且关键特征与理论结果一致。


<details>
  <summary>Details</summary>
Motivation: 准确确定图的警察数在计算上非常困难，现有精确算法仅适用于小规模图；本文旨在探索机器学习方法能否基于图的结构特性高效、可扩展地预测警察数。

Method: 采用经典机器学习（尤其是树模型）和图神经网络（GNN）对图的结构特征进行建模与预测，并结合可解释性分析识别关键影响特征。

Result: 树模型在类别不平衡下仍保持高预测精度；GNN无需显式特征工程即达相近性能；最具预测力的特征包括节点连通性、聚类系数、团结构及宽度参数。

Conclusion: 机器学习方法可作为传统警察数算法的有效补充，在计算不可行时提供可扩展的近似预测。

Abstract: Cops and Robbers is a pursuit evasion game played on a graph, first introduced independently by Quilliot \cite{quilliot1978jeux} and Nowakowski and Winkler \cite{NOWAKOWSKI1983235} over four decades ago. A main interest in recent the literature is identifying the cop number of graph families. The cop number of a graph, $c(G)$, is defined as the minimum number of cops required to guarantee capture of the robber. Determining the cop number is computationally difficult and exact algorithms for this are typically restricted to small graph families. This paper investigates whether classical machine learning methods and graph neural networks can accurately predict a graph's cop number from its structural properties and identify which properties most strongly influence this prediction. Of the classical machine learning models, tree-based models achieve high accuracy in prediction despite class imbalance, whereas graph neural networks achieve comparable results without explicit feature engineering. The interpretability analysis shows that the most predictive features are related to node connectivity, clustering, clique structure, and width parameters, which aligns with known theoretical results. Our findings suggest that machine learning approaches can be used in complement with existing cop number algorithms by offering scalable approximations where computation is infeasible.

</details>


### [275] [A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models](https://arxiv.org/abs/2602.16626)
*SungJun Cho,Chetan Gohil,Rukuang Huang,Oiwi Parker Jones,Mark W. Woolrich*

Main category: cs.LG

TL;DR: 本文系统评估了用于脑磁图（MEG）数据的样本级分词策略对大型神经影像模型性能的影响，发现可学习与不可学习分词器在信号重建和建模性能上表现相近，表明简单固定分词策略已足够有效。


<details>
  <summary>Details</summary>
Motivation: 大型神经影像基础模型需将连续神经时间序列离散化（即分词），但不同分词策略的影响尚不清楚。

Method: 系统比较可学习（基于自编码器的新方法）与不可学习的样本级分词器，在信号重建保真度及后续建模性能（如token预测、生成数据生物学合理性、被试特异性保留、下游任务性能）上的表现；实验基于三个公开MEG数据集。

Result: 两类分词器均实现高重建精度，在多数评估指标上性能相当。

Conclusion: 简单固定的样本级分词策略足以支撑神经基础模型开发，无需复杂可学习分词器。

Abstract: Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.

</details>


### [276] [Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes](https://arxiv.org/abs/2602.16629)
*Ethan Blaser,Jiuqi Wang,Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文证明了在不使用局部时钟学习率的情况下，on-policy和off-policy的n步微分TD算法几乎必然收敛，加强了微分TD的理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有微分TD算法的收敛性保证依赖于与状态访问次数绑定的局部时钟学习率，而实践中并不使用该设定，且难以推广到非表格设置。

Method: 通过理论分析，证明了使用标准衰减学习率的on-policy n步微分TD算法的几乎必然收敛性，并推导出off-policy n步微分TD收敛的三个充分条件。

Result: 确立了无需局部时钟的on-policy和off-policy n步微分TD算法的几乎必然收敛性，使理论分析更贴近实际应用。

Conclusion: 本文消除了微分TD算法收敛性分析中对局部时钟学习率的依赖，提升了其在更广泛场景（如函数逼近）中的适用性和理论严谨性。

Abstract: The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.

</details>


### [277] [Optimizer choice matters for the emergence of Neural Collapse](https://arxiv.org/abs/2602.16642)
*Jim Zhao,Tin Sum Cheng,Wojciech Masarczyk,Aurelien Lucchi*

Main category: cs.LG

TL;DR: 本文挑战了神经坍缩（NC）在所有优化器中普遍存在的假设，提出优化器的选择对NC的出现起关键作用，并引入新指标NC0来理论分析NC，证明自适应优化器（如AdamW）中的解耦权重衰减会阻碍NC的出现，同时揭示动量对NC的加速效应。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽略优化器在神经坍缩（NC）中的作用，假设NC具有优化器无关性；本文旨在揭示优化器（尤其是权重衰减方式与动量）对NC涌现的关键影响。

Method: 提出新型诊断指标NC0（其收敛至零是NC发生的必要条件），并从理论上分析SGD、SignGD（耦合/解耦权重衰减）的NC0动力学差异；同时通过3900次大规模实验验证理论发现。

Result: 证明：1）AdamW类解耦权重衰减会阻止NC出现；2）SGD与SignGD在不同权重衰减设定下NC0演化行为迥异；3）动量能加速NC（不仅加速训练损失收敛）；实验全面验证上述结论。

Conclusion: NC并非优化器无关现象，其涌现高度依赖优化器类型及权重衰减耦合方式；本文首次为NC的优化器依赖性提供理论解释，并强调权重衰减耦合是塑造优化器隐式偏置的关键因素。

Abstract: Neural Collapse (NC) refers to the emergence of highly symmetric geometric structures in the representations of deep neural networks during the terminal phase of training. Despite its prevalence, the theoretical understanding of NC remains limited. Existing analyses largely ignore the role of the optimizer, thereby suggesting that NC is universal across optimization methods. In this work, we challenge this assumption and demonstrate that the choice of optimizer plays a critical role in the emergence of NC. The phenomenon is typically quantified through NC metrics, which, however, are difficult to track and analyze theoretically. To overcome this limitation, we introduce a novel diagnostic metric, NC0, whose convergence to zero is a necessary condition for NC. Using NC0, we provide theoretical evidence that NC cannot emerge under decoupled weight decay in adaptive optimizers, as implemented in AdamW. Concretely, we prove that SGD, SignGD with coupled weight decay (a special case of Adam), and SignGD with decoupled weight decay (a special case of AdamW) exhibit qualitatively different NC0 dynamics. Also, we show the accelerating effect of momentum on NC (beyond convergence of train loss) when trained with SGD, being the first result concerning momentum in the context of NC. Finally, we conduct extensive empirical experiments consisting of 3,900 training runs across various datasets, architectures, optimizers, and hyperparameters, confirming our theoretical results. This work provides the first theoretical explanation for optimizer-dependent emergence of NC and highlights the overlooked role of weight-decay coupling in shaping the implicit biases of optimizers.

</details>


### [278] [Factorization Machine with Quadratic-Optimization Annealing for RNA Inverse Folding and Evaluation of Binary-Integer Encoding and Nucleotide Assignment](https://arxiv.org/abs/2602.16643)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 本文提出了一种基于因子分解机与二次优化退火（FMQA）的RNA逆折叠新方法，并系统分析了核苷酸到整数映射及二进制编码方式对优化性能的影响，发现domain-wall编码结合G/C置于边界整数时能提升结构热稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有RNA逆折叠方法常需大量序列评估，实验成本高；而FMQA虽具高效性，但其性能受核苷酸编码方式影响尚不明确，亟需系统研究。

Method: 构建FMQA框架求解RNA逆折叠问题，将核苷酸映射为整数并采用四种二进制编码（one-hot、binary、unary、domain-wall），穷举24种核苷酸→整数(0–3)分配方案进行对比评估。

Result: domain-wall和one-hot编码在归一化系综缺陷值上优于binary和unary；domain-wall编码中边界整数（0/3）对应核苷酸出现频率更高；将G/C分配至边界可增强茎区G/C富集，获得比one-hot更稳定的二级结构。

Conclusion: 编码方式与核苷酸分配显著影响FMQA求解质量；domain-wall编码配合G/C置于边界整数是更优策略，为RNA设计提供了新见解与实用工具。

Abstract: The RNA inverse folding problem aims to identify nucleotide sequences that preferentially adopt a given target secondary structure. While various heuristic and machine learning-based approaches have been proposed, many require a large number of sequence evaluations, which limits their applicability when experimental validation is costly. We propose a method to solve the problem using a factorization machine with quadratic-optimization annealing (FMQA). FMQA is a discrete black-box optimization method reported to obtain high-quality solutions with a limited number of evaluations. Applying FMQA to the problem requires converting nucleotides into binary variables. However, the influence of integer-to-nucleotide assignments and binary-integer encoding on the performance of FMQA has not been thoroughly investigated, even though such choices determine the structure of the surrogate model and the search landscape, and thus can directly affect solution quality. Therefore, this study aims both to establish a novel FMQA framework for RNA inverse folding and to analyze the effects of these assignments and encoding methods. We evaluated all 24 possible assignments of the four nucleotides to the ordered integers (0-3), in combination with four binary-integer encoding methods. Our results demonstrated that one-hot and domain-wall encodings outperform binary and unary encodings in terms of the normalized ensemble defect value. In domain-wall encoding, nucleotides assigned to the boundary integers (0 and 3) appeared with higher frequency. In the RNA inverse folding problem, assigning guanine and cytosine to these boundary integers promoted their enrichment in stem regions, which led to more thermodynamically stable secondary structures than those obtained with one-hot encoding.

</details>


### [279] [Retrieval-Augmented Foundation Models for Matched Molecular Pair Transformations to Recapitulate Medicinal Chemistry Intuition](https://arxiv.org/abs/2602.16684)
*Bo Pan,Peter Zhiping Zhang,Hao-Wei Pang,Alex Zhu,Xiang Yu,Liying Zhang,Liang Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种基于匹配分子对变换（MMPT）的可变长变量到变量的类药分子生成方法，结合提示机制与检索增强（MMPT-RAG），提升了生成多样性、新颖性与可控性。


<details>
  <summary>Details</summary>
Motivation: 现有ML方法在类药分子模拟中难以兼顾编辑可控性与泛化能力：全分子模型缺乏局部编辑可解释性，而小规模MMP模型泛化能力弱。

Method: 提出变量到变量（variable-to-variable）生成范式；构建大规模MMPT训练数据集；设计面向MMP模式的提示机制；引入MMPT-RAG框架，融合外部参考类似物进行检索增强生成。

Result: 在通用化学数据库和专利数据集上验证，该方法显著提升生成分子的多样性、新颖性与用户可控性，并在实际药物发现场景中成功复现真实类药结构。

Conclusion: 该工作为基于MMP的可控类药分子设计提供了可扩展的基础模型框架，兼具理论合理性与实践适用性。

Abstract: Matched molecular pairs (MMPs) capture the local chemical edits that medicinal chemists routinely use to design analogs, but existing ML approaches either operate at the whole-molecule level with limited edit controllability or learn MMP-style edits from restricted settings and small models. We propose a variable-to-variable formulation of analog generation and train a foundation model on large-scale MMP transformations (MMPTs) to generate diverse variables conditioned on an input variable. To enable practical control, we develop prompting mechanisms that let the users specify preferred transformation patterns during generation. We further introduce MMPT-RAG, a retrieval-augmented framework that uses external reference analogs as contextual guidance to steer generation and generalize from project-specific series. Experiments on general chemical corpora and patent-specific datasets demonstrate improved diversity, novelty, and controllability, and show that our method recovers realistic analog structures in practical discovery scenarios.

</details>


### [280] [Protecting the Undeleted in Machine Unlearning](https://arxiv.org/abs/2602.16697)
*Aloni Cohen,Refael Kohen,Kobbi Nissim,Uri Stemmer*

Main category: cs.LG

TL;DR: 本文揭示了机器遗忘中‘完美重训练’方法带来的隐私风险，提出了一种针对未删除数据的新型安全定义，以防止因其他数据点删除而导致的信息泄露，并证明该定义支持多种基础功能。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法追求‘完美重训练’，但本文指出这会危及未删除数据的隐私，需建立更合理、实用的安全定义。

Method: 提出一种新的安全定义，聚焦于保护未删除数据免受删除操作引发的信息泄露；并通过重构攻击分析和对现有定义的系统性评估来论证其必要性与可行性。

Result: 发现多数现有机器遗忘定义要么易受重构攻击，要么过于严格；新定义能兼顾安全性与实用性，支持公告板、求和、统计学习等基本功能。

Conclusion: ‘完美重训练’并非合适的机器遗忘安全目标；应采用以保护未删除数据为核心的新安全范式。

Abstract: Machine unlearning aims to remove specific data points from a trained model, often striving to emulate "perfect retraining", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $ω(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.

</details>


### [281] [Causality is Key for Interpretability Claims to Generalise](https://arxiv.org/abs/2602.16698)
*Shruti Joshi,Aaron Mueller,David Klindt,Wieland Brendel,Patrik Reizinger,Dhanya Sridhar*

Main category: cs.LG

TL;DR: 本文探讨了大语言模型（LLM）可解释性研究中的因果推断问题，指出当前研究常陷入非泛化结论与证据不足的因果断言；作者借助Pearl因果层次理论，区分观察、干预与反事实三类推理能力，并引入因果表征学习（CRL）框架，明确从模型激活中可恢复的变量及其前提假设，最终提出一个诊断性框架，以匹配方法、评估与主张，提升可解释性研究的严谨性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性研究存在两大问题：结论缺乏泛化性，以及因果解释超出实证支持；亟需一个基于因果推断原则的理论框架来规范主张与证据之间的匹配关系。

Method: 基于Pearl因果层次理论，系统区分观察（associations）、干预（interventions，如ablation、activation patching）与反事实（counterfactuals）三类推理；结合因果表征学习（CRL），形式化定义从模型激活中可识别的高阶结构及其所需数据/假设；据此构建诊断性实践框架。

Result: 明确了不同可解释性方法所能支撑的因果主张层级；指出反事实主张在无受控监督时基本不可验证；CRL为变量可恢复性提供了理论条件；提出的诊断框架有助于研究者选择与主张强度相匹配的方法与评估方式。

Conclusion: 将因果推断（尤其是因果层次与CRL）系统引入LLM可解释性研究，能提升其科学严谨性、可复现性与泛化能力；未来工作应聚焦于设计满足CRL假设的实验范式与监督信号，以支撑更强因果主张。

Abstract: Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies what an interpretability study can justify. Observations establish associations between model behaviour and internal components. Interventions (e.g., ablations or activation patching) support claims how these edits affect a behavioural metric (\eg, average change in token probabilities) over a set of prompts. However, counterfactual claims -- i.e., asking what the model output would have been for the same prompt under an unobserved intervention -- remain largely unverifiable without controlled supervision. We show how causal representation learning (CRL) operationalises this hierarchy, specifying which variables are recoverable from activations and under what assumptions. Together, these motivate a diagnostic framework that helps practitioners select methods and evaluations matching claims to evidence such that findings generalise.

</details>


### [282] [Knowledge-Embedded Latent Projection for Robust Representation Learning](https://arxiv.org/abs/2602.16709)
*Weijing Tang,Ming Yuan,Zongqi Xia,Tianxi Cai*

Main category: cs.LG

TL;DR: 本文提出了一种知识嵌入的潜在投影模型，利用外部语义嵌入（如临床概念预训练嵌入）来正则化高维稀疏数据（如电子健康记录）的低维表示学习，通过核主成分分析与投影梯度下降实现高效估计，并提供了统计误差界和局部收敛性保证。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录等应用场景中，数据矩阵高度不平衡（样本少、特征极多），传统潜在空间模型估计困难；而外部临床语义嵌入日益丰富，可作为先验知识提升表示学习效果。

Method: 将列嵌入建模为语义嵌入的再生核希尔伯特空间（RKHS）中的光滑函数；采用两步法：先用核PCA进行语义引导的子空间构造，再进行可扩展的投影梯度下降优化。

Result: 理论方面给出了估计误差界，刻画了统计误差与核投影引入的近似误差之间的权衡，并证明了非凸优化过程的局部收敛性；实验方面在模拟数据和真实EHR数据上验证了方法有效性。

Conclusion: 融合外部语义知识可显著提升不平衡高维离散数据的潜在空间建模性能，所提方法兼具理论保证与计算可行性。

Abstract: Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.

</details>
